<html>
<head>
<title>Data Science Modeling: How to Use Linear Regression with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学建模:如何在Python中使用线性回归</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/data-science-modeling-how-to-use-linear-regression-with-python-fdf6ca5481be?source=collection_archive---------1-----------------------#2019-05-24">https://betterprogramming.pub/data-science-modeling-how-to-use-linear-regression-with-python-fdf6ca5481be?source=collection_archive---------1-----------------------#2019-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="10f2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">看看R、均方误差等等</h2></div><p id="6dda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">布莱恩·亨利奎兹、克里斯·卡扎基斯和迪安·索伯莱特</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/65a6a5c6867eab85fd133f95ca179333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cE0yk1_a6-ROhY8XZktigw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae lv" href="https://unsplash.com/photos/pypeCEaJeZY?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">活动发起人</a>在<a class="ae lv" href="https://unsplash.com/search/photos/data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="1b8c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">简介和目标</strong></h1><p id="3d21" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">线性回归是数据科学中广泛使用的技术，因为实现和解释线性回归模型相对简单。</p><p id="3907" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本教程将使用Python遍历80种谷物数据集的简单和多元线性回归模型，并将讨论一些相关的回归指标，但我们并不假设之前有使用Python进行线性回归的经验。80种谷物的数据集可以在<a class="ae lv" href="https://www.kaggle.com/crawford/80-cereals" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="32f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是一些<strong class="kk iu">目标</strong>:</p><ul class=""><li id="4709" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">理解R的含义和局限性</li><li id="b0c9" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">了解线性回归的评估指标以及何时使用它们</li><li id="5e7a" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">使用80种谷物数据集实现简单的多元线性回归模型</li></ul><h1 id="c7d6" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">探索数据</h1><p id="28f1" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">下载数据集后，导入必要的Python包和谷物数据集本身:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nj"><img src="../Images/a9a1b3ba31b01d3e843df0f972c80392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fGlaaptqfNmqcIND"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">来自麦片的输出. head()</p></figure><p id="7ce1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里我们看到每一行是一个品牌的谷物，每一列是一个营养(蛋白质，脂肪等。)或谷物的识别特征(制造商、类型)。注意<strong class="kk iu">等级</strong>是响应或因变量。</p><p id="3391" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们创建了数据集每个特征之间相关性的pairs图，并从这个可视化中选择了三个预测变量:<strong class="kk iu">卡路里</strong>、<strong class="kk iu">纤维</strong>和<strong class="kk iu">糖</strong>。显示每个相关性的图太大了，不能在这里分享，但是我们可以用一个更小的pairs图来仔细观察，它只包括我们的预测变量。使用<code class="fe nk nl nm nn b">seaborn.pairplot</code>，我们可以看到三个带有拟合最小二乘法直线的散点图:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi no"><img src="../Images/0157e5e1b747041f75f4feed223a42df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kNDozkoPRFGHjair"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">每个预测变量与响应变量的成对图</p></figure><p id="bb11" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们对数据更加熟悉了，我们可以开始建立我们的线性回归模型。</p><blockquote class="np nq nr"><p id="b256" class="ki kj le kk b kl km ju kn ko kp jx kq ns ks kt ku nt kw kx ky nu la lb lc ld im bi translated">注:为了便于传达概念，我们不使用数据的测试/训练分割来计算R和调整的R值。但请认识到，使用随机选择的观测值的测试/训练分裂被认为是最佳实践，这就是我们在本教程快结束时呈现我们的误差和AIC/BIC的方式。</p></blockquote></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="3604" class="lw lx it bd ly lz oc mb mc md od mf mg jz oe ka mi kc of kd mk kf og kg mm mn bi translated">线性回归模型</h1><p id="6fd7" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">我们想讨论R及其对线性回归模型的意义。但是要准确理解R是什么，首先我们需要理解什么是线性模型。让我们来看一个散点图，比较一份麦片中的<strong class="kk iu">卡路里</strong>和它的<strong class="kk iu">等级</strong>:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/f4e5741acc01766d153f34833e919037.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*Mj9EbUmyqoOd6EH2JF3OTw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><strong class="bd oi">评分</strong>和<strong class="bd oi">卡路里</strong>的散点图</p></figure><p id="d46e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以清楚地看到，含有更多热量的谷类食品通常受到较差的评价。如果我们假设这两个变量之间存在某种关系，那么我们可以构建一个模型，根据卡路里的数量来预测一种谷物的等级。</p><p id="1527" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了验证这种关系实际上是线性的，我们可以在图上画出模型的残差并寻找模式。残差中的清晰模式可能表明另一个模型，如二次模型或对数模型，可能更好地描述这两个变量之间的关系。让我们检查残差:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/9390374f8422f01edb5b97135cc73ca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*eOBw37AJD4qL0noPkZHuxA.png"/></div></figure><p id="52f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">残差中没有明确的模式，因此没有证据表明存在更好的拟合非线性方程。</p><p id="2586" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于线性回归，我们会对公式感兴趣:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/14b9889759d143f5d819b36e126b2446.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*deah85Dzd9htUazH7rBxkw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><strong class="bd oi"> x </strong>是响应变量<strong class="bd oi"> y </strong>的预测变量</p></figure><p id="2cad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要制作模型，我们可以使用scipy<strong class="kk iu">linregresse</strong>方法。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="ab2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到以下输出:</p><ul class=""><li id="bfc8" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">linregression result</strong>(<strong class="kk iu">斜率</strong>=<em class="le">-0.49701318979564285</em>，<strong class="kk iu">截距</strong>=<em class="le">95.78802384439143</em>，<strong class="kk iu">右值</strong>=<em class="le">-0.6893760311652586</em>，.</li></ul><p id="691b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一项是<strong class="kk iu"> b_1 </strong>，第二项是<strong class="kk iu"> b_0 </strong>，第三项是<strong class="kk iu"> R </strong>值，也称<strong class="kk iu">相关系数</strong>。R值的范围从1到-1，衡量解释变量和响应变量之间的关系强度。卡路里相对于等级的R值为<em class="le"> -.689 </em>，这表明这两个变量之间存在很强的负相关关系。R值离0越远，模型预测值就越好。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="529d" class="lw lx it bd ly lz oc mb mc md od mf mg jz oe ka mi kc of kd mk kf og kg mm mn bi translated">稀有</h1><p id="02b1" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">通过平方R，我们得到决定系数，R，R是一个值，它表示y变量的变化中有多少百分比可以用x变量的变化来解释。高R值表示模型更强。让我们看看数据集中的一些R值:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="b97e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们打印以下内容:</p><ul class=""><li id="6e09" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">带杯预测器的模型R</strong>:<em class="le">0.0412740112014871</em></li><li id="29f7" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">带卡路里预测值的模型R</strong>:<em class="le">0.472393123451636</em></li></ul><p id="1a87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些R值向我们表明<strong class="kk iu">卡路里<em class="le"> </em> </strong>比<strong class="kk iu">杯<em class="le"> </em> </strong>更能预测<strong class="kk iu">等级</strong>。</p><p id="c202" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简单的线性回归是有用的，但是，我们经常想看看如何用几个变量来预测一个变量。让我们从谷物中取出一片，加上所有感兴趣的变量，得到一个2D预测值阵列。<strong class="kk iu">卡路里</strong>、<strong class="kk iu">纤维</strong>和<strong class="kk iu">糖</strong>在我们之前查看相关对图时似乎是很好的预测指标，所以让我们来看看使用这三种物质的模型:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="942f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到以下输出:</p><ul class=""><li id="68c7" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">R</strong>:<em class="le">0.843669504178866</em></li><li id="320e" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> R已调整</strong>:<em class="le">0.807124823500374</em></li></ul><p id="a5bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们发现R值从一元模型中的<em class="le"> .475 </em>(以<strong class="kk iu">卡路里</strong>为预测因子)增加到<em class="le"> .848 </em>。这似乎表明我们的模型的预测能力增加了。</p><p id="382e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，让我们在这个多元线性回归模型中添加一个较差的预测器<strong class="kk iu"> cups </strong>，看看会发生什么:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="18af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该代码给出以下输出:</p><ul class=""><li id="e2a5" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">R</strong>:<em class="le">0.849343364</em></li><li id="d8af" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> R调整后</strong>:<em class="le">0.788668182288071</em></li></ul><p id="e6d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下，在单一变量的情况下，每份麦片的杯数似乎与消费者评级几乎没有关联。但是当我们把它加到模型中时，总体R增加到<em class="le"> .849 </em>，这意味着模型的预测能力提高了。然而，根据我们所知，这个四变量模型应该不比三变量模型好。根据R值的计算方式，向模型中添加更多的变量总是会增加R值。因此，我们需要比较<em class="le">调整后的</em> R值，这减轻了由于额外变量导致的R增加。调整后的R的公式为</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/a4818449d0f7b85c135746305f2de2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*5Zk7cDHUHQvTJDbJ9YoAZQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">n-总样本量，p-预测数</p></figure><p id="9fc6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由此我们发现三变量模型的调整后R为<em class="le"> .807 </em>，而四变量模型的调整后R为<em class="le"> .788 </em>。因此，根据这一标准，三变量模型更好。</p><p id="a466" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">r是评估线性模型与数据拟合程度的最重要指标之一，因此对其含义有一个直观的理解非常重要。在实现线性回归模型时，了解R的局限性以及如何减轻这些局限性同样重要。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="a534" class="lw lx it bd ly lz oc mb mc md od mf mg jz oe ka mi kc of kd mk kf og kg mm mn bi translated"><strong class="ak">均方误差</strong></h1><p id="ddd3" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">回归模型有许多不同的评估指标。最流行的指标之一，我们首先要讨论的是<strong class="kk iu">均方误差</strong> <strong class="kk iu"> (MSE) </strong>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/8a424c7257d60a1e6c74b53f306450bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/0*gneJ93rtEyrZVfxC"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae lv" href="https://study.com/academy/lesson/estimation-of-r-squared-variance-of-epsilon-definition-examples.html" rel="noopener ugc nofollow" target="_blank">信号源</a></p></figure><p id="8c68" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MSE是一个评估指标，用于测量观察值和预测值之间的平均方差。换句话说，MSE告诉我们线性回归模型有多准确或不准确——MSE越低，模型预测值就“越好”。让我们找出回归模型的MSE:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="e1d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的变量<strong class="kk iu"> mse </strong>返回为<em class="le"> 26.6329 </em>。</p><p id="5000" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以使用的另一个评估指标是<strong class="kk iu">均方根误差</strong> <strong class="kk iu"> (RMSE) </strong>，它就是我们的MSE的平方根。使用Python数学模块中的平方根函数，<code class="fe nk nl nm nn b"><strong class="kk iu">sqrt(mse)</strong></code>返回为<em class="le"> 5.1607 </em>。</p><p id="4cbf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">值得注意的是，我们的RMSE值与响应变量使用相同的单位(我们取误差平方的平方根)。我们的RMSE值<em class="le"> 5.1607 </em>在<strong class="kk iu">评级</strong>变量的0-100范围内相对较低，因此我们的多元线性回归模型在预测谷物品牌的评级方面“表现良好”。但是我们可能会用到其他错误。</p><h1 id="1111" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">平均绝对误差</h1><p id="7d22" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">我们要考虑的下一个回归评估指标是<strong class="kk iu">平均绝对误差(MAE)。</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi on"><img src="../Images/f5de07e0e602d20d7070393ece2dbdfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XCZRQEl7E4vUdONe"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae lv" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="9463" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为MSE是残差的平方，所以MSE比MAE更严厉地“惩罚”了实际值和预测值之间的较大差异。由于平方项，MSE比MAE对异常值更敏感。</p><p id="a499" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们认为数据集中的异常值在分析数据时并不重要，我们可以在MSE之前转向MAE，因为异常值的残差不会因为残差的平方而被夸大。让我们找到梅:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="503c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的<strong class="kk iu"> mae </strong>变量返回<em class="le"> 3.6153 </em>。鉴于<strong class="kk iu">评级</strong>的0-100范围，我们的MAE相对较小，因此我们的MAE表明我们的模型在其预测中相当准确。</p><h1 id="e05f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">平均绝对百分比误差(MAPE) </strong></h1><p id="965c" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">我们要考虑的最后一个回归评估指标是<strong class="kk iu">平均绝对百分比误差(MAPE) </strong>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oo"><img src="../Images/84db68daa37282794fa31ad8b49538e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yMFKzfamGdamncJm"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae lv" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="fb04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MAPE用百分比给出了预测模型的准确性。请注意梅和MAPE公式的相似之处。像梅一样，MAPE并没有受到异常值的太大影响。但是，请谨慎使用MAPE，因为</p><ul class=""><li id="4ca8" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">MAPE容易被零误差除(见求和中的分母)；</li><li id="1f34" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">如果实际值很小，MAPE可以变得很大(再次参见求和中的除法运算)；</li><li id="765a" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">MAPE偏向于小于观测值的预测。</li></ul><p id="e4d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们为我们的模型找到MAPE:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="313a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的MAPE函数返回以下百分比:<em class="le"> 8.458 </em> %。因此，我们的预测平均“偏离”约8.5%。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="12fe" class="lw lx it bd ly lz oc mb mc md od mf mg jz oe ka mi kc of kd mk kf og kg mm mn bi translated">AIC和BIC</h1><p id="2f3e" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated"><strong class="kk iu">【阿凯克信息标准】</strong>和<strong class="kk iu"> BIC(贝叶斯信息标准)</strong>是评估您的回归模型并确定最佳预测子集(哪个模型更适合)的客观方法。</p><p id="367b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当您向模型添加参数时，它总是会更好一些。但这样你就有丢失真实潜在模式信息的风险。因此，在参数的数量和模型的误差量之间有一个权衡。AIC和BIC评估了模型解释你预测的变量的额外变化的能力，但没有过度拟合模型。</p><h2 id="97e8" class="op lx it bd ly oq or dn mc os ot dp mg kr ou ov mi kv ow ox mk kz oy oz mm pa bi translated">美国化学师学会(American Institute of Chemists)</h2><p id="632c" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">AIC允许您估计模型中丢失的信息量，以便您可以比较哪些模型效果最好，并选择更合适的预测子集。更具体地说，AIC值是指数据的真实似然函数与模型的拟合似然函数之间的相对距离。距离越小，模型就越接近数据的真实表示。AIC用这个公式表示:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/251a7b51eb11c08a7992f6e62ac18872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*e-ZtyXzkHJVD8MyfWaD8tA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">n个观察值，K个参数拟合+ 1</p></figure><p id="2cd9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们使用AIC方法比较两个模型的拟合度，AIC值较低的模型拟合度较好。</p><p id="3b27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们找出我们之前使用的两个多元回归模型的AIC值。一个有三个预测器，另一个有四个。首先，我们将定义要插入公式的值，然后运行公式:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="f914" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将产生以下输出:</p><ul class=""><li id="20aa" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">具有三个预测值的模型的AIC</strong>:<em class="le">60 . 3233831</em></li><li id="7310" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">四预测模型的AIC</strong>:<em class="le">62.380026097</em></li></ul><p id="20e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从我们看到的情况来看，具有三个预测值的模型具有较低的AIC值，因此比具有四个预测值的模型更适合(但在本例中并不太适合)。</p><h2 id="1e99" class="op lx it bd ly oq or dn mc os ot dp mg kr ou ov mi kv ow ox mk kz oy oz mm pa bi translated">BIC</h2><p id="31ed" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">BIC类似于AIC，但是在惩罚你的模型增加更多参数方面要严厉得多。它由以下公式表示:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/ed84cd19ca8c57796f702c1775b0fe88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*tGyBBtwyTTWSaBzSDUNGNw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">n个观察值，K个参数拟合+ 1</p></figure><p id="ebbb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们使用BIC方法比较两个模型的拟合度，BIC值较低的模型拟合度更好，类似于AIC方法的过程。</p><p id="e0e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们找到我们刚刚使用的相同的两个模型的BIC值。这里唯一的区别是我们将参数的数量乘以:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="a859" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将产生以下输出:</p><ul class=""><li id="d032" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">三预测模型的BIC:<em class="le">63</em></li><li id="647b" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">具有四个预测值的模型的BIC</strong>:<em class="le">66 . 14887</em></li></ul><p id="9260" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从这里我们可以看到，具有三个预测值的模型具有较低的BIC值，因此比具有四个预测值的模型更适合。因为BIC惩罚比AIC惩罚更严格，所以对于它们各自的模型，BIC方法的值大于AIC方法的值。</p><p id="c191" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于罚款的不同，AIC可以选择一个比BIC有更多参数的模型。建议您同时使用AIC和BIC，并根据两组结果对您的模型做出决策。在这种情况下，AIC和BIC彼此同意，选择了相同的模式。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="459c" class="lw lx it bd ly lz oc mb mc md od mf mg jz oe ka mi kc of kd mk kf og kg mm mn bi translated">关键词汇</h1><p id="8b17" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">总而言之，我们讨论了</p><ul class=""><li id="16d6" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu"> R </strong>:线性回归模型预测响应变量的强度指标</li><li id="3b3b" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">调整后的R </strong>:多元线性回归模型在校正模型中参数数量的同时，解释因变量方差的能力有多强的指标</li><li id="a6f3" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> MSE(均方误差):</strong>极大惩罚离群值的评价度量；当异常值代表数据集的真实现象时，这可能是您将计算和使用的第一个错误</li><li id="9d66" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> RMSE(均方根误差):</strong>MSE的平方根；与响应变量共享相同的单位，因此RMSE可能比MSE更“可解释”</li><li id="995d" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> MAE(平均绝对误差):</strong>用于在测量误差时降低异常值重要性的评估指标；当异常值<em class="le">不代表数据集的真实现象时使用</em></li><li id="5db2" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> MAPE(平均绝对百分比误差):</strong>用百分比来衡量回归模型的准确性；当响应变量取小值时，容易出现运行时错误或异常大的值</li><li id="1862" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> AIC(赤池信息标准):</strong>对不同模型中丢失的信息量的评估，对参数的增加进行惩罚。不管你的数据有多大，它总是有机会选择太大的模型。最好与BIC一起使用。</li><li id="431d" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu"> BIC(贝叶斯信息标准):</strong>与AIC类似，但处罚更重。不管你的数据有多大，它总是有可能选择太小的模型。最好与AIC一起使用。</li></ul><h1 id="0336" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="8dc6" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">在本教程中，我们展示了如何用Python实现简单和多元线性回归模型，以及评估这些模型及其误差的不同方法。</p><p id="e8b4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用您自己的数据集时，您可以选择使用这些方法中的任何一种来评估您的回归模型和误差。但是，使用这些模型并查看它们的结果如何一致或不同，以决定哪一个模型最能代表您的数据，这可能是您最感兴趣的。</p><p id="37c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，您应该更容易实现自己的线性回归模型，并且更加了解所有讨论的回归指标之间的相似性和差异。</p></div></div>    
</body>
</html>
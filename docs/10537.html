<html>
<head>
<title>Naïve Bayes vs. SVM for Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯与SVM在图像分类中的比较</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/na%C3%AFve-bayes-vs-svm-for-image-classification-75c16b29a96d?source=collection_archive---------9-----------------------#2022-01-13">https://betterprogramming.pub/na%C3%AFve-bayes-vs-svm-for-image-classification-75c16b29a96d?source=collection_archive---------9-----------------------#2022-01-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="27df" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">两种最流行的图像分类器的比较</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ade8afd58f55361aa599064287e80276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s8VlPiZPQoXSOF3Y"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/photos/7QjU_u2vGDs" rel="noopener ugc nofollow" target="_blank">信号源</a></p></figure><h1 id="9fbe" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">背景</h1><p id="875c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">Naïve贝叶斯是最简单的分类器，它使用图形模型的语言。该方法假设每个类别在码本上有其自己的分布，并且每个类别的分布与其他类别的分布显著不同。例如，建筑类别可能强调表示窗户、门或地板的代码字，而面类别可能显示眼睛、鼻子和嘴的代码字的重要表示。</p><p id="63cd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">另一方面，SVM分类器搜索使两类数据之间的间隔最大化的超平面，这可用于分类、回归和异常值检测。为了使用SVM对多个任务的图像进行分类，我们使用了一对多的方法。给定<em class="mp"> n个</em>类别，我们训练<em class="mp"> n个</em> SVM分类器，每个分类器负责将类别<em class="mp"> i </em>与剩余的<em class="mp">n–1</em>类别区分开来。最后，我们将一幅图像分配给具有最大计算输出的SVM类别。</p><p id="5aea" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">人们普遍认为，支持向量机比Naïve贝叶斯表现更好，返回更高的精度。在本文中，我们将在加州理工学院的<a class="ae kv" href="https://drive.google.com/drive/folders/1kLMG1pa3xV_TwK0DnibSbjYrj_hjGttf" rel="noopener ugc nofollow" target="_blank">微调数据集上执行图像分类，以查看关于SVM和Naïve贝叶斯的这一假设是否正确。</a></p><h1 id="a6b3" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据收集</h1><p id="fe7f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">下载上述数据集后，我们编写以下代码将图像划分到训练集和测试集中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="d8ad" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">特征抽出</h1><p id="95f4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">两种分类器都要求输入是从图像中提取的特征，因此我们使用视觉词袋方法:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="729c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">培养</h1><p id="346c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">从数据集中提取特征并构建码本后，我们可以将它们输入SVM和Naïve贝叶斯分类器进行训练:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="c0c5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">您可能会注意到，在上面的代码片段中，我使用了一个名为<code class="fe ms mt mu mv b">save_model</code>的函数来将训练好的模型序列化并存储在<code class="fe ms mt mu mv b">pickle</code>文件中以备后用:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="5339" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">估价</h1><p id="4986" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">获得训练模型后，我们根据测试数据评估它们的准确性:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="c663" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">主要观察结果</h1><p id="6a6b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们对<code class="fe ms mt mu mv b">Airplane</code>、<code class="fe ms mt mu mv b">Face</code>、<code class="fe ms mt mu mv b">Motorbike</code>类的图像进行分类，得到如下结果:</p><ul class=""><li id="057c" class="mw mx iq lq b lr mk lu ml lx my mb mz mf na mj nb nc nd ne bi translated">当我们以50:50的比例划分训练集和测试集时，每组100幅图像用于每一类，SVM和Naïve贝叶斯的结果分别是大约78%和74%的准确度，这表明了很小的差异。</li><li id="87c2" class="mw mx iq lq b lr nf lu ng lx nh mb ni mf nj mj nb nc nd ne bi translated">然而，当我们将训练和测试集中的图像数量增加到每个类别800个图像时，SVM和Naïve贝叶斯的结果分别变为大约91%和81%的准确度，显示出更大的差距。</li><li id="0615" class="mw mx iq lq b lr nf lu ng lx nh mb ni mf nj mj nb nc nd ne bi translated">当我们以80:20的比例对数据集进行分区时，这意味着80%的数据用于训练，剩下的20%用于测试，准确率甚至提高了:SVM的准确率为94%，Naïve贝叶斯的准确率为83%。</li></ul><h1 id="74b7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="2c3e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">从这个实验中，我们可以得出结论，支持向量机优于Naïve贝叶斯图像分类，并且随着数据集大小的增加，差异变得更大。这篇文章的代码报告可以在<a class="ae kv" href="https://github.com/billtrn/image-classification" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><pre class="kg kh ki kj gt nr mv ns nt aw nu bi"><span id="2f53" class="nv kx iq mv b gy nw nx l ny nz"><strong class="mv ir">Want to Connect?</strong></span><span id="2c8b" class="nv kx iq mv b gy oa nx l ny nz">Check out my personal <a class="ae kv" href="https://billtrn.com" rel="noopener ugc nofollow" target="_blank">blog</a>.</span></pre></div></div>    
</body>
</html>
<html>
<head>
<title>Let’s Have Some Fun With Core ML, the Vision Framework, and Swift 5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们享受一下Core ML、Vision框架和Swift 5带来的乐趣</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/lets-have-some-fun-with-coreml-vision-framework-and-swift-5-50f58f9dccce?source=collection_archive---------9-----------------------#2019-12-13">https://betterprogramming.pub/lets-have-some-fun-with-coreml-vision-framework-and-swift-5-50f58f9dccce?source=collection_archive---------9-----------------------#2019-12-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9f1d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">检查图像:这是一只猫吗？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5a9e59b197bc54a7852af6efd37321ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pHyJn23jLvUW_g44loOzfw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">法比安·格罗斯在<a class="ae kv" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="dfa7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习已被证明对创建“更智能”的程序很有价值，尤其是当你想处理以前未知的数据时。机器学习最适用于处理无法提前预测的数据。</p><p id="f0c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最令人兴奋的是苹果今年发布的<a class="ae kv" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank"> Core ML 3 </a>，让开发者有无限可能开发出使用机器学习的伟大应用。</p><p id="382e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Core ML 3将多种机器学习模型类型集成到您的app中。它使用先进的神经网络，支持100多种层类型，并无缝利用IOS设备上的CPU、GPU能力和神经引擎来提供最大的性能和效率。</p><p id="23a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这让你可以在你的设备上直接运行机器学习模型，是不是很棒？</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="2e2c" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">核心ML框架</strong></h1><p id="5577" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated"><a class="ae kv" href="https://developer.apple.com/swift/" rel="noopener ugc nofollow" target="_blank"> Swift </a>带来了强大的机器学习框架，帮助您使用机器学习模型来完成不同的任务。</p><p id="e65a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前，Core ML 3支持以下型号:</p><ul class=""><li id="d931" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">视觉框架:轻松地将计算机视觉机器学习功能构建到您的应用程序中，并利用人脸检测、跟踪和捕捉质量，以及文本识别、图像显著性和分类以及图像相似性识别。</li><li id="fd3e" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">自然语言框架(Natural Language Framework):允许您分析自然语言文本，并推断其特定于语言的元数据，以便深入理解。您可以使用这个框架和Create ML来训练和部署定制的NLP模型。</li><li id="ed0e" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">语音框架:利用10种语言的设备上语音识别以及语音显著特征，如发音信息、流置信度、话语检测和声学特征。</li></ul><p id="4a06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在官方<a class="ae kv" href="https://developer.apple.com/documentation/" rel="noopener ugc nofollow" target="_blank">苹果开发者文档</a>中了解更多关于这些框架的信息。</p><p id="b191" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将尝试使用视觉框架来检测图像中的对象。我们将创建一个简单的iOS应用程序，使我们能够探索和理解愿景框架是如何工作的。</p><p id="60ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们开始构建我们的应用程序之前，我们需要机器学习模型，所以我们不会从头开始构建我们的模型，但我们会利用<a class="ae kv" href="https://developer.apple.com/machine-learning/models/" rel="noopener ugc nofollow" target="_blank">苹果官方开发者网站</a>上提供的模型。</p><p id="4f36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用<a class="ae kv" href="https://github.com/forresti/SqueezeNet" rel="noopener ugc nofollow" target="_blank"> SqueezeNet </a>和<a class="ae kv" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>型号。你需要下载这些<strong class="ky ir">。</strong>您还可以学习使用<a class="ae kv" href="https://www.python.org/" rel="noopener ugc nofollow" target="_blank"> Python </a>从头开始创建和训练您的模型，并将它们转换成核心ML模型。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="9aee" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">创建新项目</strong></h1><p id="67f8" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">打开Xcode IDE，创建一个新项目，然后选择“故事板”作为用户界面。然后，让我们添加一个简单的图像视图和一个标签来显示我们的结果。如下图所示放置控件，并根据您自己的偏好添加约束。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/fbe318f529f5283ef0e0423c5248f76c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vpvzMxU1q3WmBW_Ommshsw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视图控制器.故事板</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f541" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">添加核心ML模型</h1><p id="7420" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">将我们之前下载的模型拖放到您的项目中。您的文件结构应该如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/700141a3be7462e58d8c9ab8994ccf8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*Azo-gz8LdfsyVZ77rATnEg.png"/></div></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="7f71" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">编写代码的时间</strong></h1><p id="131a" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我们将从简单开始，向Xcode项目添加一个图像。这将只允许我们识别硬编码到应用程序中的单个图像，但它将让我们专注于让核心ML模型在应用程序中工作。</p><p id="0fef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，首先从网上下载像鸟、狗、猫或笔记本电脑这样的图片；任何你想让我们的核心ML识别的图像。将图像拖放到您的Xcode项目中。</p><p id="2dab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们转到我们的主视图控制器，并添加下面的行。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="1a95" class="nr ma iq nn b gy ns nt l nu nv">import CoreML</span><span id="c149" class="nr ma iq nn b gy nw nt l nu nv">import Vision</span></pre><p id="1bfb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">核心ML导入允许我们的项目识别和使用添加到您的项目中的核心ML模型。视觉导入允许我们使用视觉框架来识别图像中的项目。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a78d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">添加网点</strong></h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ViewController.swift</p></figure><p id="2f32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">确保将模型的行数属性设置为零，并将之前添加的图像添加到<code class="fe nz oa ob nn b">UIImageView</code>的图像属性中，并让其显示。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="3839" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">让我们为我们的核心ML模型提供一个图像</h1><p id="6a34" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">至此，我们已经创建了我们的界面和控件，插座都已连接好并准备就绪。我们的机器学习模型需要一个图像作为输入，所以在我们的例子中，我们需要识别我们添加到Xcode项目中的图像文件。</p><p id="4088" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这涉及到两个步骤。首先，我们需要识别图像文件名、图像的文件扩展名和图像的路径。其次，我们需要将这些信息存储为URL，并将其提供给我们的核心ML模型。</p><p id="a89a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将下面几行添加到您的<code class="fe nz oa ob nn b">viewDidLoad</code>方法中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ViewController.swift</p></figure><p id="7166" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有了图像路径变量，我们将用它来赋予我们的模型。现在，让我们创建一个变量来保存核心ML模型的实例。在这种情况下，我们将尝试MobileNet模型。</p><p id="2087" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在您的<code class="fe nz oa ob nn b">viewDidLoad</code>方法上方添加下面一行。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="45d3" class="nr ma iq nn b gy ns nt l nu nv">let modelFile = MobileNetV2FP16()</span></pre><p id="a76e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nz oa ob nn b">MobileNetV2FP16()</code>标识了我们添加到项目中的<code class="fe nz oa ob nn b">MobileNetV2FP16.mlmodel</code>文件。现在，我们需要告诉我们的应用程序使用核心ML模型和Vision框架。</p><p id="ac5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们添加另一行代码，如下所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ViewController.swift</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="0769" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">用我们的核心ML模型检查图像</h1><p id="7c04" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">让我们将下面几行代码添加到我们的<code class="fe nz oa ob nn b">viewDidLoad</code>方法中，稍后我会解释代码在做什么。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ViewController.swift</p></figure><p id="681e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码中，存储在“model”常量中的核心ML模型需要检查图像，并多次将其与其训练数据进行比较，以最大限度地提高正确识别它的机会。</p><p id="8d87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们需要请求核心ML模型运行，并为我们提供一个完成处理程序，我们将在核心ML模型检查完我们传递给它的图像后使用它。</p><p id="2e04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们添加<em class="oc">查找结果</em>方法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ViewController.swift</p></figure><p id="8dc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您的最终代码应该如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">view controller . swift-最终代码</p></figure><p id="cb0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行和测试代码的时间到了。</p><p id="d621" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在模拟器或iPhone设备上运行此应用程序。如果一切顺利，您的应用程序应该显示识别的对象和置信度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/db577e26a2e756933d05dac5dd5230c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GEiuo5Ckl_XpFT5pn6DsLw.png"/></div></div></figure><p id="a96a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们快速测试另一个核心ML模型的性能。更改并替换您的代码，如下所示:</p><p id="681a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">替换:<code class="fe nz oa ob nn b">let modelFile = MobileNetV2FP16()</code></p><p id="558f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">搭配:<code class="fe nz oa ob nn b">let modelFile = SqueezeNet()</code></p><p id="8474" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，再次运行您的代码，看看它在置信度上的表现如何。所以，你可以尝试不同的图像，看看这些模型表现如何。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="1fc3" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">下一步是什么</strong></h1><p id="5b72" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在我们知道了使用Swift的Core ML是如何工作的，我将准备一些更实用的东西，从设备的媒体剪辑库或手机摄像头中提取图像并进行分析。</p><p id="4eee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非常感谢您的阅读。</p><div class="oe of gp gr og oh"><a href="https://github.com/AfroCyberGuy/CoreMLImageRecognition" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd ir gy z fp om fr fs on fu fw ip bi translated">AfroCyberGuy/CoreMLImageRecognition</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov kp oh"/></div></div></a></div></div></div>    
</body>
</html>
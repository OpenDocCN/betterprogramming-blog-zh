<html>
<head>
<title>Is a Neural Network Better Than Ash at Detecting Team Rocket? If So, How?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络比Ash更擅长探测火箭队吗？如果有，如何实现？</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/is-a-neural-network-better-than-ash-at-detecting-team-rocket-if-so-how-c00108c64174?source=collection_archive---------11-----------------------#2020-06-29">https://betterprogramming.pub/is-a-neural-network-better-than-ash-at-detecting-team-rocket-if-so-how-c00108c64174?source=collection_archive---------11-----------------------#2020-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cec4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">TensorFlow中的CNN训练、Google Cloud中的对象检测模型以及TensorFlow.js中的激活图可视化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b7d8378135d6cb5d650825a0da457585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DciUMHYgl8EW7WGxJ_bivQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2020神奇宝贝</p></figure><p id="0ae8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的整个存在是一个永无止境的谜。宇宙中只有我们吗？人生有什么意义？在识别火箭队方面，神经网络比Ash更好吗？前两个问题是让许多科学家和哲学家夜不能寐的重要问题。然而，最后一个让我无法入睡。在这篇文章中，我将尝试回答这个问题。</p><p id="1991" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些天我花了一些时间看了《口袋妖怪秀》的第一季(反正我也不需要借口)。当我看着Ash和他的朋友们开始他们的冒险，捕捉口袋妖怪并成为最棒的(就像从来没有人一样)，我不禁注意到，当他们穿着他们标志性的服装时，他们从来没有认出火箭队。我的意思是，拜托，火箭队总是在那里，在你旅程的每一步，你告诉我你不能注意到他们？太奇怪了。但是当然，没关系；我猜是口袋妖怪世界规则。</p><p id="4784" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是后来，我想，“嗯，等等，神经网络怎么样？在识别火箭队方面，神经网络会比Ash和crew更好吗？”嗯，可能吧。但是这几天我没什么事做，所以让我们看看它的实际效果。此外，有时旅程比目的地更好。</p><p id="b2c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在继续之前，对于那些不知道火箭队是谁的人来说，它是一个三人组——由杰西，詹姆斯和喵喵组成——扮演口袋妖怪动画的主要对手。它的主要目标是从亚什那里偷皮卡丘。对于这个项目，我只是考虑杰西和詹姆斯。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/8c012ff00f3c0f11a9c76c3719a8f448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n0T4ikZep1o4YMfc.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。火箭队:詹姆斯、杰西和喵喵2020神奇宝贝</p></figure><p id="2c98" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我讨论了我的实验结果，在这个实验中，我使用了两个模型来区分火箭队。第一个是在<a class="ae lv" href="https://cloud.google.com/automl" rel="noopener ugc nofollow" target="_blank"> Google Cloud AutoML </a>中训练的对象检测模型，用于检测图像中的杰西和詹姆斯。为了使用这个模型，我将它部署在一个<a class="ae lv" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> TensorFlow.js </a>应用程序中。从那里，我们可以探测到复仇女神队。第二个模型是在TensorFlow上训练的卷积神经网络(CNN)图像分类器，用于识别Jessie或James。</p><p id="0a10" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，仅仅预测这些目标就有点无聊了。为了让事情变得更有趣，我还想知道为什么图像分类器会这样预测。换句话说，我感兴趣的是看到网络看到了什么，以及为什么图像分类器将图像分类为杰西或詹姆斯。因此，我扩展了TensorFlow.js应用程序，也使用图像分类器在预测时绘制CNN层的激活图。这样，我们将能够确定网络用来计算其预测的特征。</p><p id="0888" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我将解释训练模型和构建web应用程序的所有步骤。我们开始吧。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/07295dcf443128035778b73efd235959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MDvwX8uAXouGMe6Z.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。真正邪恶的2020神奇宝贝</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="acb0" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">数据</h1><p id="0b64" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我用来解决这个问题的数据集非常非常小。它由杰西和詹姆斯的87幅和71幅图像组成。为了在Google Cloud AutoML上训练对象检测模型，Google建议每个标签至少有50张图像，所以我很好。对于图像分类器，我使用TensorFlow的<a class="ae lv" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>。该生成器在每个历元对数据集进行变换，并用新变换的数据进行训练。因此，我使用的不仅仅是158张图片。</p><p id="9904" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">警告:我完全理解158张图片对于这样的问题来说是个笑话，模型的表现不会让人印象深刻。然而，请记住这是一个有趣的实验项目，不是我打算在NeurIPS或ICLR上发表的东西。此外，我不想花几个小时寻找火箭队的图像。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="f0aa" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">问题是</h1><p id="04f5" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我说过，这里的主要问题是阿什认不出火箭队。想看看证据吗？看看这个:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="b48a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管他们挥舞着大大的“R”旗，Ash还是完全不知道。哇哦。这个怎么样？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="d926" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，是火箭队。最后，这一个:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="c340" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以Ash不是唯一有问题的人。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="ca5e" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">对象检测模型</h1><p id="2f2d" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我创建的两个模型中的第一个是使用<a class="ae lv" href="https://cloud.google.com/vision/automl/object-detection/docs" rel="noopener ugc nofollow" target="_blank">谷歌云的AutoML视觉物体检测</a>训练的物体检测器。这项服务允许您轻松地(枯燥地)注释对象检测数据集，并在几次点击中训练一个模型。可以为TensorFlow.js、TensorFlow Lite和TensorFlow等几个推理引擎导出和优化训练好的模型。</p><p id="7bed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不过，这项服务不是免费的。不过谷歌提供了一次性的信用券，应该够小型号用了。</p><h2 id="21e5" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">创建和注释数据集</h2><p id="a3e7" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在训练AutoML对象检测模型之前，第一步需要上传数据集并对其进行注释。要上传数据，请通过在云控制台搜索栏中搜索“数据集”来访问数据集管理页面。然后，创建一个新的“object detection”类型的数据集(图3)，并将图像上传到一个bucket。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/739d3fd2bb3e4d6a15ce138b04a5f66f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RZV5zCm4sXNXp_D_.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。在AutoML中创建新数据集</p></figure><p id="cd17" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上传并处理后，转到IMAGES选项卡，开始注释数据集的沉闷过程。在这种情况下，注释数据集包括在图像上绘制目标对象的边界框(图4)——这并不有趣。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/5ecf787c508a77c7478a3ec4aa005a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*p15dMNyAr0mixcc1.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4。重复这个过程100多次</p></figure><p id="ae66" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在数据集被标记后，单击“训练”选项卡来训练模型。</p><h2 id="6a5e" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">训练模型</h2><p id="2cf0" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">训练模型只需三次点击。从当前屏幕，转到培训选项卡，并点击培训新模型。然后命名模型，选择“edge”(因为我们要下载)，选择优化目标(我用的是精度更高的)和节点小时预算，然后点击开始训练。使用默认的节点小时预算，以及我的数据集的大小，训练花费了大约四个小时。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/dfd547b2cad39975d4fcd960fd87dc38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-vJqXY3lrzmebJy6.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5。定义和训练模型</p></figure><h2 id="b48e" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">评估模型</h2><p id="c82c" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">培训已经结束；欢迎回来。要评估模型的指标，请转到“评估”选项卡。在这里，您可以找到精确度和召回分数，以及在不同阈值水平计算它们的选项。我的模型分别实现了100%的准确率和93.75%的召回率(图6)。然而，在实践中，正如我们将很快看到的，该模型有点糟糕。不过没关系！考虑到训练集的规模，我不会期望模型有那么大。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/2b121990271e41536f4fe278ac312033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9uA_EhMaKtkR5U6y.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6。模特的分数。</p></figure><p id="af93" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">至于最后一步，转到TEST &amp; USE选项卡，导出TensorFlow.js模型(图7)。导出的目录应该有一个<code class="fe np nq nr ns b">model.json</code>(模型拓扑)和<code class="fe np nq nr ns b">dict.txt</code>文件(标签)，以及几个<code class="fe np nq nr ns b">.bin</code>文件(权重)。现在，让我们围绕模型构建一个应用程序。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/16c3a7baf276854e7c10a42c1872f93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LBsi_35uZb9viGLD.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7。导出模型</p></figure><h2 id="1ca9" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">在TensorFlow.js中部署模型</h2><p id="9dff" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">为了使用对象检测模型检测Team Rocket并运行图像分类模型来呈现激活图，我构建了一个web应用程序，它使用TensorFlow.js来加载模型并使用它们进行预测。在这一部分，我将展示我如何加载对象检测模型，用它进行预测，并绘制边界框。让我们从HTML开始:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="276d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在head标签中，我加载了TensorFlow.js和<a class="ae lv" href="https://www.npmjs.com/package/@tensorflow/tfjs-automl" rel="noopener ugc nofollow" target="_blank"> AutoML Edge API </a>，这是一个加载和运行用AutoML Edge生成的模型的包。在主体中，有一个用户用来上传一个图像和两个图像标签的输入元素。一个显示原始图像，另一个显示带有边界框的图像。然后我们调用JS脚本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="6616" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在脚本的顶部，我们声明了模型变量及其选项。options对象指定阈值，<a class="ae lv" href="https://en.wikipedia.org/wiki/Jaccard_index" rel="noopener ugc nofollow" target="_blank">交集超过并集(IoU) </a>阈值，以及要返回的对象的最大数量。接下来是画布的上下文，我们将在其中绘制检测、输出图像的大小以及检测覆盖图的颜色。</p><p id="22d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一个功能<code class="fe np nq nr ns b">setupODCanvas()</code>，设置目标检测画布。第二个，<code class="fe np nq nr ns b">drawBoundingBoxes()</code>，负责绘制边界框。然后是<code class="fe np nq nr ns b">processInput()</code>，预测的功能。这里我们使用图像输入元素的<code class="fe np nq nr ns b">onchange</code>事件来预测用户何时选择图像。一旦被触发，我们得到图像并把它作为<code class="fe np nq nr ns b">odModel.detect()</code>的一个参数，这个方法检测物体。检测之后，我们在画布上绘制图像和包围盒。</p><p id="0a09" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要运行web应用程序，请在项目的根目录下启动一个本地web服务器。您可以使用<code class="fe np nq nr ns b">$ python3 -m http.server</code>或<a class="ae lv" href="https://www.npmjs.com/package/http-server" rel="noopener ugc nofollow" target="_blank"> http-server </a>轻松创建一个，这是一个用于创建http服务器的命令行工具。启动服务器后，进入服务器显示的地址，如<a class="ae lv" href="http://127.0.0.1:8000/" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:8080/ </a>，访问app。注意，在代码中，我使用的是端口8080。</p><h2 id="b84d" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">模型有能力探测火箭队吗？</h2><p id="6ac9" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">从经验上来说，是的！它探测火箭队的能力比Ash强。但是，和Ash一样，它也会时不时地失败。让我们看看。下面是从上面呈现的剪辑的场景中的一些检测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/8f8dcfb4bc04d1df68db10821e5e9f1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G8GDNMjcByx-kWHZ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8。检测到杰西</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/61c8eebf67a27828feeeaae0ea038873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Z8SItT0WORUeYbBH.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图9。检测到詹姆斯</p></figure><p id="f0f6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">干得好，神经网络！那的确是杰西和詹姆斯。以下是第二段视频。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/e8408e89f6d2b5cac5915f579348bd80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tCaX1d5j1MkfPWRo.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图10。另一个发现了杰西</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/419e2fce7815b9c9e97afecf2937374e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IrtI1OeeENxlW_zZ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图11。另一个发现了詹姆斯</p></figure><p id="131e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">再次，成功。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/84fe57036cceacbc944b9fdfb90a92fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qQeS_UQdfqijVC8L.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图12。杰西。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/8692293fe12600f3b2f82263fe1aa08f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G_hEfV6XqfJVuxjr.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图13。詹姆斯。</p></figure><p id="1bd9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些是模型按计划工作的一些正面案例。但不幸的是，还有其他失败的例子。我注意到，在火箭队看起来太傻、图像缺乏细节以及从远处观看的情况下，该模型表现不佳(至少在其他人使用的相同置信度阈值下)。例如:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/90ff889afce486d6f8914d722860bba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AgT-s8_7KR_TQLwz.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图14。一个未被发现的杰西</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/408b758996eec2536826db984556e5e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*63_VcQI6OGdf8-D8.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图15。一个未被发现的詹姆斯</p></figure><p id="1967" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该网络在图像中检测它们时遇到了问题，这些图像没有显示它们最明显的特征:头发的颜色。举个例子，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/6ced3035eb2c1b82c04131c18e9d5d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8OQPd2Zbjw4D_uZm.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图16。那是杰西，不是詹姆斯。</p></figure><p id="2f12" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上图中，你几乎看不到杰西的头发。老实说，如果我不知道上下文，我也不会知道那是她。这与他们染发的情况相似:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/0609d1e1ab405af0ca831486f6b7d851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dS7Hj0yS0OSxHe4Z.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图17。不管怎么说，这并不容易。</p></figure><p id="e1fa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我想提到的最后一个问题是，在我的所有测试中，网络都无法在一张照片中检测到两个成员。相反，它会将这两者检测为一个标签。在我看来，这种不便以及假阳性是实验的最大缺陷。希望增加更多训练数据后修复。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/55c86a8e68caab8f5b75f25693ce043c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*633I1caRpZuZjWP4.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图18。从技术上讲，这是正确的。</p></figure><p id="dbaa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，总结一下，在探测火箭队方面，神经网络比Ash更好吗？我同意。现在又来了一个后续问题。网络是如何识别他们的？在说“是的，这是杰西”之前，它看到了什么？在实验的第二部分，我要解决这个问题。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="15f8" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">解释激活图</h1><p id="4f1a" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">通俗地说，卷积神经网络(CNN)通过查看其最突出的视觉特征来学习辨别类别。例如，美国有线电视新闻网可能知道香蕉是香蕉，因为它的形状像香蕉，颜色是黄色的。在实验的第二部分，我想研究CNN从杰西和詹姆斯的图像中提取的视觉特征。换句话说，我有兴趣看到网络的激活图，这是其卷积和最大池层的输出。</p><p id="0d3a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了实现这个目标，我在TensorFlow中进行了训练，这是一个CNN图像分类器，可以预测图像是杰西还是詹姆斯。这样，我就知道为什么电视台认为这不是杰西就是詹姆斯了。随着网络的训练，我扩展了之前的TensorFlow.js应用程序，以加载模型并在屏幕上绘制所有层和每个过滤器的激活图。看起来是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/2ed1d2b89659135ed8fea43006aaec2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Rja8p-Y2d-STjX_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图19。应用程序的分类输出和对象检测部分</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/79a9378f936a1da426f1cd7713cb796a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8ZvkroK24nPNwWHb.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图20。第一层的过滤器11的激活图</p></figure><h2 id="1d22" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">训练模型</h2><p id="be62" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">图像分类器模型是一个非常标准的CNN。它有三个卷积层，三个max池层，一个dropout层，一个具有ReLU激活功能的密集层，至于最后一个，另一个两个单元的密集层和softmax激活功能。这最后一位意味着输出是长度为2的向量，其中每个值是图像是James(标签0)或Jessie(标签1)的可能性。下面是模型的图表，后面是它的摘要。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/c2e98ccdc28a898febfec9163a7e8ef7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-EOmBeShjUL5mOOF.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图21。CNN。用<a class="ae lv" href="http://alexlenail.me/NN-SVG/index.html" rel="noopener ugc nofollow" target="_blank"> NN-SVG </a>创建的图表</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/31fbfebacac0dc89e87237b70160685b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uY792MxJD6qanMij.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图22。CNN摘要</p></figure><p id="7a7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与之前的模型不同，为了训练这个模型，我有一个更丰富的数据集。嗯，有点:我没有使用158张图像，而是使用TensorFlow的图像生成器，通过转换现有的数据集来增加我的数据集。我应用的变换是将图像在[-45，45]度之间旋转，水平和垂直移动，水平翻转和缩放。此外，20%的生成图像被用作验证集。为了评估模型，我使用TensorBoard。以下是完整的培训脚本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="7e8c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一个函数，<code class="fe np nq nr ns b">create_data_generators()</code>，创建生成器(当然它是这么做的，哈哈哈)。<code class="fe np nq nr ns b">train()</code>，参数都是发电机，训练模型。请注意，我们正在使用<code class="fe np nq nr ns b">model.fit()</code>上的TensorBoard回调来记录模型的训练信息。一旦训练结束，我们保存模型。</p><p id="3697" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于模型的性能，在25个时期之后，它分别实现了0.8594和0.3367的训练精度和损失值，以及0.8065和0.2541的验证精度和损失值。下面是来自TensorBoard的两张截图，展示了精确度和损耗值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/90c91ae3ad2e01d3533c72f33694242a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2aXioEkZd_7AgWFy.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图23:训练和验证的准确性。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/5a6758d778f839cbb7e53d6de02c65ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-qL0gwfqiR92Xqk7.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图24:培训和验证的损失</p></figure><p id="43c7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要启动TensorBoard，请在终端中执行:</p><pre class="kj kk kl km gt oh ns oi oj aw ok bi"><span id="dfcf" class="nc me it ns b gy ol om l on oo">$ tensorboard --logdir /tmp/tensorboard</span></pre><p id="a98f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">确保给定的路径与<code class="fe np nq nr ns b">model.fit()</code>中使用的TensorBoard回调中使用的路径相同。</p><h2 id="1ed4" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">将模型转换为TensorFlow.js模型</h2><p id="c14d" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在培训结束时，我们将模型保存到磁盘上。但是，这种格式在TensorFlow.js中是行不通的，要在我们的web app中使用模型，必须先将其转换为TensorFlow.js格式；这比听起来容易。要转换它，我们需要<a class="ae lv" href="https://github.com/tensorflow/tfjs/tree/master/tfjs-converter" rel="noopener ugc nofollow" target="_blank"> TensorFlow.js转换器</a>工具。安装后，执行以下命令来生成模型的TensorFlow.js版本:</p><pre class="kj kk kl km gt oh ns oi oj aw ok bi"><span id="28a4" class="nc me it ns b gy ol om l on oo">$ tensorflowjs_converter --input_format=keras_saved_model PATH/TO/TS_MODEL OUTPUT/PATH</span></pre><h2 id="4a7a" class="nc me it bd mf nd ne dn mj nf ng dp mn lh nh ni mp ll nj nk mr lp nl nm mt nn bi translated">TensorFlow.js激活web应用程序</h2><p id="3f73" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我们将在这里看到的激活地图web应用程序是上一个应用程序的扩展。现在，除了检测团队火箭，它将分类图像之间的“杰西”或“詹姆斯”，并提出该层的激活地图。</p><p id="06ef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在<a class="ae lv" href="https://juandes.github.io/team-rocket-activations-app/index.html" rel="noopener ugc nofollow" target="_blank">https://juandes . github . io/team-rocket-activations-app/index . html</a>找到这个应用。</p><p id="0ab8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">图20是该应用程序的屏幕截图。在这里，您可以看到图像输入控件、对象检测画布、预测结果，以及每层的一个部分，其中用户使用输入滑块来选择想要可视化的过滤器。我是如何构建应用程序的？是时候编写一些代码了，从HTML开始:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="d9fd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于这个版本的应用程序，我使用可视化库<a class="ae lv" href="https://plotly.com/" rel="noopener ugc nofollow" target="_blank"> Plotly </a>来可视化激活图。此外，我们有一个CSS文件，你可以在回购中找到。在主体中，有两个显示预测标签和输出的<code class="fe np nq nr ns b">&lt;p&gt;</code>和六个<code class="fe np nq nr ns b">&lt;div&gt;</code>(每层一个)用于选择我们希望绘制的过滤器的输入类型范围——最大值是该层的过滤器数量。这些<code class="fe np nq nr ns b">&lt;div&gt;</code>中的每一个都有另一个<code class="fe np nq nr ns b">&lt;div&gt;</code>，其中脚本以编程方式添加Plotly图。</p><p id="f8a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是HTML。至于JS脚本，在进入代码之前，让我快速解释一下它是如何工作的。该脚本使用三个模型:对象检测器、图像分类器和一个新模型。这个新模型输出一个由所有中间激活图组成的张量。我们将通过将其输入显式设置为图像分类器的输入，并将分类器的输出张量列表(卷积层和池层)作为输出来创建该模型。为了触发预测，用户首先要上传一张图片。之后，我们将在应用程序上显示检测到的火箭、分类输出和激活地图。现在，让我们一部分一部分地看代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="13cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面我们有模型的变量:图像分类器，我们将用于激活的模型，以及对象检测器。跟在它们后面的是保存我们想要分类的图像的变量、画布上下文和描述一些图层信息的地图列表。</p><p id="00ee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我想介绍的前两个函数是<code class="fe np nq nr ns b">setupODCanvas()</code>(之前的)和<code class="fe np nq nr ns b">initSliders()</code>，用于初始化滑块的输入。<code class="fe np nq nr ns b">initSliders()</code>的第二个参数是用户移动滑块时调用的回调函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="c34e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后是<code class="fe np nq nr ns b">drawActivation()</code>，在Plotly情节中绘制激活图的那个。它的参数是所有“预测的”激活、我们想要绘制其过滤器的层的索引、过滤器索引、绘图的id和过滤器的大小。在函数内部，我们使用了<code class="fe np nq nr ns b">tf.tidy(fn)</code>，一个TensorFlow.js <a class="ae lv" href="https://js.tensorflow.org/api/latest/" rel="noopener ugc nofollow" target="_blank">函数</a>，它清理了<code class="fe np nq nr ns b">fn</code>分配的所有中间张量。在<code class="fe np nq nr ns b">tf.tidy()</code>中，我们得到由<code class="fe np nq nr ns b">layerIndex</code>和<code class="fe np nq nr ns b">filterNumber</code>表示的激活张量和滤波器。然后，我们将激活图转换为2D阵列，并将其绘制为热图:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="bccd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后是<code class="fe np nq nr ns b">setupSliders()</code>。这个函数迭代<code class="fe np nq nr ns b">layersInformation</code>并使用来自<code class="fe np nq nr ns b">layersInformation</code>的值调用<code class="fe np nq nr ns b">initSliders()</code>。<code class="fe np nq nr ns b">initSliders()</code>的第二个参数是当用户使用滑块选择图层的滤镜时触发的回调。在这种情况下，我们将使用<code class="fe np nq nr ns b">activationModel</code>生成激活图。预测之后，我们称之为<code class="fe np nq nr ns b">drawActivation()</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="79da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来是<code class="fe np nq nr ns b">setupModels()</code>，负责初始化我们正在使用的三个模型。该功能从加载分类器和对象检测模型开始。之后，它遍历CNN的前六层(三个卷积和最大池)并将它们的输出添加到一个列表中。然后，我们使用TensorFlow的<a class="ae lv" href="https://www.tensorflow.org/js/guide/models_and_layers#the_functional_model" rel="noopener ugc nofollow" target="_blank">功能</a>方法创建一个新模型，命名为<code class="fe np nq nr ns b">activationModel</code>，在该方法中，我们必须指定模型的输入和输出:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="7150" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下功能与之前的<code class="fe np nq nr ns b">drawBoundingBoxes()</code>相同:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="aa95" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在出现了第一个预测函数。这个叫做<code class="fe np nq nr ns b">predictWithObjectDetector()</code>，使用输入图像检测火箭队，就像我们之前做的一样:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="8008" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下一个名为<code class="fe np nq nr ns b">predictWithClassifier()</code>的函数获取输入图像，将其转换为张量，并预测其标签和激活。预测之后，该函数从每一层绘制第一个过滤器的激活图，并将预测结果添加到HTML中。该函数在用户上传图像时运行。与我们对来自<code class="fe np nq nr ns b">initSliders()</code>的回调所做的预测不同，在那里绘制了用户选择的过滤器的激活，在这里我们将可视化每个层的第一个过滤器:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="bceb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后是将所有东西粘在一起的功能:<code class="fe np nq nr ns b">processInput()</code>。这个函数使用几个事件来加载用户选择的图像，在屏幕上绘制图像，并调用前面的预测函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="7591" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，有一个init函数作为应用程序的起始点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nb l"/></div></figure><p id="92e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那是代码。要运行该应用程序，请遵循之前讨论的方法。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="54b4" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">模型是如何识别火箭队的？</h1><p id="e442" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在那堂漂亮的TensorFlow.js和js课之后，是时候回答我们的第二个问题了:模型是如何识别火箭队的？它在预测时间看到了什么？为了回答这个问题，我将展示几个激活图，从下图开始:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/81f436ca8d148b870a3649f66eb9bb32.png" data-original-src="https://miro.medium.com/v2/resize:fit:278/format:webp/0*7hBI-yxeNQ_jRtK6.jpg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图25。更多杰西和一点喵喵2020神奇宝贝</p></figure><p id="b987" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CNN说这是杰西——0.99杰西和0.01詹姆斯，根据softmax的输出。但为什么是她？好吧，你自己看吧。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/4ff60a5ba4f3aa1055f525599c51fce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LdtloH73kpGtrGP0.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图26。激活图</p></figure><p id="ac7c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">图26显示了来自六层的一些过滤器的激活图。前两个图像来自第一个卷积层和最大池层。接下来的两个来自第二组卷积和最大池，最后两个来自第三组-因为每个连续层都比前一层小，所以图像的分辨率会降低。在这些热图上，颜色的强度代表了CNN用来识别物体的区域。这就是为什么杰西的头发，可以说是她最具标志性的特征，如此突出并不奇怪。</p><p id="0625" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，这些图像并没有讲述网络的全部故事。它们只是模型中100多个过滤器中的一小部分。虽然大多数贴图侧重于头发，但其他贴图会查看其他部分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/2981d6d419b1abc02a698d610ad14c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r8WOivSfaAVhCBQa.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图27。喵喵的确是一个美丽的地方</p></figure><p id="040b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下一个例子中，考虑詹姆斯的图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/1fc3e4f0e24d0b7c2c997e4e79e30311.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/format:webp/0*c8SdWzys4d_vqcwS.jpg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图28。詹姆斯和他令人敬畏的假胡子2020神奇宝贝</p></figure><p id="1ac4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CNN正确预测了“詹姆斯”(杰西0.20，詹姆斯0.80)。像以前一样，网络也主要关注头发，在某些情况下，关注那雄伟的假胡子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/76dea02e4acf234c3a149bc5d2c21ab3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xYSw9RpMYh_eXd2P.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图29。詹姆斯的激活地图。</p></figure><p id="93ba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">没有什么是完美的，这包括我的网络。在我的测试中，我发现了一些CNN预测错误的例子。一个例子是物体探测器无法探测到的杰西的同一张照片——我们可以说这是因为头发几乎不存在。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/966d2b5a6de23b98c0da4b0896d46f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CdoQnupU6AYBYOOv.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图30。又错了</p></figure><p id="5183" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是激活图。杰西没有可辨认的特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/fbc1b3e4b037282012f53aa7eaf8223a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-2IkU3af6soPG_SL.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图31。没有找到头发。</p></figure><p id="8497" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就这样，我们结束了实验！要查看更多示例，我将邀请您查看上面展示的交互式演示，或者克隆回购并自己运行它。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="e880" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">结论和概述</h1><p id="823e" class="pw-post-body-paragraph ky kz it la b lb mv ju ld le mw jx lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">生活充满了问题。我是谁？是先有鸡还是先有蛋？神经网络比Ash更擅长探测火箭队吗？在这个实验中，我试图回答最新的问题。结果令人满意，我愿意用“是”来回答这个问题为了这个项目，我训练了两个网络，一个对象检测器和一个图像分类器来检测图像中的团队火箭，并了解CNN认为相关的特征。为了使用这些模型，我们使用TensorFlow.js创建了一个web应用程序来加载它们，并显示检测到的火箭和激活图。</p><p id="b69a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">给我亲爱的朋友小智，这些是我给你的建议。正如我们从对象检测器模型中了解到的，如果你需要知道你面前的团队是否是火箭队，那么试着一次分析每个人；不要把他们看成一个群体。其次，试着和他们更亲近一点——这很有帮助。最后，这不是一个巨大的突破，集中在头发上。如果是鲜红色的长型，很有可能那个人就是杰西。或者，如果矮个子，浅蓝色，很可能是詹姆斯。</p><p id="bf2a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于该项目的未来迭代，我想修正对象检测器，以检测同一帧中的两个恶棍。同样，我想训练一个多标签CNN，能够在一个图像中同时识别杰西和詹姆斯。</p><p id="026f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就是这样！你可以在<a class="ae lv" href="https://github.com/juandes/team-rocket-activations-app" rel="noopener ugc nofollow" target="_blank">https://github.com/juandes/team-rocket-activations-app</a>找到完整的源代码，在<a class="ae lv" href="https://juandes.github.io/team-rocket-activations-app/index.html" rel="noopener ugc nofollow" target="_blank">https://juandes . github . io/team-rocket-activations-app/index . html</a>找到该应用的运行版本。您可以在data/test/目录中找到适合测试模型的图片。</p><p id="97bc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读。</p><p id="1bba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你有任何问题，评论，或存在危机，在这里留下评论。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/850d1af81717ab0c8fe39ba78fb86371.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/0*jJA1wVdchVQZnNfX.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">火箭队再次升空了！</p></figure><p id="1c6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ot">为了谨慎起见:神奇宝贝和所有相关名称都是任天堂1996-2020的商标。</em></p></div></div>    
</body>
</html>
<html>
<head>
<title>Twitter Sentiment Analysis Using Naive Bayes and N-Gram</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于朴素贝叶斯和N-Gram的Twitter情感分析</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/twitter-sentiment-analysis-using-naive-bayes-and-n-gram-5df42ae4bfc6?source=collection_archive---------6-----------------------#2020-08-12">https://betterprogramming.pub/twitter-sentiment-analysis-using-naive-bayes-and-n-gram-5df42ae4bfc6?source=collection_archive---------6-----------------------#2020-08-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="547f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">分析推文的积极程度</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/21efe719691cd359c76c2f73c803ec31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FoRvsEjXPg4N_Sn5sEc0tQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@ymoran?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">莫兰</a>在<a class="ae ky" href="https://unsplash.com/s/photos/twitter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6bd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将向您展示如何使用两种著名的机器学习算法:朴素贝叶斯和N-Gram，将一条推文分类为正面或负面。</p><p id="a478" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一、什么是情感分析？</p><p id="a43d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">情感分析是分析文本数据并将其分类为积极、消极或中性情感的自动化过程。使用情感分析工具来分析Twitter数据中的观点，可以帮助公司了解人们如何谈论他们的品牌。</em></p><p id="34a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在你知道什么是情感分析了，让我们开始编码吧。</p><p id="1f16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将整个计划分为三个部分:</p><ul class=""><li id="4a81" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">导入数据集</li><li id="8d73" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">数据集的预处理</li><li id="af08" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">应用机器学习算法</li></ul><p id="dc80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">注意:我们已经使用了Jupyter Notebook，但是您也可以使用自己选择的编辑器。</em></p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="5ac3" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">步骤1:导入数据集</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="1b6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示数据集的前十列:</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="ebb8" class="nq ms it nm b gy nr ns l nt nu">data.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/a19395ee92cefb9a55768797a6be132b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6cmRb-qRZK82IBIu6Cf6Pg.png"/></div></div></figure><p id="7c51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的数据集，我们可以清楚地看到以下内容的使用(没有一个在确定推文的情绪方面有任何用处):</p><ul class=""><li id="3dab" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">首字母缩略词</li><li id="bd8a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">重复字符序列</li><li id="fc7a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">情感符(= Smiley)</li><li id="4ab0" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">拼写错误</li><li id="c361" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">名词</li></ul><p id="a00b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看我们的数据集是否围绕标签类情感平衡:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/2020cc7a30e84f58f1aa66f402a0b273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*atCaxG5iHP_ODkt-PbfLNA.png"/></div></figure><p id="3610" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据集似乎在消极情绪和积极情绪之间非常平衡。</p><p id="3a4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们需要导入其他有助于我们进行预处理的数据集，例如:</p><ul class=""><li id="b976" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">一个表情词典将西方最常用的132个表情符号和它们的情绪(积极或消极)重新组合在一起:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="70d6" class="nq ms it nm b gy nr ns l nt nu">emoticons = pd.read_csv('data/smileys.csv')<br/>positive_emoticons = emoticons[emoticons.Sentiment == 1]<br/>negative_emoticons = emoticons[emoticons.Sentiment == 0]<br/>emoticons.head(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/0fb4544aa92036f9c6092be54bbc236f.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*01w208AEBjb48b65hnUMNA.png"/></div></figure><ul class=""><li id="4226" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">5465个首字母缩略词及其翻译的首字母缩略词词典:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="f135" class="nq ms it nm b gy nr ns l nt nu">acronyms = pd.read_csv('data/acronyms.csv')<br/>acronyms.tail(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1caf1873d775414bebf83e8706508e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*2fm8Q2NSe8q7QXhxIem7Iw.png"/></div></figure><ul class=""><li id="c58b" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">一个停用词词典，对应于在处理自然语言数据之前或之后被过滤掉的词，因为它们在我们的例子中没有用。</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="a4ab" class="nq ms it nm b gy nr ns l nt nu">stops = pd.read_csv('data/stopwords.csv')<br/>stops.columns = ['Word']<br/>stops.head(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/94cb91b6137984c0748be52ca825aea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*gzqNZIVU1V8DBRmwSu7czA.png"/></div></figure><ul class=""><li id="05db" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">正面和负面词汇词典:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="9196" class="nq ms it nm b gy nr ns l nt nu">positive_words = pd.read_csv('data/positive-words.csv', sep='<strong class="nm iu">\t</strong>')<br/>positive_words.columns = ['Word', 'Sentiment']<br/>negative_words = pd.read_csv('data/negative-words.csv', sep='<strong class="nm iu">\t</strong>')<br/>negative_words.columns = ['Word', 'Sentiment']<br/>positive_words.head(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/720cf6117418cb971be7711c71358291.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*OolsRGcl4Im175iwFxqfIQ.png"/></div></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="f38e" class="nq ms it nm b gy nr ns l nt nu">negative_words.head(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1ef4cfd3afcc54144de440c34a805c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*B43eRI36ds46QgnwQPNR9g.png"/></div></figure></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="1aff" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">第二步:<strong class="ak">数据集预处理</strong></h1><h2 id="454a" class="nq ms it bd mt oc od dn mx oe of dp nb li og oh nd lm oi oj nf lq ok ol nh om bi translated"><strong class="ak">什么是数据预处理？</strong></h2><p id="54f0" class="pw-post-body-paragraph kz la it lb b lc on ju le lf oo jx lh li op lk ll lm oq lo lp lq or ls lt lu im bi translated"><em class="lv">数据预处理是一种用于将原始数据转换成干净数据集的技术。换句话说，无论何时从不同来源收集数据，都是以原始格式收集的，这对于分析是不可行的。</em></p><p id="8f9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们从预处理部分开始。</p><p id="4993" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们将通过各种步骤传递数据:</p><ul class=""><li id="46e5" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">使用表情词典将所有表情替换为情绪极性<code class="fe os ot ou nm b">||pos||</code> / <code class="fe os ot ou nm b">||neg||</code>:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/5b9b24713543208afe3eb94fbe3c6b70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zU7PW_xiNave0vEq4iLY_w.png"/></div></div></figure><ul class=""><li id="7a45" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">用标签替换所有网址<code class="fe os ot ou nm b">||url||</code>:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="01e5" class="nq ms it nm b gy nr ns l nt nu">pattern_url = re.compile(ur'(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()&lt;&gt;]+|\(([^\s()&lt;&gt;]+|(\([^\s()&lt;&gt;]+\)))*\))+(?:\(([^\s()&lt;&gt;]+|(\([^\s()&lt;&gt;]+\)))*\)|[^\s`!()\[\]<strong class="nm iu">{}</strong>;:<strong class="nm iu">\'</strong>".,&lt;&gt;?\xab\xbb\u201c\u201d\u2018\u2019]))')<br/><br/>url_found = find_with_pattern(pattern_url)</span><span id="c951" class="nq ms it nm b gy ow ns l nt nu">data.SentimentText = find_with_pattern(pattern_url, <strong class="nm iu">True</strong>, '||url||') </span><span id="7e53" class="nq ms it nm b gy ow ns l nt nu">data[50:60]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/c8bb1ca851535ebbd88ec1a5bf3d823b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8HRFB5K2xqX8woEAxhzNgg.png"/></div></div></figure><ul class=""><li id="51c1" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">删除unicode字符:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="4142" class="nq ms it nm b gy nr ns l nt nu">def remove_unicode(string):<br/>    try:<br/>        string = string.decode('unicode_escape').encode('ascii','ignore')<br/>    except UnicodeDecodeError:<br/>        pass<br/>    return string<br/><br/>data.SentimentText = data.SentimentText.apply(lambda tweet: remove_unicode(tweet))</span><span id="a841" class="nq ms it nm b gy ow ns l nt nu">data[1578592:1578602]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/862146e656c5da4fcec028165bb12074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7J7p1kbW8aBfrmoag42Sig.png"/></div></div></figure><ul class=""><li id="0d5e" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">解码HTML实体:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="9d07" class="nq ms it nm b gy nr ns l nt nu">data.SentimentText[599982]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/0aa423d2bfc18b25ca0697d89baf8122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p4jlEE4nI3QzZg6RShINLg.png"/></div></div></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="b9c5" class="nq ms it nm b gy nr ns l nt nu">import HTMLParser  <br/>html_parser = HTMLParser.HTMLParser()  </span><span id="8d4c" class="nq ms it nm b gy ow ns l nt nu">data.SentimentText = data.SentimentText.apply(lambda tweet: html_parser.unescape(tweet)) </span><span id="a10c" class="nq ms it nm b gy ow ns l nt nu">data.SentimentText[599982]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/57dd407976354b2ec1e0a87748884f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NmjsCQcird7y5Q7_h36iAQ.png"/></div></div></figure><ul class=""><li id="6c37" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">将所有字母缩减为小写:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="17f7" class="nq ms it nm b gy nr ns l nt nu">data.SentimentText = data.SentimentText.str.lower() </span><span id="9423" class="nq ms it nm b gy ow ns l nt nu">data.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/dff5ff547eb3d55282c3c21cbf2e6ae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g3ta4lGpkdtlKEf1I0G70g.png"/></div></div></figure><ul class=""><li id="bc34" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">用<code class="fe os ot ou nm b">||target||</code>替换所有用户名/目标<code class="fe os ot ou nm b">@</code>:</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="f657" class="nq ms it nm b gy nr ns l nt nu">pattern_usernames = "@\w{1,}"</span><span id="115e" class="nq ms it nm b gy ow ns l nt nu">usernames_found = find_with_pattern(pattern_usernames)</span><span id="ec1c" class="nq ms it nm b gy ow ns l nt nu">data.SentimentText = find_with_pattern(pattern_usernames, <strong class="nm iu">True</strong>, '||target||')</span><span id="08a6" class="nq ms it nm b gy ow ns l nt nu">data[45:55]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/8167ad163cd1c7fd112fb224997ffa5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*te19mhwy-khwmqNtogMDaQ.png"/></div></div></figure><ul class=""><li id="3c4d" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">将所有缩写替换为其翻译:</li></ul><p id="985d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://gist.github.com/BetterProgramming/fdcccacf21fa02a8a4d697da24a8cd54.js" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/better programming/fdcccacf 21 fa 02 A8 a 4d 697 da 24 A8 CD 54 . js</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/376d1c320c39ea6e6edd903a8010bf28.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/1*TOrtkXbT-_wn90XfNWxMLw.png"/></div></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="a1a6" class="nq ms it nm b gy nr ns l nt nu">for i, (acronym, value) in enumerate(top20acronyms):<br/>    print str(i + 1) + ") " + acronym + " =&gt; " + acronym_dictionary[acronym] + " : " + str(value)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/6d59e64069eb4dee80c4db5cb872de8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*j44SQxkJ2y71C8YUV0hz1g.png"/></div></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="0395" class="nq ms it nm b gy nr ns l nt nu">plt.close()<br/>top20acronym_keys = [x[0] for x in top20acronyms]<br/>top20acronym_values = [x[1] for x in top20acronyms]<br/>indexes = np.arange(len(top20acronym_keys))<br/>width = 0.7<br/>plt.bar(indexes, top20acronym_values, width)<br/>plt.xticks(indexes + width * 0.5, top20acronym_keys, rotation="vertical")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/7a9268760d7296cbd8a682b275b8299a.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*B9W0ag68Cnr89sBwF0S0ZA.png"/></div></figure><ul class=""><li id="966c" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">用标签<code class="fe os ot ou nm b">||not||</code>替换所有的否定(例如:不，不，从不)。</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="c71d" class="nq ms it nm b gy nr ns l nt nu">negation_dictionary = dict(zip(negation_words.Negation, negation_words.Tag))   </span><span id="8223" class="nq ms it nm b gy ow ns l nt nu">def replace_negation(tweet):<br/>     return [negation_dictionary[word] if negation_dictionary.has_key(word) else word for word in tweet]   </span><span id="8f48" class="nq ms it nm b gy ow ns l nt nu">data.SentimentText = data.SentimentText.apply(lambda tweet: replace_negation(tweet)) print data.SentimentText[29]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/96fe1ad0d03d2dcd94054ce307b22be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXbYp-_-6BU9nGatO69VGw.png"/></div></div></figure><ul class=""><li id="6cde" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">用两个字符替换一系列重复的字符(例如:“helloooo”=“helloo”)，以保持单词的强调用法。</li></ul><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="b001" class="nq ms it nm b gy nr ns l nt nu">data[1578604:]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/0fd591d245d17413f20cffb77b777f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W6WaCWfj0JF4O6HOdVVhBw.png"/></div></div></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="8840" class="nq ms it nm b gy nr ns l nt nu">pattern = re.compile(r'(.)\1*')  </span><span id="8bba" class="nq ms it nm b gy ow ns l nt nu">def reduce_sequence_word(word):<br/>     return ''.join([match.group()[:2] if len(match.group()) &gt; 2 else match.group() for match in pattern.finditer(word)]) </span><span id="ce94" class="nq ms it nm b gy ow ns l nt nu">def reduce_sequence_tweet(tweet):<br/>     return [reduce_sequence_word(word) for word in tweet]  </span><span id="f482" class="nq ms it nm b gy ow ns l nt nu">data.SentimentText = data.SentimentText.apply(lambda tweet: reduce_sequence_tweet(tweet)) </span><span id="28b5" class="nq ms it nm b gy ow ns l nt nu">data[1578604:]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/15898c4a5d59863e6000534018163383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mBFeC8w_s0mj_8fmFTwibQ.png"/></div></div></figure><p id="1a77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经完成了Twitter情感分析项目中最重要和最棘手的部分，现在我们可以将我们的机器学习算法应用于处理过的数据集。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="2bd4" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">步骤3: <strong class="ak">应用机器学习算法</strong></h1><h2 id="bb20" class="nq ms it bd mt oc od dn mx oe of dp nb li og oh nd lm oi oj nf lq ok ol nh om bi translated"><strong class="ak">什么是机器学习？</strong></h2><p id="7ed9" class="pw-post-body-paragraph kz la it lb b lc on ju le lf oo jx lh li op lk ll lm oq lo lp lq or ls lt lu im bi translated">机器学习是人工智能(AI)的一种应用，它为系统提供了自动学习和根据经验改进的能力，而无需显式编程。机器学习专注于开发可以访问数据并使用数据进行自我学习的计算机程序。</p><p id="28f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有三种主要的方法用于将句子分类到给定的类别中，在我们的例子中，是肯定的(1)还是否定的(0): SVM、朴素贝叶斯和N-Gram。</p><p id="8180" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们只使用了朴素贝叶斯和N-Gram，它们是确定推文情感最常用的方法。</p><p id="fdc7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从朴素贝叶斯开始。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="1e12" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">朴素贝叶斯</strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/c7b58456cc707d355d691b4461dcf59d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C9NGtgvBex1EwU9ssHKTRw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">坦克</p></figure><p id="2446" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同类型的朴素贝叶斯分类器，但我们将使用多项式朴素贝叶斯。</p><h2 id="d2bf" class="nq ms it bd mt oc od dn mx oe of dp nb li og oh nd lm oi oj nf lq ok ol nh om bi translated"><strong class="ak">基线</strong></h2><p id="afa9" class="pw-post-body-paragraph kz la it lb b lc on ju le lf oo jx lh li op lk ll lm oq lo lp lq or ls lt lu im bi translated">我们使用多项式朴素贝叶斯作为学习算法，拉普拉斯平滑表示进行文本分类的经典方式。因为我们需要从我们的tweets数据集中提取特征，所以我们使用单词袋模型来表示它。</p><p id="666f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词包模型是文档的简化表示，它表示为一个单词包，不考虑语法或词序。在文本分类中，每个词的频率被用作训练分类器的特征。</p><p id="f84e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为简单起见，我们使用库sci-kit-learn。</p><p id="ed95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们首先将数据集分为训练集和测试集:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><ul class=""><li id="1ece" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">训练集的大小:1183958</li><li id="5a6c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">测试集的大小:394654</li></ul><p id="a4a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦创建了训练集和测试集，我们需要第三组数据，称为验证集。这真的很有用，因为它将用于根据看不见的数据验证我们的模型，并调整学习算法的可能参数，以避免欠拟合和过拟合，例如。</p><p id="657f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要这个验证集，因为我们的测试集应该只用于验证模型的泛化能力。如果我们使用测试集而不是验证集，我们的模型可能会过于乐观，扭曲我们的结果。</p><p id="9bf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要创建验证集，有两个主要选项:</p><ul class=""><li id="7679" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">将定型集拆分为两部分(60%/20%)，比例为2:8，其中每个部分包含相等分布的示例类型。我们用最大的部分训练分类器，用较小的部分进行预测，以验证模型。这种技术工作得很好，但缺点是我们的分类器没有在数据集中的所有例子上得到训练和验证(没有计算测试集)。</li><li id="79d6" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">K倍交叉验证。我们将数据集分成k个部分，保留一部分，合并其他部分并对其进行训练，然后根据保留的部分进行验证。我们重复这个过程k次(每次折叠)，每次拿出不同的部分。然后，我们对每个折叠测量的分数进行平均，以获得对我们的模型性能的更准确的估计。</li></ul><p id="6774" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将训练数据分成十份，并使用scikit-learn交叉验证它们:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="b91a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类推文总数:1183958</p><p id="27e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分数:0.77653600187</p><p id="0785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">混淆矩阵:[[465021 126305][136321 456311]]</p><p id="bf76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用我们的基线，我们得到大约0.77。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="fb3a" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">n元语法(语言模型)</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/008af0e3dc3373589553945f111b9dd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32MfG89LqoZ-bhAvLkRenw.png"/></div></div></figure><p id="3022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">注意</em> </strong> <em class="lv">:一个重要的注意事项是，n-gram分类器实际上是朴素贝叶斯的推广。具有拉普拉斯平滑的单字分类器完全对应于传统的朴素贝叶斯分类器。</em></p><p id="35a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们使用单词袋模型，意思是我们把这个句子:“我不喜欢巧克力”翻译成“我”、“不喜欢”、“喜欢”、“巧克力”，我们可以试着使用二元模型来处理这个例子中“不喜欢”的否定。我们仍然要使用拉普拉斯平滑，但是我们使用CountVectorizer中的参数ngram_range来添加二元模型特性。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="efaa" class="nq ms it nm b gy nr ns l nt nu">score, confusion = classify(training_tweets, test_tweets, (2, 2))</span><span id="9da5" class="nq ms it nm b gy ow ns l nt nu">print 'Total tweets classified: ' + str(len(training_tweets)) <br/>print 'Score: ' +  str(score) <br/>print 'Confusion matrix:' print(confusion)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/7ff219cec118be7d3a9375624b31e63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*kLKrNWZF5Rk_WI6yMT430g.png"/></div></figure><p id="7450" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仅使用二元模型特征，我们略微提高了大约0.01的准确度分数。在此基础上，我们可以认为，增加一元和二元应该增加更多的准确性得分。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="84f2" class="nq ms it nm b gy nr ns l nt nu">score, confusion = classify(training_tweets, test_tweets, (1, 2))</span><span id="72e6" class="nq ms it nm b gy ow ns l nt nu">print 'Total tweets classified: ' + str(len(training_tweets))<br/>print 'Score: ' +  str(score)<br/>print 'Confusion matrix:'<br/>print(confusion)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/5e293cd3934dadf9e2a99d6e4c916dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*XxJhvich4-iaTGnVbKd9wQ.png"/></div></figure><p id="ee86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，与基线相比，大约0.02的准确度分数已经有所提高。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="3792" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">结论</h1><p id="3ce0" class="pw-post-body-paragraph kz la it lb b lc on ju le lf oo jx lh li op lk ll lm oq lo lp lq or ls lt lu im bi translated">在这个项目中，我们试图展示一种使用朴素贝叶斯作为基线将推文分为正面或负面类别的基本方法。我们还试图展示语言模型如何与朴素贝叶斯相关，并能产生更好的结果。</p><p id="1e4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们小组的最后一年项目。我们在挖掘细节和为任务选择正确的算法时面临很多挑战。希望你们不用经历同样的过程！</p><p id="ab38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然你已经走了这么远，我就和你们分享<a class="ae ky" href="https://github.com/Sid22031998/Twitter-Sentiment-Analysis" rel="noopener ugc nofollow" target="_blank">代码链接</a>(如果你觉得有帮助的话，给这个库打个星吧)。这是一个帮助有需要的人的公开倡议。</p><p id="5ecf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读这篇文章。希望对大家有帮助！</p></div></div>    
</body>
</html>
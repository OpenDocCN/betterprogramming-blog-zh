<html>
<head>
<title>Kubernetes From Scratch (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的Kubernetes(第二部分)</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/kubernetes-from-scratch-part-2-e30b48f7ca6b?source=collection_archive---------2-----------------------#2020-04-24">https://betterprogramming.pub/kubernetes-from-scratch-part-2-e30b48f7ca6b?source=collection_archive---------2-----------------------#2020-04-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8a6a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">不含Minikube或MicroK8s的Kubernetes</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/32d0d0b0a856a5efe63c51e9dbabbddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SO9zAcpeWcrJALAqRtHvJw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Sven Mieke 在<a class="ae ky" href="https://unsplash.com/s/photos/architecture-plans?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0aa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本系列的文章“从零开始的Kubernetes”中，我讨论了一个最小的Kubernetes系统。现在我想通过使它成为一个更完整的系统来增加这一成功。</p><p id="ac26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你从云提供商那里获得Kubernetes，像存储和入口这样的东西很可能会被提供。核心的Kubernetes系统不提供像Ingress这样的东西，因为这应该与运行它的云系统紧密集成。</p><p id="909c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要继续学习，您应该已经从头开始阅读了"<a class="ae ky" href="https://medium.com/better-programming/kubernetes-from-scratch-4691283e3995" rel="noopener">Kubernetes</a>"并构建了所描述的系统。我们构建的系统是在裸机服务器上的虚拟机中运行的四个节点。只要你有一个类似的设置，你应该可以跟着做一些小的调整。集群节点被命名为<code class="fe lv lw lx ly b">kube1</code>、<code class="fe lv lw lx ly b">kube2</code>、<code class="fe lv lw lx ly b">kube3</code>和<code class="fe lv lw lx ly b">kube4</code>。这个<code class="fe lv lw lx ly b">kube1</code>节点是主人，其余的是工人。主机名为<code class="fe lv lw lx ly b">beast</code>，运行的是Ubuntu 20.04，虚拟机运行的是Ubuntu 18.04。</p><p id="46df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文的后半部分还需要一个我们在我的文章“<a class="ae ky" href="https://medium.com/better-programming/build-your-own-in-home-cloud-storage-1aa74b5c6397" rel="noopener">构建您自己的家庭云存储</a>”中构建的存储服务器该服务器在裸机上运行Ubuntu 20.04，并安装了GlusterFS。</p><p id="2d39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文旨在与云提供商无关。它不是生产系统的蓝图。如果你试图建立一个生产系统，坚持使用云提供商提供的工具。本文通过看到组成系统的各个部分，并带走一点魔力，来了解Kubernetes的内幕。您对Kubernetes的运营方式了解得越多，您在与云提供商合作时就能做出更好的决策。</p><p id="3ea2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们开始添加系统之前，让我们测试一下我们现在运行的系统的各个部分。我的前一篇文章只测试了Kubernetes API的工作情况，并且可以通过<code class="fe lv lw lx ly b">kubectl</code>命令访问。我们应该看看我们是否能实际部署一些东西。我有一句简单的“你好，世界！”图像应该适合测试。因此，回到主主机，创建一个名为<code class="fe lv lw lx ly b">test.yaml</code>的文件，并添加以下内容:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="ca6b" class="md me it ly b gy mf mg l mh mi">kind: Deployment<br/>metadata:<br/>  name: hellok8s-deployment<br/>  labels:<br/>    app: hellok8s<br/>spec:<br/>  selector:<br/>    matchLabels:<br/>      app: hellok8s<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: hellok8s<br/>    spec:<br/>      containers:<br/>      - name: hellok8s<br/>        image: docker.io/rlkamradt/hellok8s:latest<br/>        ports:<br/>        - containerPort: 8080<br/>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: hellok8s-service<br/>spec:<br/>  type: ClusterIP<br/>  selector:<br/>    app: hellok8s<br/>  ports:<br/>  - port: 8080<br/>    targetPort: 8080</span></pre><p id="774f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在用命令<code class="fe lv lw lx ly b">kubectl create -f test.yaml</code>部署它。用<code class="fe lv lw lx ly b">kubectl get all</code>应该能看到。</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="ab64" class="md me it ly b gy mf mg l mh mi">rkamradt@beast:~$ kubectl get all<br/>NAME                                      READY   STATUS    RESTARTS   AGE<br/>pod/hellok8s-deployment-85fdc9d4f-s5z4q   1/1     Running   0          13m</span><span id="957d" class="md me it ly b gy mj mg l mh mi">NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br/>service/hellok8s-service   ClusterIP   10.102.67.208   &lt;none&gt;        8080/TCP   13m<br/>service/kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    4d22h</span><span id="6573" class="md me it ly b gy mj mg l mh mi">NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE<br/>deployment.apps/hellok8s-deployment   1/1     1            1           13m</span><span id="9744" class="md me it ly b gy mj mg l mh mi">NAME                                            DESIRED   CURRENT   READY   AGE<br/>replicaset.apps/hellok8s-deployment-85fdc9d4f   1         1         1       13m</span></pre><p id="c17c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可能需要等待几秒钟，直到pod状态为<code class="fe lv lw lx ly b">Running</code>。现在我们如何测试服务呢？通常你会通过负载平衡器或入口服务来公开它，但是我们还没有这些东西。幸运的是，你可以使用<code class="fe lv lw lx ly b">kubectl</code>的<code class="fe lv lw lx ly b">port-forward</code>子命令。</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="40eb" class="md me it ly b gy mf mg l mh mi">rkamradt@beast:~$ kubectl port-forward service/hellok8s-service 8080:8080<br/>Forwarding from 127.0.0.1:8080 -&gt; 8080<br/>Forwarding from [::1]:8080 -&gt; 8080<br/>Handling connection for 8080</span></pre><p id="bbd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此命令在您完成转发之前不会返回，因此您必须打开一个新的终端来测试服务。</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="9e29" class="md me it ly b gy mf mg l mh mi">rkamradt@beast:~$ curl <a class="ae ky" href="http://localhost:8080" rel="noopener ugc nofollow" target="_blank">http://localhost:8080</a><br/>Hello World</span></pre><p id="1472" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在回到原来的终端窗口，Ctrl-C结束端口转发。</p><p id="b0be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在上一篇文章中创建的Kubernetes集群只有两个节点。从那时到现在，我重复了worker节点的指令来创建另外两个节点，因此我当前运行的系统有一个控制平面节点和三个worker节点。</p><p id="af42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的pod运行在哪个节点上？我们可以使用<code class="fe lv lw lx ly b">kubectl</code>的<code class="fe lv lw lx ly b">describe</code>子命令来了解一下。运行<code class="fe lv lw lx ly b">kubectl get pods</code>找到pod的确切名称及其描述:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="d416" class="md me it ly b gy mf mg l mh mi">rkamradt@beast:~$ kubectl describe pod hellok8s-deployment-85fdc9d4f-s5z4q<br/>Name:         hellok8s-deployment-85fdc9d4f-s5z4q<br/>Namespace:    default<br/>Priority:     0<br/>Node:         kube3/192.168.122.223<br/>...</span></pre><p id="837a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的节点被命名为<code class="fe lv lw lx ly b">kube1-4</code>，所以这个节点运行在第二个worker节点上。您可以使用pod规范中的<code class="fe lv lw lx ly b">nodeSelector</code>属性，使它总是在一个节点上运行，尤其是如果一个节点具有像额外内存或SSD驱动器这样的独特功能。但是大多数时候，让系统决定如何在节点间分配工作是有好处的。</p><p id="9a10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看是否能让所有的节点都工作起来。用这个命令<code class="fe lv lw lx ly b">kubectl scale --replicas=3 deployment hellok8s-deployment</code>放大服务的副本。</p><p id="2166" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在运行<code class="fe lv lw lx ly b">kubectl get all</code>,直到您在就绪栏中看到3/3。在每个pod上运行<code class="fe lv lw lx ly b">describe</code>应该显示pod均匀分布在节点上。如果您将服务进行端口转发，它应该对每个节点进行循环调度。不幸的是，我的<code class="fe lv lw lx ly b">hellok8s</code>应用程序没有记录每个请求，所以我们不能只通过查看日志来判断。我敢肯定，一些Kubernetes大师知道我们如何通过一些其他方式来告诉，但我们会假设它的工作，并处理检查后。</p><p id="6138" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我看到的第一个问题是，我们不想为我们提供的每项服务都运行端口转发。有几种方法可以解决这个问题，如果你使用的是云提供商，他们应该能够为你解决这个问题。但是我们是在裸机上运行，所以我们必须想出自己的解决方案。</p><p id="9bcf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">永久公开服务的两种方法是负载平衡(不要与Kubernetes服务自动为您提供的负载平衡混淆)和入口。Ingress通常仅支持HTTP/HTTPS，但支持高级功能，如虚拟主机或基于路径的路由和SSL终端。负载平衡工作在TCP层，因此它可以公开数据库和消息队列之类的东西。</p><p id="a828" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">过去，我使用了一个负载平衡器，并在主机上设置了一个nginx反向代理。这让我两全其美，尽管这意味着手动配置nginx，这并不十分困难。首先，让我们在集群上安装一个负载平衡器。我对<a class="ae ky" href="https://metallb.universe.tf/" rel="noopener ugc nofollow" target="_blank"> MetalLB </a>有些熟悉，所以让我们看看是否可以在我们的系统上安装并运行它。</p><p id="6069" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，如果您在云提供商而不是裸机上运行本练习，您需要跳过这一部分。MetalLB与大多数云提供商不兼容，这是有充分理由的:云提供商提供他们自己的负载平衡器。请参考您的云提供商的文档，以创建可访问外部IP的负载平衡器。</p><p id="1718" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">安装MetalLB并不太复杂:应用几个YAML文件，并做一些配置。</p><p id="3d3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是首先，根据MetalLB文档，“如果你在IPVS模式下使用kube-proxy，由于Kubernetes v1.14.2，你必须启用严格的ARP模式。”我不知道那是什么意思，但我认为把你的ARP设置成严格模式不会有什么坏处。因此，通过<code class="fe lv lw lx ly b">kubectl edit configmap -n kube-system kube-proxy</code>编辑kube-proxy的配置图，并将<code class="fe lv lw lx ly b">ipvs.strictARP</code>设置为<code class="fe lv lw lx ly b">true</code>。最终，这种改变会在整个系统中发挥作用。然后安装MetalLB:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="76cb" class="md me it ly b gy mf mg l mh mi">kubectl apply -f <a class="ae ky" href="https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml</a><br/>kubectl apply -f <a class="ae ky" href="https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml</a><br/>kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)"</span></pre><p id="930d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后你就可以看到所有用<code class="fe lv lw lx ly b">kubectl get all -n metallb-system</code>创造出来的新东西。上面的第一行创建了一个名称空间<code class="fe lv lw lx ly b">metallb-system</code>，所以要访问所有的片段，您必须使用带有<code class="fe lv lw lx ly b">-n metallb-system</code>的名称空间。值得注意的一点是所有的扬声器豆荚创建，每个节点一个。它创建这些路由来向网络通告它创建的所有路由。这是现代网络魅力的一部分。</p><p id="7350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们到底在用上面的命令做什么？我们使用MetalLB提供的定义文件将自己配置为系统的负载平衡器。现在，任何类型为<code class="fe lv lw lx ly b">LoadBalancer</code>的服务都将自动获得一个IP地址，该地址被路由到我们安装原始系统时创建的VM桥(参见我的文章“<a class="ae ky" href="https://medium.com/better-programming/playing-with-vms-and-kubernetes-26ef93019c22" rel="noopener">使用VM和Kubernetes </a>”)。你可以用<code class="fe lv lw lx ly b">wget</code>上面的YAML文件看看是怎么回事。</p><p id="5d24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在配置之前，MetalLB一直处于休眠状态。为了配置它，我们需要一个在名称空间<code class="fe lv lw lx ly b">metallb-system</code>中名为<code class="fe lv lw lx ly b">config</code>的配置映射。创建一个名为<code class="fe lv lw lx ly b">metallbconfig.yaml</code>的文件，并输入以下内容:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="ff9c" class="md me it ly b gy mf mg l mh mi">apiVersion: v1<br/>kind: ConfigMap<br/>metadata:<br/>  namespace: metallb-system<br/>  name: config<br/>data:<br/>  config: |<br/>    address-pools:<br/>    - name: default<br/>      protocol: layer2<br/>      addresses:<br/>      - 192.168.122.240-192.168.122.250</span></pre><p id="d8d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在应用带有<code class="fe lv lw lx ly b">kubectl apply -f metallbconfig.yaml</code>的配置。</p><p id="3550" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用<code class="fe lv lw lx ly b">layer2</code>配置，并使用<code class="fe lv lw lx ly b">192.168.122.0/24</code>的桥接网络给出一个地址池，最后一个数字范围为240-250。我不确定KVM如何从那个网络分配，所以我玩得有点危险。但是在我的服务器冒烟之前，我只能期待最好的结果。如果你在生产中这样做，你可能会想调查一下。实际上。如果你在生产中这样做，我会因为你没有使用云提供商而解雇你。总之，我们有11个IP地址用于公开服务。</p><p id="2c81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们第二次使用<code class="fe lv lw lx ly b">ConfigMaps</code>，我想提出它的用法。它允许您将应用程序的定义与配置分开。</p><p id="300d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几个好处是显而易见的:首先，您可以在不同的名称空间中拥有不同的<code class="fe lv lw lx ly b">ConfigMaps</code>,所以如果您在不同的名称空间中拥有不同的环境(dev/test/prod ),您可以为每一个都拥有一个配置。这也意味着如果你在不同的微服务中有相似的配置元素，你可以共享<code class="fe lv lw lx ly b">ConfigMaps</code>并确保每个人都在相同的配置页面上。</p><p id="10ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要公开一个服务，可以将其类型设置为<code class="fe lv lw lx ly b">LoadBalancer</code>。如果你的系统有一个负载平衡器提供者(我们现在有)，它会给服务一个永久的IP地址。运行<code class="fe lv lw lx ly b">kubectl edit service/hellok8s-service</code>，将<code class="fe lv lw lx ly b">spec.type</code>从<code class="fe lv lw lx ly b">ClusterIP</code>编辑到<code class="fe lv lw lx ly b">LoadBalancer</code>，然后查看<code class="fe lv lw lx ly b">kubectl get services</code>命令的输出:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="c998" class="md me it ly b gy mf mg l mh mi">rkamradt@beast:~$ kubectl get services<br/>NAME               TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)          AGE<br/>hellok8s-service   LoadBalancer   10.99.129.137   192.168.122.240   8080:30210/TCP   10h<br/>kubernetes         ClusterIP      10.96.0.1       &lt;none&gt;            443/TCP          5d15h</span></pre><p id="1ed6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所见，<code class="fe lv lw lx ly b">hellok8s-service</code>现在有了一个外部IP，<code class="fe lv lw lx ly b">192.168.122.240</code>(你的会有所不同)。用<code class="fe lv lw lx ly b">curl</code>打起来:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="4c48" class="md me it ly b gy mf mg l mh mi">rkamradt@beast:~$ curl <a class="ae ky" href="http://192.168.122.240:8080/" rel="noopener ugc nofollow" target="_blank">http://192.168.122.240:8080/</a><br/>Hello World</span></pre><p id="0826" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嘣！现在，您已经配置了一个负载平衡器，并且可以自动公开多达11个服务。我想开一个关于<em class="mk">到11 </em>的玩笑，但这有失我的身份。</p><p id="32c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一个问题:只有我们的主主机可以看到它托管的桥。如果我们想让主网络看到我们的服务，我们需要建立一个路由。</p><p id="3f35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的家庭网络路由器相当笨重，试图让它做任何花哨的事情都是徒劳的。也许你的路由器运气会更好，但还有另一个选择。我在我的主机上设置了一个nginx反向代理，让它像一个边缘服务器一样工作。所以现在我可以将HTTP从主网络代理到主主机，主主机可以看到桥接网络。同样，请参阅我的文章“<a class="ae ky" href="https://medium.com/better-programming/playing-with-vms-and-kubernetes-26ef93019c22" rel="noopener">使用虚拟机和Kubernetes </a>”了解详细信息。</p><p id="d8c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的系统还缺少什么？到目前为止，我们只公开了打印相同内容的虚拟服务。相当无聊。我们可以通过在组合中添加一个数据库来使事情变得更令人兴奋。但是数据库需要存储东西——它们需要开箱即用，Kubernetes没有可靠的持久存储。我们需要提供一个。当然，有许多供应商可供选择。</p><p id="c810" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你在云提供商上运行，他们会内置持久存储。但是我在客厅角落的一个盒子上运行，所以我必须找到一个存储提供商并安装它，类似于我安装负载平衡器的方式。</p><p id="eea4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在之前的一篇文章“构建你自己的家庭云存储”中，我用GlusterFS搭建了一个盒子。GlusterFS是Kubernetes合作的存储提供商之一。为了能够在您的节点中挂载GlusterFS，您必须对每个节点进行ssh并安装GlusterFS客户端:<code class="fe lv lw lx ly b">sudo apt-get install glusterfs-client</code>。</p><p id="43da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们需要设置一个<code class="fe lv lw lx ly b">Endpoints</code>资源，并将其连接到一个无头服务。下面是我的设置中的<code class="fe lv lw lx ly b">Endpoints</code>资源的样子:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="fc86" class="md me it ly b gy mf mg l mh mi">apiVersion: v1<br/>kind: Endpoints<br/>metadata:<br/>  name: glusterfs-cluster<br/>subsets:<br/>- addresses:<br/>  - ip: 192.168.0.104<br/>  ports:<br/>  - port: 1</span></pre><p id="7bfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的存储主机在<code class="fe lv lw lx ly b">192.168.0.104</code>，端口可以是1-64，000之间的任何数字(它必须是合法值，但除了与下面定义的服务匹配之外，它不被使用)。我只有一个单节点集群，所以它不是弹性的或分布式的，但它能满足我的需要。接下来是无头服务，其定义如下:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="37fe" class="md me it ly b gy mf mg l mh mi">apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: glusterfs-cluster<br/>spec:<br/>  ports:<br/>  - port: 1</span></pre><p id="b9ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">端口会将其匹配到<code class="fe lv lw lx ly b">endpoints</code>。创建这两个文件为<code class="fe lv lw lx ly b">endpoints.yaml</code>和<code class="fe lv lw lx ly b">service.yaml</code>，然后应用它们:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="0958" class="md me it ly b gy mf mg l mh mi">kubectl apply -f endpoints.yaml<br/>kubectl apply -f service.yaml</span></pre><p id="d1c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你在这里做一个<code class="fe lv lw lx ly b">kubectl get all</code>，你会看到一个新服务。要查看端点，可以运行<code class="fe lv lw lx ly b">kubectl get ep</code>和<code class="fe lv lw lx ly b">kubectl decribe ep glusterfs-cluster</code>。</p><p id="f8f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在更新您之前创建的<code class="fe lv lw lx ly b">test.yaml</code>，并将该卷放入pod规范:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="aab8" class="md me it ly b gy mf mg l mh mi">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: hellok8s-deployment<br/>  labels:<br/>    app: hellok8s<br/>spec:<br/>  selector:<br/>    matchLabels:<br/>      app: hellok8s<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: hellok8s<br/>    spec:<br/>      containers:<br/>      - name: hellok8s<br/>        image: docker.io/rlkamradt/hellok8s:latest<br/>        ports:<br/>        - containerPort: 8080<br/>        volumeMounts:<br/>        - mountPath: "/mnt/glusterfs"<br/>          name: glusterfsvol<br/>      volumes:<br/>      - name: glusterfsvol<br/>        glusterfs:<br/>          endpoints: glusterfs-cluster<br/>          path: /gv0<br/>          readOnly: true<br/>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: hellok8s-service<br/>spec:<br/>  type: ClusterIP<br/>  selector:<br/>    app: hellok8s<br/>  ports:<br/>  - port: 8080<br/>    targetPort: 8080</span></pre><p id="65c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">glusterfs:</code>部分指示Kubernetes使用GlusterFS并提供配置参数。<code class="fe lv lw lx ly b">path: /gv0</code>是我们在前一篇文章中创建的卷。现在，删除并重新创建部署:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="f76f" class="md me it ly b gy mf mg l mh mi">kubectl delete -f test.yaml<br/>kubectl apply -f test.yaml</span></pre><p id="a342" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以进入分离舱，看看<code class="fe lv lw lx ly b">/mnt/glusterfs</code>是否在那里。但是等等，有个问题。pod没有启动—它停留在<code class="fe lv lw lx ly b">ContainerCreating</code>状态—所以有些不对劲。让我们做一点故障排除。运行<code class="fe lv lw lx ly b">kubectl describe pod &lt;podname&gt;</code>将排除安装卷的问题。</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="3432" class="md me it ly b gy mf mg l mh mi">Mounting command: systemd-run<br/>Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/6aa61d4b-0673-4b77-a2b6-9e8c990986e9/volumes/kubernetes.io~glusterfs/glusterfsvol --scope -- mount -t glusterfs -o auto_unmount,log-file=/var/lib/kubelet/plugins/kubernetes.io/glusterfs/glusterfsvol/hellok8s-deployment-666fcddc56-lsllq-glusterfs.log,log-level=ERROR,ro 192.168.0.104:/gv0 /var/lib/kubelet/pods/6aa61d4b-0673-4b77-a2b6-9e8c990986e9/volumes/kubernetes.io~glusterfs/glusterfsvol<br/>Output: Running scope as unit: run-r20968ad0da8d4b5380bebfaaba201e23.scope<br/>Mount failed. Please check the log file for more details.<br/>, the following error information was pulled from the glusterfs log to help diagnose this issue: <br/>[2020-04-21 22:54:12.196614] E [fuse-bridge.c:900:fuse_getattr_resume] 0-glusterfs-fuse: 3: GETATTR 1 (00000000-0000-0000-0000-000000000001) resolution failed<br/>The message "E [MSGID: 101046] [dht-common.c:1501:dht_lookup_dir_cbk] 0-gv0-dht: dict is null" repeated 2 times between [2020-04-21 22:54:12.178581] and [2020-04-21 22:54:12.196594]<br/>  Warning  FailedMount  20s  kubelet, kube3  MountVolume.SetUp failed for volume "glusterfsvol" : mount failed: mount failed: exit status 1</span></pre><p id="5265" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基本问题是<code class="fe lv lw lx ly b">resolution failed</code>。但这意味着什么呢？无论我提供的错误消息多或少，在整个错误消息上进行广泛的Google搜索都没有发现任何东西。我尝试了一些事情，比如在每个节点上安装Gluster客户端包。但是什么都没用。</p><p id="dd35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">于是我仔细看了一下<code class="fe lv lw lx ly b">mount</code>命令，找到了<code class="fe lv lw lx ly b">log-level=ERROR</code>。我想如果我能把它换成<code class="fe lv lw lx ly b">log-level=DEBUG</code>，我就能更好地知道哪里出了问题。</p><p id="583d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过进一步挖掘，我发现您可以在卷的规范中指定<code class="fe lv lw lx ly b">mountOptions</code>。但是Kubernetes的精英们决定不允许<code class="fe lv lw lx ly b">mountOptions</code>在线音量定义。</p><p id="848e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们需要更精确的定义。我们需要创建一个<code class="fe lv lw lx ly b">PersistentVolume</code>和一个<code class="fe lv lw lx ly b">PersistentVolumeClaim</code>，然后将<code class="fe lv lw lx ly b">PersistenVolumeClaim</code>附加到pod规范。我认为应该更明确一些，尽管出于本文简洁的目的，我希望通过内嵌的卷定义来保持简单。</p><p id="c614" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们创造一个<code class="fe lv lw lx ly b">PersistentVolume</code>和<code class="fe lv lw lx ly b">PersistentVolumeClaim</code>。首先，创建一个名为<code class="fe lv lw lx ly b">pv.yaml</code>的文件，并添加以下内容:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="f6c5" class="md me it ly b gy mf mg l mh mi">apiVersion: v1<br/>kind: PersistentVolume<br/>metadata:<br/>  name: gluster-pv<br/>  labels:<br/>    pv: gluster-pv<br/>spec:<br/>  capacity:<br/>    storage: 5Gi<br/>  accessModes:<br/>    - ReadWriteOnce<br/>  persistentVolumeReclaimPolicy: Recycle<br/>  mountOptions:<br/>    - log-level=DEBUG<br/>  glusterfs:<br/>    path: /gv0<br/>    endpoints: glusterfs-cluster</span></pre><p id="acbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后创建一个名为<code class="fe lv lw lx ly b">pvc.yaml</code>的文件，并输入以下内容:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="fb5e" class="md me it ly b gy mf mg l mh mi">apiVersion: v1<br/>kind: PersistentVolumeClaim<br/>metadata:<br/>  name: gluster-claim<br/>spec:<br/>  accessModes:<br/>    - ReadWriteOnce<br/>  volumeMode: Filesystem<br/>  resources:<br/>    requests:<br/>      storage: 5Gi</span></pre><p id="bef6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些是对什么是可用的，什么是需要的更明确的定义。<code class="fe lv lw lx ly b">PersistentVolume</code>表示GlusterFS提供了5 GB，并提供了路径和参数。</p><p id="594f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它还允许我们定义<code class="fe lv lw lx ly b">mountOptions</code>，这样我们就可以创建一个更详细的日志。<code class="fe lv lw lx ly b">PersistentVolumeClaim</code>表示，出于某种目的，我们需要5 GB的存储空间。因为我们只有一个持久卷，所以它应该总是与那个相匹配。现在更新<code class="fe lv lw lx ly b">test.yaml</code>文件中的卷。</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="3ffc" class="md me it ly b gy mf mg l mh mi">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: hellok8s-deployment<br/>  labels:<br/>    app: hellok8s<br/>spec:<br/>  selector:<br/>    matchLabels:<br/>      app: hellok8s<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: hellok8s<br/>    spec:<br/>      containers:<br/>      - name: hellok8s<br/>        image: docker.io/rlkamradt/hellok8s:latest<br/>        ports:<br/>        - containerPort: 8080<br/>        volumeMounts:<br/>        - mountPath: "/mnt/glusterfs"<br/>          name: glusterfsvol<br/>      volumes:<br/>      - name: glusterfsvol<br/>        persistentVolumeClaim:<br/>          claimName: gluster-claim<br/>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: hellok8s-service<br/>spec:<br/>  type: ClusterIP<br/>  selector:<br/>    app: hellok8s<br/>  ports:<br/>  - port: 8080<br/>    targetPort: 8080</span></pre><p id="72aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在应用所有内容:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="ece4" class="md me it ly b gy mf mg l mh mi">kubectl apply -f pv.yaml<br/>kubectl apply -f pvc.yaml<br/>kubectl delete -f test.yaml<br/>kubectl apply -f test.yaml</span></pre><p id="6b4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，它仍然不起作用，但是现在我们可以通过SSH进入节点并查看GlusterFS日志。要了解具体情况，请描述pod <code class="fe lv lw lx ly b">kubectl describe pod &lt;podname&gt;</code>。您应该会找到类似下面这样的一行:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="9c9c" class="md me it ly b gy mf mg l mh mi">Normal   Scheduled         32s                   default-scheduler  Successfully assigned default/hellok8s-deployment-7667684f95-tfx9k to kube3<br/>  Warning  FailedMount       32s                   kubelet, kube3     MountVolume.SetUp failed for volume "gluster-pv" : mount failed: mount failed: exit status 1<br/>Mounting command: systemd-run<br/>Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/2a54c709-efea-4af6-8aa8-8a4634f980ae/volumes/kubernetes.io~glusterfs/gluster-pv --scope -- mount -t glusterfs -o auto_unmount,log-file=/var/lib/kubelet/plugins/kubernetes.io/glusterfs/gluster-pv/hellok8s-deployment-7667684f95-tfx9k-glusterfs.log,log-level=DEBUG 192.168.0.104:/gv0 /var/lib/kubelet/pods/2a54c709-efea-4af6-8aa8-8a4634f980ae/volumes/kubernetes.io~glusterfs/gluster-pv</span></pre><p id="80f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到它被部署到<code class="fe lv lw lx ly b">kube3</code>节点，并给出了<code class="fe lv lw lx ly b">log-file</code>路径。所以SSH连接到节点，而<code class="fe lv lw lx ly b">cat</code>连接到日志。我们应该会看到更多的日志线，这将为我们提供一些关于哪里出错的线索。</p><p id="bc95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终，我找到了线<code class="fe lv lw lx ly b">DNS resolution failed on host artful</code>。我发现这很奇怪，因为在Kubernetes的描述中我只使用了IP地址——它怎么知道这个名字<code class="fe lv lw lx ly b">artful</code>？</p><p id="f357" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">答案是GlusterFS将关于使用主机名而不是IP地址的卷的元数据发送回客户端。为了测试这一点，我编辑了<code class="fe lv lw lx ly b">kube3</code>上的<code class="fe lv lw lx ly b">/etc/hosts</code>，并为<code class="fe lv lw lx ly b">artful</code>添加了一行。几分钟后，Kubernetes自动再次尝试挂载该卷，并且成功了！</p><p id="97c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以用<code class="fe lv lw lx ly b">kubectl exec -it &lt;podname&gt; -- /bin/sh</code>查看一下pod内部，这将显示一个在pod内部运行的shell。然后，您可以<code class="fe lv lw lx ly b">ls /mnt/glusterfs</code>查看我们在“<a class="ae ky" href="https://medium.com/better-programming/build-your-own-in-home-cloud-storage-1aa74b5c6397" rel="noopener">构建您自己的家庭云存储</a>”中测试存储时创建的文件</p><p id="0160" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是对Kubernetes系统进行故障诊断时必须做的一个小例子。能够<code class="fe lv lw lx ly b">ssh</code>进入您的节点，在您的pod内打开一个外壳，并在您的pod陷入非就绪状态时使用describe命令解决问题，这是您找出问题所在的工具。</p><p id="bb10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，在所有节点上编辑<code class="fe lv lw lx ly b">/etc/hosts</code>并不是正确的答案——可能有更好的方法。也许在GlusterFS的配置中，我们应该只使用IP地址。但是我将只在所有节点上编辑<code class="fe lv lw lx ly b">/etc/hosts</code>，因为我只有三个工作节点(pods通常不在主节点上运行)，并且我不打算再添加任何节点。一旦我这样做了，我们就可以看看我们是否能为我们的解决方案找到一个目的(想想数据库)。</p><p id="77dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们会做一个MongoDB数据库——谁不爱Mongo？这将允许我们了解一些我以前没有介绍过的功能。Mongo将在由一个<code class="fe lv lw lx ly b">StatefulSet</code>创建的pod中运行，这些pod类似于副本集，除了它们有非常具体的pod创建限制。</p><p id="abd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，a <code class="fe lv lw lx ly b">StatefulSet</code>用顺序号来命名pod，而不是你通常看到的最后一组数字的随机数。它还可以一次启动一个，这样当它们启动时，吊舱就不会互相踩踏。不过，对于我们的目的来说，这些都无关紧要，因为我将只启动一个pod。您可以尝试扩大规模，看看会发生什么，但为了一开始就保持简单，我坚持使用单个pod。</p><p id="4947" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我要做的另一件事是添加一个用户名/密码密码，这样我们就不必在描述文件中显式地设置它。让我们从这个开始。创建Kubernetes秘密的方法有很多，但最简单的方法是在命令行中使用文字值:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="bdf9" class="md me it ly b gy mf mg l mh mi">kubectl create secret generic mongo-secret \<br/>    --from-literal=username=mongo \<br/>    --from-literal=password=ognom</span></pre><p id="21dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这并不完全是超级秘密，但是在真实环境中，您可能会从文件或其他地方获得值。从Kubernetes 1.14开始，您可以使用Kustomize来生成随机密码，并将其放入secrets中。但这只是一个演示，展示了一旦秘密被创造出来，如何使用它们。一旦创建完毕，你可以使用<code class="fe lv lw lx ly b">kubectl describe secret mongo-secret</code>来查看关于这个秘密的信息。显然，实际值是隐藏的。</p><p id="d904" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以创建我们的<code class="fe lv lw lx ly b">StatefulSet</code>。创建一个名为<code class="fe lv lw lx ly b">mongo.yaml</code>的文件，并输入以下内容:</p><pre class="kj kk kl km gt lz ly ma mb aw mc bi"><span id="6778" class="md me it ly b gy mf mg l mh mi">apiVersion: apps/v1<br/>kind: StatefulSet<br/>metadata:<br/>  name: mongodb<br/>spec:<br/>  serviceName: database<br/>  replicas: 1<br/>  selector:<br/>    matchLabels:<br/>      app: database<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: database<br/>        selector: mongodb<br/>    spec:<br/>      containers:<br/>      - name: mongodb<br/>        image: mongo:4.0.8<br/>        env:<br/>          - name: MONGO_INITDB_ROOT_USERNAME<br/>            valueFrom:<br/>              secretKeyRef:<br/>                name: mongo-secret<br/>                key: username<br/>          - name: MONGO_INITDB_ROOT_PASSWORD<br/>            valueFrom:<br/>              secretKeyRef:<br/>                name: mongo-secret<br/>                key: password<br/>        volumeMounts:<br/>        - name: mongodb-data<br/>          mountPath: /data/db<br/>      volumes:<br/>      - name: mongodb-data<br/>        persistentVolumeClaim:<br/>          claimName: gluster-claim</span></pre><p id="603b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在运行<code class="fe lv lw lx ly b">kubectl apply -f mongo.yaml</code>，等待它启动。最终，应该会有一个叫做<code class="fe lv lw lx ly b">mongodb-0</code>的pod，我们可以用<code class="fe lv lw lx ly b">kubectl exec -it mongodb-0 — /bin/sh</code>在里面启动一个shell。从那里，您可以访问MongoDB shell: <code class="fe lv lw lx ly b">mongo mongodb://localhost:27017</code>。嘭！你被录取了。</p><p id="2d61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您必须启动一个服务来从其他pod访问数据库。也许在我的下一篇文章中，我会这样做，并编写一个访问数据库的REST服务。现在，如果您想向自己证明它确实有效，您可以回到您的存储主机(在我的例子中是<code class="fe lv lw lx ly b">artful</code>)并查看我们设置为砖块的目录。现在里面应该有一堆数据库文件。</p><p id="ac98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你和我一样，在完成这一切的过程中获得了很多乐趣，包括一些小的故障排除。曾经有过令人沮丧的时候，但那只是增加了事情实际运作时的成就感。本文的所有脚本都可以在最终版本的<a class="ae ky" href="https://github.com/rkamradt/KubernetesFromScratchScripts/tree/v1.0" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Image Segmentation in Python (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的图像分割(下)</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/image-segmentation-python-7a838a464a84?source=collection_archive---------2-----------------------#2020-08-17">https://betterprogramming.pub/image-segmentation-python-7a838a464a84?source=collection_archive---------2-----------------------#2020-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9d41" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过从训练数据集中移除背景来提高模型准确性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ccf9a932f042b5c082c6b98db0784d6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ijKKaSRhQpYommYOn9E7Hg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">插图鸣谢:作者</p></figure><p id="2ee4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">卡在付费墙后面？点击</em> <a class="ae lv" href="https://medium.com/better-programming/image-segmentation-python-7a838a464a84?source=friends_link&amp;sk=64fb47244786896746949ece7ae92b76" rel="noopener"> <em class="lu">此处</em> </a> <em class="lu">阅读全文与我的朋友链接。</em></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="b93d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欢迎回来！</p><p id="d966" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是关于图像分类的三部分系列的第二部分。如果您还没有阅读过本系列的第1部分，我建议您先阅读一下(下面的链接)。我已经详细介绍了设置环境和使用Google Colab中Google Drive的图像数据的细节。我们将在这里使用该代码的输出。</p><div class="md me gp gr mf mg"><a href="https://medium.com/better-programming/introduction-to-image-augmentation-in-python-1691cbf8901f" rel="noopener follow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd iu gy z fp ml fr fs mm fu fw is bi translated">Python中的图像增强简介</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">通过扩展训练数据集来防止模型过度拟合</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">medium.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu ks mg"/></div></div></a></div></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="417f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">图像分割</strong>是“将一幅数字图像分割成多个片段”的过程。因为我们只关心这里的背景去除，我们将把图像分为前景和背景。</p><p id="a3b7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这包括五个基本步骤:</p><ol class=""><li id="ca95" class="mv mw it la b lb lc le lf lh mx ll my lp mz lt na nb nc nd bi translated">将图像转换为灰度。</li><li id="805d" class="mv mw it la b lb ne le nf lh ng ll nh lp ni lt na nb nc nd bi translated">对图像应用阈值处理。</li><li id="41c5" class="mv mw it la b lb ne le nf lh ng ll nh lp ni lt na nb nc nd bi translated">找到图像轮廓(边缘)。</li><li id="de02" class="mv mw it la b lb ne le nf lh ng ll nh lp ni lt na nb nc nd bi translated">使用最大的轮廓创建一个遮罩。</li><li id="0843" class="mv mw it la b lb ne le nf lh ng ll nh lp ni lt na nb nc nd bi translated">在原始图像上应用蒙版以移除背景。</li></ol><p id="7fb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将解释和编码每一步。前进！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="14a0" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">设置工作空间</h1><p id="4e85" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated"><em class="lu">如果您已经完成了第一部分，并且一直执行到最后，您可以跳过这一部分。</em></p><p id="326c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于那些没有，只是来学习图像分割的人，我假设你知道Colab是如何工作的。如果您不同意，请浏览第一部分。</p><p id="5b02" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据集在处<a class="ae lv" href="https://drive.google.com/drive/folders/1qSSQJndVtmcTn9q_YxeIbRPNKf0lkEqM?usp=sharing" rel="noopener ugc nofollow" target="_blank">可用。这是第一部分代码的结果。在登录到您的Google帐户时打开链接，以便它可以在您的Google Drive的“与我共享”文件夹中找到。然后打开</a><a class="ae lv" href="http://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>，连接到一个运行时，并把你的Google Drive挂载到上面:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/94f0d1aa299ced9c2ea5cdffd893f9d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-B1nWjijg_B9xF3k.png"/></div></div></figure><p id="76cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">跟随URL，选择您用来访问数据集的Google帐户，并向您的驱动器授予Colab权限。将授权码粘贴到单元格输出的文本框中，您将得到消息<code class="fe oh oi oj ok b">Mounted at /gdrive</code>。</p><p id="3cd1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后我们导入所有必要的库:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="0e31" class="op nk it ok b gy oq or l os ot">import cv2<br/>import glob<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from PIL import Image<br/>import random<br/>from tqdm.notebook import tqdm</span><span id="48ee" class="op nk it ok b gy ou or l os ot">np.random.seed(1)</span></pre><p id="5fe6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的笔记本现在设置好了！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="82ac" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">从驱动器读取图像</h1><p id="0f43" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">如果您正在使用本文中共享的链接中的数据，那么您的路径将是<code class="fe oh oi oj ok b">‘/gdrive/<strong class="la iu">Shared with me</strong>/LeafImages/color/Grape*/*.JPG’</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/e669ff5fe00cec5c45debaba8cf57a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F0whA6is_H6zwyv35phj-w.png"/></div></div></figure><p id="25da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那些遵循第一部分并使用整个训练集的人应该看到4062条路径。</p><p id="e279" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们从路径中加载图像，并将它们保存到NumPy数组中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/d25d00604264a3354a914eb6c91a3996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*1yrX_rR-qqaLRK-vSxsIHw.png"/></div></figure><p id="3b1b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(20，256，256，3)的形状表示我们有20个256x256大小的图像，有三个颜色通道。</p><p id="e9d0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看这些图像是什么样子的:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="a7af" class="op nk it ok b gy oq or l os ot">plt.figure(figsize=(9,9))</span><span id="3411" class="op nk it ok b gy ou or l os ot">for i, img in enumerate(orig[0:16]):<br/>    plt.subplot(4,4,i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(img)</span><span id="9355" class="op nk it ok b gy ou or l os ot">plt.suptitle("Original", fontsize=20)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/08e93e5c5fc27d107618c84e2c63bf08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*ozhlnpjkwGdZWanyc1JG4A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原始图像</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="eaaa" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">灰度等级</h1><p id="68dd" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">分割的第一步是将图像转换成灰度。灰度化是从图像中移除颜色并仅通过强度来表示每个像素的过程，0表示黑色，255表示白色。</p><p id="1fa6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">OpenCV让这变得简单:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/83348482468716381a72cb98a51ed3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fuOmrNbF5E5Z1M80F1ziHg.png"/></div></div></figure><p id="409b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以从形状中看出颜色通道已经被移除。</p><p id="44d9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显示转换后的图像:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="11d9" class="op nk it ok b gy oq or l os ot">plt.figure(figsize=(9,9))</span><span id="71b0" class="op nk it ok b gy ou or l os ot">for i, img in enumerate(gray[0:16]):<br/>    plt.subplot(4,4,i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(cv2.cvtColor(img, cv2.COLOR_GRAY2RGB))</span><span id="55f1" class="op nk it ok b gy ou or l os ot">plt.suptitle("Grayscale", fontsize=20)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/891841926fe90f017561f42c2cc81253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*3vLbJtc-attQuTKaEPiF0w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">灰度图像</p></figure><p id="f03f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在第一幅图像中，我们可以看到第一个像素(左上角)是白色的，而左下角的像素是黑色的。这可以通过检查第一幅图像的像素阵列来验证:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/bf004c973c21fa20c4cbca472c85bbed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*je6bKFc5EHrtSnAQH8CAqg.png"/></div></figure><p id="5b44" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，左上角的像素是白色(255)，左下角的像素是黑色(0)。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="8eab" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">阈值处理</h1><p id="c6fd" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">在图像处理中，阈值处理是从灰度图像创建二值图像的过程。二进制图像的像素只能有两个值，即0(黑色)或255(白色)。</p><p id="3a73" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在最简单的阈值情况下，您选择一个值作为阈值，任何高于该值的像素都变成白色(255)，而任何低于该值的像素都变成黑色(0)。查看<a class="ae lv" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html" rel="noopener ugc nofollow" target="_blank"> OpenCV图像阈值处理文档</a>了解更多类型和相关参数。</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="cac7" class="op nk it ok b gy oq or l os ot">thresh = [cv2.threshold(img, np.mean(img), 255, cv2.THRESH_BINARY_INV)[1] for img in tqdm(gray)]</span></pre><p id="8e36" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">传递给<code class="fe oh oi oj ok b">cv2.threshold()</code>的第一个参数是要转换的灰度图像，第二个是阈值，第三个是当像素超过阈值时分配给像素的值，最后是阈值类型。</p><p id="0d61" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe oh oi oj ok b">cv2.threshold()</code>返回两个值，第一个是使用<code class="fe oh oi oj ok b">cv2.THRESH_OTSU</code>时自动计算的最佳阈值，第二个是实际的阈值对象。因为我们只关心对象，所以我们下标<code class="fe oh oi oj ok b">[1]</code>来在我们的<code class="fe oh oi oj ok b">thresh</code>列表中只追加第二个返回值。</p><p id="e304" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以选择一个静态阈值，但这样就无法考虑不同照片的不同光照条件。我选择了<code class="fe oh oi oj ok b">np.mean()</code>，它给出了图像像素的平均值。较亮的图像的值将大于127.5 (255/2)，而较暗的图像的值将较小。这使您可以根据图像的光照条件来设定图像的阈值。</p><p id="2ae2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于第一幅图像，阈值是126.34，这意味着该图像比平均值稍暗。任何大于此值的像素将被转换为白色，小于此值的像素将被转换为黑色。但是等等！如果你注意到灰度图像，叶子比背景暗。如果我们应用正常的阈值，较暗的像素变成黑色，而较亮的像素变成白色。这将在叶子上应用黑色遮罩，而不是背景。为了解决这个问题，我们使用了<code class="fe oh oi oj ok b">THRESH_BINARY_INV</code>方法，它反转了阈值处理过程。现在，亮度大于阈值的像素将变成黑色，亮度小于阈值的像素变成白色。</p><p id="984f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看第一个阈值图像的像素强度:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/7aee215d0a8b6ae9b021b9daf05e3d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*32Gh6jLrUTCXZ4_hDJBM2w.png"/></div></figure><p id="3de8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，灰度阵列中较亮的像素(顶行)现在是黑色的，而较暗的像素(底行)现在是白色的。</p><p id="fbd3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看阈值图像来验证:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/95960962401089b988e7f500ea576029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*dAO_HGbEfsTEJZ-OkUoJSg.png"/></div></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="9e87" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">边缘检测</h1><p id="82dc" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">顾名思义，边缘检测是在图像中寻找对象边界(边缘)的过程。在我们的情况下，它将是白色和黑色像素之间的边界。</p><p id="c8dc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">OpenCV允许您使用<a class="ae lv" href="https://docs.opencv.org/2.4/modules/imgproc/doc/feature_detection.html?highlight=canny" rel="noopener ugc nofollow" target="_blank"> Canny算法</a>来实现这一点。</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="1369" class="op nk it ok b gy oq or l os ot">edges = [cv2.dilate(cv2.Canny(img, 0, 255), None) for img in tqdm(thresh)]</span></pre><p id="faea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">扩张是一种噪声去除技术，它有助于将边缘的断开部分连接在一起，以便它们形成连续的轮廓。在这里阅读更多关于边缘检测<a class="ae lv" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html" rel="noopener ugc nofollow" target="_blank">中的其他噪声去除技术。你也可以用它们做实验，看看结果是否更好看。</a></p><p id="f44f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的0和255分别是下阈值和上阈值。您可以在文档中了解它们的用法。在我们的例子中，因为图像已经设定了阈值，所以这些值并不重要。</p><p id="580e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们绘制边缘:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="f9fc" class="op nk it ok b gy oq or l os ot">plt.figure(figsize=(9,9))</span><span id="570d" class="op nk it ok b gy ou or l os ot">for i, edge in enumerate(edges[0:16]):<br/>    plt.subplot(4,4,i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(cv2.cvtColor(edge, cv2.COLOR_GRAY2RGB))</span><span id="aa76" class="op nk it ok b gy ou or l os ot">plt.suptitle("Edges", fontsize=20)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/0cdc5ac24796fc262683c75253d5e5c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*p4PgHj3qLDOhN2Y4DKDyTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">边缘检测</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="01ac" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">屏蔽和分段</h1><p id="4d18" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">终于来了。这涉及到相当多的步骤，所以为了容易理解，我将暂时不列出理解的内容。</p><p id="ce40" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">遮罩是从图像创建遮罩以应用于另一个图像的过程。我们采用掩模，并将其应用于原始图像，以获得最终的分割图像。</p><p id="13f4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们想从我们的图像中掩盖背景。为此，我们首先需要找到边缘(已经完成)，然后按面积找到最大的轮廓。假设这将是前景对象的边缘。</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="99c8" class="op nk it ok b gy oq or l os ot">cnt = sorted(cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2], key=cv2.contourArea)[-1]</span></pre><p id="bc37" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这已经是屈指可数了——我们来解剖一下吧！</p><p id="d191" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先我们找到所有的轮廓。如果您想了解第二个和第三个参数的细节，那么<a class="ae lv" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html" rel="noopener ugc nofollow" target="_blank">文档</a>还是您的好朋友。这将返回图像、轮廓和轮廓层次。因为我们只需要轮廓，所以我们用<code class="fe oh oi oj ok b">[-2]</code>对其下标，以检索倒数第二个返回的项目。因为我们必须找到面积最大的轮廓，所以我们将整个函数包装在<code class="fe oh oi oj ok b">sorted()</code>中，并使用cv2.contourArea作为键。因为默认情况下sorted按升序排序，所以我们选择最后一个带有<code class="fe oh oi oj ok b">[-1]</code>的项目，它给出了最大的轮廓。</p><p id="a02c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后我们创建一个和我们的图像<code class="fe oh oi oj ok b">mask = np.zeros((256,256), np.uint8)</code>一样大小的黑色画布。我称之为“面具”，因为这将是面具后，前景已被删除。</p><p id="935e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了生动化它，我们合并了蒙版上最大的轮廓，并用白色<code class="fe oh oi oj ok b">cv2.drawContours(mask, [cnt], -1, 255, -1))</code>填充。在我们的例子中，第三个参数<code class="fe oh oi oj ok b">-1</code>是要绘制的轮廓的数量。因为我们已经选择了最大的轮廓，所以您可以在这里使用1或-1(全部)。第二个参数是填充颜色。既然我们有单通道，想用白色填充，那就是<code class="fe oh oi oj ok b">255</code>。最后是厚度。</p><p id="cbcc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">既然一张图胜过千言万语，下面这张仓促制作的插图可以让这个过程简单一点，便于理解:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/92b45687f8e3067d755dd6ade2c0471c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVW38qbKvTp_0Gr-nw3OPw.png"/></div></div></figure><p id="2427" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我想你可以猜到最后一步——在原图上叠加最终蒙版，有效去除背景。</p><p id="c4dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这可以使用<code class="fe oh oi oj ok b">bitwise_and</code>操作来完成。这个<a class="ae lv" href="https://www.geeksforgeeks.org/arithmetic-operations-on-images-using-opencv-set-2-bitwise-operations-on-binary-images/" rel="noopener ugc nofollow" target="_blank">教程</a>将帮助你理解它实际上是如何工作的。</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="48e6" class="op nk it ok b gy oq or l os ot">dst = cv2.bitwise_and(orig, orig, mask=mask)</span></pre><p id="1098" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们只需将这一部分放入一个循环中，将所有的遮罩和分割图像附加到它们各自的数组中，这样我们就可以最终看到我们的工作是什么样子了:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="f234" class="op nk it ok b gy oq or l os ot">masked = []<br/>segmented = []</span><span id="a2e1" class="op nk it ok b gy ou or l os ot">for i, img in tqdm(enumerate(edges)):<br/>    cnt = sorted(cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2], key=cv2.contourArea)[-1]<br/>    mask = np.zeros((256,256), np.uint8)<br/>    masked.append(cv2.drawContours(mask, [cnt],-1, 255, -1))<br/>    dst = cv2.bitwise_and(orig[i], orig[i], mask=mask)<br/>    segmented.append(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))</span></pre><p id="177b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">绘制遮罩:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="9cc8" class="op nk it ok b gy oq or l os ot">plt.figure(figsize=(9,9))</span><span id="2f72" class="op nk it ok b gy ou or l os ot">for i, maskimg in enumerate(masked[0:16]):<br/>    plt.subplot(4,4,i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(maskimg, cmap='gray')</span><span id="f394" class="op nk it ok b gy ou or l os ot">plt.suptitle("Mask", fontsize=20)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/554c908bfb478e6f8e405da4520d639a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*RfOJu_FtLQ_KhtH3NijyJg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">面具</p></figure><p id="2903" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以及最终的分割图像:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="0a42" class="op nk it ok b gy oq or l os ot">plt.figure(figsize=(9,9))</span><span id="8bc1" class="op nk it ok b gy ou or l os ot">for i, segimg in enumerate(segmented[0:16]):<br/>    plt.subplot(4,4,i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(cv2.cvtColor(segimg, cv2.COLOR_BGR2RGB))</span><span id="2576" class="op nk it ok b gy ou or l os ot">plt.suptitle("Segmented", fontsize=20)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/f75a63186533bdceb5769c67a2b8023d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*MyhrdtPVPZtcDpFpGUQrJQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分割图像</p></figure><p id="11c0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后我们可以最后将这些图像放在一个单独的“分段”文件夹中:</p><pre class="kj kk kl km gt ol ok om on aw oo bi"><span id="305d" class="op nk it ok b gy oq or l os ot">import os</span><span id="9893" class="op nk it ok b gy ou or l os ot">for i, image in tqdm(enumerate(segmented)):<br/>    directory = paths[i].rsplit('/', 3)[0] + '/segmented/' + paths[i].rsplit('/', 2)[1]+ '/'<br/>    os.makedirs(directory, exist_ok = True)<br/>    cv2.imwrite(directory + paths[i].rsplit('/', 2)[2], image)</span></pre></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="cf9b" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">期待更好的结果？</h1><p id="ec9b" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">这只是对该过程的介绍——我们没有深入研究参数，因此结果远非完美。尝试找出哪一步引入了失真，并思考如何改进这一步。正如我前面所说的，<a class="ae lv" href="https://docs.opencv.org/master/d2/d96/tutorial_py_table_of_contents_imgproc.html" rel="noopener ugc nofollow" target="_blank"> OpenCV图像处理教程</a>是一个很好的起点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/e39b1f37013f86917c17a09ecd958717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6c69RHO9vUtZhwsvQ4vNyg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">灰度&gt;阈值&gt;边缘&gt;蒙版</p></figure><p id="a8e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我很想在评论中看到你的结果，并了解你是如何实现的！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="2082" class="nj nk it bd nl nm nn no np nq nr ns nt jz nu ka nv kc nw kd nx kf ny kg nz oa bi translated">敬请关注…</h1><p id="7f98" class="pw-post-body-paragraph ky kz it la b lb ob ju ld le oc jx lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">你可以在这里找到我用的<a class="ae lv" href="https://colab.research.google.com/drive/1ZrSlb0X11eGTy9SpSJAXuSaSkSmy70VX?usp=sharing" rel="noopener ugc nofollow" target="_blank">的Colab笔记本</a>。</p><p id="570b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">三部曲的第二部到此结束。请继续关注最后一部分，我们将使用这些分割图像来训练一个非常基本的图像分类器。它的链接将在发布后添加到这里。</p><p id="6f0a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读，花束和砖块欢迎！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="4584" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Medium仍然不支持向印度以外的作者支付费用。如果你喜欢我的内容，你可以给我买杯咖啡:)</p><div class="md me gp gr mf mg"><a href="https://www.buymeacoffee.com/siddhantsadangi" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd iu gy z fp ml fr fs mm fu fw is bi translated">Siddhant Sadangi正在Streamlit上创建python网络应用程序</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">嘿👋我刚刚在这里创建了一个页面。你现在可以给我买杯咖啡了！</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">www.buymeacoffee.com</p></div></div><div class="mp l"><div class="ph l mr ms mt mp mu ks mg"/></div></div></a></div></div></div>    
</body>
</html>
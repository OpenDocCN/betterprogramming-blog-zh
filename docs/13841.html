<html>
<head>
<title>How To Train YOLOv5 For Recognizing Game Objects In Real-Time</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何训练YOLOv5实时识别游戏物体</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-train-yolov5-for-recognizing-custom-game-objects-in-real-time-9d78369928a8?source=collection_archive---------2-----------------------#2022-10-03">https://betterprogramming.pub/how-to-train-yolov5-for-recognizing-custom-game-objects-in-real-time-9d78369928a8?source=collection_archive---------2-----------------------#2022-10-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a828" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本文将研究如何在自定义数据集上使用Python和PyTorch训练YOLOv5进行对象检测和识别。对于本例，数据集将包含一个名为Albion Online的游戏中的对象。</h2></div><div class="ki kj kk kl gt ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/0d4d26601eaa7a29b2378ef10183a9e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6j_a7XRtmGFHD-6OCpMPKg.png"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/d0e99fd25bb78c693b7fb897019e11a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1_Bb23Dyjb1SQAwkEmrh1w.png"/></div></figure></div><div class="ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/3ef17cb96d1cb06f1a23eb9ebef9df68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*gy_POFaQ6FFeRALkYWzVgg.png"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/ae115ddf6e66728506a4c31c409b3642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*oR7ZITneity4lC3wTyEc3A.png"/></div></figure></div><p id="6600" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前几天，我在YouTube频道<a class="ae lv" href="https://www.youtube.com/c/LearnCodeByGaming" rel="noopener ugc nofollow" target="_blank">“通过游戏学习代码”上看了一系列关于如何编写游戏机器人的节目</a>在名为<a class="ae lv" href="https://www.youtube.com/watch?v=XrCAvs9AePM" rel="noopener ugc nofollow" target="_blank">“训练级联分类器——游戏#8中的OpenCV对象检测”</a>的视频中，作者展示了他如何构建一个简单的对象分类器。</p><p id="1861" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现那个视频的结果很鼓舞人心。因此，我认为通过使用更高级的分类算法来改善这些结果会很有趣。这就是我如何使用Python和PyTorch开始试验YOLOv5对象检测算法的。本文的内容就是基于这些实验。</p><p id="3212" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在接下来的内容中，我将向你展示如何从一款名为<a class="ae lv" href="https://albiononline.com/en/home" rel="noopener ugc nofollow" target="_blank"> Albion Online </a>的免费游戏中截图。这些截图也将被编辑为隐私，因为多个球员将是可见的。这不会对后来的物体检测和识别产生影响。</p><p id="34d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随后，我将向您展示如何在Albion Online的游戏世界的特定区域中标记代表基本资源的游戏对象。一旦被标记，标签和截图都将被用作YOLOv5算法的训练和验证数据。结果将是我们数据的新PyTorch模型。</p><p id="391d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我将向您展示如何将经过训练的PyTorch模型导出为针对快速推断而优化的TensorRT模型。这是(准)实时推理所必需的，因此可以在玩游戏的同时进行物体检测和识别。</p><h1 id="a0b0" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">从你的游戏中截图</h1><p id="00f9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们从一些<a class="ae lv" href="https://albiononline.com/en/home" rel="noopener ugc nofollow" target="_blank"> Albion Online </a>游戏的截图开始。所以一定要安装游戏——它是免费的。另外，请注意，我将在Windows上工作。</p><p id="1b5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面你可以找到我用来截图的代码。</p><figure class="ki kj kk kl gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="05f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您需要首先启动游戏，然后运行Python脚本。</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="da11" class="na lx it mw b gy nb nc l nd ne">python screenshot.py</span></pre><p id="2f29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，您可以随时按“f”键进行截图。</p><p id="7fd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当按下“f”键时，你还需要确保上面程序的窗口被选中——也就是说，它在前台。这不是超级方便，但是很管用。您将看到一条消息，说明当您正确按键时，屏幕截图已被拍摄。</p><p id="bc4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，Albion网络游戏有白天/夜晚周期。因此，你需要截屏覆盖整个循环，让所有游戏对象的颜色变化出现在数据集中。</p><p id="0b2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦所有的截图都被拍摄下来，我选择编辑它们以保护隐私。这意味着涂黑我自己的玩家头像的名字，也涂黑其他玩家的名字。</p><p id="bde9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">涂黑我自己的球员的名字很容易，因为这个名字总是出现在相同的地方。为此，我写了下面一小段代码。</p><figure class="ki kj kk kl gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="4f63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他球员的名字不能用这种方式涂掉，因为他们总是出现在不同的地方。实际上我最后手动把它们涂黑了。</p><p id="e0b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面，您可以看到一些用于训练YOLOv5网络的最终图像数据的示例。</p><div class="ki kj kk kl gt ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/620206becdbb44451a74c53fbf05370e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*DHlz6zNDS9iHv1Npz-BaCQ.jpeg"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/7e546d6262c116b8da1d5a46add4dbdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*m_BI2AYTerFR4zAMU7g6Ig.jpeg"/></div></figure></div><div class="ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/bf8657722da8342e0c39c712c22d26b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*4QKcrJKnC7tE-BaczDnQZA.jpeg"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/ceeacfb4539bd0f3fe4b24b1273db1c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*0od1GGw0HWD4A5L8Z1qsNA.jpeg"/></div></figure></div><h1 id="2b1f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">使用Make Sense应用程序进行标注</h1><p id="94a4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们将使用<a class="ae lv" href="http://www.makesense.ai" rel="noopener ugc nofollow" target="_blank"> makesense.ai </a>进行对象检测的图像标记。</p><p id="646b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在开始之前，创建一个名为<em class="nf"> labels.txt </em>的文件，标签的顺序与您在标签应用程序中输入的顺序相同。</p><p id="96d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面，你可以看到我做了什么。</p><figure class="ki kj kk kl gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5e1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当你启动<a class="ae lv" href="https://www.makesense.ai/" rel="noopener ugc nofollow" target="_blank"> Make Sense应用</a>时，你首先需要输入所有你想要注释的图像的文件名。然后点击“物体检测”</p><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ng"><img src="../Images/ea7947fb1816327969cf49c0ce8c9668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A6J1AskyiE-bXTtDvQQiMg.png"/></div></div></figure><p id="2354" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，您可以输入label.txt文件，如下图所示，然后单击“创建标签列表”</p><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ng"><img src="../Images/9b97a48c9c104de81bdc8ce23ba75fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQShvrdEfRDWaTin9kt3gg.png"/></div></div></figure><p id="77cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每一张截图中，你都需要在需要识别的对象周围画出矩形。</p><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nh"><img src="../Images/2d5293bf525f3313e7ac94159d6161a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TYA_f1T8gv-ZCUhZJNVrvg.png"/></div></div></figure><p id="92ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">确保正确标记图像中的对象。如果你只是犯了几个错误，那应该不是什么大问题，因为人工智能算法应该会把它们作为噪音过滤掉。</p><p id="1fd9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成后，因为我们使用的是YOLOv5，所以需要选择将图像标注导出为YOLO格式。</p><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nh"><img src="../Images/4757a0f7070264eba94e8f255418c9ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ArjSbQzlMw2UY1qc-QHqw.png"/></div></div></figure><p id="fe23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我建议你在开始真正注释所有图像之前，先用一小组图像来玩一下Make Sense应用程序。像这样，你就可以知道这个应用程序是如何工作的。</p><h1 id="c28d" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">基于图像和标签创建数据集</h1><p id="2260" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">正如你在上面的截图中看到的，我在279张图片中标注了物体。</p><p id="14c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是将数据集分成训练集和验证集。我决定将251幅图像放在训练集中，将28幅图像放在验证集中。这些图像需要放在各自的目录中。</p><p id="8b1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们从Make Sense导出的标签也需要这样做。确保标签位于正确的目录中。所以如果图像nr。0005在<em class="nf"> train_data/image/val </em>目录中，那么属于0005的标签需要在<em class="nf"> train_data/labels/val </em>目录中。</p><p id="f4b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">按如下方式订购包含图像和标签的目录:</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="4303" class="na lx it mw b gy nb nc l nd ne">D:.<br/>├───test_data<br/>└───train_data<br/>    ├───images<br/>    │   ├───train<br/>    │   └───val<br/>    └───labels<br/>        ├───train<br/>        └───val</span></pre><p id="ed73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，在<em class="nf"> test_data </em>目录下，我选择了一些我横向镜像的随机截图。这是为了看看我们训练的模型是否对翻转的图像有效。</p><p id="506f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面我创建了一个名为<em class="nf"> ready_data.yaml </em>的文件，它包含了训练、验证和测试数据集的路径，还包含了网络应该能够识别的类。训练YOLOv5网络需要这个文件。</p><figure class="ki kj kk kl gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="b725" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">使用迁移学习训练YOLOv5</h1><p id="c9f1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">一旦我们创建并设置了数据集，我们就可以使用迁移学习来训练YOLOv5网络。</p><p id="4481" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要安装<a class="ae lv" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLOv5 </a>。实现这一点的一种方法如下:</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="1a0a" class="na lx it mw b gy nb nc l nd ne">git clone <a class="ae lv" href="https://github.com/ultralytics/yolov5.git" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5.git</a><br/>cd yolov5<br/>pip install -r requirements.txt</span></pre><p id="b674" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保你可以使用PyTorch的GPU进行训练和推理，你可能需要<a class="ae lv" href="https://www.datasciencelearner.com/assertionerror-torch-not-compiled-with-cuda-enabled-fix/" rel="noopener ugc nofollow" target="_blank">安装cuda版本</a>。因为我安装了CUDA Toolkit 11.5，所以我运行PIP如下:</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="c5ca" class="na lx it mw b gy nb nc l nd ne">pip install torch==1.11.0+cu115 torchvision==0.12.0+cu115 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu115</span></pre><p id="d024" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，为了在我们的数据集上训练YOLOv5网络，您需要编写以下代码。</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="881d" class="na lx it mw b gy nb nc l nd ne">python train.py --img 640 --batch 2 --epochs 240 --data ../PROJECT/ready_data.yaml --weights yolov5s.pt --cache --device 0 --workers 2</span></pre><p id="ffde" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">名为<code class="fe ni nj nk mw b">yolo5s.pt</code>的模型会自动下载。根据您使用的GPU，您可以增加批次的数量。如果您想查看选项的完整列表，您可以在编辑器中打开<em class="nf"> train.py </em>文件。</p><p id="0217" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦完成训练，模型和附加信息将出现在名为<em class="nf"> runs/train/exp </em>的目录中。困惑矩阵总是能提供很多信息。</p><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nl"><img src="../Images/aad5a36e3b1e432f36e22ab87d635afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zCBwmh39nJDXw2vpy1mIDA.png"/></div></div></figure><p id="1c11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以使用新的网络模型对我们的测试集进行推理。</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="3f44" class="na lx it mw b gy nb nc l nd ne">python detect.py --weights runs/train/exp/weights/best.pt --img 640 --source ../PROJECT/ready_data/test_data/ --conf-thres 0.65</span></pre><p id="e7cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我将<code class="fe ni nj nk mw b">--conf-thres</code>(置信度阈值)设置得相对较高，以删除一些不需要的重复检测。</p><p id="6f32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果将出现在名为<em class="nf">运行/检测/实验</em>的目录中。</p><div class="ki kj kk kl gt ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/cc1b08071dffbaf1704d5c0a69f6f243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*XlRKe3R8TH7CBqa-wb9Qig.jpeg"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/30edde46d7f5b8ecfbe3c48791f549c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*aoTEspV0lB09uxsF16CwrA.jpeg"/></div></figure></div><div class="ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/a2b63fe874f1616ca47d905503623a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*PZ_iq-yM53Q4LVw5buz10w.jpeg"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/a862d01449e40bc77c6582911ff6c1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*B84vQEgnwh7vIE_a3jrmcQ.jpeg"/></div></figure></div><h1 id="c77e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">将模型转换为TensorRT以进行快速推理</h1><p id="2a3a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了使用我们新学习的YOLOv5网络模型进行实时推理——在我们的例子中是游戏的流捕获——我们需要将网络模型导出到一种运行速度比基本PyTorch模型快得多的类型。</p><p id="edd9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有几种可能性，但我选择使用TensorRT网络类型进行快速推断。然而，不幸的是，为Python安装TensorRT并不像许多其他Python包那样简单。</p><p id="25cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是NVidia为<a class="ae lv" href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html" rel="noopener ugc nofollow" target="_blank">安装tensort</a>提供的指南。你可以试着通过PIP 安装它，但是这对我不起作用。我最终通过Zip文件安装了TensorRT。</p><p id="2d26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦安装了TensorRT，我就可以从YOLOv5运行导出功能。</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="63a2" class="na lx it mw b gy nb nc l nd ne">python export.py --weights ../best_albion.pt --include engine --half --device 0</span></pre><p id="498b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我写了一段代码，对来自Albion网游的截图进行实时推断。</p><figure class="ki kj kk kl gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="6579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要运行推理代码，请启动Albion在线游戏，并确保玩家位于用于创建数据集的区域。然后用下面的代码开始上面的代码:</p><pre class="ki kj kk kl gt mv mw mx my aw mz bi"><span id="0e72" class="na lx it mw b gy nb nc l nd ne">python albion_test.py</span></pre><p id="c8a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面，你可以看到结果。</p><figure class="ki kj kk kl gt kn"><div class="bz fp l di"><div class="nm mu l"/></div></figure><h1 id="3d32" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">参考</h1><p id="e440" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae lv" href="https://docs.ultralytics.com/" rel="noopener ugc nofollow" target="_blank"> YOLOv5文档</a></p><p id="7d57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://www.youtube.com/watch?v=GRtgLlwxpc4" rel="noopener ugc nofollow" target="_blank">YouTube上DeepLearning的“用定制数据进行YOLOv5训练”</a></p><p id="e084" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://www.youtube.com/watch?v=XrCAvs9AePM" rel="noopener ugc nofollow" target="_blank">“训练级联分类器——8号游戏中的OpenCV对象检测”，由YouTube上的“通过游戏学习代码”</a></p><p id="b8bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="http://makesense.ai" rel="noopener ugc nofollow" target="_blank">说得通艾</a></p><p id="5373" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://albiononline.com/en/home" rel="noopener ugc nofollow" target="_blank">阿尔比恩在线MMORPG </a></p><p id="0bf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://www.datasciencelearner.com/assertionerror-torch-not-compiled-with-cuda-enabled-fix/" rel="noopener ugc nofollow" target="_blank">“assertion error:torch未在启用cuda的情况下编译(修复)”由数据科学学习团队完成</a></p><p id="17d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://stackoverflow.com/questions/53900910/typeerror-can-t-convert-cuda-tensor-to-numpy-use-tensor-cpu-to-copy-the-tens" rel="noopener ugc nofollow" target="_blank">"类型错误:无法将CUDA张量转换为numpy。"来自StackOverflow </a></p><p id="3f70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html" rel="noopener ugc nofollow" target="_blank"> NVidia TensorRT文档—安装指南</a></p><p id="c381" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://github.com/ultralytics/yolov5/issues/251" rel="noopener ugc nofollow" target="_blank">“TF lite，ONNX，CoreML，TensorRT Export”关于YOLOv5 Github问题</a></p><p id="8cd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://stackoverflow.com/questions/67244258/how-to-get-class-and-bounding-box-coordinates-from-yolov5-predictions" rel="noopener ugc nofollow" target="_blank">“如何从YOLOv5预测中获取类和边界框坐标？”来自StackOverflow </a></p></div></div>    
</body>
</html>
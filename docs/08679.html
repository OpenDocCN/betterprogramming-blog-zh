<html>
<head>
<title>Core ML Background Removal in SwiftUI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SwiftUI中的核心ML背景移除</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/coreml-image-segmentation-background-remove-ca11e6f6a083?source=collection_archive---------0-----------------------#2021-05-29">https://betterprogramming.pub/coreml-image-segmentation-background-remove-ca11e6f6a083?source=collection_archive---------0-----------------------#2021-05-29</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="8df8" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">使用DeepLabV3图像分割模型在iOS应用程序中添加、移除和修改图像背景</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/f4c038c0402a85a4fd7efe12d72195a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*23fg3RS5cCiPYXCre629-Q.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">由<a class="ae kz" href="https://unsplash.com/photos/HRZUzoX1e6w" rel="noopener ugc nofollow" target="_blank">布鲁克·卡吉尔</a>在<a class="ae kz" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的原始照片。作者的最终结果。</p></figure><p id="b9c9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><a class="ae kz" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank"> Core ML </a>是苹果的移动机器学习框架，可以让你在设备上部署、运行和重新训练模型。</p><p id="2d20" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">从文本和声音到图像识别，使用Core ML可以实现的事情是无限的。除此之外，还有Vision，这是苹果自己的计算机视觉框架，提供了六种以上的内置模型。更重要的是，它充当了Core ML的容器，使预处理和推断变得更加容易。</p><p id="8801" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在本教程中，我们将实现移动设备上最流行的机器学习用例之一:iOS应用程序中的图像分割。</p><p id="4502" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">图像分割是一种深度学习机制，让我们能够分离图像中的不同对象。这是自动驾驶汽车中常用的计算机视觉技术，用于在图像的特定部分绘制边界框。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj lw"><img src="../Images/831bc5c9645cede90a5008cf61481c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*TvcpIDoIU30HDhxGHkCxsg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:<a class="ae kz" href="https://developer.apple.com/machine-learning/models/" rel="noopener ugc nofollow" target="_blank">苹果开发者</a></p></figure><p id="a84d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在接下来的几节中，我们将使用DeepLabV3模型在SwiftUI应用程序中分割图像的前景和背景部分。通过这样做，您将能够添加、删除和修改照片的背景。毕竟，谁不想用漂亮的虚拟背景来翻转他们无聊的背景风景呢？</p><p id="14f0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">别再浪费时间了，让我们开始吧。</p></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="c2bc" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">获取DeepLab核心ML模型</h1><p id="5fc0" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">以前，你必须从Pytorch和Tensorflow等其他格式转换它，但现在苹果为我们提供了一个可下载的核心ML文件，可以直接在Xcode中使用。可以从<a class="ae kz" href="https://developer.apple.com/machine-learning/models/" rel="noopener ugc nofollow" target="_blank">苹果的机器学习页面</a>获取DeepLabV3 CoreML模型。</p><p id="5166" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">使用SwiftUI作为我们的用户界面启动一个新的Xcode项目，并拖放上面的核心ML文件。您应该会看到如下所示的核心ML模型描述:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nb"><img src="../Images/bbb51f9c6fb95427652b65deebb6caf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*03oy-AgP2kjNZllCjY7xTw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">Xcode核心ML浏览器。作者截图。</p></figure><p id="b58b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">输入类型是一个尺寸为513 x 513的<code class="fe nc nd ne nf b">Image</code>，而输出是一个尺寸相同的<code class="fe nc nd ne nf b">MLMultiArray</code>。我们很快就会看到如何将输出类型转换成我们想要的图像格式。</p><p id="ba15" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">但是首先，让我们设置一下SwiftUI视图。</p></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="c013" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">设置我们的SwiftUI视图</h1><p id="87be" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">下面的代码在屏幕上显示两个等距的图像。左边的是输入图像，右边的将最终显示分割结果。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ng nh l"/></div></figure><p id="82d8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">注意:SwiftUI按钮<code class="fe nc nd ne nf b">action </code>中调用的<code class="fe nc nd ne nf b">runVisionRequest</code>函数是我们实现核心ML图像分割的地方。</p><p id="e4ab" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">以下是当前SwiftUI视图的屏幕截图:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ni"><img src="../Images/e5d0fb465e5dc1a1df2513ffae06be66.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*A0b1EBazpwI5EGEWkgYfgQ.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">iOS模拟器。作者截图。</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="2863" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">使用视觉请求运行图像分割</h1><p id="3c69" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">接下来，让我们设置视觉请求以运行DeepLabV3图像分割模型:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ng nh l"/></div></figure><p id="e5aa" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们可以从上面的代码中得到一些启示:</p><ul class=""><li id="c29e" class="nj nk iu lc b ld le lg lh lj nl ln nm lr nn lv no np nq nr bi translated">核心ML在iOS 14中弃用了默认的init方法(<code class="fe nc nd ne nf b">DeepLabV3()</code>)，所以我们使用了新的<code class="fe nc nd ne nf b">init(configuration:)</code>。</li><li id="4b2d" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><code class="fe nc nd ne nf b">VNCoreMLModel</code>是核心ML模型的容器。我们需要这种格式来使用<code class="fe nc nd ne nf b">VNCoreMLRequest</code>执行视觉处理。</li><li id="8ce1" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated">一旦<code class="fe nc nd ne nf b">VNCoreMLRequest</code>完成，它触发完成处理函数。在我们的例子中，我们在一个<code class="fe nc nd ne nf b">visionRequestDidComplete</code>函数中定义了它。</li><li id="5e35" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><code class="fe nc nd ne nf b">VNImageRequestHandler</code>功能是触发我们视觉请求的地方。我们在这里传递输入图像(Vision对其进行预处理以匹配模型输入大小),并在<code class="fe nc nd ne nf b">handler.perform</code>函数中设置<code class="fe nc nd ne nf b">VNCoreMLRequest</code>。</li></ul></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="6939" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">从输出中检索分段掩码</h1><p id="f5c1" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">一旦<code class="fe nc nd ne nf b">VNImageRequest</code>完成，我们可以在下面定义的<code class="fe nc nd ne nf b">visionRequestDidComplete</code>完成处理器中处理结果:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ng nh l"/></div></figure><p id="6057" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">从上面的代码中可以得出一些推论:</p><ul class=""><li id="593c" class="nj nk iu lc b ld le lg lh lj nl ln nm lr nn lv no np nq nr bi translated">视觉图像分析返回的输出是一个字典:<code class="fe nc nd ne nf b"><a class="ae kz" href="https://developer.apple.com/documentation/vision/vncoremlfeaturevalueobservation" rel="noopener ugc nofollow" target="_blank">VNCoreMLFeatureValueObservation</a></code>。</li><li id="8a32" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated">包含我们的分割图的<code class="fe nc nd ne nf b">MLMultiArray</code>位于字典的第一个键中。</li><li id="b162" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated">我们需要将2D阵列分割图转换成一个<code class="fe nc nd ne nf b">UIImage</code>。为了做到这一点，我使用了Matthijs Hollemans的CoreMLHelper工具来减少我们编写的样板代码。您可以在本教程的末尾找到该代码。</li><li id="79ed" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><code class="fe nc nd ne nf b">segmentationmap.image(min: 0, max: 1)</code>辅助函数将<code class="fe nc nd ne nf b">MLMultiArray</code>转换为<code class="fe nc nd ne nf b">UIImage</code>，然后我们可以调整其大小以匹配初始图像的大小。</li><li id="279d" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><code class="fe nc nd ne nf b">resizedImage</code>是我写的一个<code class="fe nc nd ne nf b">UIImage</code> Swift扩展。在这个要点中有<a class="ae kz" href="https://gist.github.com/anupamchugh/75fed37246f77ed68b3061f242847c51" rel="noopener ugc nofollow" target="_blank">可用。</a></li><li id="66f1" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><code class="fe nc nd ne nf b">maskInputImage()</code>功能是我们用分割结果屏蔽我们的初始图像，以产生新的背景。</li></ul><p id="09f3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在我们的分割蒙版已经准备好了，让我们来看看它:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nx"><img src="../Images/9914dffc0d472b972f935b3d4b85da56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w0YOmA_F75Itoz7Mi0Nj1w.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">iOS模拟器。作者截图。</p></figure><p id="c69b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">太好了！我们的分割遮罩通过对每组像素使用不同的颜色来将前景图像从背景中分离出来。</p><p id="f0f9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，是时候复习一下我们的<code class="fe nc nd ne nf b">CoreImage</code>技巧了，在图像上混合蒙版。</p></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="e88e" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">使用分段遮罩修改背景</h1><p id="ad3d" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated"><a class="ae kz" href="https://developer.apple.com/documentation/coreimage" rel="noopener ugc nofollow" target="_blank">核心图像</a>是苹果的图像处理库。它提供了各种各样的图像过滤器可供选择。</p><p id="a547" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我们的例子中，我们需要混合原始图像上的分割蒙版，以便隐藏背景。此外，我们想添加一个新的背景。</p><p id="f91a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">核心图像的<code class="fe nc nd ne nf b">CIBlendWithMask</code>滤镜非常适合我们的情况。下面来看看它是如何运作的:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ny"><img src="../Images/db5eb9ed97579c3a7f0832e0c18ac4ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgTVs9bSplgnougwbFuuWA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:<a class="ae kz" href="https://developer.apple.com/library/archive/documentation/GraphicsImaging/Reference/CoreImageFilterReference/index.html#//apple_ref/doc/filter/ci/CIBlendWithMask" rel="noopener ugc nofollow" target="_blank">苹果开发者</a>。作者添加的文本。</p></figure><p id="c346" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">让我们来看看<code class="fe nc nd ne nf b">maskInputImage</code>函数，我们的<code class="fe nc nd ne nf b">CIBlendWithMask</code>过滤器运行于此:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ng nh l"/></div></figure><p id="ed20" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">以下是对这段代码的一些重要观察:</p><ul class=""><li id="5206" class="nj nk iu lc b ld le lg lh lj nl ln nm lr nn lv no np nq nr bi translated"><code class="fe nc nd ne nf b">imageFromColor</code>是一个<a class="ae kz" href="https://gist.github.com/anupamchugh/6aefb0fc8043fa7fe584e99e7e8f2e2c" rel="noopener ugc nofollow" target="_blank">快速扩展</a>，将纯色转换成UIImage。我们传递颜色、输入图像大小和<code class="fe nc nd ne nf b">scale</code>。设置相同的比例对于确保<code class="fe nc nd ne nf b">CGImage</code>尺寸与我们的原始图像相匹配非常重要。否则，核心图像<code class="fe nc nd ne nf b">CIBlendWithMask</code>滤镜会产生失真的结果。</li><li id="cff3" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated"><code class="fe nc nd ne nf b">CIBlendWithMask</code>滤波器需要三个参数键:<code class="fe nc nd ne nf b">kCIInputImageKey</code>、<code class="fe nc nd ne nf b">kCIInputBackgroundImageKey</code>和<code class="fe nc nd ne nf b">kCIInputMaskImageKey</code>。</li><li id="cfda" class="nj nk iu lc b ld ns lg nt lj nu ln nv lr nw lv no np nq nr bi translated">从过滤器返回的<code class="fe nc nd ne nf b">outputImage</code>是一个CIImage。要将其转换为UIImage，我们首先使用<code class="fe nc nd ne nf b">createCGImage</code>将其转换为CGImage。</li></ul><p id="be33" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">背景发生变化的图像的最终输出如下所示:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nz"><img src="../Images/7cf79a0081d3e6b1e80e375e75afb642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55C_FXdzFxkuaByTXHzKbw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">iOS模拟器。作者截图。</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="f80c" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">在图像中混合渐变背景</h1><p id="1f84" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">除了纯色，你可以添加任何图像作为你的主题的背景。让我们设置渐变颜色。</p><p id="9e61" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我已经使用<a class="ae kz" href="https://stackoverflow.com/a/44866438/3849039" rel="noopener ugc nofollow" target="_blank">这个堆栈溢出</a>答案来实现渐变的UIImage扩展。结果如下:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oa"><img src="../Images/da596c29aea9fdadccf583ade622d932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JbBYeKaTxODm9ys1HI5hyw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">iOS模拟器。作者截图。</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="040a" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">更有趣</h1><p id="0415" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我们看到了如何通过SwiftUI实现使用Core ML和Vision来删除和修改图像中的背景。你可以做更多的事情，比如模糊背景或者只隐藏背景图像的一部分。</p><p id="5f67" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">只是为了好玩，我把背景换成了埃菲尔铁塔:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/d82c63a60ffc409ea58381cfaa41ad8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AO--X3PYVmekLygQiN4ZNA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">Lucas Albuquerque 在<a class="ae kz" href="https://unsplash.com/s/photos/eiffel-tower?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。与核心ML模型一起改变。</p></figure><pre class="kk kl km kn gu ob nf oc od aw oe bi"><span id="343c" class="of mf iu nf b gz og oh l oi oj">let bgImage = UIImage(named: "tower")!.resized(to: self.inputImage.size, scale: self.inputImage.<strong class="nf iv">scale</strong>)</span></pre><p id="ead8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我不能强调对背景图像使用相同的<code class="fe nc nd ne nf b">scale</code>来确保它适合视图是多么重要。</p><p id="f3d5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这个项目的完整源代码可以在这个<a class="ae kz" href="https://github.com/anupamchugh/iowncode/tree/master/CoreMLBackgroundChangeSwiftUI" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><p id="208d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这一次到此为止。尝试对一群人使用一张图片，看看效果如何。这里有一个例子:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ok"><img src="../Images/55d89bf9d81f18b538a2cb570c7cf479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8Wsl1v4dc2i5kctA77kOw.jpeg"/></div></div></figure></div></div>    
</body>
</html>
<html>
<head>
<title>Regression, Machine Learning, and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归、机器学习和Python</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/regression-in-machine-learning-c733cac6fcbc?source=collection_archive---------5-----------------------#2020-04-10">https://betterprogramming.pub/regression-in-machine-learning-c733cac6fcbc?source=collection_archive---------5-----------------------#2020-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="63e2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让我们建立一个使用回归的模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a976d4e894b1b3b7ec7abe3f52815b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R77xmjSGhGPp23l5U9Werw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">里卡多·戈麦斯·安吉尔在<a class="ae kv" href="https://unsplash.com/s/photos/pattern?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="87e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一、什么是<em class="ls">回归</em>？</p><p id="06bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">回归</strong>是一种用于金融、投资和其他学科的统计方法，试图确定一个因变量(通常用Y表示)和一系列其他变量(称为自变量)之间关系的强度和特征。你可以查看<a class="ae kv" href="https://www.investopedia.com/terms/r/regression.asp" rel="noopener ugc nofollow" target="_blank">这里</a>更深入的定义。</p><p id="8aad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在统计学中，线性回归是一种建模标量响应(或因变量)与一个或多个解释变量(或自变量)之间关系的线性方法。只有一个解释变量的情况称为简单线性回归。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="a1d8" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">学习目标</strong></h1><p id="dea3" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">在本文结束时，您将了解到以下内容:</p><ol class=""><li id="b1b5" class="mx my iq ky b kz la lc ld lf mz lj na ln nb lr nc nd ne nf bi translated">回归中的一些术语</li><li id="82bc" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">对回归背后理论的深入探究</li><li id="9b65" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">如何做一些基本的预处理和数据探索</li><li id="5df2" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">回归算法的类型以及如何实现它们</li><li id="49d3" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">回归问题中使用的一些评估指标</li></ol></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="da96" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak"> <em class="nl">先决条件</em> </strong></h1><ol class=""><li id="452e" class="mx my iq ky b kz ms lc mt lf nm lj nn ln no lr nc nd ne nf bi translated">你有机器学习的基础知识。可以查一下我之前的<a class="ae kv" href="https://medium.com/@Koikibabatunde1/introduction-to-machine-learning-7697477a5e40" rel="noopener">文章</a>了解一下机器学习的基础知识。</li><li id="da2d" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">良好的Python基础知识，直到函数，是必需的。可以看看这个<a class="ae kv" href="https://www.w3schools.com/python/default.asp" rel="noopener ugc nofollow" target="_blank"> w3 schools python教程</a>。</li><li id="54d7" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">还需要Numpy和熊猫的基本知识。你可以看看这个关于熊猫的<a class="ae kv" href="https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/" rel="noopener ugc nofollow" target="_blank">黑客地球教程。</a></li><li id="0f07" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">高中代数和统计的基础知识是必须的。不要担心，如果你有数学恐惧症，这篇文章会尽可能简单，让任何人都能理解。</li></ol></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="ed9a" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">回归术语</strong></h1><ol class=""><li id="a66c" class="mx my iq ky b kz ms lc mt lf nm lj nn ln no lr nc nd ne nf bi translated"><strong class="ky ir">功能:</strong>从一组输入到一组可能的输出的关系，其中每个输入恰好与一个输出相关。</li><li id="ac05" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">关联</strong>:两个或两个以上事物之间的相互关系或联系。也是变量的相互依赖。</li><li id="2a98" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">特征/独立变量:</strong>我们传递到函数中进行预测的变量。</li><li id="7874" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">目标/因变量</strong>:被预测的变量。</li><li id="6d83" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">统计测试:提供了一种对一个或多个过程进行定量决策的机制。</li><li id="dcfd" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">简单线性回归:</strong>具有一个特征的回归问题，其中特征和目标之间的关系是线性的。</li><li id="42bd" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">多元线性回归:</strong>具有多个特征的回归问题，其中特征和目标之间的关系是线性的。</li><li id="9583" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">非线性回归:</strong>特征和目标之间的关系不是线性的回归问题。</li><li id="dca4" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">斜率/权重:</strong>斜率是函数生成的线的“陡度”，也就是俗称的<em class="ls">上升超过运行</em>。统计权重是增加或减少项目重要性的数量。</li><li id="8d26" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">截距/偏差:</strong>是统计技术或其结果的一个特征，由此结果的期望值不同于被估计的真实潜在定量参数。</li><li id="01ae" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><strong class="ky ir">回归残差:</strong>在回归分析中，因变量的观测值(y)与预测值(ŷ)之差称为残差(e)。残差=观察值-预测值。e = y — ŷ.残差的和与均值都等于零。</li></ol></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="c09a" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak"> <em class="nl">简单线性回归</em> </strong></h1><div class="kg kh ki kj gt ab cb"><figure class="np kk nq nr ns nt nu paragraph-image"><img src="../Images/3b240012c2f7a7635b932cfb98ccd797.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*OQ2LYx9A6LsADPORD5N9JQ.png"/></figure><figure class="np kk nv nr ns nt nu paragraph-image"><img src="../Images/60acea068154346ff42cc045624d7577.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*ldBTCJRYi36MHq7X-l3ZPA.png"/><p class="kr ks gj gh gi kt ku bd b be z dk nw di nx ny translated">简单线性回归信用<a class="ae kv" href="http://researchgate.net" rel="noopener ugc nofollow" target="_blank">研究门</a></p></figure></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/377ccb320a6341f9d50b189ff6f819f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:212/1*ZVp9nGrLtMcoQ4ZCun2f1w.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单线性回归方程</p></figure><p id="de19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在简单的线性回归中，只有一个独立变量x1。b是权重，b0是偏差。从上面的图表中，我们可以看到，并不是所有的数据点都直接符合这条线；因此，我们有所谓的残余误差。我们知道这个误差的和与均值等于0。</p><p id="3893" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，我们如何知道我们的预测/模型是否是好的呢？我们将在本文的后面讨论这个问题。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="15cb" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">多元线性回归</strong></h1><div class="kg kh ki kj gt ab cb"><figure class="np kk oa nr ns nt nu paragraph-image"><img src="../Images/642fd11980bb37bff8d802a2449054ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*1GA4Ydfe09apzHyoRTnzEQ.jpeg"/></figure><figure class="np kk oa nr ns nt nu paragraph-image"><img src="../Images/f8f577656877e9c29e6254350189ce48.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*5nnzIUyschyGGqsUpB6xWg.jpeg"/><p class="kr ks gj gh gi kt ku bd b be z dk ob di oc ny translated">多元线性回归</p></figure></div><div class="ab cb"><figure class="np kk od nr ns nt nu paragraph-image"><img src="../Images/c8595442bfebb4e4b7332f78e3f06e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/1*LRzayxjr08iq3595hV9nxQ.gif"/></figure><figure class="np kk oe nr ns nt nu paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/6a12673204f27b283d5c706515b15306.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*76_v7-EK3oZIUA_A-MXfAw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk of di og ny translated">多元线性回归方程</p></figure></div><p id="6a71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">多元线性回归中，自变量x1，x2，x3，…，xp不止一个。b是权重，每个特征分别有自己唯一的权重b1，b2，b3，…，bp，b0是偏差。从上面的图表来看。我们可以看到，并不是所有的数据点都直接符合这条线；因此，我们有所谓的残余误差。我们知道这个误差的和与均值等于0。可以通过这篇<a class="ae kv" href="http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704-EP713_MultivariableMethods/BS704-EP713_MultivariableMethods2.html" rel="noopener ugc nofollow" target="_blank">文章</a>更好的学习MLR。</p><p id="e46a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文的其余部分，我们将使用scikit learn库中的波士顿数据集。</p><p id="48f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用一些特征来预测房子的价格。这里的目标不是获得非常高的准确性，而是学习如何使用不同的模型进行预测。最后，我们将看看评估指标。</p><h2 id="d35d" class="oh mb iq bd mc oi oj dn mg ok ol dp mk lf om on mm lj oo op mo ln oq or mq os bi translated"><strong class="ak"> 1。导入数据</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/f4e80dcf2ea2f372c9df4789be90656d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SK3pZG2Ik3TOOITjjeavYg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/d2f17625d8ab92e2ec6fedf5f4876211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TJFp8fGKphdUHfLYH5BFQg.png"/></div></div></figure><p id="f7e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从<strong class="ky ir"> boston_dataset.keys()，</strong>的输出中，我们看到四个值，分别是数据、目标、特征名和描述。所有sklearn数据集都是这样构建的。数据代表特性的值，而目标是我们想要预测的值。feature_names是功能的名称。描述是数据集的一般描述。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/0982a641882a41c57380e825c61479fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JMAXrBUh1-f1G6AI0k8UrQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">描述方法</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/6d9877c4b7deef01e4b3b9cb2bfb19a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kD-ihyEkXGFv76yTNKEmBA.png"/></div></div></figure><p id="ac1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从这个图表中，我们可以大致了解我们的数据是如何分布的。我们可以看到数据的平均值、标准差、计数、最小值、最大值和分位数。这有助于我们确定数据中是否有异常值和其他一些基本数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/98fc1f73d679143c72c75e3f3c404739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9RMGEZNAd23Hi6KFzWeeMQ.png"/></div></div></figure><p id="0e2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">info方法用于检查是否有缺失值以及数据框的数据类型。它返回非缺失值的计数。注默认情况下，空值由nan表示。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="cf7b" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">特征选择和模型选择</h1><p id="9afb" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">从信息中，我们可以看到数据没有任何空值，它们都是浮点型的，因此，回归模型将是此数据的一个好模型。</p><p id="2dd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将使用海运库中的热图方法来绘制特性和目标变量的相关性图，以了解与我们的目标变量最相关的特性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/6222851035fb58ff4c1209484a595e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMC4BKQvjViMSfJDxQ6SRA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/a7b6c276969320885110f7cec32e9031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A08zuFKZ8TMf4ivfjWLfFg.png"/></div></div></figure><p id="573b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面的图中，我们看到特征:RM，LSTAT与我们的目标变量有很好的相关性。然而，以下特征CRIM、INDUS、NOX、PTRATIO也具有相关性，尽管其在0.3和0.49之间很小。</p><p id="ef23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用简单的线性回归。</p><h2 id="3190" class="oh mb iq bd mc oi oj dn mg ok ol dp mk lf om on mm lj oo op mo ln oq or mq os bi translated">回归模型的示例:</h2><ol class=""><li id="a0cd" class="mx my iq ky b kz ms lc mt lf nm lj nn ln no lr nc nd ne nf bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank">线性回归</a></li><li id="781c" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html" rel="noopener ugc nofollow" target="_blank">套索</a></li><li id="c10a" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html" rel="noopener ugc nofollow" target="_blank">山脊</a></li><li id="56a6" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=random%20forest%20regressor#sklearn.ensemble.RandomForestRegressor" rel="noopener ugc nofollow" target="_blank">随机森林回归器</a></li><li id="e12f" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html?highlight=decision%20tree#sklearn.tree.DecisionTreeRegressor" rel="noopener ugc nofollow" target="_blank">决策树回归器</a></li><li id="3aac" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html?highlight=sgdregressor#sklearn.linear_model.SGDRegressor" rel="noopener ugc nofollow" target="_blank">随机梯度下降回归器(SGDRegressor) </a></li><li id="8309" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated"><a class="ae kv" href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" rel="noopener ugc nofollow" target="_blank">xgb回归器</a>、<a class="ae kv" href="https://catboost.ai/docs/concepts/python-reference_catboostregressor.html" rel="noopener ugc nofollow" target="_blank"> Cat Boost回归器</a>、<a class="ae kv" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html" rel="noopener ugc nofollow" target="_blank"> Light GBM回归器</a>等。</li></ol><p id="16e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:所有这些算法都以类似的方式使用；在本教程中，我将使用其中的三个。</p><p id="e1c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">选择我们的特征和一个目标变量</em> </strong></p><p id="31be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们将使用简单的线性回归来训练我们的模型，在本文的这一部分，我们将在sklearn的linear_model模块中实现线性回归、Ridge和Lasso。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/5d1798889faf73f08d32a51e62a2a75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dubLYkcWYpEfLwUEhb_70g.png"/></div></div></figure><p id="60ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了这个，我们就建立了我们的模型。为了预测特征为30的目标变量，我们需要做的就是<strong class="ky ir"> lin_reg.predict([30])。</strong>如果我们想用套索来预测，我们会有<strong class="ky ir"> ls.predict([30]) </strong>或者<strong class="ky ir"> rd.predict([30]) </strong>如果我们用的是Ridge。</p><p id="b675" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后三行返回每个模型的权重和偏差。Sklearn约定在训练后对对象使用尾随下划线。你可以看到我们从创建我们的对象开始，这个对象接受一些<a class="ae kv" href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)" rel="noopener ugc nofollow" target="_blank">超参数</a>；它有一些默认值，这就是我在这个例子中使用的。然后我们使用<strong class="ky ir">拟合</strong>方法训练模型，然后我们使用<strong class="ky ir">预测</strong>方法进行预测。t这里还有<a class="ae kv" href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener ugc nofollow" target="_blank">分数</a>，是决定系数。</p><p id="1c9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们将使用多元线性回归。</p><p id="0d8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，我将使用Spearman等级相关性选择最佳的五个特征。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/e0c3916788a84d5a41a2d703b68e2b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1Fjs3G1uA0dWueoVJv6Vg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这些函数返回最佳特性。</p></figure><p id="879a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我将调用此函数并将其保存为名为“要素”的名称，然后从主数据框创建一个新的数据框。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/64bde552c908dd9f4a5af0dcf02ec2a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0B8wYUutFXvtbtCMhsp0Tw.png"/></div></div></figure><p id="be6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面的图表中，我们可以看到预测发生了变化。每当我们建立一个模型时，我们总要做的一件事就是评估我们的模型。我们已经用六种不同的模型做了同样的事情。然后，我们需要从模型评估中选择最佳模型。</p><h2 id="70b2" class="oh mb iq bd mc oi oj dn mg ok ol dp mk lf om on mm lj oo op mo ln oq or mq os bi translated"><strong class="ak">非线性回归</strong></h2><p id="e9dc" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">在这里，我们将建立非线性回归模型。我将使用随机森林回归和二阶多项式回归。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/7019fdd555b74be77913408a86db6860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KnnFIYQevpBH6x-vNoy9aA.png"/></div></div></figure><p id="c2f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面的代码中，我们做了一些类似于我们之前一直在做的事情，但是我们做了一些不同的事情。我们将X变量转换为二阶数据，这是我们在训练模型和进行预测时使用的数据。</p><p id="f09c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们将评估我们的模型并选出最佳模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/79f29d424ebf3f1ef50bda921fdcf6bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eogi9EGDOzEkbCSELiqsTA.png"/></div></div></figure><p id="5fc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用了三个评估指标:均方误差、平均绝对误差和R2分数。R2分数被称为决定系数，最佳值是1，也可能是负数，但理想情况下，它的范围在0到1之间。均方误差是预测值和实际值偏差的平方和。最佳值为0。平均绝对误差是预测值和实际值的绝对偏差之和。最佳值是0</p><div class="kg kh ki kj gt ab cb"><figure class="np kk pd nr ns nt nu paragraph-image"><img src="../Images/88d0a6a07000e0318fb77bbf75d38c83.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*CMnk5gyWr6yQ1IQCb4TMFA.png"/></figure><figure class="np kk pe nr ns nt nu paragraph-image"><img src="../Images/9cb1bd012bd6081c0b29dc967f923492.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*cCsFL6KoAU5ynZ8qvN_wiA.png"/><p class="kr ks gj gh gi kt ku bd b be z dk pf di pg ny translated">r2分数、mse和mae的图像。</p></figure></div><p id="9c8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">根据我们的评估，哪个型号性能最好，哪个性能最差？</strong></p><ol class=""><li id="c12f" class="mx my iq ky b kz la lc ld lf mz lj na ln nb lr nc nd ne nf bi translated">我们最好的模型是使用二阶多项式特征的线性回归。</li><li id="3eb7" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">我们最差的模型是带有一个特征的套索。</li></ol></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="69f1" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">结论</strong></h1><p id="ea29" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">本文带您构建了八个模型，并从中挑选出最好的。模型评估是模型开发中的一项重要工作。</p><p id="271a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的目标不是调优模型使其变得更好；因此，我使用了默认的超参数。</p><p id="2ee8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>
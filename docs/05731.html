<html>
<head>
<title>3 Useful PyTorch Tensor Functions to Check Out</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3个有用的PyTorch张量函数</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/3-useful-pytorch-tensor-functions-to-check-out-zero-to-gans-5fa72965b840?source=collection_archive---------6-----------------------#2020-07-31">https://betterprogramming.pub/3-useful-pytorch-tensor-functions-to-check-out-zero-to-gans-5fa72965b840?source=collection_archive---------6-----------------------#2020-07-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4e24" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">零到GANS</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/5d95b8e8eff5aac15e95d3c68f4ca08f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/0*xXUYOs5MWWenxoNz"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">照片来自<a class="ae kr" href="http://pytorch.org" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>。</p></figure><p id="ca56" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这篇文章中，我将回顾我在<a class="ae kr" href="http://pytorch.org" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>中发现的一些有用的张量函数，这是一个用于深度学习的Python库。要在计算机上构建大脑，首先要学会构建模块。在深度学习中，那些是张量。对于不知道的人来说，<a class="ae kr" href="https://en.wikipedia.org/wiki/Tensor" rel="noopener ugc nofollow" target="_blank">张量</a>是数字，向量，矩阵，或者任何<em class="lo"> n </em>维数组，深度学习模型可以用张量来理解。当我在做的时候，这里有一个很好的关于这个话题的视频。</p><p id="7d88" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在木星的第一个任务中。ML和FreeCodeCamp的深度学习with PyTorch课程，我学到了一个ML工程师或一般数据科学家可能每天都会用到的五个有趣的张量函数，包括与线性代数和统计相关的函数。在这五个当中，这三个是我最感兴趣的。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="60c8" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">1.整形—torch . shape()</h1><p id="f7bc" class="pw-post-body-paragraph ks kt iq ku b kv mo jr kx ky mp ju la lb mq ld le lf mr lh li lj ms ll lm ln ij bi translated">顾名思义，这个PyTorch函数重塑了一个张量的维数，所以一个<em class="lo"> m x n </em>矩阵可以转换成一个<em class="lo"> n x m </em>矩阵。这在数据分析和机器学习中是一个有用的特性，因为矩阵和向量需要重新成形以适应各种模型。</p><p id="5857" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下面是该函数的一个使用示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="c63b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">正如我们所看到的，一个16 x 1的向量被整形为一个4 x 4的矩阵，整形函数的第一个参数是张量，第二个参数是所需的维数。注意这些张量中元素的数量(<em class="lo"> m x n </em>)。</p><p id="1bf2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下面的例子说明了为什么在整形时记住这些很重要:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="bee5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">错误代码说明了一切:您不能将一个16元素张量重塑为一个25元素张量(4 x 4！= 5×5)。这一点在整形时很容易记住，所以要确保你要操作的张量与你想要的元素数量一致。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="b5a8" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">2.<strong class="ak"> Unique — torch.unique() </strong></h1><p id="e968" class="pw-post-body-paragraph ks kt iq ku b kv mo jr kx ky mp ju la lb mq ld le lf mr lh li lj ms ll lm ln ij bi translated">这个函数返回一个张量的唯一值，这个张量可能是一个矩阵或者一个向量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="6d8d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上面的简单例子让你知道这个函数的作用，返回张量中的所有值，因为在这种情况下它们都是唯一的。这里有一个更有趣的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="26f8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这里，我创建了一个张量，它将<code class="fe mv mw mx my b">2</code>和<code class="fe mv mw mx my b">3</code>作为众数(最频繁出现的数字),并且在每一行中有一个唯一的值。我想用PyTorch玩玩数学和条件运算符，所以我写了上面的代码，看看<code class="fe mv mw mx my b">w</code>和<code class="fe mv mw mx my b">y</code>的唯一值之和是否等于解<code class="fe mv mw mx my b">30</code>。看到这种情况真的很有趣。</p><p id="b964" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这个例子还展示了unique函数如何返回张量的重复元素一次。</p><p id="4c3a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">打破这个函数的唯一方法是在函数执行之前删除张量，因此下面是一个简单的例子:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="9699" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如前所述，unique函数仅从零矩阵返回一个<code class="fe mv mw mx my b">0</code>，并且该函数返回一个错误，因为测试张量由于<code class="fe mv mw mx my b">del()</code>而不再被定义。在张量中找到唯一值与在数据集中找到它们一样重要:避免重复。重复会扭曲深度学习模型和先前分析的结果。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="a17e" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated"><strong class="ak"> 3。最小二乘法— torch.lstsq() </strong></h1><blockquote class="mz na nb"><p id="09f6" class="ks kt lo ku b kv kw jr kx ky kz ju la nc lc ld le nd lg lh li ne lk ll lm ln ij bi translated">“最小二乘法是回归分析中的一种标准方法，通过最小化每个方程结果的残差平方和来近似求解超定系统(方程组，其中方程比未知数多)。”— <a class="ae kr" href="https://en.wikipedia.org/wiki/Least_squares" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><p id="9748" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">正如wiki所说，这是最常见的线性回归方法，一种分析自变量和因变量之间线性关系的统计方法。因此，它最适用于数字数据。幸运的是，PyTorch有<code class="fe mv mw mx my b">torch.lstsq()</code>函数可以快速找到两个矩阵(一组特性和一组目标)之间的最小二乘解。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="17f3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">关于PyTorch中的最小二乘，需要注意的一点是，当<em class="lo"> m </em>大于或等于<em class="lo"> m x n </em>特征矩阵中的<em class="lo"> n </em>时，该函数将返回最小二乘解(根据<a class="ae kr" href="https://pytorch.org/docs/master/generated/torch.lstsq.html" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>文档)。这意味着当行数大于列数时，将返回最小二乘法。</p><p id="b22c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然而，如果在<em class="lo"> m x n </em>特征矩阵中<em class="lo"> m </em>小于<em class="lo"> n </em>，那么<code class="fe mv mw mx my b">lstsq()</code>函数将返回最小二乘最小范数解或无限个最小二乘解中的最小二乘解，因为矩阵的行数比列数少(更多信息请参见本<a class="ae kr" href="https://math.stackexchange.com/questions/2253443/difference-between-least-squares-and-minimum-norm-solution#:~:text=Least%20squares%20solution%20of%20minimum%20norm&amp;text=In%20fact,%20chose%20the%20vector,in%20R(A%E2%88%97)." rel="noopener ugc nofollow" target="_blank"> StackExchange页面</a>)。在这些无限的解中，最小范数解总是唯一的，这就是为什么它被寻找出来。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/242e716fb40ea14535129bc63532fd0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gf-dtd8As9lIEh3f9NX6MQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图片来自<a class="ae kr" href="https://math.stackexchange.com/questions/2253443/difference-between-least-squares-and-minimum-norm-solution#:~:text=Least%20squares%20solution%20of%20minimum%20norm&amp;text=In%20fact%2C%20chose%20the%20vector,in%20R(A%E2%88%97)." rel="noopener ugc nofollow" target="_blank"> StackExchange </a>。</p></figure><p id="3d34" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你愿意，你可以在<a class="ae kr" href="https://jovian.ml/marcelinov/01-tensor-operations-550ca" rel="noopener ugc nofollow" target="_blank">笔记本</a>中看到，尽管它看起来与<em class="lo"> m &gt; n </em>最小二乘解的输出没有太大区别。</p><p id="14c2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">相反，我将向您展示一种相当明显的方法来打破这个函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="e34e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">总而言之，当矩阵中的行数(<em class="lo"> m </em>)不匹配时，<code class="fe mv mw mx my b">lstsq()</code>函数会中断。这是因为如果行是观察值的数量，列是特征的数量，那么两个矩阵必须具有相同的观察值数量。否则，数据集不能相同。这就是我对这个错误的理解，但是还需要进一步研究这个函数。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="1c6f" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated"><strong class="ak">结论</strong></h1><p id="8703" class="pw-post-body-paragraph ks kt iq ku b kv mo jr kx ky mp ju la lb mq ld le lf mr lh li lj ms ll lm ln ij bi translated">PyTorch是一个伟大的机器学习和深度学习库，用于从自然语言处理到神经网络(如CNN、RNN或GANS)的任务。我鼓励大家亲自去看看，深入研究一项正在改变人们日常生活方式的技术。</p></div></div>    
</body>
</html>
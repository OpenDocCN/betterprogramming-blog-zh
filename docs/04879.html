<html>
<head>
<title>Python Celery Best Practices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python芹菜最佳实践</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/python-celery-best-practices-ae182730bb81?source=collection_archive---------0-----------------------#2020-05-19">https://betterprogramming.pub/python-celery-best-practices-ae182730bb81?source=collection_archive---------0-----------------------#2020-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cd32" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">帮助您用Celery构建可伸缩的分布式应用程序的提示和技巧</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e37f30d730064dce5e57577a957ed412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oMQun4oLQWF6w-6XH617tw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@fabioha?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">法比奥</a>在<a class="ae ky" href="https://unsplash.com/s/photos/data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="5f54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建具有弹性的独立系统已经足够具有挑战性了。加上分销，你突然有了更多需要担心的活动部件。自然，一个软件中活动的部分越多，维护起来就越复杂，花费的时间也越多——Python Celery也不例外。</p><p id="0418" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Celery系列文章的第一部分中，我们介绍了如何使用独立的python开始使用Celery，并将其集成到您的Django web应用程序项目中。</p><div class="lv lw gp gr lx ly"><a href="https://medium.com/better-programming/breaking-down-celery-4-x-with-python-and-django-e95eeb7de2a6" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">用Python和Django分解芹菜≥4.x</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">用芹菜分配您的Python任务</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">medium.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="997e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一部分中，我们将研究您应该遵循的最佳实践，以使启用Celery的应用程序更有弹性、性能更好，并提高监控和可观察性。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="bb27" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">芹菜适合正确的使用案例</h1><p id="c4c8" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">人们很容易认为芹菜是解决所有可信问题的通用解决方案。当你对这个工具不够了解的时候，很容易试图让它适应每一个用例。但是当您有一个简单的用例并且您不寻求分布时，使用芹菜可能是多余的。如果您有需要节流的资源，像AWS SQS这样的简单队列就足够了——它比配置Celery更容易配置和维护。</p><p id="2bf7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Celery的用处在于执行需要耗费性能和资源的任务——例如，在HTTP请求的处理程序中，或者当需要处理复杂的计算或ETL工作时，这些工作可能需要时间来执行。在这种情况下，使用Celery是有意义的，因为尽管您通过提供的级别抽象失去了细粒度控制，但您获得了异步和分布行为。</p><p id="2c5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然芹菜可以处理大数据，这取决于你如何编码你的工作，但它不是Apache Spark等开源解决方案的直接替代品——尽管芹菜可以补充Spark，并让Spark做它最擅长的事情。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="b830" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">选择正确的结果后端</h1><p id="4deb" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">在Celery中，结果后端是当您使用return语句调用Celery任务时，存储任务结果的地方。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="dc67" class="nw mv it ns b gy nx ny l nz oa">@task(name='imageprocessor.proj.image_processing')<br/>def image_processing(images: list):<br/>    results = []<br/>    <em class="ob"># perform some work<br/>    </em>return results # results stored in backend of your choice</span></pre><p id="1a81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择正确的结果后端可能会为您节省几个小时的痛苦。维护良好的主要后端是Redis，然后是RabbitMQ。</p><p id="6d6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果将结果存储在数据库中，可能需要定期从数据库中清除旧数据。在使用Redis奖项时，您可以利用Redis内置的旧数据自动过期功能。</p><p id="d2b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您使用AMQP/RabbitMQ作为结果后端，如下所示:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="0577" class="nw mv it ns b gy nx ny l nz oa">from __future__ import absolute_import<br/><br/>from celery import Celery<br/><br/>app = Celery('mypackage',<br/>             broker='amqp://guest@localhost//',<br/>             backend='amqp://guest@localhost//')</span></pre><p id="1e88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Celery将创建队列来存储结果。如果不定期清除它们，这很容易使您的RabbitMQ服务器被数千个死队列淹没。</p><p id="4eb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个问题已经在4.x中通过使用下面的<code class="fe oc od oe ns b">CELERY_TASK_RESULT_EXPIRES</code>(或者在4.1版的<code class="fe oc od oe ns b">CELERY_RESULT_EXPIRES</code>)得到解决，它允许一个定期清理任务从RabbitMQ中删除过时数据。关于这方面的更多文档，见芹菜文档<a class="ae ky" href="https://docs.celeryproject.org/en/master/userguide/configuration.html#std:setting-result_expires" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="8971" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得注意的是，如果您的利用率很高，那么在下一个清理周期调用之前，如果您耗尽了资源，那么RabbitMQ服务器就有可能失败。因此，选择一个到期时间，确保清理过程足够频繁地发生，以避免出现问题。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="b44e" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">使用分布式锁避免芹菜竞争情况</h1><p id="98c4" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">与<code class="fe oc od oe ns b">cron</code>一样，如果第一个任务没有在下一个之前完成，任务可能会重叠。如果这是一个问题，那么使用锁定策略来确保一次只能运行一个实例。</p><p id="b506" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重要的一点是——如果由于某种原因，您的周期性功能不能重叠——如果您在不同的进程中有Celery实例，可能跨不同的服务器，或者在关键资源共享时竞争条件，那么就需要一个分布式锁定系统。</p><p id="8177" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个典型的例子。您将定期任务设置为一分钟，但您的工作没有在指定的时间范围内完成。添加一个锁来防止两个工作者试图访问同一个资源的重复情况是有意义的。我们之前在<a class="ae ky" href="https://medium.com/better-programming/breaking-down-celery-4-x-with-python-and-django-e95eeb7de2a6" rel="noopener">“用Python和Django分解芹菜≥4 . x”</a>中安装的Python Redis包提供了Redis锁，我们可以用它来防止分布式环境中的竞争情况。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="0649" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以进一步扩展上述内容，将它放入一个可重用的包装器中，我们可以将它标记到任何函数上——我们在任何时候都只需要执行一个实例。在装饰器下面，我们设置了一个锁超时时间，这个时间可以充分估计任务的持续时间——这样，如果任务或芹菜节点崩溃，任务最终将能够重新获得锁。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="dded" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了Redis，还有其他适合分布式锁定实现的分布式开源解决方案，比如ZooKeeper和<a class="ae ky" href="https://etcd.io/" rel="noopener ugc nofollow" target="_blank"> etcd </a> <a class="ae ky" href="https://github.com/haizi-zh/python-etcd-lock" rel="noopener ugc nofollow" target="_blank"> Python客户端</a>。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="b7c0" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">数据库不应作为AMQP经纪人时期的替代品</h1><p id="ff71" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">当您将数据库用作代理时，随着芹菜集群中工作线程数量的增加，您会增加IO的风险。这可能会降低可能利用同一数据库的其他应用程序的速度。您可能会有同样的想法——您已经有了一个数据库，您不想在托管合适的代理时产生额外的成本。</p><p id="7726" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，当您的应用程序很小时，一个合适的队列系统的长期成本超过了您可能获得的直接利益。像<a class="ae ky" href="http://www.rabbitmq.com/" rel="noopener ugc nofollow" target="_blank"> RabbitMQ </a>这样的AMQPs利用数据在内存中的存储，所以你不会因为磁盘IO而损失性能。也不需要像使用数据库时需要的语句管理。</p><p id="37ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据库带来了更多您需要担心的问题。假设芹菜集群中有N个工人，每个工人都需要根据请求获得某种锁。一旦获得了该行的排他锁，系统就需要处理更新(例如，将状态更新为“正在处理”)。之后，需要尽快释放锁(例如，通过提交事务)，以便其他工作人员可以访问队列。当这样的设计应用于数据库时，性能会显著降低。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="efa8" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">努力以原子的方式编码</h1><p id="84ad" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">原子操作是一系列不可分割和不可约的数据库操作，要么全部发生，要么什么都不发生。尽管原子性的概念通常与数据库操作相关联，但它也可以应用于芹菜。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="0658" class="nw mv it ns b gy nx ny l nz oa">@app.task<br/>def update_data():<br/>    user.status = 'updated'<br/>    user.save()<br/>    r = twitter_get_profile()<br/>    user.name = r.name<br/>    user.save()</span></pre><p id="a6d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这段代码中，我们有一个任务，它将用户状态设置为<code class="fe oc od oe ns b">updated</code>，保存它，向Twitter发出请求，然后更新用户名。这不是原子性的——如果请求失败，我们在数据库中会有一个不一致的状态(带有<code class="fe oc od oe ns b">status=updated</code>的用户和一个尚未更新的名称)。</p><p id="73df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正确的做法是首先发出请求，然后同时更新用户状态和名称:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="0b88" class="nw mv it ns b gy nx ny l nz oa">@app.task<br/>def update_data():<br/>    r = twitter_get_profile()</span><span id="723d" class="nw mv it ns b gy oh ny l nz oa">    if r.status != 200:<br/>        return</span><span id="580d" class="nw mv it ns b gy oh ny l nz oa">    user.name = r.name<br/>    user.status = 'updated'<br/>    user.save()</span></pre><p id="cd93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们的操作已经变得原子化——要么一切成功，要么一切失败。这是我们应该永远努力的。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="55b7" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">经常设置检查点</h1><p id="b3fb" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">当使用任务处理大量数据时，请始终确保有检查点，以便在出现故障时，可以从中断的地方继续，而不是重新处理整批数据。您可以利用<code class="fe oc od oe ns b">Memcache</code>或像Redis这样的键值对存储来恢复您的任务。检查点的目的是在失败的情况下，如果您需要重新启动Celery任务，将浪费的时间和精力减到最少。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="a372" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">给你的任务起个名字</h1><p id="7479" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">默认情况下，Celery根据模块的导入方式创建任务名称。为了避免与其他包冲突，使用标准的命名约定，比如<code class="fe oc od oe ns b">proj.package.module.function_name</code>。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="ef8c" class="nw mv it ns b gy nx ny l nz oa">@app.task(name='<!-- -->celery_tasks<!-- -->.tasks.add')<br/>def add(a, b):<br/>    return a + b</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="1a5b" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">始终使用auto_retry和max_retries</h1><p id="80a6" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">自动重试提供了在特定异常发生时使用相同的重试任务的能力。自动重试接受预期异常的列表，并在其中一个异常发生时重试任务。设置<code class="fe oc od oe ns b">max_retries</code>来防止无限循环的发生总是一个好主意。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="6f78" class="nw mv it ns b gy nx ny l nz oa">from httplib import HTTPException</span><span id="4e9f" class="nw mv it ns b gy oh ny l nz oa">@app.task(name='<!-- -->celery_tasks<!-- -->.tasks.train_ml_model', auto_retry=[CoinDeskClientException], max_retries=3)<br/>def train_ml_model():<br/>    return train_ml_model_result()</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="8dba" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">apply_async过延迟</h1><p id="66ef" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">Celery提供了两个函数调用选项，<code class="fe oc od oe ns b">delay()</code>和<code class="fe oc od oe ns b">apply_async()</code>，用于调用Celery任务。<code class="fe oc od oe ns b">delay()</code>已经预先配置好，只需要将参数传递给任务——这足以满足大多数基本需求。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="15ca" class="nw mv it ns b gy nx ny l nz oa">add.delay(5, 5)<br/>add.delay(a=5, b=10)</span></pre><p id="a31a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oc od oe ns b">Apply_async</code>比预配置的延时更复杂，但也更强大。最好使用<code class="fe oc od oe ns b">apply_async</code>和特别设置的选项，以获得最大的灵活性。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="c26f" class="nw mv it ns b gy nx ny l nz oa">add.apply_async(queue='low_priority', args=(5, 5))<br/>add.apply_async(queue='high_priority', kwargs={'a': 5, 'b': 5})</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="7d6d" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">总是定义队列</h1><p id="ade3" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">始终定义一个队列来处理优先级较低的作业。您可能希望至少有三个队列，一个用于高优先级任务，一个用于低优先级任务，一个默认队列用于普通优先级。可以选择设置<code class="fe oc od oe ns b">app.conf.task_create_missing_queues = True</code>。通过这种方式，您可以将队列创建委托给Celery。</p><p id="0cfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以对任何队列使用<code class="fe oc od oe ns b">apply_async</code>，只要您的任务知道<code class="fe oc od oe ns b">apply_async</code>使用的队列，Celery就会处理它。如果没有提供，那么工作线程将只监听默认队列。</p><p id="1f5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的命令可用于运行一个worker，其中我们基于优先级指定队列:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="b5d1" class="nw mv it ns b gy nx ny l nz oa">(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q default,low_priority,high_priority</span><span id="0230" class="nw mv it ns b gy oh ny l nz oa">(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q default -c 2<br/>(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q low_priority -c 1<br/>(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q high_priority -c 4</span></pre><p id="c9f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的额外好处是并发性。参数<code class="fe oc od oe ns b">-c</code>定义了工作线程创建了多少个并发线程。可以为自动缩放工作线程添加一个附加参数:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="0524" class="nw mv it ns b gy nx ny l nz oa">(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q default --autoscale 4,2<br/>(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q low_priority --autoscale 2,1<br/>(venv) $ celery -A <!-- -->celery_tasks.tasks<!-- --> worker -l info -Q high_priority --autoscale 8,4</span></pre><p id="b901" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应用上述组合，我们可以控制并行性，以增加排队工作的出列。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="1779" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">保持并发数量接近CPU核心数量</h1><p id="7e49" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">这条规则适用于几乎所有用于分布式计算的Python库:如果服务器有8个核心CPU，那么最大并发数应该设置为8或N -1，其中最后一个用于其他基本的操作系统功能。</p><p id="5ca1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这条经验法则可以帮助您在不过度使用资源的情况下获得最大可能的性能，而过度使用资源可能会减少通过分发获得的收益。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="5c20" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">对单个队列应用优先级</h1><p id="ae3b" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">就性能而言，分布在多个队列中的任务总是比将所有内容放在一个队列中要好。虽然这可能是真的，但是单队列任务可能具有不同的优先级，其中优先级可以用从0到9的整数范围来定义。</p><p id="b735" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，队列很有可能没有机会对消息进行优先级排序，因为它们可以在排序之前出队。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="acee" class="nw mv it ns b gy nx ny l nz oa">add.apply_async(queue='high_priority', priority=0, kwargs={'a': 10, 'b': 5})<br/>add.apply_async(queue='high_priority', priority=3, kwargs={'a': 10, 'b': 5})<br/>add.apply_async(queue='high_priority', priority=9, kwargs={'a': 10, 'b': 5})</span></pre><p id="d41a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了获得想要的效果，需要进行一些设置:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="d2bd" class="nw mv it ns b gy nx ny l nz oa">CELERY_ACKS_LATE = True<br/>CELERYD_PREFETCH_MULTIPLIER = 1</span></pre><p id="9b95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下，预取乘数是4。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="f764" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">组块是你最好的朋友——经常做</h1><p id="8045" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">如果你有几十万个对象，那么更谨慎的做法是分块处理它们。例如，<code class="fe oc od oe ns b">1 000 000</code>元素可以被分割成每个作业的<code class="fe oc od oe ns b">1000</code>元素块，给你队列中的<code class="fe oc od oe ns b">1000</code>任务。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="44cf" class="nw mv it ns b gy nx ny l nz oa">@celery_app.task(name='<!-- -->celery_tasks.tasks<!-- -->.process_data')<br/>def process_data(elements):<br/>    return process_elements(elements)</span><span id="d027" class="nw mv it ns b gy oh ny l nz oa">process_data.chunks(iter(elements), 1000).apply_async(queue='low_priority')</span></pre><p id="71b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:块是按顺序执行的。我们可以将数据块转换成一组并行使用的数据。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="0bd3" class="nw mv it ns b gy nx ny l nz oa">process_data.chunks(iter(elements), 100).group().apply_async(queue='low_priority')</span></pre><h1 id="dddb" class="mu mv it bd mw mx oi mz na nb oj nd ne jz ok ka ng kc ol kd ni kf om kg nk nl bi translated">芹菜配置:选择最适合的</h1><p id="2756" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">我们之前看到了如何通过<code class="fe oc od oe ns b">settings.py</code>配置celery设置，或者直接使用Celery应用程序上下文。以下是其他一些可能有用的加载芹菜配置的方法，这取决于你想如何安排你的配置。</p><p id="4a9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可能在网上遇到的大多数例子都使用了以下设置的一个或多个变体。重要的是要理解总体结果是相同的—您决定采取的方法完全取决于您希望如何安排您的配置。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="1619" class="nw mv it ns b gy nx ny l nz oa">import celeryconfig</span><span id="76b6" class="nw mv it ns b gy oh ny l nz oa">from celery import Celery</span><span id="26c1" class="nw mv it ns b gy oh ny l nz oa">app = Celery()</span><span id="b1c6" class="nw mv it ns b gy oh ny l nz oa">app.config_from_object(celeryconfig)</span></pre><p id="a1ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您的<code class="fe oc od oe ns b">celeryconfig.py</code>将包含如下所示的设置常量值。因为我们在这里没有使用namespace属性，所以Celery希望从默认的<code class="fe oc od oe ns b">BROKER_URL</code>常量中找到Redis broker URL只是需要记住一些东西。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="fc70" class="nw mv it ns b gy nx ny l nz oa">REDIS_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379/0')<br/>BROKER_URL = <!-- -->REDIS_URL<br/>CELERY_RESULT_BACKEND = <!-- -->REDIS_URL<br/>CELERY_ROUTES = {'task_name': {'queue': 'queue_name_task'}}</span></pre><p id="5b58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是另一种使用Celery上下文对象直接进行更新的方法。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="ba23" class="nw mv it ns b gy nx ny l nz oa">from celery import Celery</span><span id="9162" class="nw mv it ns b gy oh ny l nz oa">app = Celery('tasks')</span><span id="1095" class="nw mv it ns b gy oh ny l nz oa">REDIS_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379/0')</span><span id="c71d" class="nw mv it ns b gy oh ny l nz oa">app.conf.update(<br/>    result_expires=60,<br/>    task_acks_late=True,<br/>    broker_url=<!-- -->REDIS_URL<!-- -->,<br/>    result_backend=<!-- -->REDIS_URL<br/>)</span></pre><p id="7ed0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您希望有一个类对象，您可以使用配置类获得相同的结果:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="159c" class="nw mv it ns b gy nx ny l nz oa">from celery import Celery</span><span id="4aea" class="nw mv it ns b gy oh ny l nz oa">REDIS_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379/0')</span><span id="5456" class="nw mv it ns b gy oh ny l nz oa">app = Celery(<!-- -->'tasks', broker=REDIS_URL, backend='redis'<!-- -->)</span><span id="1b36" class="nw mv it ns b gy oh ny l nz oa">class Config:<br/>    enable_utc = True<br/>    timezone = '<!-- -->Asia/Singapore<!-- -->'</span><span id="8350" class="nw mv it ns b gy oh ny l nz oa">app.config_from_object(Config)<br/># or using the fully qualified name of the object:<br/>#   app.config_from_object('module:Config')</span></pre><p id="b715" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oc od oe ns b"><a class="ae ky" href="https://docs.celeryproject.org/en/stable/reference/celery.html#celery.Celery.config_from_envvar" rel="noopener ugc nofollow" target="_blank">app.config_from_envvar()</a></code>从环境变量中获取配置模块名</p><p id="68bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，从名为<code class="fe oc od oe ns b">CELERY_CONFIG_MODULE</code>的环境变量中指定的模块加载配置:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="3fdc" class="nw mv it ns b gy nx ny l nz oa">$ export CELERY_CONFIG_MODULE="celeryconfig.prod"</span></pre><p id="5603" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者直接在试图运行一个工人时:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="e8f9" class="nw mv it ns b gy nx ny l nz oa">$ CELERY_CONFIG_MODULE="celeryconfig.prod" celery worker -l info</span></pre><p id="96ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是如何注册<code class="fe oc od oe ns b">CELERY_CONFIG_MODULE</code>以便Celery应用程序上下文可以获取配置并加载它们:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="4cd4" class="nw mv it ns b gy nx ny l nz oa">import os<br/>from celery import Celery</span><span id="3ac9" class="nw mv it ns b gy oh ny l nz oa">#: Set default configuration module name<br/>os.environ.setdefault('CELERY_CONFIG_MODULE', 'celeryconfig')</span><span id="2720" class="nw mv it ns b gy oh ny l nz oa">app = Celery()<br/>app.config_from_envvar('CELERY_CONFIG_MODULE')</span></pre><h1 id="02a3" class="mu mv it bd mw mx oi mz na nb oj nd ne jz ok ka ng kc ol kd ni kf om kg nk nl bi translated">强制进行监控和观察</h1><p id="8472" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">当环境像今天这样复杂，多个工作人员在不同的机器上运行时，现代监控方法应该融入到部署流程中。</p><p id="2350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对已知问题的监控并不能解决越来越多的未知问题，如果没有可观察的系统，这些未知问题可能会出现—您不知道是什么导致了问题，也没有标准的起点/图表来找出问题。对于Celery，随着节点数量的增加，系统变得更加复杂，这变成了N个故障点——当您发送请求时，这是一个黑盒。</p><p id="a076" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从基础开始:日志。确保尽可能多地记录日志。这将有助于您在出现bug时跟踪出了什么问题。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="a6ec" class="nw mv it ns b gy nx ny l nz oa">from celery.utils.log import get_task_logger</span><span id="6089" class="nw mv it ns b gy oh ny l nz oa">logger = get_task_logger(__name__)</span><span id="1a08" class="nw mv it ns b gy oh ny l nz oa">@app.task<br/>def add(a, b):<br/>    logger.info('Adds {0} + {1}'.format(a, b))<br/>    return a + b</span></pre><p id="2ca4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">诸如Newrelic、<a class="ae ky" href="https://sentry.io/" rel="noopener ugc nofollow" target="_blank"> Sentry </a>和<a class="ae ky" href="https://opbeat.com/" rel="noopener ugc nofollow" target="_blank"> Opbeat </a>等服务和工具可以很容易地集成到Django和Celery中，并帮助您监控错误。您还可以将它们与Slack集成，这样每当出现问题时您都会收到通知，同时还可以微调生成通知的内容。假阳性太多，你最终会忽略实际的错误。</p><p id="2ba4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是一些你可以用来提高你的监控和观察能力的工具</p><ul class=""><li id="3e4a" class="on oo it lb b lc ld lf lg li op lm oq lq or lu os ot ou ov bi translated"><a class="ae ky" href="https://watchtower.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Watchtower </a>是亚马逊Web服务CloudWatch日志的日志处理程序。您可以做的一件有趣的事情是将您的云观察日志映射到<a class="ae ky" href="https://grafana.com/" rel="noopener ugc nofollow" target="_blank"> Grafana </a>以获得更好的<a class="ae ky" href="https://grafana.com/grafana/dashboards/9970" rel="noopener ugc nofollow" target="_blank">可视化</a>。</li><li id="6f0e" class="on oo it lb b lc ow lf ox li oy lm oz lq pa lu os ot ou ov bi translated"><a class="ae ky" href="http://flower.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> Flower </a>是芹菜任务现场监控的便捷工具。您可以检查哪些任务正在运行，并跟踪已执行的任务。缺点之一是它是一个独立的应用程序，可能无法与您现有的监控解决方案很好地结合。</li></ul></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="1862" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">不要低估测试</h1><p id="f3fd" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">测试和调试Celery任务通常比我们在普通的独立和web应用程序中所习惯的要困难。Celery提供了<code class="fe oc od oe ns b"><a class="ae ky" href="http://docs.celeryproject.org/en/latest/userguide/configuration.html#std:setting-task_always_eager" rel="noopener ugc nofollow" target="_blank">task_always_eager</a></code>，这是一个很好的设置，便于测试和调试。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="5406" class="nw mv it ns b gy nx ny l nz oa">celery.conf.task_always_eager = False</span><span id="8447" class="nw mv it ns b gy oh ny l nz oa">or <!-- -->celery.conf.CELERY_ALWAYS_EAGER = False<!-- --> , if you're using pre-<!-- -->4.0<!-- --> Celery</span><span id="180e" class="nw mv it ns b gy oh ny l nz oa">You can do this on a per-test basis<br/>Make sure it’s not activated in a production environment as you loose distribution ability.</span></pre><p id="a15a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你把它设置为<code class="fe oc od oe ns b">True</code>，无论何时你调用<code class="fe oc od oe ns b">delay</code>或<code class="fe oc od oe ns b">apply_async</code>，它都会同步运行任务，而不是把它委托给一个工人。这简化了本地环境中的调试，并促进了自动化测试。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="39dc" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">最后的想法</h1><p id="afc9" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">在构建Celery分布式应用程序时，我们已经介绍了许多最佳实践。</p><p id="e1a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总而言之，在用Celery构建分布式系统时，测试应该是开发工作中不可或缺的一部分。在努力通过监控和可观察性获得可见性的同时，实践这些将有助于您在出现问题时导航调试遗忘的深渊。</p><p id="5e4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望您喜欢这篇文章，并且这里的信息可以帮助您构建更好的支持Celery的应用程序。如果您有任何意见或反馈，请在下面留言。</p><p id="5c66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编码快乐！</p></div></div>    
</body>
</html>
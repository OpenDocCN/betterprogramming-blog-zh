<html>
<head>
<title>Boosting and Bagging: How To Develop A Robust Machine Learning Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">助推和装袋:如何开发一个健壮的机器学习算法</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-develop-a-robust-algorithm-c38e08f32201?source=collection_archive---------5-----------------------#2017-11-21">https://betterprogramming.pub/how-to-develop-a-robust-algorithm-c38e08f32201?source=collection_archive---------5-----------------------#2017-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/c07b35847d0c6eaba515cc925294f7b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNnC9r25vEAuRffNy2mjdw.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="1960" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">机器学习和数据科学需要的不仅仅是将数据扔进Python库并利用任何输出</h2></div><h1 id="1d35" class="kt ku je bd kv kw kx ky kz la lb lc ld kk le kl lf kn lg ko lh kq li kr lj lk bi translated">自举/装袋/增压</h1><p id="9cc8" class="pw-post-body-paragraph ll lm je ln b lo lp kf lq lr ls ki lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">机器学习和数据科学需要的不仅仅是将数据扔进Python库并利用任何输出。</p><p id="a2b3" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">数据科学家需要真正理解数据及其背后的流程，才能实施成功的系统。</p><p id="49aa" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">实现的一个关键方法是知道一个模型何时可以从使用<strong class="ln jf">引导</strong>方法中获益。这些就是所谓的<strong class="ln jf">集合模型</strong>。集合模型的一些例子是AdaBoost和随机梯度增强。</p><p id="6a90" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">为什么要用系综模型？</p><p id="5468" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">它们有助于提高算法的准确性或使模型更加稳健。两个例子是<strong class="ln jf">增压</strong>和<strong class="ln jf">装袋</strong>。Boosting和bagging是数据科学家和机器学习工程师必须知道的话题，尤其是如果你打算参加<a class="ae mm" href="http://www.acheronanalytics.com/acheron-blog/how-to-prepare-for-a-data-science-interview" rel="noopener ugc nofollow" target="_blank">数据科学/机器学习面试</a>。</p><p id="b68e" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">从本质上来说，集成学习是真正意义上的集成。不同的是，集成学习不是让几个人以不同的八度音阶唱歌来创建一个美丽的和声(每个声音填充另一个声音的空白)，而是使用数百到数千个相同算法的模型，这些模型一起工作来找到正确的分类。</p><p id="03fb" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">另一种思考整体学习的方式是盲人摸象的寓言。在这个例子中，每个盲人都感觉到大象的不同部位，所以他们对自己的感觉有不同的看法。然而，如果他们聚在一起讨论，他们可能会发现他们看到的是同一事物的不同部分。</p><p id="00b7" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">使用boosting和bagging等技术提高了统计模型的稳健性，减少了方差。</p><p id="cbd2" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">现在问题变成了，所有这些不同的“B”字之间的区别是什么？</p><h1 id="bd2c" class="kt ku je bd kv kw kx ky kz la lb lc ld kk le kl lf kn lg ko lh kq li kr lj lk bi translated">拔靴带</h1><p id="ca79" class="pw-post-body-paragraph ll lm je ln b lo lp kf lq lr ls ki lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">先说自举这个非常重要的概念。许多数据科学家忽略了这一点，并直接解释增压和装袋。但是两者都需要自举。</p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mn"><img src="../Images/0f412e07d754f8c1fe6372def030cbf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jW2hAGmYEFH0RP9W."/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图1引导</p></figure><p id="bd8b" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">在机器学习中，bootstrap方法指的是带有替换的随机抽样。这个样本被称为重采样。这使得模型或算法能够更好地理解重采样中存在的各种偏差、方差和特征。获取数据样本允许重采样包含与其作为整体可能包含的特征不同的特征。图1展示了这一点，其中每个样本群体都有不同的部分，没有一个是完全相同的。这将影响数据集的总体均值、标准差和其他描述性指标。反过来，它可以开发更稳健的模型。</p><p id="0264" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">Bootstrapping对于小规模的数据集也很有用，这些数据集可能会倾向于<a class="ae mm" href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" rel="noopener ugc nofollow" target="_blank">过度适应</a>。事实上，我们向一家公司推荐了这种方法，该公司担心他们的数据集与“大数据”相去甚远在这种情况下，自举可以是一种解决方案，因为根据方法(boosting或bagging)，利用自举的算法可以更健壮，并处理新的数据集。</p><p id="ff3d" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">使用bootstrap方法的原因是因为它可以测试解决方案的稳定性。它可以通过使用多个样本数据集和测试多个模型来提高稳健性。也许一个样本数据集比另一个样本数据集具有更大的均值，或者具有不同的标准差。这可能会打破一个过度拟合且没有使用不同变量的数据集进行测试的模型。</p><p id="d36a" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">自举变得普遍的众多原因之一是因为计算能力的增加。这允许用不同的重采样进行比其他可能方式更多的排列。如下所述，自举被用在打包和升压中。</p><h1 id="8656" class="kt ku je bd kv kw kx ky kz la lb lc ld kk le kl lf kn lg ko lh kq li kr lj lk bi translated">制袋材料</h1><p id="dfec" class="pw-post-body-paragraph ll lm je ln b lo lp kf lq lr ls ki lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">Bagging实际上指的是(引导聚合器)。几乎任何引用bagging算法的论文或帖子都会引用Leo Breiman，他于1996年在<a class="ae mm" href="https://link.springer.com/content/pdf/10.1023/A:1018054314350.pdf" rel="noopener ugc nofollow" target="_blank">发表了一篇名为“Bagging预测者”的论文。</a></p><p id="5bfa" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">李奥将装袋描述为:</p><p id="a445" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated"><em class="mw">“Bagging预测值是一种生成多个版本的预测值并使用这些预测值获得一个聚合预测值的方法。”</em></p><p id="ad2e" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">Bagging有助于<a class="ae mm" href="https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-in-practice/variance-reduction-methods" rel="noopener ugc nofollow" target="_blank">减少可能非常精确的模型的差异</a>，但只是基于它们被训练的数据。这也被称为过度拟合。</p><p id="68c2" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">过度拟合是指函数与数据拟合得太好。通常，这是因为实际方程太复杂，无法将每个数据点和异常值考虑在内。</p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/ff0a0b49e1c75ac64ef2e669e60eaa86.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/0*x96-pW_THQkPHWsC."/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图2过度拟合</p></figure><p id="15b7" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">另一个容易过度拟合的算法例子是决策树。使用<a class="ae mm" href="https://en.wikipedia.org/wiki/Decision_tree" rel="noopener ugc nofollow" target="_blank">决策树</a>开发的模型需要非常简单的<a class="ae mm" href="https://en.wikipedia.org/wiki/Heuristic" rel="noopener ugc nofollow" target="_blank">试探法</a>。决策树由一组按特定顺序执行的“if-else”语句组成。因此，如果数据集被改变为新的数据集，与先前的数据集相比，新的数据集可能具有一些偏差或差异，而不是潜在的特征，则模型将不能同样准确。这是因为数据也不适合模型(这是一个倒退的说法)。</p><p id="79ab" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated"><a class="ae mm" href="http://scott.fortmann-roe.com/docs/BiasVariance.html" rel="noopener ugc nofollow" target="_blank"> Bagging在测试多个假设(模型)时，通过采样和替换数据在数据中创建自己的方差来解决这个问题</a>。反过来，这通过利用最有可能由具有各种属性(中值、平均值等)的数据组成的多个样本来减少噪声。</p><p id="2638" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">一旦每个模型开发了一个假设，模型使用<strong class="ln jf">投票进行分类</strong>或<strong class="ln jf">平均进行回归</strong>。这就是“引导聚合”中“聚合”发挥作用的地方。每个假设都和其他假设一样重要。<em class="mw">当我们稍后讨论升压时，这是两种方法不同的地方之一。</em></p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/c14b1981893429573b97797f8e439c02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zrm9Q8twgrq8lfLk."/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图3装袋</p></figure><p id="35eb" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">本质上，所有这些模型同时运行，投票决定哪个假设是最准确的。</p><p id="48e6" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这有助于减少差异，即减少过度拟合。</p><h1 id="71a6" class="kt ku je bd kv kw kx ky kz la lb lc ld kk le kl lf kn lg ko lh kq li kr lj lk bi translated">助推</h1><p id="abba" class="pw-post-body-paragraph ll lm je ln b lo lp kf lq lr ls ki lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">Boosting是指一组利用加权平均使弱学习者变成强学习者的算法。与bagging不同，boosting让每个模型独立运行，然后在最后汇总输出，而不偏向任何模型，boosting完全是“团队合作”。每个运行的模型决定了下一个模型将关注的特性。</p><p id="2e77" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">升压也需要自举。然而，这里还有一个不同之处。与打包不同，boosting对每个数据样本进行加权。这意味着一些样本将比其他样本运行得更频繁。</p><p id="3dfc" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">为什么要对数据样本进行加权？</p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e8f6550cd8b45a3104917d364e0e4b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/0*xOFz7cCUP6aS7C1R."/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图4升压</p></figure><p id="9b61" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">当boosting运行每个模型时，它会跟踪哪些数据样本最成功，哪些不成功。具有最多错误分类输出的数据集被赋予更重的权重。这些被认为是具有更大复杂性并且需要更多迭代来正确训练模型的数据。</p><p id="2ad3" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">在实际分类阶段，boosting处理模型的方式也有所不同。在boosting中，模型的错误率被跟踪，因为更好的模型被赋予更好的权重。</p><p id="a507" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这样，当“投票”发生时，就像装袋一样，具有更好结果的模型对最终输出有更强的吸引力。</p><h1 id="1254" class="kt ku je bd kv kw kx ky kz la lb lc ld kk le kl lf kn lg ko lh kq li kr lj lk bi translated">摘要</h1><p id="8336" class="pw-post-body-paragraph ll lm je ln b lo lp kf lq lr ls ki lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">助推和装袋都是减少差异的好方法。集合方法通常优于单个模型。这就是为什么许多Kaggle获奖者使用了系综方法。这里没有讨论的一个是<a class="ae mm" href="http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/" rel="noopener ugc nofollow" target="_blank">堆叠</a>。(那需要自己的岗位。)</p><p id="b4c1" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">但是，他们不会修复每个问题，他们自己也有自己的问题。有不同的原因让你选择使用其中的一个。当模型过拟合时，装袋对于减少方差是非常有用的。然而，在这两种方法中，增压更有可能是更好的选择。提升也更有可能导致性能问题。这对于减少欠拟合模型中的偏差也很有帮助。</p><p id="34ea" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这就是经验和专业知识发挥作用的地方！很容易跳到第一个有效的模型上。然而，<a class="ae mm" href="https://www.theseattledataguy.com/intro-data-analysis-everyone-part-1/" rel="noopener ugc nofollow" target="_blank">分析算法</a>和它选择的所有特性是很重要的。例如，如果决策树设置了特定的叶子，问题就变成了为什么！如果你不能用其他数据点和视觉效果来支持它，它可能不应该被实现。</p><p id="bdb9" class="pw-post-body-paragraph ll lm je ln b lo mh kf lq lr mi ki lt lu mj lw lx ly mk ma mb mc ml me mf mg im bi translated">这不仅仅是在各种数据集上尝试AdaBoost或随机森林。最终的算法取决于它得到的结果，以及有什么支持。</p></div></div>    
</body>
</html>
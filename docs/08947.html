<html>
<head>
<title>New in iOS 15: Vision Person Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">iOS 15新增:视觉人物分割</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822?source=collection_archive---------7-----------------------#2021-06-29">https://betterprogramming.pub/new-in-ios-15-vision-person-segmentation-5c031a2f3822?source=collection_archive---------7-----------------------#2021-06-29</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="8618" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">在图像和视频中将人与背景分开</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/204c39a43d458a22606af6fef152f88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KIJPtVMpLdMQ3qJGx_bNFw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者截屏。</p></figure><p id="0867" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">Vision是苹果的框架，为复杂的计算机视觉挑战提供开箱即用的解决方案。它还通过在分类期间处理图像的预处理来抽象核心ML请求。</p><p id="1b05" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在iOS 14中，我们获得了半打<a class="ae lv" href="https://heartbeat.fritz.ai/whats-new-in-the-vision-framework-in-ios-14-73d22a942ba5" rel="noopener ugc nofollow" target="_blank">新的视觉功能</a>，包括轮廓检测、光流、轨迹检测、离线视频处理以及手和身体姿势估计。</p><p id="cbeb" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在WWDC 2021上，苹果宣布了两个新的视觉要求:人和文档分割。</p><p id="7edc" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在这篇文章中，我将重点关注iOS 15引入的新的<a class="ae lv" href="https://developer.apple.com/documentation/vision/vngeneratepersonsegmentationrequest" rel="noopener ugc nofollow" target="_blank">人物细分愿景请求</a>。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="518c" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">Vision人员细分请求</h1><p id="c23e" class="pw-post-body-paragraph kz la iu lb b lc mv jv le lf mw jy lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">语义分割是一种用于对图像中的每个像素进行分类的技术。它通常用于从背景中分离前景对象。</p><p id="25fe" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">视频通话中的自动驾驶和虚拟背景是两个流行的用例，您可能已经观察到某种形式的语义分段。</p><p id="814d" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated"><a class="ae lv" href="https://developer.apple.com/machine-learning/models/" rel="noopener ugc nofollow" target="_blank"> DeepLabV3 </a>是一个流行的机器学习模型，用于执行图像分割。如果你想走ML的核心道路，看看这个教程<a class="ae lv" rel="noopener ugc nofollow" target="_blank" href="/coreml-image-segmentation-background-remove-ca11e6f6a083">告诉你如何修改图像中的背景。</a></p><p id="587e" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">回到Vision框架，新的<code class="fe na nb nc nd b"><a class="ae lv" href="https://developer.apple.com/documentation/vision/vngeneratepersonsegmentationrequest" rel="noopener ugc nofollow" target="_blank">VNGeneratePersonSegmentationRequest</a></code>类有助于人物分割，并为帧中的人物返回分割遮罩。</p><p id="e5b6" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">下面是设置它的方法:</p><pre class="kk kl km kn gu ne nd nf ng aw nh bi"><span id="35ce" class="ni me iu nd b gz nj nk l nl nm">let request = VNGeneratePersonSegmentationRequest()<br/>request.qualityLevel = .accurate<br/>request.outputPixelFormat = kCVPixelFormatType_OneComponent8</span></pre><p id="2f3e" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这三个质量级别是<code class="fe na nb nc nd b">accurate</code>、<code class="fe na nb nc nd b">balanced</code>和<code class="fe na nb nc nd b">fast</code> —在视频处理任务中推荐使用后一种。</p><p id="e353" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在下一节中，我们将了解如何在SwiftUI应用程序中对图像执行人物分割。随后，我们将看到如何使用新的核心图像过滤器做同样的事情。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="bd91" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">设置我们的SwiftUI视图</h1><p id="af37" class="pw-post-body-paragraph kz la iu lb b lc mv jv le lf mw jy lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">这是一个简单的SwiftUI界面，包含三个垂直堆栈的图像:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nn no l"/></div></figure><p id="eaa6" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated"><code class="fe na nb nc nd b">task</code>是全新的SwiftUI修改器，用于执行异步操作。在其中，我们调用了我们的<code class="fe na nb nc nd b">runVisionRequest</code>方法。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="c9c8" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">运行愿景请求</h1><p id="e2ab" class="pw-post-body-paragraph kz la iu lb b lc mv jv le lf mw jy lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">以下方法运行Vision人员细分请求，并返回屏蔽的输出结果:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nn no l"/></div></figure><p id="c23f" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">以下是原始图像和遮罩图像的外观:</p><div class="kk kl km kn gu ab cb"><figure class="np ko nq nr ns nt nu paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/045b4164d57d4476e7340a6265a034ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*S9RFlBNQn_F0iC5RiuJX0Q.png"/></div></figure><figure class="np ko nq nr ns nt nu paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/7b073d63f71713c97f06e7b1cb379760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3rP4J-IrZViIUEOthjTnhg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk nv di nw nx translated"><a class="ae lv" href="https://unsplash.com/@omarlopez1?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">奥马尔·洛佩兹</a>在<a class="ae lv" href="https://unsplash.com/s/photos/friends-laughing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的原始照片</p></figure></div><p id="652b" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">虽然上面的分割蒙版使用了<code class="fe na nb nc nd b">accurate</code>质量水平，但下面看看<code class="fe na nb nc nd b">fast</code>和<code class="fe na nb nc nd b">balanced</code>的结果:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ny"><img src="../Images/7ac7d7638d89c4065f42ada44c4ac2e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BErCgiRI1jLOwOIrWKH_5Q.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者截屏</p></figure><p id="5886" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">为了添加新的背景，我们将分割蒙版传递给<code class="fe na nb nc nd b">maskInputImage</code>函数。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nn no l"/></div></figure><p id="1924" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这个函数使用一个<code class="fe na nb nc nd b">CoreImage</code>混合滤镜来裁剪掉原始图像上的蒙版图像，然后将其与一个新的背景图像混合。</p><p id="38c6" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">它返回以下结果:</p><div class="kk kl km kn gu ab cb"><figure class="np ko nq nr ns nt nu paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/700c6630a396888c5159c58bf523d6b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*KGL-Y-JJwduHyPIi9JmFfA.png"/></div></figure><figure class="np ko nq nr ns nt nu paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/67836accc96ef39c9589434f1856a240.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*L3Ff0675rA7a_OPS0OFIXQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk nv di nw nx translated">帕特里克·托马索在<a class="ae lv" href="https://unsplash.com/s/photos/background?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的背景照片</p></figure></div></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="9b9b" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">运行核心图像过滤器</h1><p id="095d" class="pw-post-body-paragraph kz la iu lb b lc mv jv le lf mw jy lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">Core Image是苹果的图像处理框架，广泛用于简单的计算机视觉任务。</p><p id="a66c" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在iOS 15中，Core Image获得了以下新过滤器:</p><pre class="kk kl km kn gu ne nd nf ng aw nh bi"><span id="02ae" class="ni me iu nd b gz nj nk l nl nm">CIFilter.personSegmentation()</span></pre><p id="4a4c" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我们可以通过以下方式将其应用于我们之前的SwiftUI视图:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nn no l"/></div></figure><p id="c3ca" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这是它在模拟器上的样子:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nz"><img src="../Images/7128e110bae19a93a1eec07592a3b231.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*K6YkNuL_Zk3gCZvCxHXMeg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">屏幕上显示程序运行的图片</p></figure><p id="7d8c" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">为了将上面的分割混合到新的背景中，你需要将红色转换成白色，这样<a class="ae lv" href="https://developer.apple.com/library/archive/documentation/GraphicsImaging/Reference/CoreImageFilterReference/index.html#//apple_ref/doc/filter/ci/CIBlendWithMask" rel="noopener ugc nofollow" target="_blank">混合滤镜</a>才能正常工作。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="273f" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">结论</h1><p id="b86d" class="pw-post-body-paragraph kz la iu lb b lc mv jv le lf mw jy lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">这概括了视觉的新的人细分的要求。在实时视频播放器上看到结果会很有趣。</p><p id="3397" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">您可以从<a class="ae lv" href="https://github.com/iosdevie/iOS15-Resources/tree/main/iOS15VisionPersonSegmentation" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>下载完整的源代码。</p><p id="82cb" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我们还可以运行顺序视觉请求。例如，你可以将上面的人物分割与面部姿态请求结合起来，构建创造性的人工智能应用程序。</p><p id="8e40" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated"><a class="oa ob ep" href="https://medium.com/u/144ed0020011?source=post_page-----5c031a2f3822--------------------------------" rel="noopener" target="_blank"> Philipp Gehrke </a>展示如何实现<a class="ae lv" rel="noopener ugc nofollow" target="_blank" href="/ios-14-vision-body-pose-detection-count-squat-reps-in-a-workout-c88991f7cad4">视觉身体姿态估计</a>。这可能是开始整合上述人物分割请求并更准确地检测人物姿态的一个好地方。</p><p id="5445" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这一次到此为止。感谢阅读。</p><h1 id="c2fb" class="md me iu bd mf mg oc mi mj mk od mm mn ka oe kb mp kd of ke mr kg og kh mt mu bi translated">参考</h1><ul class=""><li id="986a" class="oh oi iu lb b lc mv lf mw li oj lm ok lq ol lu om on oo op bi translated"><a class="ae lv" href="https://developer.apple.com/videos/play/wwdc2021/10040/" rel="noopener ugc nofollow" target="_blank"> WWDC第21届</a></li></ul></div></div>    
</body>
</html>
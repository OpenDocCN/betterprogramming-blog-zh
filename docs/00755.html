<html>
<head>
<title>Calculating Text Similarity With Gensim</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Gensim计算文本相似度</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/introduction-to-gensim-calculating-text-similarity-9e8b55de342d?source=collection_archive---------2-----------------------#2019-07-10">https://betterprogramming.pub/introduction-to-gensim-calculating-text-similarity-9e8b55de342d?source=collection_archive---------2-----------------------#2019-07-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="968a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Genism工具轻松比较不同的文本</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f5dd0d33b6ad15672a8b60f595d1551b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vWOBONiJMU7FFLY6AwVLCA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://www.maxpixel.net/Education-Dictionary-Book-Literature-Page-3294946" rel="noopener ugc nofollow" target="_blank"> Maxpixel </a>的照片</p></figure><p id="f74a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两年前，我构建了我的第一个Python项目:一个在多篇文章之间生成相似性得分的工具。当时，我只是使用Python字典来存储文本文件的不同属性——比如词频、词干频率、句子长度、标点符号等等。—并以相对高效的方式进行比较。</p><p id="72c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多亏了这个Python项目，我在暑期实习时被分配独自做一个类似的项目。我被告知要建立一个工具来比较大量电影和电视产品的不同属性。该工具应该生成一组字典，其中包含相同或最相似的产品，这些产品以不同的相似性得分成对出现。</p><p id="7972" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我开始用和上次一样的方法做这个项目，但是进展并不顺利。然后，我被介绍到了<a class="ae ky" href="https://radimrehurek.com/gensim/intro.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Gensim </strong> </a>。</p><p id="63b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Gensim官方网站上的内容和它的教程有点太模糊了，所以我想谈谈什么是Gensim。更重要的是，我想说说我学习和使用Gensim的经历。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/ea0ca8660da989f419ade9622b986ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GYEB8J6c5aaMiUgceMp6HQ.jpeg"/></div></div></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="13e8" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">什么是Gensim？</h1><p id="b738" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">根据Gnism的官方网站:</p><blockquote class="na"><p id="3e3a" class="nb nc it bd nd ne nf ng nh ni nj lu dk translated">Gensim是一个免费的Python库，旨在尽可能高效(对计算机而言)和无痛苦(对人类而言)地从文档中自动提取语义主题。Gensim旨在处理原始的、非结构化的数字文本(“<em class="nk">纯文本</em>”)。</p></blockquote></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="0fd2" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">主要概念</h1><p id="7706" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><strong class="lb iu">文集</strong></p><p id="8b1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语料库用于在Gensim中训练机器学习模型，并且模型使用语料库来初始化模型的参数。</p><p id="747c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">向量空间模型(VSM) </strong></p><p id="5595" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个文档都由一系列功能表示，您可以将这些功能看作一个问答对。一个特征的例子可以是如下:<strong class="lb iu">单词“happy”在文本文档中出现了多少次？三个。</strong></p><p id="94b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">问题由其id(整数)表示，因此文本文档的表示变成一系列对，例如(2，4.0)、(3，6.0)、(4，5.0)。这个系列可以被认为是一个<strong class="lb iu">向量。</strong></p><p id="afa7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果两个文档中的向量相似，那么这两个文档也一定相似。</p><p id="86d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">稀疏向量</strong></p><p id="8ebe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Gensim中的文档由稀疏向量表示。Gensim省略了所有值为0.0的向量，每个向量都是一对(feature_id，feature_value)。</p><p id="a730" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">型号</strong></p><p id="9091" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型可以被认为是从一个向量空间到另一个向量空间的变换。通过训练语料库，学习这种转换的参数。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="bbd4" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">使用Gensim确定文本相似性</h1><p id="1d19" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">下面是一个生成文本相似性的简单代码实现示例:</p><p id="89c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(这里，<code class="fe nl nm nn no b">jieba</code>是一个文本分段Python模块，用于将单词切割成分段，以便于将来进行文本相似性分析。)</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="ba5f" class="nt me it no b gy nu nv l nw nx">from gensim import corpora, models, similarities<br/>import jieba</span><span id="f55a" class="nt me it no b gy ny nv l nw nx">texts = ['I love reading Japanese novels. My favorite Japanese writer is Tanizaki Junichiro.', 'Natsume Soseki is a well-known Japanese novelist and his Kokoro is a masterpiece.', 'American modern poetry is good. ']</span><span id="8638" class="nt me it no b gy ny nv l nw nx">keyword = 'Japan has some great novelists. Who is your favorite Japanese writer?'</span><span id="1949" class="nt me it no b gy ny nv l nw nx">texts = [jieba.lcut(text) for text in texts]</span><span id="cf06" class="nt me it no b gy ny nv l nw nx">dictionary = corpora.Dictionary(texts)</span><span id="1d4f" class="nt me it no b gy ny nv l nw nx">feature_cnt = len(dictionary.token2id)</span><span id="a379" class="nt me it no b gy ny nv l nw nx">corpus = [dictionary.doc2bow(text) for text in texts]</span><span id="bb09" class="nt me it no b gy ny nv l nw nx">tfidf = models.TfidfModel(corpus) </span><span id="0a0e" class="nt me it no b gy ny nv l nw nx">kw_vector = dictionary.doc2bow(jieba.lcut(keyword))</span><span id="b69b" class="nt me it no b gy ny nv l nw nx">index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)</span><span id="f219" class="nt me it no b gy ny nv l nw nx">sim = index[tfidf[kw_vector]]</span><span id="ba68" class="nt me it no b gy ny nv l nw nx">for i in range(len(sim)):<br/>    print('keyword is similar to text%d: %.2f' % (i + 1, sim[i]))</span></pre><p id="6a32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">打印结果:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="c57f" class="nt me it no b gy nu nv l nw nx">keyword is similar to text1: 0.50<br/>keyword is similar to text2: 0.02<br/>keyword is similar to text3: 0.00</span></pre></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="5b0d" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">代码解释</h1><h2 id="487e" class="nt me it bd mf nz oa dn mj ob oc dp mn li od oe mp lm of og mr lq oh oi mt oj bi translated">第一步:使用Jieba进行分词</h2><p id="20ed" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">首先，我们来看看<code class="fe nl nm nn no b">jieba</code>是如何工作的。我们要从谷崎润一郎的小说<a class="ae ky" href="https://en.wikipedia.org/wiki/Naomi_(novel)" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ok">中截取一段语录【直美</em> </strong> </a> <em class="ok"> : </em></p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="667f" class="nt me it no b gy nu nv l nw nx">import jieba </span><span id="73ff" class="nt me it no b gy ny nv l nw nx">text = ‘I wanted to boast to everyone. This woman is mine. Take a look at my treasure. ‘ </span><span id="6aad" class="nt me it no b gy ny nv l nw nx">words = jieba.lcut(text)</span><span id="3baa" class="nt me it no b gy ny nv l nw nx">print(words)<br/></span></pre><p id="1775" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">打印结果:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="983c" class="nt me it no b gy nu nv l nw nx">[‘I’, ‘wanted’, ‘to’, ‘boast’, ‘to’, ‘everyone’, ‘.’, ‘This’, ‘woman’, ‘is’, ‘mine’, ‘.’, ‘Take’, ‘a’, ‘look’, ‘at’, ‘my’, ‘treasure’, ‘.’]</span></pre><h2 id="3560" class="nt me it bd mf nz oa dn mj ob oc dp mn li od oe mp lm of og mr lq oh oi mt oj bi translated">第二步:根据<code class="fe nl nm nn no b">dictionary</code>获得特征的数量</h2><p id="08a9" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><code class="fe nl nm nn no b">corpora.Dictionary</code>建立字典。</p><p id="fecc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nl nm nn no b">len(dictionary.token2id)</code>代表字典中的字数。</p><p id="071a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">示例</strong>:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="66b7" class="nt me it no b gy nu nv l nw nx">from gensim import corpora<br/>import jieba</span><span id="679d" class="nt me it no b gy ny nv l nw nx"><br/>text1 = ‘痴人の愛’</span><span id="df22" class="nt me it no b gy ny nv l nw nx">text2 = ‘よく世間では「女が男を欺す」と云います。’</span><span id="1e80" class="nt me it no b gy ny nv l nw nx">texts = [text1, text2]</span><span id="a824" class="nt me it no b gy ny nv l nw nx"># Generate a word list for the text set</span><span id="3425" class="nt me it no b gy ny nv l nw nx">texts = [jieba.lcut(text) for text in texts]</span><span id="a386" class="nt me it no b gy ny nv l nw nx">print(‘Text set:’, texts)<br/></span><span id="a6c3" class="nt me it no b gy ny nv l nw nx">#Build a dictionary based on a text set</span><span id="11bd" class="nt me it no b gy ny nv l nw nx">dictionary = corpora.Dictionary(texts)</span><span id="c3dd" class="nt me it no b gy ny nv l nw nx">print(‘dictionary:’, dictionary)<br/></span><span id="39f4" class="nt me it no b gy ny nv l nw nx"># Extract dictionary features</span><span id="c437" class="nt me it no b gy ny nv l nw nx">feature_cnt = len(dictionary.token2id)</span><span id="a7f7" class="nt me it no b gy ny nv l nw nx">print(‘Dictionary feature number: %d’ % feature_cnt)</span></pre><p id="9beb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">打印结果:</strong></p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="1495" class="nt me it no b gy nu nv l nw nx">Text set: [['痴人', 'の', '愛'], ['よ', 'く', '世間', 'で', 'は', '「', '女', 'が', '男', 'を', '欺', 'す', '」', 'と', '云', 'い', 'ま', 'す', '。']]</span><span id="67c8" class="nt me it no b gy ny nv l nw nx">dictionary: Dictionary(21 unique tokens: ['の', '愛', '痴人', '。', '「']...)</span><span id="1a30" class="nt me it no b gy ny nv l nw nx">Dictionary feature number: 21</span></pre><h2 id="2240" class="nt me it bd mf nz oa dn mj ob oc dp mn li od oe mp lm of og mr lq oh oi mt oj bi translated">第三步:基于词典获取语料库</h2><p id="ae0a" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><strong class="lb iu">举例:</strong></p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="84e0" class="nt me it no b gy nu nv l nw nx">from gensim import corpora<br/>import jieba</span><span id="11c3" class="nt me it no b gy ny nv l nw nx">text1 = 'I love Tokyo'</span><span id="34e3" class="nt me it no b gy ny nv l nw nx">text2 = 'Tokyo, Tokyo, Tokyo'</span><span id="c66e" class="nt me it no b gy ny nv l nw nx">texts = [text1, text2]</span><span id="69bf" class="nt me it no b gy ny nv l nw nx">texts = [jieba.lcut(text) for text in texts]</span><span id="796a" class="nt me it no b gy ny nv l nw nx">dictionary = corpora.Dictionary(texts)</span><span id="53b7" class="nt me it no b gy ny nv l nw nx">corpus = [dictionary.doc2bow(text) for text in texts]</span><span id="aa89" class="nt me it no b gy ny nv l nw nx">print('Dictionary (dictionary):', dictionary.token2id)</span><span id="4026" class="nt me it no b gy ny nv l nw nx">print('Corpus: ', corpus)</span></pre><p id="8521" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">打印结果:</strong></p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="eb09" class="nt me it no b gy nu nv l nw nx">Dictionary (dictionary): {' ': 0, 'Come': 1, 'Tokyo': 2, 'cuisine': 3, 'for': 4, 'to': 5, ',': 6}</span><span id="addd" class="nt me it no b gy ny nv l nw nx">Corpus: [[(0, 5), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1)], [(0, 2), (2, 3), (6, 2)]]</span></pre><p id="7646" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，<code class="fe nl nm nn no b">doc2bow</code>函数生成<a class="ae ky" href="https://stackoverflow.com/questions/31522893/sparse-vector-vs-dense-vector" rel="noopener ugc nofollow" target="_blank">稀疏向量</a>。</p><h2 id="8099" class="nt me it bd mf nz oa dn mj ob oc dp mn li od oe mp lm of og mr lq oh oi mt oj bi translated">第四步:使用TF-IDF模型对语料进行处理，获得索引</h2><p id="a3ca" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">这里有更多关于TF-IDF的信息。</p><p id="eab9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nl nm nn no b">tfidf = models.TfidfModel(corpus)</code></p><p id="d41c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nl nm nn no b">index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)</code></p><h2 id="ad73" class="nt me it bd mf nz oa dn mj ob oc dp mn li od oe mp lm of og mr lq oh oi mt oj bi translated">步骤5:将搜索词转换成稀疏向量</h2><p id="3391" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><strong class="lb iu">例如:</strong></p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="6cea" class="nt me it no b gy nu nv l nw nx">from gensim import corpora<br/>import jieba</span><span id="bddb" class="nt me it no b gy ny nv l nw nx">text1 = ‘Tanizaki Junichiro writes good stories’ </span><span id="cb61" class="nt me it no b gy ny nv l nw nx">text2 = ‘Naomi is a story written by Tanizaki’</span><span id="2fc6" class="nt me it no b gy ny nv l nw nx">texts = [text1, text2]</span><span id="ee66" class="nt me it no b gy ny nv l nw nx">texts = [jieba.lcut(text) for text in texts]</span><span id="3482" class="nt me it no b gy ny nv l nw nx">dictionary = corpora.Dictionary(texts)</span><span id="6ad5" class="nt me it no b gy ny nv l nw nx"># Use [Dictionary] to convert [search word] to [sparse vector]<br/>keyword = ‘good stories’</span><span id="1fbb" class="nt me it no b gy ny nv l nw nx">kw_vector = dictionary.doc2bow(jieba.lcut(keyword))</span><span id="54a8" class="nt me it no b gy ny nv l nw nx">print(kw_vector)</span></pre><p id="9338" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">打印结果:</strong></p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="e986" class="nt me it no b gy nu nv l nw nx">[(0, 1), (3, 1), (4, 1)]</span></pre><h2 id="46a0" class="nt me it bd mf nz oa dn mj ob oc dp mn li od oe mp lm of og mr lq oh oi mt oj bi translated">第五步:把所有东西放在一起:相似度计算</h2><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="af5a" class="nt me it no b gy nu nv l nw nx">texts = [jieba.lcut(text) for text in texts]</span><span id="b2c1" class="nt me it no b gy ny nv l nw nx">dictionary = corpora.Dictionary(texts)</span><span id="f871" class="nt me it no b gy ny nv l nw nx">feature_cnt = len(dictionary.token2id)</span><span id="22a6" class="nt me it no b gy ny nv l nw nx">corpus = [dictionary.doc2bow(text) for text in texts]</span><span id="7779" class="nt me it no b gy ny nv l nw nx">tfidf = models.TfidfModel(corpus)</span><span id="7c75" class="nt me it no b gy ny nv l nw nx">kw_vector = dictionary.doc2bow(jieba.lcut(keyword))</span><span id="cc08" class="nt me it no b gy ny nv l nw nx">index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)</span><span id="c228" class="nt me it no b gy ny nv l nw nx">sim = index[tfidf[kw_vector]]</span><span id="356d" class="nt me it no b gy ny nv l nw nx">for i in range(len(sim)):<br/>    print('keyword is similar to text%d: %.2f' % (i + 1, sim[i]))</span></pre></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="60ea" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">Gensim在电影比较项目中的应用</h1><p id="5eb0" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在了解了Gensim的基本用途后，我将Gensim融入到我的项目中来比较电影和电视。</p><p id="7081" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，最初的输入是包含电影和电视属性的两个Excel表。表单的标题如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/465174d95a46914f960d3d11c4dcdbf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*vkfY2cUGdm24HFnJNXSfrw.png"/></div></figure><p id="2a73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">名称和摘要是最难比较的资产，因为它们是句子/段落的形式。因此，这里使用Gensim和<code class="fe nl nm nn no b">jieba</code>。</p><p id="f8d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在使用<code class="fe nl nm nn no b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html" rel="noopener ugc nofollow" target="_blank">pandas</a></code>从两个Excel表中提取所有数据并保存在数据框中之后，我们可以将名称和摘要分别存储在字典中。这有助于指示资产的ID及其相应的属性。</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="bcd6" class="nt me it no b gy nu nv l nw nx">df = pd.read_excel ("YOUR LOCAL FILE ADDRESS", sheetname = 'Sheet1')<br/>df2 = pd.read_excel("YOUR LOCAL FILE ADDRESS", sheetname = "Sheet1")</span><span id="c636" class="nt me it no b gy ny nv l nw nx"># This is the first excel file<br/>ccms_title = {}<br/>for i in range(len(df[‘assets_id’])):<br/> name = df[‘assets_name’][i]<br/> iD = str(df[‘assets_id’][i])<br/> ccms_title[iD] = name</span><span id="c06d" class="nt me it no b gy ny nv l nw nx"># This is the second excel file<br/>douban_title = {}<br/>for i in range(len(df2[‘assets_id’])):<br/> name = df2[‘assets_name’][i]<br/> iD = str(df2[‘assets_id’][i])<br/> douban_title[iD] = name</span><span id="e60c" class="nt me it no b gy ny nv l nw nx">ccms_summary = {}<br/>for i in range(len(df['assets_id'])):<br/>    name = df['assets_name'][i]<br/>    iD = str(df['summary'][i])<br/>    ccms_summary[iD] = name</span><span id="dc0f" class="nt me it no b gy ny nv l nw nx">douban_summary = {}<br/>for i in range(len(df2['assets_id'])):<br/>    name = df2['assets_name'][i]<br/>    iD = str(df2['summary'][i])<br/>    douban_summary[iD] = name</span></pre><p id="3318" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建一个使用Gensim计算标题和摘要之间相似性得分的函数。</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="abe0" class="nt me it no b gy nu nv l nw nx">def gensimCalculation(d1, d2):<br/>  new_dict = {}</span><span id="29cb" class="nt me it no b gy ny nv l nw nx">  for x in d1:<br/>    text1 = d1[x]<br/>    texts = [jieba.lcut(d2[y]) for y in d2] <br/>    dictionary = corpora.Dictionary(texts)<br/>    feature_cnt = len(dictionary.token2id)<br/>    corpus = [dictionary.doc2bow(text) for text in texts]<br/>    tfidf = models.TfidfModel(corpus)<br/>    new_vec = dictionary.doc2bow(jieba.lcut(text1))<br/>    index = similarities.SparseMatrixSimilarity(tfidf[corpus],     num_features = feature_cnt)<br/>    sim = index[tfidf[new_vec]]<br/>    new_dict[x] = max(sim) </span><span id="732e" class="nt me it no b gy ny nv l nw nx"> print(new_dict)<br/> return</span><span id="6a1b" class="nt me it no b gy ny nv l nw nx">print(gensimCalculation(ccms_summary, douban_summary)) </span></pre><p id="ea5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该函数将excel1中的单个资产摘要与excel2中的所有其他摘要进行比较，并找到最相似的摘要。输出是一个字典，包含资产的ID和最相似的资产ID及其最相似的摘要。</p><p id="c828" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他的相似性计算，比如比较标题，也可以用这种方式有效地生成。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="f47d" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">摘要</h1><p id="3ae2" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在接近Gensim时，我学会了更加关注每一步的输入和输出。在Python中的分词模块<code class="fe nl nm nn no b">jieba</code>的帮助下，文本相似度很容易计算。</p></div></div>    
</body>
</html>
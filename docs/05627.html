<html>
<head>
<title>Building a neural network from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建神经网络</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/building-a-neural-network-from-scratch-without-frameworks-61a7ac225e82?source=collection_archive---------10-----------------------#2020-07-22">https://betterprogramming.pub/building-a-neural-network-from-scratch-without-frameworks-61a7ac225e82?source=collection_archive---------10-----------------------#2020-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9f6c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">对神经网络的更深入理解</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0fe1375ca305768ce68f7a5c18d1d013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9hDmNr4q0Kp-H6Wb"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">亚历山大·米洛在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="f233" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">什么是神经网络？</strong></h1><p id="98ca" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">神经网络是神经元层的集合，它将数据作为输入，训练自己识别数据中的模式，并预测相似类型数据的输出。</p><p id="2265" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">人工神经网络是生物神经网络的松散模型。</p><p id="24d3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">通俗地说，就像生物神经网络中极少量的信息从一个神经元传递到另一个神经元一样，人工神经网络中信息在不同层的神经元之间传递。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/d677ed6e8a8a45e493925de6b9412ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*akHYKaEdaOUazZBmdoNlzg.png"/></div></div></figure><p id="4ebd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">每个人工神经网络都有以下组件:</p><p id="f515" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">输入层:</em> </strong>在结构化数据中，输入层的节点数将等于特征数。在非结构化数据中，例如图像，节点的数量将等于图像的大小。</p><p id="8fd5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">权重和偏差:</em> </strong>使用权重修改每个神经元/节点的输入，并与偏差相加。</p><p id="8112" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">隐藏层:</em> </strong>隐藏层的大小(隐藏层的数量和每个隐藏层中神经元的数量)将根据我们正在处理的数据类型而定。隐藏层中的神经元是神经网络的核心处理单元。隐藏层中的每个神经元保存关于数据的特定子成分的信息。例如，在图像识别任务中，网络中的每个神经元都有一些关于图像边缘的信息。</p><p id="b58d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">输出层:</em> </strong>输出层中的节点数取决于标签列中的类数。</p><p id="da09" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">激活函数:</em> </strong>这些是应用于隐藏层和输出层中每个神经元的数学函数。有许多可用的激活功能，其中我们将使用<strong class="lq ir"><em class="mq"/></strong>和<strong class="lq ir"> <em class="mq"> ReLU </em> </strong>。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="0e3a" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">让我们建立我们的神经网络</h1><p id="7d45" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">让我们考虑一个三层神经网络(两个隐藏层和一个输出层)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/8877d9a0ec989904c6a990a19ca8e595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3fA77_mLNiJTSgZFhYnU0Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">三层神经网络</p></figure><p id="52a3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们必须为我们的神经网络创建一个类，并为所有三层随机初始化权重和偏差。</p><p id="8969" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">注:</em> </strong>开机前导入<strong class="lq ir"> <em class="mq"> NumPy </em> </strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="46f8" class="ng kx iq bd ky nh ni dn lc nj nk dp lg lx nl nm li mb nn no lk mf np nq lm nr bi translated"><strong class="ak">正向传播</strong></h2><p id="81dc" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">使用相应层的权重和偏差来修改每个层的输入。然后将结果输入激活函数，并转发到下一层。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/d5864753aa9af66194a9986a0c2e859b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YHhh5J5AZWfBG9WTfTJDXg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">正向传播</p></figure><p id="7fa2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于所有隐藏层，我们将使用<strong class="lq ir"> <em class="mq"> ReLU </em> </strong> <em class="mq"> </em>激活函数，对于输出层，我们将使用<strong class="lq ir"><em class="mq">sigmoid</em></strong><em class="mq"/>激活函数，因为它是一个二进制分类。我们可以用<strong class="lq ir"><em class="mq">soft max</em></strong><em class="mq"/><strong class="lq ir"><em class="mq">回归</em> </strong>的例子进行多类分类。</p><p id="ed35" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">注:tanH </em> </strong>和<strong class="lq ir"><em class="mq">leaky relu</em></strong><em class="mq"/>是其他可以使用的激活功能。</p><p id="1713" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">注:</em> </strong>我们对图层的权重和输入执行点积。所以，我们总是要跟踪矩阵的维数。在需要的地方调换输入。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="29d9" class="ng kx iq bd ky nh ni dn lc nj nk dp lg lx nl nm li mb nn no lk mf np nq lm nr bi translated"><strong class="ak">损失函数</strong></h2><p id="c0c4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">使用随机初始化的权重，我们将预测输出，然后计算预测中的误差。这种预测值与真实值的误差/偏差称为神经网络的成本/损失。</p><p id="3109" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面是神经网络的损失函数(<strong class="lq ir"> <em class="mq">)二元交叉熵</em> </strong>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/e3cde1957d3f3e26a3f4c7ba54b3b3ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mBs5vzfPHFBRenrac-iVLQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="3f19" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">有许多损失函数可用。既然我们在处理分类，<strong class="lq ir"> <em class="mq">二元交叉熵</em> </strong>用于二元分类，<strong class="lq ir"> <em class="mq">稀疏分类交叉熵</em> </strong>用于多类分类。</p><h2 id="5e14" class="ng kx iq bd ky nh ni dn lc nj nk dp lg lx nl nm li mb nn no lk mf np nq lm nr bi translated"><strong class="ak">反向传播</strong></h2><p id="b60e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们现在将反向传播，找出成本函数的斜率，以更新我们的权重和偏差。</p><p id="d87c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们不能根据权重和偏差直接计算成本函数的斜率。我们需要按顺序进行，如下图所示。</p><p id="8906" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">注:</em> </strong>在下面的推导中我已经使用了<strong class="lq ir"> <em class="mq"> sigmoid </em> </strong>激活函数。您可以更改激活功能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/32b8aae51741e09c7f1bae5c786ea9ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GN76DsIK-0P1XtqwrN06OQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/cfa92856de13ac0eba4a7c038e529760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*yRz_mxKkVInaxwxByUmqwA.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">反向传播</p></figure><h2 id="3783" class="ng kx iq bd ky nh ni dn lc nj nk dp lg lx nl nm li mb nn no lk mf np nq lm nr bi translated"><strong class="ak">梯度下降</strong></h2><p id="3a3f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们必须不断更新神经网络的权重和偏差，直到神经网络的成本最小。技术上来说，直到成本达到全球最低。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d919e1a1df1c4d63e3e2fc0916fee384.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*zhMRJeNe8zmgKsJHHcuVjA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">更新权重和偏差</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/05a7b1de4f018ea495f76e7adc9bc2bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nAUzoWNPMkIYUeDlDRfdGw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">梯度下降</p></figure><p id="e0aa" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">注:</em> </strong>代价达到全局最小值的速率由学习速率(alpha)决定。如果学习率很高，那么步长将很大，并且成本可能永远不会达到全局最小值。如果学习率低，达到全局最小值需要很多时间。所以，学习速度应该是最佳的。</p><p id="4df4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下图对此进行了解释。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/fd8989f3c3d546a2a4cff0678f2d2fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q52v-kT0Ner-A5r4FChEUw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">调整学习率</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="9455" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在全局最小值时，我们将拥有最佳的权重和偏差集，并且成本也将是最小的。</p><p id="1371" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们的目标是找出可用于进一步预测的最佳权重和偏差集。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="30bd" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">如何知道全局最小值？</h1><p id="1fc6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对一些迭代运行正向传播、反向传播函数，并计算每次迭代的成本。成本低的迭代是全局最小值。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="ab60" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">接下来呢？</h1><p id="aae2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">尝试编写一个函数来预测测试集的输出。</p><p id="3f27" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">了解超参数并尝试调整超参数以提高精度。</p><p id="fcb2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">了解正规化。它有助于您概括您的模型，并防止过度拟合数据。</p><p id="a6fd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mq">过得愉快。</em> </strong></p></div></div>    
</body>
</html>
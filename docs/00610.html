<html>
<head>
<title>Web Scraping in Python With Beautiful Soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用蟒蛇皮刮网，汤很美</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/webscraping-in-python-with-beautiful-soup-part-1-into-the-miso-soup-5115ff34192f?source=collection_archive---------4-----------------------#2019-06-18">https://betterprogramming.pub/webscraping-in-python-with-beautiful-soup-part-1-into-the-miso-soup-5115ff34192f?source=collection_archive---------4-----------------------#2019-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0989" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第一部分——加入味噌汤</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e0de661a190348544ca93084f814fa3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgclYm3HF_PcuELR5BMbzQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Siarhei Horbach 在<a class="ae kv" href="https://unsplash.com/search/photos/security-camera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="e9a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于数据分析和数据科学，我最喜欢的事情之一是，只要有数据要分析，人们使用它的工具集就可以研究几乎任何领域或问题。虽然有大量的数据集可供探索，但经常会出现这样的情况，即您想要研究的主题还没有现成的数据集，或者数据无法以可用的格式访问。这就是网络抓取派上用场的地方。简而言之，网络抓取是从网站提取数据的过程，通常是为了编译数据并将其存储在本地数据库中。网络抓取是你工具包中的一个很好的工具，因为它本质上使你能够创建你自己的关于任何你能在网上找到信息的主题的数据集。</p><p id="2c4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然网络抓取本身提出了一些道德和法律问题，但我的观点是，如果一个网站上有公开可用的数据，我可以手动访问和记录这些数据以编译数据集，那么我通过抓取该网站所做的一切就是使用代码来自动完成我原本可以手动完成的任务。然而，我应该提到，检查一个网站的robot.txt，看看他们是否允许网络抓取，通常是一个好主意。</p><p id="3467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在最近的一个分析项目中，我在研究<a class="ae kv" href="http://www.mediaeater.com/cameras/locations.html" rel="noopener ugc nofollow" target="_blank">纽约市监控摄像头项目</a>的工作，这是一个从20世纪90年代末到21世纪初的公民测绘项目，通过收集全市社区委员会中视频监控摄像头的位置，提高了人们对纽约市越来越多的监控基础设施的认识。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/2eeb9390a7c853bcdfd985f246ebbb65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*faZ1V-877eTm9x9KvypYrA.jpeg"/></div></div></figure><p id="9481" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我感兴趣的是搜集所有已识别的摄像机的位置，以便创建一个截至2006年曼哈顿所有摄像机位置的地图。点击其中一个<em class="lt">文本列表</em>链接，会出现一个如下所示的页面:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/f07af4bd982c51f4c45f5340bf02afb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ij_DqvKXXKRH5P5QbmblWw.jpeg"/></div></div></figure><p id="0bd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如你所见，摄像机位置的格式通常非常相似。位置要么以十字路口(州街和大桥街)的形式给出，要么以街区面(州街和白厅街之间的大桥街)的形式给出。其后是冒号(:)、摄像机数量，然后是下一行的具体位置信息。</p><p id="289b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我知道了我要找的信息存储在网站上的什么地方，以及这些信息的一般格式，我只需要写一些代码来自动执行转到每个社区公告板的<code class="fe lv lw lx ly b">text_listing</code>链接并提取每个摄像机位置的过程。</p><p id="f05d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个任务，我将导入<code class="fe lv lw lx ly b">pandas</code> <strong class="ky ir"> </strong>和<code class="fe lv lw lx ly b">numpy</code>(三个常见的嫌疑对象中的两个)，以及<code class="fe lv lw lx ly b">requests</code>和<code class="fe lv lw lx ly b">BeautifulSoup</code>，这两个Python库用于访问网站和解析HTML。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="2749" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，要使用<code class="fe lv lw lx ly b">requests</code>库，我需要提供一个到网站的链接。在这里，我将链接分成两部分:<code class="fe lv lw lx ly b">url</code>和<code class="fe lv lw lx ly b">locations</code>。这种拆分的原因稍后会变得更清楚，但我决定以这种方式拆分链接，以便稍后当我希望访问网站上的其他页面时重用<code class="fe lv lw lx ly b">url</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="c38f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我可以通过对从<code class="fe lv lw lx ly b">requests</code>调用返回的内容调用<code class="fe lv lw lx ly b">BeautifulSoup</code>来使用<code class="fe lv lw lx ly b">BeautifulSoup</code>解析HTML。</p><pre class="kg kh ki kj gt mb ly mc md aw me bi"><span id="0273" class="mf mg iq ly b gy mh mi l mj mk">soup = BeautifulSoup(res.content, ‘lxml’)</span></pre><p id="6838" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe lv lw lx ly b">soup</code>对象现在包含了第一个网页的所有HTML:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不太漂亮的汤</p></figure><p id="8310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的部分挑战是识别你要寻找的信息存储在HTML的什么地方。虽然有一些方法可以加快这个过程，比如右键单击页面并选择<em class="lt"> Inspect </em>来识别引用特定元素的HTML部分，但是我发现自己浏览一些HTML对于理解我在做什么是一个有用的练习。</p><p id="e46f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">向下滚动到HTML中的第20行，我可以看到每个社区公告板有两行，如下所示:</p><pre class="kg kh ki kj gt mb ly mc md aw me bi"><span id="bcfc" class="mf mg iq ly b gy mh mi l mj mk">&lt;b&gt;Community Board 1&lt;/b&gt;&lt;br/&gt;<br/>&lt;a href="info/cb-01.html"&gt;[ text listing ]&lt;/a&gt;   [ &lt;a href="maps/nyc.pdf"&gt;map&lt;/a&gt; ]&lt;p&gt;</span></pre><p id="0959" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我要寻找的位置信息存储在每个社区板的信息页面上，我想检查<a>(超链接)部分并提取<code class="fe lv lw lx ly b">href</code>(指定链接目的地的属性)。在这个例子中，我想要的<code class="fe lv lw lx ly b">href</code>是<code class="fe lv lw lx ly b">info/cb-01.html</code>，它是社区公告板信息页面的URL结尾。</a></p><p id="5e39" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了访问我正在寻找的HTML部分，我可以使用BeautifulSoup的<code class="fe lv lw lx ly b">.<em class="lt">find()</em></code>方法来搜索一个标签和我想要指定的任何附加属性；这将返回HTML中标记的第一个实例(具有指定的属性)。在这种情况下，我可以看到有一个包含所有社区板<code class="fe lv lw lx ly b">hrefs</code>的<code class="fe lv lw lx ly b">table</code>部分，从第16行开始，到第51行结束。然而，如果我尝试使用<code class="fe lv lw lx ly b">soup.find(“table”)</code>，那么将返回从第7行开始的表，一个包含我尝试引用的表的更大的表。我仍然可以通过这种方式获得信息，但是通过更具体地查询，我可以让<code class="fe lv lw lx ly b">find</code>只返回我正在寻找的表。因为我可以看到我想要的表有一个等于450的<code class="fe lv lw lx ly b">width</code>属性，而较大的表有一个585的<code class="fe lv lw lx ly b">width</code>，所以我可以使用<code class="fe lv lw lx ly b">soup.find(‘table’, attrs = {‘width’:”450"})</code>。这将返回:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="983e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正是我想要的部分。我将把它保存为<code class="fe lv lw lx ly b">cb_table</code>，这样我现在可以只在那个部分中搜索，而不是整个<code class="fe lv lw lx ly b">soup</code>对象。所以我写道:</p><p id="7fef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe lv lw lx ly b">cb_table = soup.find(‘table’, attrs = {‘width’:”450"})</code></p><p id="7f32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我可以使用BeautifulSoup的<code class="fe lv lw lx ly b">find_all()</code>方法来搜索一个HTML标签并返回所有匹配的标签对象。因为我想要所有的超链接，所以我可以使用<code class="fe lv lw lx ly b">.find_all(‘a’)</code>。所以现在行<code class="fe lv lw lx ly b">cb_table.find_all(‘a’)</code>返回:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="1c18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将把它保存为<code class="fe lv lw lx ly b">cb_links</code>,因为这是我在这一点上需要引用的该页面的唯一部分。现在<code class="fe lv lw lx ly b">cb_links</code>是一个漂亮的组<code class="fe lv lw lx ly b">ResultSet</code>，一个行为很像列表的对象。为了了解如何访问这个<code class="fe lv lw lx ly b">ResultSet</code>中的<code class="fe lv lw lx ly b">hrefs</code>，我可以尝试用<code class="fe lv lw lx ly b">cb_links[0]</code>访问第一个元素。这将返回:</p><pre class="kg kh ki kj gt mb ly mc md aw me bi"><span id="31db" class="mf mg iq ly b gy mh mi l mj mk">&lt;a href="info/cb-01.html"&gt;[ text listing ]&lt;/a&gt;</span></pre><p id="96ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个漂亮的Soup <code class="fe lv lw lx ly b">Tag</code>对象，所以我可以使用<code class="fe lv lw lx ly b">cb_links[0].attrs</code>返回标签属性的字典，而<code class="fe lv lw lx ly b">cb_links[0].text</code>将返回为那个<code class="fe lv lw lx ly b">Tag</code>存储的文本。由于我需要<code class="fe lv lw lx ly b">href</code>信息，我可以使用<code class="fe lv lw lx ly b">cb_links[0].attrs[‘href’]</code>返回<code class="fe lv lw lx ly b">info/cb-01.html</code>，但是由于<code class="fe lv lw lx ly b">cb_links</code>中有两种类型的<code class="fe lv lw lx ly b">a</code>标签，我想使用为信息<code class="fe lv lw lx ly b">hrefs</code>存储的文本作为识别这些标签的方法。我可以在<code class="fe lv lw lx ly b">cb_links</code>中看到，所有的信息<code class="fe lv lw lx ly b">hrefs</code>都有相同的文本<code class="fe lv lw lx ly b">[ text listing ]</code>，因此我可以编写一个for循环来遍历<em class="lt"> cb_links </em>以检查文本是否等于<code class="fe lv lw lx ly b">[ text listing ]</code>，如果相等则返回<code class="fe lv lw lx ly b">href</code>。对于这样的简单循环，我更喜欢使用列表理解，所以下面的代码行将完成这个任务:</p><p id="5238" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe lv lw lx ly b">cb_hrefs = [link.attrs[‘href’] for link in cb_links if link.text == ‘[ text listing ]’]</code></p><p id="5b07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我有了一个列表，其中仅列出了社区公告板信息页面的URL结尾，如下所示:</p><pre class="kg kh ki kj gt mb ly mc md aw me bi"><span id="f996" class="mf mg iq ly b gy mh mi l mj mk">['info/cb-01.html',<br/> 'info/cb-02.html',<br/> 'info/cb-03.html',<br/> 'info/cb-04.html',<br/> 'info/cb-05.html',<br/> 'info/cb-06.html',<br/> 'info/cb-07.html',<br/> 'info/cb-08.html',<br/> 'info/cb-09.html',<br/> 'info/cb-10.html',<br/> 'info/cb-11.html',<br/> 'info/cb-12.html']</span></pre><p id="9b3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不错！现在，类似于我如何将<code class="fe lv lw lx ly b">locations.html</code>追加到原始URL、<code class="fe lv lw lx ly b"><a class="ae kv" href="http://www.mediaeater.com/cameras/," rel="noopener ugc nofollow" target="_blank">http://www.mediaeater.com/cameras/</a></code>、<a class="ae kv" href="http://www.mediaeater.com/cameras/," rel="noopener ugc nofollow" target="_blank">、</a>中，我可以将这些<code class="fe lv lw lx ly b">hrefs</code>追加到原始URL中以访问信息页面，并重复我在开始时使用requests和BeautifulSoup来访问每个社区板的信息页面的过程。</p><p id="c2bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第一个<code class="fe lv lw lx ly b">href</code>上测试这个过程，我可以看到信息页面的结构:</p><blockquote class="ml mm mn"><p id="36e2" class="kw kx lt ky b kz la jr lb lc ld ju le mo lg lh li mp lk ll lm mq lo lp lq lr ij bi translated"><code class="fe lv lw lx ly b">test_url = url+cb_hrefs[0]<br/>res = requests.get(test_url)<br/>soup = BeautifulSoup(res.content, ‘lxml’)</code></p></blockquote><p id="f5b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在HTML soup明显更长了(大约579行)，所以我不会在这里展示它，但是正如我必须浏览上一个HTML soup来找到我想要的信息一样，我可以浏览这个HTML来找到相机位置存储在哪里。</p><p id="de83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于这篇文章有点长，我将在这里把它剪掉，在我的下一篇文章中继续剖析这个网站。我将通过类似的过程从第一页中提取摄像机位置，然后我将概括我的方法，这样我可以编写一个for循环来在所有社区公告板信息页面上执行相同的过程。敬请关注。</p></div></div>    
</body>
</html>
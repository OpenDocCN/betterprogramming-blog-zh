# ML 模型训练的 10 大罪

> 原文：<https://betterprogramming.pub/10-deadly-sins-of-ml-model-training-a5046c1f5094>

## 这些错误很容易被忽视，但要弥补却代价高昂

![](img/dcf642dca1e6dbb0d5d524e047ce6709.png)

弗兰克·维西亚在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

ML 模型训练是整个建模过程中最耗时、最耗费资源的部分。根据定义，培训是迭代的，但是在迭代过程中的某个地方，错误会渗入其中。在这篇文章中，我分享了在 ML 模型训练中的十大罪——这些是最常见也是最容易被忽视的。

# ML 模型训练的十大罪

## ***1。模型不收敛时盲目增加历元数***

在模型训练过程中，会出现丢失历元图不断跳动，并且无论历元的数量如何似乎都不收敛的情况。没有灵丹妙药，因为有多个根本原因需要调查——糟糕的训练示例、遗漏的事实、不断变化的数据分布、过高的学习率。我见过的最常见的例子是与异常数据和不正确标签的组合相关的糟糕的训练例子。

## 2. ***不混洗训练数据集***

有时会出现这样的情况，模型似乎正在收敛，但损失值突然显著增加，即损失值随着时间的推移先减少，然后显著增加。这种爆炸性的损失有多种原因。我见过的最常见的是数据中的异常值，这些异常值在数据中不是均匀分布/混合的。一般来说，洗牌是一个重要的步骤，包括对于损失显示重复阶跃函数行为的模式。

## 3. ***在多类分类中，不优先考虑具体的每类度量准确性***

对于多类预测问题，不是只跟踪总体分类精度，而是优先考虑特定类的精度并逐个类地迭代改进模型通常是有用的。例如，在对不同形式的欺诈交易进行分类时，应根据业务需求重点提高特定类别(如国外交易)的召回率。

## 4. ***假设特异性会导致模型精度降低***

与其构建一个通用模型，不如设想为特定的地理区域或特定的用户角色构建一个模型。特异性将使数据更加稀疏，但可以提高这些特定问题的准确性。在调优过程中探索特异性和稀疏性之间的权衡是很重要的。

## 5. ***忽略预测偏差***

预测偏差是预测的平均值与数据集中标注的平均值之间的差异。预测偏差是模型问题的早期指标。一个大的非零预测偏差表明模型中的某个地方有错误。在广告中心的背景下有一篇有趣的[脸书论文](https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf)。通常，偏差对于跨预测时段进行测量非常有用。

## 6. ***称之为成功只是在型号准确度上的数字***

95%的准确率意味着 100 个预测中有 95 个是正确的。准确性是一个有缺陷的度量，数据集中存在类别不平衡。取而代之的是深入调查指标，如精确度/召回率，以及它与总体用户指标(如垃圾邮件检测、肿瘤分类等)的关系。

## 7. ***不了解正规化的影响***

Lambda 是在简单性和训练数据拟合之间取得平衡的关键参数。高 lambda →简单模型→可能不合适。低 lambda →复杂模型→可能过度拟合您的数据(无法推广到新数据)。lambda 的理想值是能够很好地概括以前看不到的数据的值:依赖于数据并需要分析。

## 8.一遍又一遍地使用相同的测试集

参数和超参数设置中使用的相同数据越多，结果实际推广的可信度就越低。收集更多的数据并不断添加到测试和验证集是很重要的。

## ***9。不注意神经网络中的初始值***

给定 NN 中的非凸优化，[初始化关系到](https://www.deeplearning.ai/ai-notes/initialization/)。

## 10.假设错误的标签总是需要被修正

当检测到错误的标签时，人们很容易跳出来修复它们。首先分析错误分类的例子以找出根本原因是很重要的。通常，由于不正确的标签导致的错误可能只占很小的百分比。针对可能是主要根本原因的特定数据切片进行更好的培训的机会可能更大。

总的来说，避免这些错误会让你远远领先于大多数其他团队。在你的过程中把这些作为一个清单。
<html>
<head>
<title>The Best Way To Choose a Regression Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">选择回归算法的最佳方式</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/the-best-way-to-choose-a-regression-algorithm-c23992c82d8e?source=collection_archive---------13-----------------------#2021-04-26">https://betterprogramming.pub/the-best-way-to-choose-a-regression-algorithm-c23992c82d8e?source=collection_archive---------13-----------------------#2021-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8081" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们比较一下梯度下降、KNN、决策树和随机森林算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1d2535e062858a3877042b02940136f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ziYPE5EtHJ4AXgs2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7dbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的机器学习之旅的开始，我对我工作的每个数据集应该使用什么模型有很多疑虑。如果我对每个模型的最佳用例有所了解，事情会变得更简单。虽然在机器学习领域，它是关于一遍又一遍地尝试不同的模型，以找到最适合你的数据和目标的模型，但减少选项也是很好的，特别是作为初学者。</p><p id="3d31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将使用ka ggle:<a class="ae ky" href="https://www.kaggle.com/kaggle/sf-salaries" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/kaggle/sf-salaries</a>上的SF薪水数据集来比较回归问题的基本监督学习技术</p><p id="9085" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将要做的是:</p><ul class=""><li id="28b6" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">回归导论</li><li id="5915" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">对数据集执行一些预处理</li><li id="18f9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用整个SF薪水数据集来比较我们的算法</li><li id="195e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">结论</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="870c" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">回归导论</h1><p id="75ba" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如果你已经知道什么是监督学习，你一定遇到过术语<em class="nn">回归</em>。</p><p id="c7c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习中的回归可以定义为基于一个或多个预测变量(<em class="nn"> x </em>)的值预测连续结果(<em class="nn"> y </em>)的多种数学方法<em class="nn"> / </em>模型。</p><p id="6c62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一些回归问题可能是:</p><ul class=""><li id="d6e5" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">预测产品的销售</li><li id="135f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">洞察消费者行为和盈利能力</li><li id="1b3f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">评估市场趋势，做出估计和预测</li><li id="d54e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">对学生成绩的期望</li></ul><p id="b06a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在所有这些情况下，预期的输出都是无法分类的连续数值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/4fe3cb7278cffe7ed2919911ecc33fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wxteA11vBY4z4Hnb.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">监督学习基本算法图(图片来源:作者)</p></figure><p id="5717" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:我们不会调查正则化或助推技术。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="65ef" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">数据预处理</h1><p id="9237" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">首先，使用以下命令导入所需的库:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="8b94" class="nu mr it nq b gy nv nw l nx ny">import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>from matplotlib import pyplot as plt%matplotlib inline<br/>sns.set(rc={'figure.figsize': [10, 10]}, font_scale=1.3)df = pd.read_csv('Salaries.csv')</span></pre><p id="cf72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么是时候调查数据集了。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="6e26" class="nu mr it nq b gy nv nw l nx ny">df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/76de12e84a604531567729e6a1705481.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/0*EkUz8Vw3zN4sPNch.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出的屏幕截图</p></figure><p id="9fcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是可读的，非常简单。它有许多空值和两行没有任何值。为了更好的预测，这些nan最好被移除。以下是我如何删除它们。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="f803" class="nu mr it nq b gy nv nw l nx ny"># Dropping the empty columns<br/>df = df.drop(['Notes','Status','Id'], axis=1)<br/>df = df.drop(df[df['OvertimePay'].isna()==True].index)# Filling Nan in values<br/>df['BasePay'].fillna(df['BasePay'].mean(), inplace=True)<br/>df['Benefits'].fillna(df['Benefits'].mean(), inplace=True) # contain outliers so use median (not affected by outliers as mean)</span></pre><p id="5f12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于<code class="fe oa ob oc nq b">BasePay</code> float列，最好使用平均值来处理，对于<code class="fe oa ob oc nq b">Benefits</code>列，最佳实践是使用中位数，因为它不受异常值的影响。</p><h2 id="447a" class="nu mr it bd ms od oe dn mw of og dp na li oh oi nc lm oj ok ne lq ol om ng on bi translated">处理分类数据</h2><p id="9982" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我们有三个分类特征:<code class="fe oa ob oc nq b">Agency</code>、<code class="fe oa ob oc nq b">EmployeeName</code>和<code class="fe oa ob oc nq b">JobTitle</code>。在我们的任务中，<code class="fe oa ob oc nq b">EmployeeName</code>并不那么重要，而且<code class="fe oa ob oc nq b">Agency</code>都被同一个国家(三藩市)填满了，所以我们放弃了它们。</p><p id="fd93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oa ob oc nq b">JobTitle</code>包含了2158种不同的工作，所以我决定将它们分成四个基本类别:<code class="fe oa ob oc nq b">Manager</code>、<code class="fe oa ob oc nq b">Engineer</code>、<code class="fe oa ob oc nq b">Medicin</code>和<code class="fe oa ob oc nq b">Other</code>。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="ffec" class="nu mr it nq b gy nv nw l nx ny">job_type = {'Director':['senior','director','chief','supervisor','leader','sheriff','manager','head','department'],<br/>           'Medicin':['nurse', 'doctor', 'sychologist','surgeon', 'pharmacist','patient','health'],<br/>           'Engineering':['engineer','information','architect']}''' Converted JobTitle into 4 categories: Director, Medicin, Engineering, Otherjobs <br/>and implemented onehotencoder by hand to perform the categorical to numerical transformation'''</span></pre><p id="76bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我创建了<code class="fe oa ob oc nq b">set_job_type</code>函数来替我完成这项工作。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="7cee" class="nu mr it nq b gy nv nw l nx ny">def set_job_type(job, job_category_list):<br/>    job = job.lower()<br/>    words = job.split()<br/>    for word in words:<br/>        if word in job_category_list:<br/>            return 1<br/>        else:<br/>            return 0</span></pre><p id="9f12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我开始填充新的列。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="b720" class="nu mr it nq b gy nv nw l nx ny">Director = []<br/>for i in list(df['JobTitle'].values):<br/>    Director.append(set_job_type(i,job_type['Director']))Medicin = []<br/>for i in list(df['JobTitle'].values):<br/>    Medicin.append(set_job_type(i,job_type['Medicin']))Engineering = []<br/>for i in list(df['JobTitle'].values):<br/>    Engineering.append(set_job_type(i,job_type['Engineering']))</span></pre><p id="fa52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将它们添加到数据框中，然后添加了<code class="fe oa ob oc nq b">Other</code>列。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="8d03" class="nu mr it nq b gy nv nw l nx ny">df['Director'] = Director<br/>df['Medicin'] = Medicin<br/>df['Engineering'] = EngineeringOtherJob = [1 if not(i or j or k) else 0 for i,j,k in zip(df['Director'], df['Medicin'], df['Engineering'])]</span></pre><p id="3a8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更新后的数据框为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/48d8fe7d546be299825f99511f8f7376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n-Z7XLLr3h67oOtj.png"/></div></div></figure><p id="23a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:最好增加一个删除异常值的步骤。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="af18" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">使用完整的数据集</h1><p id="2bf8" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">现在是时候在我们的数据集上比较每个模型的性能了。首先，让我们导入必要的库。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="74ff" class="nu mr it nq b gy nv nw l nx ny">from sklearn.linear_model import LinearRegressionfrom sklearn.preprocessing import PolynomialFeatures<br/>from sklearn.svm import SVR<br/>from sklearn.tree import DecisionTreeRegressor<br/>from sklearn.neighbors import KNeighborsRegressor<br/>from sklearn.metrics import mean_squared_error</span></pre><h2 id="4051" class="nu mr it bd ms od oe dn mw of og dp na li oh oi nc lm oj ok ne lq ol om ng on bi translated">梯度下降算法</h2><p id="f33d" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">a)多元线性回归</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="dc4b" class="nu mr it nq b gy nv nw l nx ny">linReg = LinearRegression()<br/>linReg.fit(scaled_x_train, y_train)<br/>y_pred = linReg.predict(scaled_x_test)print(f'Training Score: {linReg.score(scaled_x_train, y_train)}')<br/>print(f'Test Score: {linReg.score(scaled_x_test, y_test)}')rmse = np.sqrt(mean_squared_error(y_test, y_pred))<br/>print(f'Root Mean Square Error: {rmse}')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/4b3b4b99c78678d643e1565646500a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*xZ0KhVTkLh0QNlid.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归输出的屏幕截图</p></figure><p id="5308" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">b)多项式回归</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="dc61" class="nu mr it nq b gy nv nw l nx ny">poly = PolynomialFeatures(degree=3)<br/>x_train_poly = poly.fit_transform(scaled_x_train)<br/>x_test_poly = poly.fit_transform(scaled_x_test)linReg.fit(x_train_poly, y_train)<br/>y_pred = linReg.predict(x_test_poly)print(f'Training Score: {linReg.score(x_train_poly, y_train)}')<br/>print(f'Test Score: {linReg.score(x_test_poly, y_test)}')rmse = np.sqrt(mean_squared_error(y_test, y_pred))<br/>print(f'Root Mean Square Error: {rmse}')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/433bcfafd8dfe966908ce5bc5fa0cc2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/0*aK8rKPhMHt2cUah-.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多项式回归输出的屏幕截图</p></figure><p id="a4c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">c) SVM回归量</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="469a" class="nu mr it nq b gy nv nw l nx ny">svm = SVR(kernel='linear') # select linear kernel since the distribution of datapoints is linear<br/>svm.fit(scaled_x_train, y_train)<br/>y_pred = svm.predict(scaled_x_test)print(f'Training Score: {svm.score(scaled_x_train, y_train)}')<br/>print(f'Test Score: {svm.score(scaled_x_test, y_test)}')rmse = np.sqrt(mean_squared_error(y_test, y_pred))<br/>print(f'Root Mean Square Error: {rmse}')</span></pre><p id="27bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SVM是一个非常复杂的算法。处理具有多个特征的大型数据集需要很长时间。</p><p id="1da4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">d)决策树</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="7460" class="nu mr it nq b gy nv nw l nx ny">DecTree = DecisionTreeRegressor()<br/>DecTree.fit(scaled_x_train, y_train)<br/>y_pred = DecTree.predict(scaled_x_test)print(f'Training Score: {DecTree.score(scaled_x_train, y_train)}')<br/>print(f'Test Score: {DecTree.score(scaled_x_test, y_test)}')rmse = np.sqrt(mean_squared_error(y_test, y_pred))<br/>print(f'Root Mean Square Error: {rmse}')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/6c6730b863418a53eb5b20f3b192dab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/0*b-Bm_T4wRPdbXy5z.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">决策树输出的屏幕截图</p></figure><p id="88b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">e) KNN回归量</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="6bb7" class="nu mr it nq b gy nv nw l nx ny">KNN = KNeighborsRegressor(n_neighbors=5)<br/>KNN.fit(scaled_x_train, y_train)<br/>y_pred = KNN.predict(scaled_x_test)print(f'Training Score: {KNN.score(scaled_x_train, y_train)}')<br/>print(f'Test Score: {KNN.score(scaled_x_test, y_test)}')rmse = np.sqrt(mean_squared_error(y_test, y_pred))<br/>print(f'Root Mean Square Error: {rmse}')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/7ab1610d6dc76ded5f14714ad85e3e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/0*_X22uItKOH_3Xi3k.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KNN的输出截图</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="9255" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论</h1><p id="46af" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我喜欢将结果放在一个表格中进行比较。因此，比较是根据误差、训练/测试分数和每个模型的性能进行的。现在您可以看到总结的差异。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/138a0fdb87637bcdd0e8278e30a5e333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7w2xq0d_wMLV1dil.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><p id="007b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，我们可以认为决策树有最好的结果。如果不是太理想化，我会选择多项式回归模型，这表明这个结果很可能有问题。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="7571" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我喜欢向您展示如何为我的数据集选择回归算法。你也可以将同样的步骤应用到你的情况中，从而做出最好的决定。您可以在这个<a class="ae ky" href="https://github.com/NadaAbbasMohamed/Data-science-Diploma/blob/main/Assignment%2015%20-%20Supervised%20Learning/Regression-Large%20Dataset-WITH%20Feature%20Engineering-Salaries%2Ccsv.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上探索本文中使用的代码。我也很想知道你们是如何比较算法的。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="0680" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章是纳达·阿巴斯在<a class="ae ky" href="https://theactivereader.medium.com/" rel="noopener">萨拉姆写的🌿</a>。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Http Server Performance: NodeJS vs. Go</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Http服务器性能:NodeJS与Go</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/http-server-performance-nodejs-vs-go-397751e8d275?source=collection_archive---------0-----------------------#2022-01-22">https://betterprogramming.pub/http-server-performance-nodejs-vs-go-397751e8d275?source=collection_archive---------0-----------------------#2022-01-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ad47" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">谁交付的并发请求数量更多？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b38c547de37b5f2845f5fae4b952b271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BiFEeeV6UbTUQNFd"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">让·格柏在Unsplash<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">上的照片</a></p></figure><p id="2100" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们正在开发类似广告代理或谷歌广告缓冲区的东西。服务只是将ad HTTP请求转发到SSPs服务器。为此，有必要用最少的硬件资源创建许多HTTP请求。因此，我们决定研究和比较虚拟机的编程语言，并编译了一个。</p><p id="e962" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们非常熟悉NodeJS和JavaScript技术。因此，我们开始测试与V8引擎的HTTP连接。当然，我们不是从零开始，我们用的是<a class="ae kv" href="https://github.com/fastify/fastify" rel="noopener ugc nofollow" target="_blank"> fastify </a>包。它实际上是基于NodeJS HTTP包。所以在软件栈的底部是一个编译好的低级HTTP服务器。但无论如何，V8下有一个很小的层在运行。问题是这一层如何降低执行速度。</p><h1 id="8a81" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">节点JS </strong></h1><p id="3e7b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个脚本非常简单。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="75bf" class="mu lt iq mq b gy mv mw l mx my">const fastify = require(“fastify”)({<br/> logger: false,<br/>});</span><span id="bcf1" class="mu lt iq mq b gy mz mw l mx my">fastify.get(“/fillbuffer”, async (request, reply) =&gt; {<br/> reply.type(“application/json”).code(200);<br/> return {<br/> result: `{result: “Hello world”}`,<br/> };<br/>});</span><span id="3290" class="mu lt iq mq b gy mz mw l mx my">fastify.listen(3008, (err, address) =&gt; {<br/> if (err) throw err;<br/>});</span></pre><p id="8183" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用ApacheBench (ab)工具进行测试。让我们跳过完整的硬件规格。我只能说我用的是I7–8550 u CPU。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="1526" class="mu lt iq mq b gy mv mw l mx my">ab -n 1000000 -c 100 localhost:3008/fillbuffer</span><span id="3bbc" class="mu lt iq mq b gy mz mw l mx my">Requests per second: 12925.33 [#/sec] (mean)<br/>Time per request: 7.737 [ms] (mean)<br/>Time per request: 0.077 [ms] (mean, across all concurrent requests)</span><span id="89c0" class="mu lt iq mq b gy mz mw l mx my">Percentage of the requests served within a certain time (ms)<br/> 50% 8<br/> 66% 8<br/> 75% 8<br/> 80% 8<br/> 90% 9<br/> 95% 10<br/> 98% 12<br/> 99% 13<br/> 100% 106 (longest request)</span></pre><p id="c9d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们尝试更多的并发连接。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="678a" class="mu lt iq mq b gy mv mw l mx my">ab -n 1000000 -c 500 localhost:3008/fillbuffer</span><span id="d495" class="mu lt iq mq b gy mz mw l mx my">Results:<br/>Requests per second: 9673.37 [#/sec] (mean)<br/>Time per request: 51.688 [ms] (mean)<br/>Time per request: 0.103 [ms] (mean, across all concurrent request</span><span id="8453" class="mu lt iq mq b gy mz mw l mx my">Percentage of the requests served within a certain time (ms)<br/> 50% 48<br/> 66% 49<br/> 75% 50<br/> 80% 51<br/> 90% 58<br/> 95% 79<br/> 98% 137<br/> 99% 156<br/> 100% 286 (longest request)</span></pre><p id="92df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到目前为止一切顺利。500个并发连接达到了CPU极限，节点解决方案开始陷入困境，但让我们开始吧。</p><h1 id="b36b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">走</strong></h1><p id="75b0" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">剧本有点长，但仍然很短。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="6ff9" class="mu lt iq mq b gy mv mw l mx my">package main</span><span id="3d14" class="mu lt iq mq b gy mz mw l mx my">import (<br/> “encoding/json”<br/> “fmt”<br/> “log”<br/> “github.com/valyala/fasthttp”<br/>)</span><span id="acf3" class="mu lt iq mq b gy mz mw l mx my">var (<br/> addr = “:3008”<br/> strContentType = []byte(“Content-Type”)<br/> strApplicationJSON = []byte(“application/json”)<br/> httpClient *fasthttp.Client<br/>)</span><span id="4848" class="mu lt iq mq b gy mz mw l mx my">func main() {<br/> fmt.Println(“Starting server…”)<br/> h := requestHandler<br/> h = fasthttp.CompressHandler(h)</span><span id="3405" class="mu lt iq mq b gy mz mw l mx my">httpClient = &amp;fasthttp.Client{<br/> MaxConnsPerHost: 2048,<br/> }</span><span id="958f" class="mu lt iq mq b gy mz mw l mx my">if err := fasthttp.ListenAndServe(addr, h); err != nil {<br/> log.Fatalf(“Error in ListenAndServe: %s”, err)<br/> }<br/>}</span><span id="9005" class="mu lt iq mq b gy mz mw l mx my">func requestHandler(ctx *fasthttp.RequestCtx) {<br/> if string(ctx.Method()) == “GET” {<br/> switch string(ctx.Path()) {<br/> case “/fillbuffer”:<br/> ctx.Response.Header.SetCanonical(strContentType, strApplicationJSON)<br/> ctx.Response.SetStatusCode(200)<br/> response := map[string]string{“result”: fmt.Sprintf(“hello world”)}<br/> if err := json.NewEncoder(ctx).Encode(response); err != nil {<br/> log.Fatal(err)<br/> }<br/> }<br/> }<br/>}</span></pre><p id="10fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，我决定使用<code class="fe na nb nc mq b">fasthttp</code>作为HTTP服务器。该服务器不基于任何HTTP库。所以真的是纯HTTP协议实现。让我们看看100个并发请求的结果。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="7530" class="mu lt iq mq b gy mv mw l mx my">ab -n 1000000 -c 100 localhost:3008/fillbuffer</span><span id="5868" class="mu lt iq mq b gy mz mw l mx my">Requests per second: 15847.80 [#/sec] (mean)<br/>Time per request: 6.310 [ms] (mean)<br/>Time per request: 0.063 [ms] (mean, across all concurrent requests)</span><span id="2908" class="mu lt iq mq b gy mz mw l mx my">Percentage of the requests served within a certain time (ms)<br/> 50% 6<br/> 66% 7<br/> 75% 7<br/> 80% 7<br/> 90% 7<br/> 95% 7<br/> 98% 8<br/> 99% 8<br/> 100% 18 (longest request)</span></pre><p id="d16e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">嗯，相对于NodeJS解决方案来说，数字确实很大。尤其是在特定时间内满足的请求。几乎是平的。让我们开始最后的测试。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="b426" class="mu lt iq mq b gy mv mw l mx my">ab -n 1000000 -c 500 localhost:3008/fillbuffer</span><span id="ee3c" class="mu lt iq mq b gy mz mw l mx my">Requests per second: 14682.27 [#/sec] (mean)<br/>Time per request: 34.055 [ms] (mean)<br/>Time per request: 0.068 [ms] (mean, across all concurrent requests)</span><span id="243a" class="mu lt iq mq b gy mz mw l mx my">Percentage of the requests served within a certain time (ms)<br/> 50% 34<br/> 66% 36<br/> 75% 37<br/> 80% 37<br/> 90% 39<br/> 95% 40<br/> 98% 41<br/> 99% 41<br/> 100% 62 (longest request)</span></pre><h1 id="f69d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="2abd" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如您所见，Go解决方案的服务时间仍然持平。看起来仍然有获得更多并发请求的空间，但是让我们比较一下基本数字。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/6f53b1cd4f83e13b549d8858fe52b921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YQzLxJe6_i6rTLTu"/></div></div></figure><p id="52d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Go是这里唯一的赢家，尤其是在并发请求数较高的情况下。</p><p id="ce21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以在V8引擎下运行的微小层并不那么微小。对于100个并发请求，交付的请求会增加18%以上。500个并发请求将收益提高了34%以上。</p></div></div>    
</body>
</html>
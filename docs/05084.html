<html>
<head>
<title>Making a Face GAN With TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用张量流做鬼脸</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/making-a-face-gan-with-tensorflow-23b4b79b4de7?source=collection_archive---------3-----------------------#2020-06-07">https://betterprogramming.pub/making-a-face-gan-with-tensorflow-23b4b79b4de7?source=collection_archive---------3-----------------------#2020-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1126" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">训练你的大脑识别人脸</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/95ceac046e601abd13fc9590c49c4995.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKXJ3Ol6typcJ0DRbBaKHg.jpeg"/></div></div></figure><p id="8bd9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我一直对机器学习能够实现的奇迹着迷。我最近的发现之一是生成敌对网络(GANs)。计算机可以在没有任何图像信息的情况下制作任何图像，这个想法让我很惊讶。给它一个100×1的随机、正常数字阵列，GAN将生成一个随机图像(根据它已经被训练过的图像)。因此，我探索了它是如何工作的，并变得更加兴奋——它不是一个，而是两个网络相互竞争并使自己变得更好的组合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lr"><img src="../Images/95463540e2c34c4c418ea8e751d6f352.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*hUNiV_fL_JP5lQzUKjSnQw.png"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">图片来自<a class="ae lw" href="https://www.tensorflow.org/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/generative/dcgan</a></p></figure><p id="b8a3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一个模型制作一个随机生成的图像，并试图欺骗另一个模型认为这是一个真实的图像。然后，第二个模型试图区分真实图像和第一个模型创建的图像。第一个模型称为“生成器”，是生成模型的主模型。第二个模型称为“鉴别器”，它试图捕捉生成的图像。随着训练的进行，网络会调整自己的权重来完成任务。最后，发电机模型变得足够好，以欺骗鉴别器模型，并给出合理的低损失分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/4b6a4b14e9e2b2c0a7d88223fe09e4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*7gas3JvsOxz9Zq5RJ8ygBg.png"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">图片来自<a class="ae lw" href="https://www.tensorflow.org/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/generative/dcgan</a></p></figure></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="347e" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak">架构</strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/5885c852d990bfdfab71c22395dd2c83.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*5qp3OOIo-84CM6jnF3CopQ.png"/></div></figure><p id="d903" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这两种网络的架构都非常简单。生成器网络使用<code class="fe my mz na nb b">Upsamle</code>或卷积转置层将输入重新整形为所需的高维数据空间。</p><p id="b610" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">鉴别器网络是一个普通的CNN，它使用卷积层，然后是最后的<code class="fe my mz na nb b">Dense</code>层来预测图像。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="67e6" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak">损失函数</strong></h1><p id="4966" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">用于GANs的最简单和最常用的损失公式之一是“最小最大”损失，由下式给出:</p><p id="e0c0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe my mz na nb b">Ex[log(D(x))]+Ez[log(1−D(G(z)))]</code></p><p id="eaca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在此功能中:</p><ul class=""><li id="ba26" class="nh ni it kw b kx ky la lb ld nj lh nk ll nl lp nm nn no np bi translated"><code class="fe my mz na nb b">D(x)</code>是鉴别器对真实数据实例x为真实的概率的估计。</li><li id="bfd5" class="nh ni it kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated"><code class="fe my mz na nb b">Ex</code>是所有真实数据实例的期望值。</li><li id="2263" class="nh ni it kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated"><code class="fe my mz na nb b">G(z)</code>是给定噪声时发电机的输出<code class="fe my mz na nb b">z</code>。</li><li id="b9ef" class="nh ni it kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated"><code class="fe my mz na nb b">D(G(z))</code>是鉴别者对假实例为真的概率的估计。</li><li id="364d" class="nh ni it kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated"><code class="fe my mz na nb b">Ez</code>是对生成器的所有随机输入的期望值(实际上，是对所有生成的假实例<code class="fe my mz na nb b">G(z)</code>的期望值)。</li><li id="ecc0" class="nh ni it kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">该公式源自真实分布和生成分布之间的<a class="ae lw" href="https://developers.google.com/machine-learning/glossary#cross-entropy" rel="noopener ugc nofollow" target="_blank">交叉熵</a>。</li></ul><p id="132e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">发电机不能直接影响函数中的<code class="fe my mz na nb b">log(D(x))</code>项，所以，对于发电机来说，最小化损耗相当于最小化<code class="fe my mz na nb b">log(1 — D(G(z)))</code>。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="d928" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak">代码</strong></h1><p id="bb97" class="pw-post-body-paragraph ku kv it kw b kx nc ju kz la nd jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">完整的代码可以在我的<a class="ae lw" href="https://github.com/RahulBarman101/Face-Gan" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上找到。</p><p id="19a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好了，现在让我们进入有趣的部分:实现用于创建人脸的GAN网络。</p><p id="d14a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从最终结果接收的人脸将是模糊的和低分辨率的，因为该模型是针对64x64图像大小训练的，并且持续时间非常短。要获得更多高清图像，请提高分辨率并训练更长时间。</p><p id="a783" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，获取<a class="ae lw" href="http://vis-www.cs.umass.edu/lfw/lfw.tgz" rel="noopener ugc nofollow" target="_blank">数据集</a>:</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="1828" class="nz mg it nb b gy oa ob l oc od">!wget <a class="ae lw" href="http://vis-www.cs.umass.edu/lfw/lfw.tgz" rel="noopener ugc nofollow" target="_blank">http://vis-www.cs.umass.edu/lfw/lfw.tgz</a><br/><strong class="nb iu">import</strong> <strong class="nb iu">tarfile</strong></span><span id="8e56" class="nz mg it nb b gy oe ob l oc od">my_tar = tarfile.open('lfw.tgz')</span><span id="ec2d" class="nz mg it nb b gy oe ob l oc od">my_tar.extractall('./lfw') <em class="lq"># specify which folder to extract to</em></span><span id="2806" class="nz mg it nb b gy oe ob l oc od">my_tar.close()</span></pre><p id="529c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">提取文件的内容:</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="2314" class="nz mg it nb b gy oa ob l oc od"><strong class="nb iu">import</strong> <strong class="nb iu">tensorflow</strong> <strong class="nb iu">as</strong> <strong class="nb iu">tf</strong><br/><strong class="nb iu">import</strong> <strong class="nb iu">numpy</strong> <strong class="nb iu">as</strong> <strong class="nb iu">np</strong><br/><strong class="nb iu">import</strong> <strong class="nb iu">matplotlib.pyplot</strong> <strong class="nb iu">as</strong> <strong class="nb iu">plt</strong><br/><strong class="nb iu">import</strong> <strong class="nb iu">PIL</strong><br/><strong class="nb iu">from</strong> <strong class="nb iu">tensorflow.keras</strong> <strong class="nb iu">import</strong> layers<br/><strong class="nb iu">import</strong> <strong class="nb iu">os</strong><br/>%matplotlib inline</span></pre><p id="7aca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">导入必要的库:</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="e607" class="nz mg it nb b gy oa ob l oc od">images = []<br/><strong class="nb iu">for</strong> i <strong class="nb iu">in</strong> os.scandir('lfw/lfw'):<br/>  <strong class="nb iu">for</strong> j <strong class="nb iu">in</strong> os.scandir(i.path):<br/>    images.append(j.path)<br/>images = tf.data.Dataset.from_tensor_slices(images)</span></pre><p id="97c1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这里，我们保存所有要使用的图像的文件名，并创建一个<code class="fe my mz na nb b">tf.data</code>变量，这将有助于构建训练过程的输入管道，以避免内存过载。</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="cdc8" class="nz mg it nb b gy oa ob l oc od"><strong class="nb iu">def</strong> get_ds(path):<br/>  img = tf.io.read_file(path)<br/>  img = tf.image.decode_jpeg(img,channels=3)<br/>  img = tf.image.convert_image_dtype(img,tf.float32)<br/>  img = tf.divide(tf.subtract(tf.multiply(img,255),127.5),127.5)<br/>  <strong class="nb iu">return</strong> tf.image.resize(img,(64,64))</span></pre><p id="3f45" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个简单的函数来接收图像的路径，读取它，规范化它，并调整它的大小。</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="c0c4" class="nz mg it nb b gy oa ob l oc od">BATCH_SIZE = 64</span><span id="0b66" class="nz mg it nb b gy oe ob l oc od">train_images = images.map(get_ds,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE).shuffle(60000)</span></pre><p id="d62e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是相当简单的代码，它映射每个图像的路径，并使用前面的函数将其转换为所需的形式。<code class="fe my mz na nb b">num_parallel_calls=tf.data.experimental.AUTOTUNE</code>参数用于批量向函数发送数据，CPU无需过度扩展即可处理这些数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="c66c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的函数是生成器模型。第一层是<code class="fe my mz na nb b">Dense</code>模型，它将接受一个100行的随机正常数字数组。<code class="fe my mz na nb b">Reshape</code>层将<code class="fe my mz na nb b">Dense</code>层的输出转换成3D向量，以传入卷积转置层。这些图层放大输入的大小，并最终以所需的形状输出结果。</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="b842" class="nz mg it nb b gy oa ob l oc od">generator = make_generator_model()</span><span id="7f48" class="nz mg it nb b gy oe ob l oc od">noise = tf.random.normal([1,100])</span><span id="948a" class="nz mg it nb b gy oe ob l oc od">generated_image = generator(noise,training=<strong class="nb iu">False</strong>)</span><span id="bea3" class="nz mg it nb b gy oe ob l oc od">plt.imshow(generated_image[0]*127.5+127.5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/4486860f1fc1c4636e5380fe6102acfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*QsMzD8rsvIMk9YFDUR3MLA.png"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">训练前发电机模型的图像输出</p></figure><p id="55d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是没有经过训练的生成器产生的图像。它产生一个标准化的矢量，需要对其进行缩放以生成RGB颜色。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="0e4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个函数是<code class="fe my mz na nb b">Discriminator</code>模型，它预测图像是真的还是假的:</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="8f43" class="nz mg it nb b gy oa ob l oc od">discriminator = make_discriminator_model()</span><span id="1891" class="nz mg it nb b gy oe ob l oc od">decision = discriminator(generated_image)</span><span id="c2a3" class="nz mg it nb b gy oe ob l oc od">print(decision)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/24f330c3a9d7b89f0a50708878045b21.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*rF7oc2tHGw5d5Fczf3F9Rg.png"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">训练前鉴别器模型的输出</p></figure><p id="a4c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果图像是假的——即由生成器模型创建的图像——则鉴别器模型的输出将更负，而如果是真实图像，则输出为正。</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="a7a4" class="nz mg it nb b gy oa ob l oc od">cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=<strong class="nb iu">True</strong>)<br/><strong class="nb iu">def</strong> discriminator_loss(real_output,fake_output):<br/>  real_loss = cross_entropy(tf.ones_like(real_output),real_output)<br/>  fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)<br/>  total_loss = real_loss + fake_loss<br/>  <strong class="nb iu">return</strong> total_loss<br/><strong class="nb iu">def</strong> generator_loss(fake_output):<br/>  <strong class="nb iu">return</strong> cross_entropy(tf.ones_like(fake_output),fake_output)</span></pre><p id="f254" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">两个模型的损失函数。它使用交叉熵损失来创建“最小最大”损失函数。</p><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="8389" class="nz mg it nb b gy oa ob l oc od">generator_optimizer = tf.keras.optimizers.Adam(1e-4)<br/>discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)</span></pre><p id="d3ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于优化器，两者都使用<code class="fe my mz na nb b">Adam</code>优化器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="4010" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是主要的训练功能。它创建一个随机的100行数组，作为生成器模型的输入。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="349f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个小函数，在调用时生成生成器模型的输出。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="a77b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是调用训练函数的主循环，并在每个时期后调用<code class="fe my mz na nb b">generate_images</code>函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="98ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个小模块，用于制作训练完成后保存的图像的gif。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="kj kk kl km gt nv nb nw nx aw ny bi"><span id="fee7" class="nz mg it nb b gy oa ob l oc od">new_image = generator(tf.random.normal([1,100]),training=<strong class="nb iu">False</strong>)</span><span id="e12d" class="nz mg it nb b gy oe ob l oc od">plt.imshow(new_image[0,:,:,:])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/4288f1c2223a668c65fd70950aaaf237.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*3M5qhPNYUCmSEgtKWvrCsA.png"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">来自训练后的生成器模型输出的图像</p></figure><p id="c444" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">瞧，</em>生成人脸的GAN完成了！我希望你喜欢它。</p><p id="bdff" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我前面所说，所有的代码都在我的<a class="ae lw" href="https://github.com/RahulBarman101/Face-Gan" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中。请随意评论和提问。另外，看看我的<a class="ae lw" href="http://www.rahulbarman.com" rel="noopener ugc nofollow" target="_blank">网站</a>上其他很酷的项目。</p></div></div>    
</body>
</html>
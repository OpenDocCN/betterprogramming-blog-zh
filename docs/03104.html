<html>
<head>
<title>Introduction to RealityKit on iOS— Entities, Gestures, and Ray Casting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">iOS上的RealityKit简介—实体、手势和光线投射</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/introduction-to-realitykit-on-ios-entities-gestures-and-ray-casting-8f6633c11877?source=collection_archive---------2-----------------------#2020-01-21">https://betterprogramming.pub/introduction-to-realitykit-on-ios-entities-gestures-and-ray-casting-8f6633c11877?source=collection_archive---------2-----------------------#2020-01-21</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="5339" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">利用现实工具包、愿景和铅笔工具包框架。是时候和SceneKit说再见了？</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/94c55b64cace6a556f1593cc46584785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LRtRe4RYwx2_cQg16meVbw.png"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">由DALL-E 2绘制</p></figure><p id="fa11" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">iOS 13的推出为苹果的增强现实框架带来了重大升级。ARKit 3带来了许多有趣的新功能——人物遮挡、运动跟踪、前后摄像头同步以及协作支持。ARKit的这些增强强烈表明了苹果进一步推动AR沉浸的雄心。</p><p id="7274" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">在iOS 12之前，我们有SceneKit、SpriteKit和Metal作为主要的渲染框架。其中，3D图形框架SceneKit是构建ARKit应用程序最合理的选择。</p><p id="db8a" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">虽然SceneKit框架的许多增强功能预计将在2019年WWDC大会上宣布，但苹果公司推出了一个全新的独立3D引擎框架，让我们大吃一惊——<strong class="ky is">reality kit</strong>，它允许开发人员比以往任何时候都更容易地创建AR体验和场景。此外，它还附带了一个实用程序Reality Composer，允许我们创建自己的3D对象和定制。</p><h1 id="019c" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">我们的目标</h1><p id="7aa5" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">本文的目的是让您开始使用RealityKit，并开始构建令人惊叹的基于增强现实的应用程序。我们将首先为基于AR的iOS应用程序设置一个Xcode项目，然后简单浏览一下RealityKit框架的各个关键组件。</p><p id="e9f0" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">在我们学习本教程的过程中，我们将把各个部分放在一起，最终形成一个非常酷的AR应用程序，让用户可以将3D模型和结构添加到RealityKit的虚拟场景中，并通过使用手势与它们进行交互。</p><p id="44e3" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">此外，我们将设置一个绘图画布视图来处理用户输入。在这种情况下，用户输入将包括使用<a class="ae mp" href="https://developer.apple.com/machine-learning/models/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>核心ML模型推断的数字，这些数字然后将被转换成3D文本，最终被放置在虚拟场景中。</p><p id="70f3" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">除了<code class="fe mq mr ms mt b">RealityKit</code>和<code class="fe mq mr ms mt b">ARKit</code>，我们将在应用中使用以下iOS框架:</p><ul class=""><li id="7fda" class="mu mv ir ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><strong class="ky is"> PencilKit </strong> —这是iOS 13中引入的一个绘图框架，允许我们创建自定义的、基于画布的应用程序。我们将利用这个框架来处理输入。</li><li id="1abd" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><strong class="ky is"> SwiftUI和Vision </strong> — SwiftUI是流行的新声明式UI框架，而<a class="ae mp" href="https://heartbeat.fritz.ai/advancements-in-apples-vision-framework-2019-year-in-review-4c9d3ad5b138" rel="noopener ugc nofollow" target="_blank"> Vision </a>用一个易于使用的API抽象了复杂的计算机视觉算法。</li></ul><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ni"><img src="../Images/8441f431e06576f2a308e583c5cfea08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3xBMRVwvGKVjvWBIUFN9A.png"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">我们应用程序的主要参与者</p></figure><h1 id="6fd2" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">项目设置</h1><p id="a37c" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">首先，打开Xcode 11或更高版本，然后创建一个新项目。转到iOS选项卡，选择<em class="nj">增强现实应用</em>模板。在向导中，确保选择RealityKit作为技术，SwiftUI作为用户界面，如下所示:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nk"><img src="../Images/0f4aae406a49bd3ff49bed587c989638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1-lAHhnUHhJbvMPFo48LA.png"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">SwiftUI支持不适用于SceneKit。苹果倾向于RealityKit的另一个迹象。</p></figure><p id="bb46" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">如果你在Xcode中查看左侧面板，你会看到一个名为<code class="fe mq mr ms mt b">Experience.rcproject</code>的文件。这是一个现实作曲家文件。默认情况下，它带有一个由一个钢箱组成的单一场景。您可以使用自定义模型、3D资源和效果创建自己的场景。</p><p id="f454" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">您刚刚创建的starter项目由一个<code class="fe mq mr ms mt b">ARView</code>组成，在这个项目中，box实体被加载并添加到<code class="fe mq mr ms mt b">ARView</code>的锚中。在构建项目时，以下框将显示在AR应用程序屏幕的中间:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj nl"><img src="../Images/21c80a5173182586c281898318721380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UXny3BAkiUJKWICzG0RdfA.png"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">Reality Composer场景文件中默认框的一瞥。</p></figure><p id="fcf8" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">起始项目没有任何手势和与虚拟场景的交互。随着我们的进行，我们将不再使用Reality Composer来构建场景和结构，而是以编程方式创建我们自己的3D实体。但在我们这样做之前，让我们谈谈构建RealityKit场景的核心组件，并解决一些花哨的术语——场景、实体、锚点等。</p></div><div class="ab cl nm nn hv no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ik il im in io"><h1 id="bacf" class="ls lt ir bd lu lv nt lx ly lz nu mb mc jx nv jy me ka nw kb mg kd nx ke mi mj bi translated">现实解剖工具包</h1><p id="9030" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">RealityKit的<code class="fe mq mr ms mt b">ARView</code>是负责处理AR体验的视图。从设置onboarding体验(稍后将详细介绍)到配置ARKit配置、相机和交互，一切都要经过<code class="fe mq mr ms mt b">ARView</code>。</p><p id="c205" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">每个<code class="fe mq mr ms mt b">ARView</code>都包含一个<code class="fe mq mr ms mt b">scene</code>——一个只读实例，我们在其上添加了<code class="fe mq mr ms mt b">AnchorEntities</code>。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ny"><img src="../Images/bea6bef807ca909567c8a080659f87de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rwbYk2g9153vTTnqanVqsA.png"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">来自<a class="ae mp" href="https://developer.apple.com/documentation/realitykit/entity" rel="noopener ugc nofollow" target="_blank">苹果文档</a></p></figure><p id="58f5" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">An <code class="fe mq mr ms mt b">Entity</code>是RealityKit最重要的组成部分。RealityKit <code class="fe mq mr ms mt b">scene</code>中的所有对象都是实体。An <code class="fe mq mr ms mt b">AnchorEntity</code>是所有实体的根。与ARKit的<code class="fe mq mr ms mt b">ARAnchor</code>类似，它负责保存实体及其子实体。</p><p id="88fc" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">我们可以给一个实体添加<code class="fe mq mr ms mt b"><a class="ae mp" href="https://developer.apple.com/documentation/realitykit/component" rel="noopener ugc nofollow" target="_blank">Components</a></code>来进一步定制它。一个<code class="fe mq mr ms mt b">ModelComponent</code>让我们定义3D对象的几何图形，一个<code class="fe mq mr ms mt b">CollisionComponent</code>让我们处理对象之间的碰撞。</p><p id="d311" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">RealityKit使生成简单的3D形状变得非常容易，如盒子、球体、平面和文本。</p><p id="8b73" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">下面的代码展示了如何创建一个代表立方体的<code class="fe mq mr ms mt b">ModelEntity</code>:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="8b80" class="od lt ir mt b gz oe of l og oh">let box = MeshResource.generateBox(size: 0.3) // size in metres</span><span id="f17a" class="od lt ir mt b gz oi of l og oh">let material = SimpleMaterial(color: .green, isMetallic: true)<br/>let entity = ModelEntity(mesh: box, materials: [material])</span></pre><p id="ff18" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated"><code class="fe mq mr ms mt b">Material</code>协议用于设置实体的颜色和纹理。目前，RealityKit提供的三种内置类型的<code class="fe mq mr ms mt b">Material</code>为:</p><ul class=""><li id="265f" class="mu mv ir ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><code class="fe mq mr ms mt b">SimpleMaterial</code> —用于设置颜色和实体是否是金属的。</li><li id="0a00" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><code class="fe mq mr ms mt b">OcclusionMaterial</code> —一种隐藏其背后渲染对象的不可见材质。</li><li id="d123" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><code class="fe mq mr ms mt b">UnlitMaterial</code> —这种实体对AR场景中的灯光没有反应。</li></ul><p id="7b69" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">通过以下方式将实体添加到场景中:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="ec0d" class="od lt ir mt b gz oe of l og oh">let anchor = AnchorEntity(plane: .horizontal)<br/>anchor.addChild(entity)<br/>arView.scene.addAnchor(anchor)</span></pre><p id="aa81" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">为了将实体添加到虚拟场景中，我们需要确保它符合<code class="fe mq mr ms mt b">HasAnchoring</code>协议，或者作为子元素添加到具有该属性的锚点中，正如我们上面所做的那样。</p><p id="051c" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">由于<code class="fe mq mr ms mt b">ModelEntity</code>不符合<code class="fe mq mr ms mt b">HasAnchoring</code>协议，因此以下内容不起作用:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="adca" class="od lt ir mt b gz oe of l og oh">arView.scene.anchors.append(entity) //<strong class="mt is">this would not work</strong></span></pre><p id="3b41" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">在我们创建第一个自定义实体并将其添加到场景中之前，让我们看看<code class="fe mq mr ms mt b">ARCoachingOverlay</code>是什么以及如何将其集成到我们的<code class="fe mq mr ms mt b">ARView</code>中。</p></div><div class="ab cl nm nn hv no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ik il im in io"><h1 id="c072" class="ls lt ir bd lu lv nt lx ly lz nu mb mc jx nv jy me ka nw kb mg kd nx ke mi mj bi translated">配置ARCoachingOverlay</h1><p id="99cb" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated"><code class="fe mq mr ms mt b">ARCoachingOverlayView</code>用于向用户提供视觉指示，以便于ARKit的世界跟踪。为此，我们需要将该视图添加为<code class="fe mq mr ms mt b">ARView</code>的子视图，并设置<code class="fe mq mr ms mt b">goal</code>属性，该属性指定了跟踪需求— <code class="fe mq mr ms mt b">horizontalPlane</code>、<code class="fe mq mr ms mt b">verticalPlane</code>、<code class="fe mq mr ms mt b">anyPlane</code>或<code class="fe mq mr ms mt b">tracking</code>(跟踪特征点)。一旦目标确定，则<code class="fe mq mr ms mt b">ARCoachingOverlayView</code>解除。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oj"><img src="../Images/ed95a3f47242c103c5b2f54632e94d3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*FDzypCQtuU10Ky203NQr-A.png"/></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">教练覆盖视图一瞥</p></figure><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="1882" class="od lt ir mt b gz oe of l og oh">extension ARView: ARCoachingOverlayViewDelegate {<br/>    func addCoaching() {<br/>        <br/>        let coachingOverlay = ARCoachingOverlayView()<br/>        coachingOverlay.delegate = self<br/>        coachingOverlay.session = self.session<br/>        coachingOverlay.autoresizingMask = [.flexibleWidth, .flexibleHeight]<br/>        <br/>        coachingOverlay.goal = .anyPlane<br/>        self.addSubview(coachingOverlay)<br/>    }<br/>    <br/>    public func coachingOverlayViewDidDeactivate(_ coachingOverlayView: ARCoachingOverlayView) {<br/>        //Ready to add entities next?<br/>    }<br/>}</span></pre><p id="2fa7" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">一旦目标达到，代表的<code class="fe mq mr ms mt b">coachingOverlayViewDidDeactivate</code>功能就会被触发。默认情况下<code class="fe mq mr ms mt b">ARCoachingOverlay</code>是自动的。这意味着，如果在场景中，特征点或平面丢失，登机将重新开始。您可以通过将其设置为一次性操作来防止这种情况，并通过设置<code class="fe mq mr ms mt b">coachingOverlayView.activatesAutomatically = false</code>来禁用自动行为。</p><p id="1f45" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">接下来，只需在<code class="fe mq mr ms mt b">ARView</code>实例上执行上面的<code class="fe mq mr ms mt b">addCoaching</code>功能，如下所示:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="0e7c" class="od lt ir mt b gz oe of l og oh">struct ARViewContainer: UIViewRepresentable {<br/>    <br/>    func makeUIView(context: Context) -&gt; ARView {<br/>        <br/>        let arView = ARView(frame: .zero)<br/>        arView.addCoaching()<br/>        <br/>        let config = ARWorldTrackingConfiguration()<br/>        config.planeDetection = .horizontal<br/>        arView.session.run(config, options: [])<br/>        <br/>        return arView<br/>    }<br/>    func updateUIView(_ uiView: ARView, context: Context) {}<br/>}</span></pre><p id="7ebb" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">接下来，我们将创建一个自定义实体，并在<code class="fe mq mr ms mt b">ARCoachingOverlayView</code>消失后将其添加到场景中。</p><h1 id="85b4" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">创建自定义框实体</h1><p id="27fe" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">通过遵循<code class="fe mq mr ms mt b"><a class="ae mp" href="https://developer.apple.com/documentation/realitykit/hasmodel" rel="noopener ugc nofollow" target="_blank">HasModel</a></code>和<code class="fe mq mr ms mt b"><a class="ae mp" href="https://developer.apple.com/documentation/realitykit/hasanchoring" rel="noopener ugc nofollow" target="_blank">HasAnchoring</a></code>协议，我们可以创建自己的自定义形状和大小的<code class="fe mq mr ms mt b">Entity</code>子类。此外，<code class="fe mq mr ms mt b"><a class="ae mp" href="https://developer.apple.com/documentation/realitykit/hascollision" rel="noopener ugc nofollow" target="_blank">HasCollision</a></code>协议用于实现与实体的交互——光线投射(稍后将详细介绍)、手势处理(缩放、平移、旋转)等。</p><p id="6859" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">以下代码显示了如何创建自定义实体框结构:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="3d63" class="od lt ir mt b gz oe of l og oh">class CustomBox: Entity, HasModel, HasAnchoring, HasCollision {<br/>    <br/>    required init(color: UIColor) {<br/>        super.init()<br/>        self.components[ModelComponent] = ModelComponent(<br/>            mesh: .<strong class="mt is">generateBox</strong>(size: 0.1),<br/>            materials: [SimpleMaterial(<br/>                color: color,<br/>                isMetallic: false)<br/>            ]<br/>        )<br/>    }<br/>    <br/>    convenience init(color: UIColor, position: SIMD3&lt;Float&gt;) {<br/>        self.init(color: color)<br/>        self.position = position<br/>    }<br/>    <br/>    required init() {<br/>        fatalError("init() has not been implemented")<br/>    }<br/>}</span></pre><p id="f74a" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">还有一个方便的初始化器，允许我们指定实体在场景中相对于摄像机的位置:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="73a4" class="od lt ir mt b gz oe of l og oh">let box = CustomBox(color: .yellow)<br/>//or<br/>let box = CustomBox(color: .yellow, <strong class="mt is">position</strong>: [-0.6, -1, -2])</span><span id="a451" class="od lt ir mt b gz oi of l og oh">self.scene.anchors.append(box) //self is arView</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ok"><img src="../Images/7bc47d2bef6306afc660bff0040f9921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8Ma2RHGocj09vw1255dpg.jpeg"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">放在离摄像机一定距离的盒子</p></figure><p id="9423" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">现在我们已经在AR场景中添加了一个实体，但是我们还不能与它进行任何交互！要做到这一点，我们需要添加手势，这将是我们接下来要探讨的。</p><h1 id="029d" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">实体手势和子实体</h1><p id="5ab5" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">RealityKit为我们提供了一堆内置的手势交互。具体来说，它允许缩放、旋转和平移AR场景中的实体。要在一个实体上启用手势，我们需要确保它符合<code class="fe mq mr ms mt b">HasCollision</code>协议(我们在上一节中已经这么做了)。</p><p id="9e08" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">此外，我们需要通过以下方式在实体上“安装”相关的手势(<code class="fe mq mr ms mt b">scale</code>、<code class="fe mq mr ms mt b">translate</code>、<code class="fe mq mr ms mt b">rotate</code>或<code class="fe mq mr ms mt b">all</code>):</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="56b9" class="od lt ir mt b gz oe of l og oh">let box = CustomBox(color: .yellow, position: [-0.6, -1, -2])<br/><strong class="mt is">self.installGestures(.all, for: box)<br/>box.generateCollisionShapes(recursive: true)</strong><br/>self.scene.anchors.append(box)</span></pre><p id="b5da" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">函数<code class="fe mq mr ms mt b">generateCollisionShapes</code>生成与实体模型组件尺寸相同的实体碰撞组件的形状。碰撞组件负责与实体交互。</p><p id="d580" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">为了安装多个手势，我们使用数组中的手势列表调用方法，如下所示:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="102a" class="od lt ir mt b gz oe of l og oh">arView.installGestures(.init(arrayLiteral: [.rotate, .scale]), for: box)</span></pre><p id="c9f5" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">这样，我们的实体就可以在AR场景中进行交互和玩耍了。</p><h2 id="edba" class="od lt ir bd lu ol om dn ly on oo dp mc lf op oq me lj or os mg ln ot ou mi ov bi translated">将实体添加到另一个实体</h2><p id="8e8c" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">我们还可以向当前实体添加子实体，并相对于当前实体定位它们。让我们通过在盒子顶部添加3D文本网格来扩展我们当前的案例，如下所示:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="90a8" class="od lt ir mt b gz oe of l og oh">let mesh = MeshResource.generateText(<br/>            "RealityKit",<br/>            extrusionDepth: 0.1,<br/>            font: .systemFont(ofSize: 2),<br/>            containerFrame: .zero,<br/>            alignment: .left,<br/>            lineBreakMode: .byTruncatingTail)<br/>        <br/>        let material = SimpleMaterial(color: .red, isMetallic: false)<br/>        let entity = ModelEntity(mesh: mesh, materials: [material])<br/>        entity.<strong class="mt is">scale</strong> = SIMD3&lt;Float&gt;(0.03, 0.03, 0.1)<br/>        <br/>        <strong class="mt is">box.addChild(entity)</strong><br/>        <br/>        entity.<strong class="mt is">setPosition</strong>(SIMD3&lt;Float&gt;(0, 0.05, 0), relativeTo: box)</span></pre><p id="6856" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">下面是我们的RealityKit应用程序的一瞥，文本放在框的上方:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj ow"><img src="../Images/db25248c43cb51f3b3fb6c71f958cbc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/1*6qhbUvdRIRkNdiMLwsaNHQ.gif"/></div></figure><p id="3994" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">注意，世界环境对实体的照明有影响。上图中看起来呈淡黄色的同一个盒子在不同的环境下会看起来更亮。</p><p id="79ab" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">现在，我们已经为实体添加了交互性并创建了一个3D文本网格，让我们继续RealityKit的最后一部分——光线投射。</p><h1 id="fd8d" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">光线投射</h1><p id="e955" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">光线投射，很像命中测试，帮助我们从你的屏幕点找到一个AR场景中的3D点。它负责通过使用光线相交来查找真实世界表面上的点，将触摸屏上的2D点转换为真实的3D坐标。</p><p id="7383" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">虽然<code class="fe mq mr ms mt b"><a class="ae mp" href="https://developer.apple.com/documentation/realitykit/arview/3243230-hittest" rel="noopener ugc nofollow" target="_blank">hitTest</a></code>出于兼容性原因在RealityKit中可用，但光线投射是首选方法，因为它不断完善场景中跟踪表面的结果。</p><p id="ebd8" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">我们将扩展上面的应用程序，以允许SwiftUI中的<code class="fe mq mr ms mt b">ARView</code>中的触摸手势被转换为3D点，我们最终将在那里定位实体。</p><p id="3661" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">目前，SwiftUI中的<code class="fe mq mr ms mt b">TapGesture</code>方法不返回视图的位置——它被按下的位置。所以我们将依靠UIKit框架来帮助我们找到点击手势的2D位置。</p><p id="1185" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">在下面的代码中，我们在<code class="fe mq mr ms mt b">ARView</code>中设置了我们的<code class="fe mq mr ms mt b">UITapGestureRecognizer</code>，如下所示:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ox oy l"/></div></figure><ul class=""><li id="0b82" class="mu mv ir ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated">注意<code class="fe mq mr ms mt b">findEntities</code>功能——这有助于我们根据2D屏幕点在3D空间中找到附近的实体。</li><li id="4a9d" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">将在我们的<code class="fe mq mr ms mt b">ARView</code>实例上调用<code class="fe mq mr ms mt b">setupGestures</code>方法。</li><li id="2aca" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><code class="fe mq mr ms mt b">makeRaycastQuery</code>创建了一个<code class="fe mq mr ms mt b"><a class="ae mp" href="https://developer.apple.com/documentation/arkit/arraycastquery" rel="noopener ugc nofollow" target="_blank">ARRaycastQuery</a></code>，其中我们已经通过了屏幕上的点。或者，如果您打算每次只将实体添加到屏幕的中心，则可以通过屏幕的中心点。此外，平面<code class="fe mq mr ms mt b">type</code>(精确或估计)和<code class="fe mq mr ms mt b">orientation</code>(您可以在<code class="fe mq mr ms mt b">horizontal</code>、<code class="fe mq mr ms mt b">vertical</code>或<code class="fe mq mr ms mt b">any</code>中选择设置)。</li><li id="701b" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">光线投射返回的结果用于创建一个<code class="fe mq mr ms mt b">AnchorEntity</code>,我们在上面添加了带有文本的框实体。</li><li id="c7c3" class="mu mv ir ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><code class="fe mq mr ms mt b">overlayText</code>是我们将从用户输入中接收到的3D文本标签(稍后将详细介绍)。</li></ul><p id="c6e1" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">在我们跳到<code class="fe mq mr ms mt b">PencilKit</code>来创建输入数字之前，让我们修改一下<code class="fe mq mr ms mt b">ARViewContainer</code>，它用我们到目前为止所做的修改来加载<code class="fe mq mr ms mt b">ARView</code>。</p><h1 id="fd9e" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">使用SwiftUI协调器配置ARView</h1><p id="cc42" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">在下面的代码中，<code class="fe mq mr ms mt b">Coordinator</code>类被添加到<code class="fe mq mr ms mt b">ARViewContainer</code>中，以允许数据从<code class="fe mq mr ms mt b">PencilKitView</code>流向<code class="fe mq mr ms mt b">ARView</code>。</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ox oy l"/></div></figure><p id="1b3c" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated"><code class="fe mq mr ms mt b">overlayText</code>由<code class="fe mq mr ms mt b">ARView</code>场景从<code class="fe mq mr ms mt b">Coordinator</code>类中选取。接下来，PencilKit符合愿景框架。</p><h1 id="0bfa" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">使用PencilKit处理输入</h1><p id="264b" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">PencilKit是iOS 13中引入的新绘图框架。在我们的应用程序中，我们将让用户在PencilKit的画布上绘制数字，并通过将核心ML MNIST模型馈送到视觉框架来对这些手写数字进行分类。</p><p id="6da8" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">以下代码设置SwiftUI中的PencilKit视图(<code class="fe mq mr ms mt b">PKCanvasView</code>):</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="5ff1" class="od lt ir mt b gz oe of l og oh">struct PKCanvasRepresentation : UIViewRepresentable {<br/>    <br/>    let canvasView = PKCanvasView()<br/>    <br/>    func makeUIView(context: Context) -&gt; PKCanvasView {<br/>        <br/>        canvasView.tool = PKInkingTool(.pen, color: .secondarySystemBackground, width: 40)<br/>        return canvasView<br/>    }<br/>    <br/>    func updateUIView(_ uiView: PKCanvasView, context: Context) {<br/>    }<br/>}</span></pre><h1 id="1068" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">内容视图</h1><p id="e142" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">现在是时候将<code class="fe mq mr ms mt b">ARView</code>和<code class="fe mq mr ms mt b">PKCanvasView</code>合并到我们的<code class="fe mq mr ms mt b">ContentView</code>中了。默认情况下，SwiftUI视图占用最大的可用空间。因此，这两个视图几乎占据了屏幕的一半。</p><p id="2f76" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated"><code class="fe mq mr ms mt b">ContentView.swift</code>文件的代码如下所示:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ox oy l"/></div></figure><p id="29ca" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">以下代码为SwiftUI按钮设计样式:</p><pre class="kh ki kj kk gu nz mt oa ob aw oc bi"><span id="1b12" class="od lt ir mt b gz oe of l og oh">struct MyButtonStyle: ButtonStyle {<br/>    var color: Color = .green<br/>    <br/>    public func makeBody(configuration: MyButtonStyle.Configuration) -&gt; some View {<br/>        <br/>        configuration.label<br/>            .foregroundColor(.white)<br/>            .padding(15)<br/>            .background(RoundedRectangle(cornerRadius: 5).fill(color))<br/>            .compositingGroup()<br/>            .shadow(color: .black, radius: 3)<br/>            .opacity(configuration.isPressed ? 0.5 : 1.0)<br/>            .scaleEffect(configuration.isPressed ? 0.8 : 1.0)<br/>    }<br/>}</span></pre><p id="67ec" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">终于，我们的app做好了！下面是RealityKit + PencilKit iOS应用程序的示例:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oz"><img src="../Images/c432077bdfa32506f101d18a7b5fa6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*d0pG0ag1WJfXBu005SwCeQ.gif"/></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">iPad的输出</p></figure><p id="8b7c" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">从PencilKit绘图中提取数字后，我们所做的就是从屏幕上触摸<code class="fe mq mr ms mt b">ARView</code>的点投射光线，在平面上创建一个实体。目前，这些实体不支持碰撞，并且可以相互拖动。我们将在后续教程中处理碰撞和更多的交互，敬请关注！</p><h1 id="4ba0" class="ls lt ir bd lu lv lw lx ly lz ma mb mc jx md jy me ka mf kb mg kd mh ke mi mj bi translated">结论</h1><p id="a6f4" class="pw-post-body-paragraph kw kx ir ky b kz mk js lb lc ml jv le lf mm lh li lj mn ll lm ln mo lp lq lr ik bi translated">RealityKit在这里抽象了很多样板代码，让开发者专注于构建更加沉浸式的AR体验。它完全用Swift编写，是SceneKit的替代品。</p><p id="94af" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">在这里，我们也很好地了解了RealityKit的实体和组件，并了解了如何设置教练层。此外，我们创建了自己的自定义实体和子实体。随后，我们深入研究了RealityKit当前支持的3D手势，并将它们集成到实体上，然后探索了光线投射。最后，我们集成了PencilKit来处理用户输入，并使用Vision框架来预测手绘数字。</p><p id="1c87" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">完整的源代码以及MNIST核心ML模型可以在这个<a class="ae mp" href="https://github.com/anupamchugh/iowncode/tree/master/RealityKitEntitiesVision" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><p id="4199" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">从这里开始，我们将探索RealityKit中其他有趣的功能。加载不同种类的对象，添加声音，以及执行和检测碰撞的能力将是下一个目标。</p><p id="8fdf" class="pw-post-body-paragraph kw kx ir ky b kz la js lb lc ld jv le lf lg lh li lj lk ll lm ln lo lp lq lr ik bi translated">这一次到此为止。感谢阅读。</p></div></div>    
</body>
</html>
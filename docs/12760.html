<html>
<head>
<title>Using AWS and Hyperscan to Match Regular Expressions on 100GB of Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AWS和Hyperscan匹配100GB文本上的正则表达式</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/using-aws-and-hyperscan-to-match-regular-expressions-on-100gb-of-text-4d87a62141ee?source=collection_archive---------8-----------------------#2022-06-29">https://betterprogramming.pub/using-aws-and-hyperscan-to-match-regular-expressions-on-100gb-of-text-4d87a62141ee?source=collection_archive---------8-----------------------#2022-06-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e34c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">受到对冲基金如何处理信用卡交易数据的启发</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1d9f90b3e22f67f127e36cddeca8a4ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7udrWpIvA53PSIDu"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">帕特里克·托马索在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="531a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个系列的第二篇文章，介绍如何使用<a class="ae kv" href="https://meadowrun.io/" rel="noopener ugc nofollow" target="_blank"> Meadowrun </a>在大型文本数据集上快速运行正则表达式，使用英语维基百科作为我们的示例数据集。如果您想继续阅读第二篇文章，您需要我们在第一篇文章中提供的简化的文章摘录。或者，翻译本文中的代码来处理任何数据格式的数据集应该很简单。</p><h2 id="e387" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">背景和动机</h2><p id="a40a" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">这个系列的灵感来自对冲基金过去解析信用卡交易数据的项目。为了简化起见，我们将查看每笔交易的描述字段，看它是否与一家可交易的上市公司匹配，将每家公司所有交易的金额加起来，并使用它来尝试预测每家公司的收入。</p><p id="74c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要使这些收入预测准确，有很多挑战。我们在这篇文章中关注的问题是，由于某种原因(这一点<a class="ae kv" href="https://bam.kalzumeus.com/archive/" rel="noopener ugc nofollow" target="_blank"> patio11 </a>可能会深入解释)，信用卡交易的描述字段对我们来说完全是乱码。对于像麦当劳这样的公司，我们会看到像<code class="fe mq mr ms mt b">mcdonalds</code>、<code class="fe mq mr ms mt b">mcdonald's</code>、<code class="fe mq mr ms mt b">mcdonalds</code>、<code class="fe mq mr ms mt b">mcdonald s</code>、<code class="fe mq mr ms mt b">mcd</code>这样的变体，甚至还有像<code class="fe mq mr ms mt b">mcdnalds</code>这样的拼写错误和错别字。我们的解决方案是创建正则表达式，涵盖我们感兴趣的每家公司的所有品牌的所有常见变化。</p><p id="278c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个数据集大约有1tb未压缩，我们有数百个正则表达式，这意味着我们需要两个主要的基础设施:一个真正快速的正则表达式库和一个分布式计算引擎。对于正则表达式，我们使用Hyperscan，我们将在这里介绍。我们的分布式计算引擎还没有公开，但是我们将引入Meadowrun，它以类似的方式工作。</p><p id="e820" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然，我们使用的信用卡数据集也不能公开获得，所以我们将使用英语维基百科作为替身(大约67 GB未压缩)，因为本文的目标是浏览该分析的工程方面。</p><h2 id="3efa" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">跟上速度</h2><p id="39ce" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">如果您没有遵循本系列的第一篇文章中的<a class="ae kv" href="https://medium.com/@meadowrun/use-aws-to-unzip-all-of-wikipedia-in-10-minutes-c419f1b6972f" rel="noopener">，那么只要您安装了</a><a class="ae kv" href="https://github.com/RaRe-Technologies/smart_open" rel="noopener ugc nofollow" target="_blank"> smart_open </a>和Meadowrun，您应该能够遵循这篇文章并使用您自己的数据集。smart_open是一个令人惊叹的库，它允许您打开S3(和其他云对象存储)中的对象，就像它们是您的文件系统上的文件一样，Meadowrun使您可以轻松地在云上运行Python代码。</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="9360" class="ls lt iq mt b gy my mz l na nb">poetry add smart_open[s3]</span><span id="9b29" class="ls lt iq mt b gy nc mz l na nb">poetry add meadowrun<br/>poetry run meadowrun-manage-ec2 install</span></pre><p id="1234" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们假设您在这里使用的是诗歌，但是也可以随意使用任何环境管理器。我们还假设您已经配置了AWS CLI。(<a class="ae kv" href="https://docs.meadowrun.io/en/stable/" rel="noopener ugc nofollow" target="_blank">参见文档</a>了解更多上下文，以及如何将Meadowrun与Azure、pip和/或conda一起使用。)</p><h2 id="99d1" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">一些现实的数据</h2><p id="8413" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我们将使用由本系列第一篇文章中的代码生成的英文维基百科的简化摘录。作为一个快速概览，它产生了222个文件，如S3://Wikipedia-meadow run-demo/extracted-200000 . tar . gz，这是一个tar.gz文件，包含第200，000到第299，999篇维基百科文章。文件名是文章的标题，每个文件的内容是相应文章的文本。我们需要一个小函数来读取这些tar文件中的一个，<a class="ae kv" href="https://gist.github.com/hrichardlee/4be2881a66faaee24f122eeaccf0b2c0#file-read_articles_extract-py" rel="noopener ugc nofollow" target="_blank"> iterate_extract </a>。</p><p id="299c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于我们的正则表达式，我们将做一个我上面描述的简化版本，只取S&amp;P500的公司名称，当然，这是从维基百科得到的。(如果你很好奇，这是2022-06-20索引中的第1379418篇文章，所以你也可以在S3://Wikipedia-meadow run-demo/extracted-1300000 . tar . gz中找到它。)我用了一点力气将它放入一个名为<a class="ae kv" href="https://gist.github.com/hrichardlee/4be2881a66faaee24f122eeaccf0b2c0?file=companies.txt" rel="noopener ugc nofollow" target="_blank"> companies.txt </a>的文件中，前几行看起来像是:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="7b53" class="ls lt iq mt b gy my mz l na nb">3M<br/>A. O. Smith<br/>Abbott</span></pre><p id="8b53" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将用<code class="fe mq mr ms mt b">aws s3 cp companies.txt s3://wikipedia-meadowrun-demo/companies.txt</code>将它上传到S3，并用这段代码将它转换成一个简单的正则表达式:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="cde6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将为我们提供一个类似于<code class="fe mq mr ms mt b">3M|A.O. Smith|Abbott|...</code>的正则表达式，让我们查找这些公司名称的任何出现。</p><h2 id="cff4" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">正则表达式引擎:re vs re2 vs Hyperscan</h2><blockquote class="nf"><p id="5810" class="ng nh iq bd ni nj nk nl nm nn no lr dk translated">有些人，当遇到问题时，会想“我知道，我会用正则表达式。”现在他们有两个问题。(<a class="ae kv" href="http://regex.info/blog/2006-09-15/247" rel="noopener ugc nofollow" target="_blank">杰米·扎温斯基</a></p></blockquote><p id="5441" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">如果你没有在正则表达式领域花太多时间，你可能会从<a class="ae kv" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank"> re标准库</a>开始——毕竟Python自带电池。让我们看看这是怎么做到的。我们将使用Meadowrun的<code class="fe mq mr ms mt b">run_function</code>直接在EC2上运行一些探索性代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="58c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe mq mr ms mt b">scan_re</code>将从指定的. tar.gz文件中提取前100篇文章，并对这些文章运行我们公司名称的regex，告诉我们它每秒能够处理多少字节。</p><p id="855d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe mq mr ms mt b">scan_re_ec2</code>使用Meadowrun在EC2实例上运行<code class="fe mq mr ms mt b">scan_re</code>——这里我们要求它启动一个至少有1个CPU和2 GB内存的EC2实例，并且我们可以接受高达80%的逐出机会(即中断)。我们可以只在本地运行<code class="fe mq mr ms mt b">scan_re</code>，但这实际上会更快，因为从S3下载数据从EC2比通过互联网要快得多。换句话说，我们将代码发送给数据，而不是相反。</p><p id="8d21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行这个程序会给我们带来:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="b898" class="ls lt iq mt b gy my mz l na nb">Scanned 1,781,196 bytes in 10.38 seconds (171,554 B/s)</span></pre><p id="428d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，对于这个正则表达式，我们得到了大约170 KB/s。我们有大约67 GB，所以在许多EC2实例上分布它仍然是缓慢和昂贵的。</p><p id="c01b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们试试<a class="ae kv" href="https://github.com/google/re2" rel="noopener ugc nofollow" target="_blank"> re2 </a>，这是一个由Google <a class="ae kv" href="https://github.com/google/re2/wiki/WhyRE2" rel="noopener ugc nofollow" target="_blank">构建的正则表达式引擎，主要目标是</a>用线性时间搜索字符串中的任何正则表达式。对于上下文，python的内置re库使用回溯方法，这可能需要<a class="ae kv" href="https://www.regular-expressions.info/catastrophic.html" rel="noopener ugc nofollow" target="_blank">的指数时间来搜索一个字符串</a>。re2使用了一种<a class="ae kv" href="https://swtch.com/~rsc/regexp/regexp1.html" rel="noopener ugc nofollow" target="_blank">汤普森NFA方法</a>，这种方法可以保证线性时间搜索，但是提供的功能较少。</p><p id="5475" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">PyPI上的官方python包是google-re2，但是pyre2也为Windows和Mac提供了很好的预编译版本(除了Linux之外):</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="b690" class="ls lt iq mt b gy my mz l na nb">poetry add pyre2</span></pre><p id="7ee5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">pyre2被设计为一个直接替换，所以我们可以在最后一个代码片段中用<code class="fe mq mr ms mt b">import re2 as re</code>替换<code class="fe mq mr ms mt b">import re</code>，然后重新运行，看看re2的性能如何。请注意，Meadowrun会自动同步对远程机器上的代码和环境的更改，我们不必担心手动重建虚拟环境或包含新re2库的容器映像。</p><p id="f98d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">重新运行re2和10，000篇文章，我们得到:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="7209" class="ls lt iq mt b gy my mz l na nb">Scanned 190,766,485 bytes in 6.94 seconds (27,479,020 B/s)</span></pre><p id="e7d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大幅加速至27 MB/s！</p><p id="fafb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的最后一站是<a class="ae kv" href="https://github.com/intel/hyperscan" rel="noopener ugc nofollow" target="_blank"> Hyperscan </a>，这是一个正则表达式引擎，最初由一家名为Sensory Networks的初创公司创建，旨在进行深度数据包检查，该公司于2013年被英特尔收购。Hyperscan有很多非常酷的部分——有一个维护者Geoff Langdale的很好的概述，这篇文章会更深入。我只强调我最喜欢的一个，它广泛使用了<a class="ae kv" href="https://branchfree.org/2018/05/30/smh-the-swiss-army-chainsaw-of-shuffle-based-matching-sequences/" rel="noopener ugc nofollow" target="_blank"> SIMD指令来搜索字符串</a>。</p><p id="a4b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">多亏了<a class="ae kv" href="https://python-hyperscan.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> python-hyperscan </a>，pypi中有一个带有python绑定的编译版Hyperscan。python-hyperscan只有为Linux预先构建的轮子，但这没关系，因为Meadowrun为我们创建的EC2实例正在运行Linux。如果我们在Linux上，我们甚至可以告诉poem只安装Hyperscan，因为在Windows或Mac上安装它可能会失败:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="8a54" class="ls lt iq mt b gy my mz l na nb">poetry add hyperscan --platform linux</span></pre><p id="4954" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(Pip requirements.txt文件也支持“<a class="ae kv" href="https://stackoverflow.com/questions/16011379/operating-system-specific-requirements-with-pip" rel="noopener ugc nofollow" target="_blank">环境标记</a>”，这允许您完成同样的事情。)</p><p id="cb28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Hyperscan的API不是re2的直接替代品，所以我们需要调整我们的代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="c452" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe mq mr ms mt b">scan_hyperscan</code>展示了python-hyperscan API的一个非常基本的用法，而<code class="fe mq mr ms mt b">scan_hyperscan_ec2</code>正在做同样的事情，使用Meadowrun在EC2上运行它。运行这个程序会给我们带来:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="e098" class="ls lt iq mt b gy my mz l na nb">Scanned 190,766,485 bytes in 2.74 seconds (69,679,969 B/s)</span></pre><p id="68bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是在re2基础上的又一次坚实的改进。</p><h2 id="3081" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">把所有的放在一起</h2><p id="6711" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">现在我们可以用Meadowrun的<code class="fe mq mr ms mt b">run_map</code>在整个维基百科上运行这个:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="2222" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe mq mr ms mt b">run_map</code>和python内置的<a class="ae kv" href="https://docs.python.org/3/library/functions.html#map" rel="noopener ugc nofollow" target="_blank"> map </a>函数语义相似。如果你以前没看过，<code class="fe mq mr ms mt b">map(f, xs)</code>大致相当于<code class="fe mq mr ms mt b">[f(x) for x in xs]</code>。<code class="fe mq mr ms mt b">run_map</code>和<code class="fe mq mr ms mt b">map</code>做着同样的事情，但是在云上并行进行。因此，我们像以前一样为每个任务请求相同的CPU/内存，并且我们要求Meadowrun启动足够的EC2实例，以便我们可以并行运行64个任务。每个任务将在不同的提取文件上运行<code class="fe mq mr ms mt b">scan_hyperscan</code>,尽管我们实际上检查了数据集两次，以综合地使数据集变得更大。</p><p id="3099" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Meadowrun选择的确切实例类型将因现货实例可用性和实时定价而异，但在一个示例中，run Meadowrun打印出:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="820b" class="ls lt iq mt b gy my mz l na nb">Launched 1 new instance(s) (total $0.6221/hr) for the remaining 64 workers:<br/>    ec2-18-117-89-205.us-east-2.compute.amazonaws.com: c5a.16xlarge (64 CPU/128.0 GB), spot ($0.6221/hr, 2.5% chance of interruption), will run 64 job/worker</span></pre><p id="e0be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">加倍后的维基百科数据集大约有135GB，在标准普尔500搜索一个公司名称大约需要5分钟，只需花费我们5美分！</p><h2 id="f232" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结束语</h2><ul class=""><li id="2fc4" class="nu nv iq ky b kz ml lc mm lf nw lj nx ln ny lr nz oa ob oc bi translated">Hyperscan使用起来可能有点烦人，因为它有一个不同于re的API，并且没有任何针对Windows或Mac的预编译版本(可以针对这些平台进行编译，只是需要一点工作)。在这些非常不科学的基准测试中，它“只”比re2快2.5倍，但根据我的经验，这是值得的，因为随着正则表达式变得越来越大和复杂，与re2相比，性能差距也越来越大。这真是计算机科学理论和工程学的奇迹。</li><li id="be9a" class="nu nv iq ky b kz od lc oe lf of lj og ln oh lr nz oa ob oc bi translated">Meadowrun使得在EC2(或Azure)中使用真正强大的机器来处理数据变得很容易。显然，对于这种精确的工作负载，使用Google或Wikipedia自己的搜索功能会更快，但是我们在这里展示的方法可以用于任何具有任意复杂正则表达式的大型文本数据集。对于任何尚未被谷歌或其他科技巨头索引的东西，我认为没有比这更好的工具组合了。</li><li id="f89b" class="nu nv iq ky b kz od lc oe lf of lj og ln oh lr nz oa ob oc bi translated">这个系列的完整代码是<a class="ae kv" href="https://gist.github.com/hrichardlee/4be2881a66faaee24f122eeaccf0b2c0" rel="noopener ugc nofollow" target="_blank">这里是</a>，以防你想把它用作模板。</li></ul><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="de79" class="ls lt iq mt b gy my mz l na nb"><em class="oi">To stay updated on Meadowrun, star us on </em><a class="ae kv" href="https://github.com/meadowdata/meadowrun" rel="noopener ugc nofollow" target="_blank"><em class="oi">Github</em></a><em class="oi"> or follow us on </em><a class="ae kv" href="https://twitter.com/kurt2001?s=21&amp;t=66yV7Xy4agKRFj4dOaLLew" rel="noopener ugc nofollow" target="_blank"><em class="oi">Twitter</em></a><em class="oi">!</em></span></pre></div></div>    
</body>
</html>
<html>
<head>
<title>A Beginner’s Guide to Apache Spark and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark和Python初学者指南</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/beginners-guide-to-apache-spark-and-python-dcdbf5bef64?source=collection_archive---------3-----------------------#2019-05-25">https://betterprogramming.pub/beginners-guide-to-apache-spark-and-python-dcdbf5bef64?source=collection_archive---------3-----------------------#2019-05-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="65c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">安装和设置Apache Spark的综合指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bad2bb6e55d268cc6be3f118f453700e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWR0-KbMg1MYooaV8ZJXfg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="http://www.zoom-comics.com/" rel="noopener ugc nofollow" target="_blank">http://www.zoom-comics.com</a></p></figure><h1 id="abb4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是阿帕奇火花？</h1><p id="e891" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>是一个开源框架，自2009年在加州大学伯克利分校的AMPLab问世以来一直在兴风作浪；其核心是<strong class="lt iu">一个<em class="mn">大数据分布式处理引擎</em> </strong>，可以随意扩展。</p><p id="a968" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">简而言之，随着数据的增长，处理大型流数据并能够处理和执行机器学习等其他操作变得至关重要，而Apache Spark正是这样做的。一些专家说，在不久的将来，它将成为流计算的首选平台。</p><p id="ba5d" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">人们经常误以为它是Hadoop<a class="ae ky" href="https://www.bernardmarr.com/default.asp?contentID=1080" rel="noopener ugc nofollow" target="_blank">的替代品，但它只是Hadoop</a><a class="ae ky" href="https://medium.com/sarccom/hadoop-fundamental-5179099f5b21" rel="noopener">map-reduce框架</a>的竞争对手。这是理所当然的，因为它速度快得多，对开发人员来说是最短的学习曲线之一，再加上它被市场上的顶级公司所使用，这使得它成为一种简单有效的简历补充技能。</p><p id="af8f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">正如您在下面看到的，分布式处理是关键特性之一，但不是唯一的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/ba1ada041504f18c3c476c10ef7f6d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*ITGPIgVYc88gYDknDA0TyQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/</a></p></figure><p id="7ebe" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">由于Spark非常受欢迎，您可以预期许多供应商以许多不同的方式提供Spark服务。有时选择太多或太多，所以学习新事物的兴奋和渴望只是在尝试探索正确的选择中丢失了。</p><h2 id="0ae6" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated"><strong class="ak"> <em class="ng">剧透预警！</em> </strong></h2><p id="60d8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu"> <em class="mn">在本文中，我们不会详细讨论Spark的细节以及如何使用它来处理流数据。相反，它将作为一个可能的选项列表的汇编来开始使用它。那么我把选择权交给你——你可以选择自己的冒险！</em> </strong></p><p id="6363" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我建议您在尝试给出的选项之前通读这篇文章。这个想法是了解可用的选项，然后选择最适合你的一个，然后动手去做。如果您对学习Spark特别感兴趣，请查看参考资料。</p><h1 id="8913" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">1.去当地</h1><p id="efeb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">第一个选项是全能的本地设置。如果你对在线服务不感兴趣，那就试试这个吧。它是本地的，你可以控制它，但是要知道这很费时间。</p><p id="d9c7" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">如果时间不在你这边，或者你不喜欢安装的麻烦，我会帮你省去麻烦，直接跳到选项2和3。T3】</p><p id="06d2" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">本地设置需要的东西:虚拟盒子；Ubuntu时间和耐心！</strong></p><p id="e52d" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">Virtual Box是一个允许你在个人电脑上运行虚拟计算机的应用程序，你将在那里安装基于Linux的操作系统Ubuntu和Spark。如果你已经安装了Ubuntu，你可以跳过这一步。</p><div class="nh ni gp gr nj nk"><a href="https://www.virtualbox.org/wiki/Downloads" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">下载- Oracle VM VirtualBox</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">关于屏幕截图下载文档最终用户文档技术文档贡献社区</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">www.virtualbox.org</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ks nk"/></div></div></a></div><p id="1a7f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">导航至以上链接，根据您的电脑选择Windows主机或OS X主机，并下载安装程序。下载完成后，只需双击并按照默认设置进行操作，就可以开始了。虚拟箱现已安装。</p><p id="0f11" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">跳到下面的下一个链接，下载Ubuntu。Ubuntu桌面优先。经过这一步，你现在应该有一个<strong class="lt iu">。iso </strong>文件已下载。</p><div class="nh ni gp gr nj nk"><a href="https://www.ubuntu.com/download" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">获取Ubuntu |下载|</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">Ubuntu是一个开源软件操作系统，可以运行在桌面、云、互联网上</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">www.ubuntu.com</p></div></div></div></a></div><p id="fe7e" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">一旦完成，您就可以跳转到虚拟盒子应用程序。这一点基本上是空的。您可以通过单击“New”按钮来添加新的虚拟机。给机器起一个好听的名字，选择Linux，然后点击next。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/c97473a5bb99822968f277fa724c0e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*kFTpjjsDdIqvfQwnbrGO9w.png"/></div></figure><p id="3515" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">完成此步骤后，您将经历一系列可为机器设置的选项。<strong class="lt iu">首先是</strong>，内存大小。您可以保留推荐的大小，但是根据您的规格，您可以分配合理的RAM大小。</p><p id="2e1e" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">其次</strong>，硬盘。您可以将其保留在建议的8.00 GB，并设置一个选项来立即创建虚拟硬盘，然后在硬盘文件类型窗口中选择VDI (VirtualBox磁盘映像)并单击下一步。</p><p id="d23f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">第三</strong>，存储。您可以选择动态分配或固定大小。建议使用固定大小来提高输入/输出速度。20Gb应该是个不错的量。点击创建。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/92f55afd8a4b3e96180dae32c9b27488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*7RljoI23a5vlLtYZyW44Vw.png"/></div></figure><p id="6c09" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">一旦你点击创建，这将需要一段时间。当它准备好的时候，你将被带回到Virtual box应用程序的主屏幕，但是这一次是用创建的机器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/7c33474fbd04b228cbce0f7f57642e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*aU0JAG-Ux1yVwXI1rhK97Q.png"/></div></figure><p id="69f1" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">默认情况下，它是关闭的，但您可以双击来打开它。在第一次启动时，你会被要求选择一个启动盘。这很重要，你可以在这里将它指向你之前下载的<strong class="lt iu"> Ubuntu.iso </strong>镜像。选择<strong class="lt iu"> Ubuntu.iso </strong>，点击开始。这将把Ubuntu安装到你的虚拟机上。在这个过程中，您将看到许多安装选项，您可以选择自定义它或保留默认值。无论哪种方式都应该没问题，最终你应该有一个工作的操作系统——一个虚拟的操作系统。</p><p id="8c47" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在虚拟机中，您首先要做的是确认Python是否已经安装。要做到这一点，进入Ubuntu的终端应用程序，输入python3并按enter键。这应该会产生类似如下的输出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/a3b2a42359d7cbe08a373c7d9976bde8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*KohEvjVv5SgxHcV33NDLTA.png"/></div></figure><p id="51ac" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">Python的版本可能不同，但只要是3以上就没问题。</p><p id="e7ac" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">接下来，我们将进行一系列安装，这对于Spark在我们的虚拟机上运行是必不可少的。</p><h2 id="69f2" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">Jupyter笔记本</h2><p id="afe9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">安装<a class="ae ky" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter Notebook </a>是与Python交互和构建优秀代码的最简单方式之一。为此，在同一终端或新终端上，键入以下命令:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="b29b" class="mu la it oe b gy oi oj l ok ol">pip3 install jupyter</span></pre><p id="c030" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这应该安装Jupyter笔记本系统。完成后，您可以通过在终端上输入以下命令来测试它:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="360c" class="mu la it oe b gy oi oj l ok ol">jupyter notebook</span></pre><p id="45ea" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这将打开一个带有Jupyter笔记本界面的浏览器(可能是默认的)。这表明我们的笔记本设置正在工作。</p><h2 id="5bff" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated"><strong class="ak"> Java </strong></h2><p id="b3df" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在让我们安装Java，这是Spark运行所必需的。在另一个终端窗口中，依次键入以下命令:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="0802" class="mu la it oe b gy oi oj l ok ol">sudo apt-get update</span><span id="165f" class="mu la it oe b gy om oj l ok ol"><em class="mn">sudo apt-get install default-jre</em></span></pre><p id="2596" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">第一个命令将更新我们的apt-get机制，之后我们使用第二个命令安装Java。</p><h2 id="e007" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">斯卡拉</h2><p id="9fc1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">同样，让我们安装<a class="ae ky" href="https://www.scala-lang.org/" rel="noopener ugc nofollow" target="_blank"> Scala </a>:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="865c" class="mu la it oe b gy oi oj l ok ol">sudo apt-get install scala</span></pre><p id="effb" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">要测试安装是否成功，您可以输入下面的命令，它应该会打印出所安装的Scala版本。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="79c9" class="mu la it oe b gy oi oj l ok ol">scala -version</span></pre><h2 id="bc28" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">安装Py4j</h2><p id="7c5a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们将安装一个Python库，用Python连接Java和Scala。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="3e84" class="mu la it oe b gy oi oj l ok ol">pip3 install py4j</span></pre><h2 id="fb9f" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">Spark和Hadoop</h2><p id="36df" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，当我们移动到最后，我们只需要安装Spark和Hadoop本身。导航到以下链接并直接下载Spark版本。<strong class="lt iu">确保在您的虚拟机上执行此步骤</strong>，以便直接下载到虚拟机上。</p><div class="nh ni gp gr nj nk"><a href="https://spark.apache.org/downloads.html" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">下载| Apache Spark</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">注意，Spark是用Scala 2.11预构建的，除了版本2.4.2，它是用Scala 2.12预构建的。</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">spark.apache.org</p></div></div><div class="nt l"><div class="on l nv nw nx nt ny ks nk"/></div></div></a></div><p id="f05f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">打开一个新的终端，并确保您位于下载文件的同一位置。您可以将cd放入正确的文件夹并运行下面的命令(注意，根据当时的Spark版本，文件名可能会有所不同):</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="d825" class="mu la it oe b gy oi oj l ok ol">sudo tar -zxvf spark-2.1.0-bin-hadoop2.7.tgz</span></pre><p id="fa27" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">基本上，这将解压软件包并创建我们需要的文件夹。</p><p id="5d21" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">接下来，我们需要告诉Python在哪里可以找到Spark。这可能看起来像纯粹的魔法，但只是跟着做！在终端上这样做，并在每行之后按Enter键。注意SPARK_HOME的路径，它应该是你解压文件夹的位置。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="daac" class="mu la it oe b gy oi oj l ok ol">export SPARK_HOME=’home/ubuntu/spark-2.1.0-bin-hadoop2.7'</span><span id="24ee" class="mu la it oe b gy om oj l ok ol">export PATH=@SPARK_HOME:$PATH</span><span id="d9cc" class="mu la it oe b gy om oj l ok ol">export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH</span><span id="efca" class="mu la it oe b gy om oj l ok ol">export PYSPARK_DRIVER_PYTHON=”jupyter”</span><span id="9d52" class="mu la it oe b gy om oj l ok ol">export PYSPARK_DRIVER_PYTHON_OPTS=”notebook”</span><span id="14aa" class="mu la it oe b gy om oj l ok ol">export PYSPARK_PYTHON=python3</span></pre><p id="cbad" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">唷，太多了！如果你还和我在一起，我们就都准备好了。锦上添花的只能是奔跑火花的甜味。</p><p id="c8ea" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">打开终端，将cd放入以下路径(安装Spark的路径):</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="9d3e" class="mu la it oe b gy oi oj l ok ol">cd /spark-2.1.0-bin-hadoop2.7/python</span></pre><p id="bca4" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">进入正确的目录后，打开Jupyter笔记本:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="71e8" class="mu la it oe b gy oi oj l ok ol">jupyter notebook</span></pre><p id="b317" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">现在你应该可以打开Jupyter笔记本系统的浏览器了。创建一个新的Python笔记本，在空白单元格中键入下面的命令，然后按CTRL+Enter。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="e1fa" class="mu la it oe b gy oi oj l ok ol">import pyspark</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/b9c3309a22daec38a49c5172f089c676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3zNODYuMcpHyOErr3pV0KQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.uhdpaper.com/" rel="noopener ugc nofollow" target="_blank">https://www.uhdpaper.com</a></p></figure><p id="fec3" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">瞧啊。我们自己的虚拟机，安装了Spark，并且运行良好。闪闪发光！</p><h2 id="38f9" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">2.数据砖</h2><p id="d8fd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://databricks.com/" rel="noopener ugc nofollow" target="_blank"> Databricks </a>是由Apache Spark的原始创建者创建的平台，这是一个仅通过浏览器就能利用Spark强大功能的好方法。Databricks消除了烦人的安装负担，并将计算能力直接带到您的浏览器上。如果你正在寻找一个快速的火花之旅，这是最好的方法。</p><p id="3aba" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">如果本地设置是一个家常菜，考虑Databricks美食。</p><p id="ac1a" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">你需要的:网络浏览器和强大的互联网连接。</strong></p><p id="4052" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">虽然Databricks的目标是向大数据和分布式计算过渡的公司，但他们确实提供了一个社区版本，应该可以满足我们的目的。</p><p id="fae3" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">为了开始，导航到下面的链接并注册社区版。</p><div class="nh ni gp gr nj nk"><a href="https://databricks.com/try-databricks" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">尝试数据块</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">无限集群，可扩展至任何规模的作业调度程序，为生产管道执行作业完全交互式…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">databricks.com</p></div></div><div class="nt l"><div class="op l nv nw nx nt ny ks nk"/></div></div></a></div><p id="af3d" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">首次登录时，您需要验证您的电子邮件地址。一旦进入，您将有可能使用预安装的Python笔记本设置。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/a7751e679e9f1a4d16afa69738470a69.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*MggdH88NTKUeRnf1h6enVQ.png"/></div></figure><p id="3c5f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">登录后，单击“创建空白笔记本”开始。您将看到一个Jupyter笔记本，您可以在其中的每个单元格中键入Python代码并单独运行它们。</p><p id="a555" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">Databricks专为Spark打造，因此您无需担心额外的设置。您可以立即在第一个单元格中键入<code class="fe or os ot oe b">spark</code>，然后按下<strong class="lt iu"> Ctrl+Enter </strong>或单元格右侧的小播放按钮。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/b5721878f853eb566eab6b9b8ea1e68e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yx4zTyYU2MR3FaWYYHGwsQ.png"/></div></div></figure><p id="1782" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">第一次运行时，会要求您启动并运行一个集群。继续做，之后你应该会看到类似上面的图片。现在，您可以创建更多的单元并继续评估Spark，无论是摄取数据集还是执行机器学习，都由您决定。</p><p id="24f5" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">额外收获: Databricks之所以酷，是因为它提供了一个巨大的数据库，可以在所有马力下进行实验。</p><p id="3da2" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">要浏览一下提供的内容，您需要使用一个神奇的命令进入Databricks的“文件系统”。在新的单元格中，键入<code class="fe or os ot oe b">%fs</code>后接<strong class="lt iu"> </strong> <code class="fe or os ot oe b">ls </code>并运行单元格。您应该会看到列出的dbfs路径。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/9bb0c40531ef9ec8853b1aa03a0e577f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DiE-lLxBlVwR1PKqY8JhpA.png"/></div></div></figure><p id="50cc" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">接下来，点击<code class="fe or os ot oe b">ls /databricks-datasets/</code>查看所有可用的数据集。如果你喜欢其中的任何一个，你可以很容易地在你的代码中使用它。例如，我碰巧喜欢简单的<code class="fe or os ot oe b">/people/people.json</code> <strong class="lt iu"> <em class="mn"> </em> </strong>数据，并希望在我的代码中使用它。我可以简单地这样做:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="2730" class="mu la it oe b gy oi oj l ok ol">data = spark.read.json(“/databricks-datasets/samples/people/people/.json”)</span></pre><p id="cbef" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">深入其中，尝试一些数据集，你不会失望的！也许这是最容易擦出火花的方式。</p><h2 id="4fff" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">3.Google Colab</h2><p id="09c6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colaboratory </a>是一个免费的Jupyter笔记本环境，就像Databricks一样，完全在云上运行，但所有的讨论都不是关于免费的笔记本系统，而是免费的GPU 。是啊！你没听错，Colab提供免费GPU！这对所有深度学习的传播者来说都是一件大事。那是另一个季节的故事——我们今天的焦点是火花。</p><p id="dd58" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">你需要什么:一个网络浏览器；强大的互联网连接；一个谷歌账户。</p><div class="nh ni gp gr nj nk"><a href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">谷歌联合实验室</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">编辑描述</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">colab.research.google.com</p></div></div><div class="nt l"><div class="ow l nv nw nx nt ny ks nk"/></div></div></a></div><p id="88fb" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">导航到上面的链接。你应该通过你的谷歌账户登录，然后出现一个屏幕来创建一个<em class="mn">“新的Python 3笔记本”</em>继续创造吧。</p><p id="841c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这一步将把我们带入熟悉的领域:一个带有空单元格的Python笔记本。与Databricks不同，Google Colab不是现成的Spark，所以我们需要稍微调整一下才能开始。</p><p id="9551" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">如果你试图在空单元格中运行<code class="fe or os ot oe b">pyspark</code>，你会得到一个错误。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/41e828b385fb2679379dbd92b5da4e09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMx9TblcaRzQFj2NRuvsBQ.png"/></div></div></figure><p id="074c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">大家一起修吧！Google Colab既像虚拟机又像笔记本。让我们将下面的命令输入到一个空的单元格中，然后点击<strong class="lt iu"> CTRL+Enter </strong>来安装<strong class="lt iu"> Java </strong>:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="d9aa" class="mu la it oe b gy oi oj l ok ol">!apt install openjdk-8-jdk-headless -qq &gt; /dev/null</span></pre><p id="8014" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">使用“！”在命令开始时会简单地在一个shell中运行它，表明它不是Python代码。</p><p id="8657" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">现在让我们下载Spark和Hadoop。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="1d5b" class="mu la it oe b gy oi oj l ok ol">!wget -q <a class="ae ky" href="http://www-eu.apache.org/dist/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz" rel="noopener ugc nofollow" target="_blank">http://www-eu.apache.org/dist/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz</a></span></pre><p id="dd1c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">一旦完成，您就可以像在Linux shell上一样，通过运行<code class="fe or os ot oe b">!ls -l</code>来查看文件是否被下载。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/5be85280af8808e03251ff45571a6fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*4NZsE4D4bx3hmM_G0NaxzQ.png"/></div></figure><p id="3ed3" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">如您所见，下载的文件是一个zip文件，所以让我们解压缩它:</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="bc34" class="mu la it oe b gy oi oj l ok ol">!tar xf spark-2.3.3-bin-hadoop2.7.tgz</span></pre><p id="4455" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">现在我们只需要在被激发之前做几件事情:如下设置Java和Spark变量。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="e4e9" class="mu la it oe b gy oi oj l ok ol">import os<br/>os.environ[“JAVA_HOME”] = “/usr/lib/jvm/java-8-openjdk-amd64”<br/>os.environ[“SPARK_HOME”] = “/content/spark-2.3.3-bin-hadoop2.7”</span></pre><p id="8736" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这就是要设置的全部内容！</p><p id="c7e5" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">现在看看这个示例代码:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/590cccf93ab46d5786b0534ef1cc97a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*Hd_9QiNo9QCVgRO5mtyemg.png"/></div></figure><p id="fbbc" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">上面的代码通过创建一个新的SparkSession来初始化Spark，然后使用P <a class="ae ky" href="https://www.datacamp.com/community/tutorials/python-list-comprehension?utm_source=adwords_ppc&amp;utm_campaignid=1455363063&amp;utm_adgroupid=65083631748&amp;utm_device=c&amp;utm_keyword=&amp;utm_matchtype=b&amp;utm_network=g&amp;utm_adpostion=1t1&amp;utm_creative=332602034358&amp;utm_targetid=aud-392016246653:dsa-486527602543&amp;utm_loc_interest_ms=&amp;utm_loc_physical_ms=9067548&amp;gclid=EAIaIQobChMIwsvLmYSw4gIVyasYCh0uEQ8eEAAYASAAEgIERPD_BwE" rel="noopener ugc nofollow" target="_blank"> ython list comprehension </a>动态创建一个新的Spark数据帧，最后打印出数据帧。在新的牢房区试试。</p></div><div class="ab cl pa pb hx pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="im in io ip iq"><p id="fd98" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们完了——就这样！我希望通过这份安装信息的汇编，我已经让你对整个过程更加清楚了，所以希望你能停止担心信息过载，只关注刚刚开始！</p><h2 id="a67a" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">参考</h2><ol class=""><li id="f8b2" class="ph pi it lt b lu lv lx ly ma pj me pk mi pl mm pm pn po pp bi translated">https://spark.apache.org/docs/latest/quick-start.html<a class="ae ky" href="https://spark.apache.org/docs/latest/quick-start.html" rel="noopener ugc nofollow" target="_blank"/></li><li id="ceff" class="ph pi it lt b lu pq lx pr ma ps me pt mi pu mm pm pn po pp bi translated">【https://www.dezyre.com/apache-spark-tutorial/spark-tutorial T4】</li><li id="b34b" class="ph pi it lt b lu pq lx pr ma ps me pt mi pu mm pm pn po pp bi translated"><em class="mn">何塞·波尔蒂利亚的伟大课程，学习完整的Spark，包括所有不同的安装选项:</em><a class="ae ky" href="https://www.udemy.com/course/spark-and-python-for-big-data-with-pyspark/" rel="noopener ugc nofollow" target="_blank">https://www . udemy . com/course/Spark-and-python-for-big-data-with-py Spark/</a></li></ol></div></div>    
</body>
</html>
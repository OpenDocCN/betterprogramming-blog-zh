<html>
<head>
<title>Generating Images With Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习生成图像</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/generating-images-with-deep-learning-2e73043427e4?source=collection_archive---------9-----------------------#2021-09-14">https://betterprogramming.pub/generating-images-with-deep-learning-2e73043427e4?source=collection_archive---------9-----------------------#2021-09-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a5fd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习如何使用人工智能生成新的图像，如人脸或艺术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ec5c2cb7f680c27d912c3d6520658978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cni4XixqKDKrafnZp3Lf5g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="32c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们正处于人工智能时代，它正以令人难以置信的速度前进。如果只是说人工智能现在正在自动化人工智能，那将是非常诚实的。这篇文章探讨了我刚刚提到的惊人事实的细节。</p><p id="05eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人工智能进步的速度令人难以置信，根据埃隆·马斯克的说法，已经接近指数级，计算机视觉也取得了一些令人兴奋的突破。通过创建一个名为GANs的算法，著名的深度学习研究人员Ian Goodfellow将传统的计算机视觉转变为新的计算机视觉。嗯，我创造了这些名字“传统的”和“新的”，而不是CV社区，看到了在为几个计算机视觉问题产生数据方面的巨大转变。</p><h1 id="df5d" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">传统和新的计算机视觉</h1><p id="7aea" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">传统的计算机视觉涉及通过下载、清理、渲染并将其存储到数据库中来创建大型数据集，或者手动捕捉图片、制作视频并使其能够被网络使用。这种技术给研究人员和开发人员带来了巨大的挑战，特别是在时间、资源和产生的数据质量不达标的情况下。</p><p id="e9d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，新的计算机视觉让人松了一口气，减轻了迄今为止收集最佳数据集的巨大负担。现在，gan用于生成与有限可用数据具有相同特征的数据。从而将研究人员从收集和管理数据的繁忙工作中解放出来。</p><h1 id="643f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">GANs是如何工作的？</h1><p id="1660" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">GANs这个时髦词的概念就是两个神经网络相互竞争。这些竞争的神经网络以这样一种方式执行分配的任务，即学习可用数据中存在的概率分布。基于这样的概率分布，生成具有与训练数据相同特征的逼真数据。</p><h1 id="16d5" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">两个竞争的神经网络</h1><p id="9be7" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">这些竞争网络被称为生成器和鉴别器。生成器网络学习训练数据中的模式并生成图像，而鉴别器检查生成的图像的真实性，即，它决定生成的图像是否属于训练集。简而言之，它检查生成的图像是“真”还是“假”</p><h1 id="55b6" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">发电机</h1><p id="302d" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">当给定一组随机值或噪声时，发生器在执行一系列非线性计算后产生一个新的假图像，并将其传递给鉴别器。它这样做是因为它希望被鉴别器声明为真实的。简单来说，生成器的目标是创建图像来撒谎而不被识破，即愚弄鉴别者。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/34d856ae246335669621910091cbdf51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mMEwQ7QZ00IbAqGN.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">发电机网络，<a class="ae ms" href="https://learnopencv.com/introduction-to-generative-adversarial-networks/#why" rel="noopener ugc nofollow" target="_blank">信用点</a></p></figure><h1 id="8ef2" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">鉴别器</h1><p id="a244" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">鉴别器的目标是处理来自生成器的图像(假图像如下所示)并识别它们是假的。它的作用是二元分类器。它需要两个输入:真实图像(来自训练数据)和来自生成器的生成图像。它对它们进行比较，并判断它们是否来自同一个分布。“真实”意味着它们来自同一个分布，而“虚假”则表明它们属于不同的分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/4f182490e71446d1015b8b5bc5b8558e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*R2sz0DBmDKZ3Zh7Z.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">甄别网络，<a class="ae ms" href="https://learnopencv.com/introduction-to-generative-adversarial-networks/#why" rel="noopener ugc nofollow" target="_blank">学分</a></p></figure><h1 id="2608" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">GAN的训练和收敛</h1><p id="0663" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">GAN的训练以交替的方式进行，即，当鉴别器正在学习将生成的图像真正分类为“真实”或“虚假”时，生成器保持不变，即，捕捉生成器的缺陷，并且鉴别器保持不变，而生成器正在学习愚弄鉴别器(生成器试图使其虚假生成的图像被鉴别器分类为真实)。这种来回训练允许GAN模型收敛，否则这将变得难以处理。这种训练有助于克服训练有素的生成者和训练不足的鉴别者之间的无赢局面，反之亦然，否则这是不可避免的。</p><p id="77d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">发生器性能的提高恶化了鉴别器的性能，因为它不能容易地区分真假。如果发生器工作正常，鉴别器有50%的准确度。实际上，鉴别器做的和扔硬币做预测没什么不同。</p><p id="d663" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这使得收敛在整体上是不可能的:鉴别器的反馈对于发生器来说变得非常没有意义。如果在鉴别器达到一个给出完全随机反馈的点之后继续训练GAN，那么生成器就开始对垃圾(误导性反馈)进行训练，自身质量就崩溃了。</p><p id="900c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，交替训练对GANs的收敛有着至关重要的意义。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/74f6f88034ded5bbd472db235be64368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KRO0AAaPFWIcsgNZ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">甘架构，<a class="ae ms" href="https://www.analyticsvidhya.com/blog/2021/04/generate-your-own-dataset-using-gan/" rel="noopener ugc nofollow" target="_blank">学分</a></p></figure><h1 id="b842" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">甘斯背后的数学</h1><p id="3549" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">现在我们更深入地挖掘甘斯的数学基础。</p><p id="a42e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">GAN由两个神经网络组成:生成器<code class="fe mt mu mv mw b">G</code>和鉴别器<code class="fe mt mu mv mw b">D</code>，它们在一起学习训练数据集的未知分布时相互竞争。我们的目标是生成器生成与训练数据不可区分的图像。</p><p id="a118" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，生成器的权重应该使得生成器生成鉴别器不能识别为假的假图像。这使得该优化成为最小-最大优化问题，其中我们希望发生器的权重最小化鉴别器正确分类真假样本的速率(成本函数<code class="fe mt mu mv mw b">J(D)</code>，如下所示)。我们需要鉴别器的权重来最大化这个速率。由于在这种情况下使用了二元类分类，所以我们使用二元交叉熵函数作为我们的成本函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/61d6850b726a55a5988c4594f1319e35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WVVjSzRtV7YQse3M.png"/></div></figure><p id="5a18" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成本函数J(D)中的第一项表示输入鉴别器的真实数据，鉴别器想要最大化预测的对数概率，表明数据是真实的。第二项表示生成器生成的假图像，<code class="fe mt mu mv mw b">G</code>。这里，鉴别器想要最大化预测零的对数概率，显示数据是假的。另一方面，生成器寻求最小化鉴别器正确的对数概率。这个权衡的平衡点就是这个优化问题的解，也就是鉴频器损耗的鞍点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/4b175cae79e3780cf750dfef18943840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*z-58HmqMdgr1Jzi7.jpg"/></div></figure><p id="d073" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe mt mu mv mw b">D()</code>是给定图像属于训练数据<code class="fe mt mu mv mw b">X</code>的概率。对于发电机，我们希望最小化<code class="fe mt mu mv mw b">log(1-D(G(z))</code>，即当<code class="fe mt mu mv mw b">D(G(z))</code>为高时，那么<code class="fe mt mu mv mw b">D</code>认为<code class="fe mt mu mv mw b">G(z)</code>就是<code class="fe mt mu mv mw b">X</code>，这使得<code class="fe mt mu mv mw b">1-D(G(z))</code>非常低。我们想把这个最小化，这个更小。对于鉴别器，我们希望最大化<code class="fe mt mu mv mw b">D(X)</code>和<code class="fe mt mu mv mw b">(1-D(G(z)))</code>。所以<code class="fe mt mu mv mw b">D</code>的最佳状态会是<code class="fe mt mu mv mw b">P(x)=0.5</code>。然而，发生器<code class="fe mt mu mv mw b">G</code>应进行训练，以便为鉴别器<code class="fe mt mu mv mw b">D</code>产生结果，从而<code class="fe mt mu mv mw b">D</code>无法区分<code class="fe mt mu mv mw b">z</code>和<code class="fe mt mu mv mw b">X</code>。</p><p id="0e98" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们称之为最小-最大优化的原因在于，鉴别器试图最大化目标，而生成器试图最小化目标。由于这种最小化和最大化，我们说它是最小-最大。它们都通过交替梯度下降来一起学习。</p><h1 id="eef0" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">GANs的实施</h1><p id="8d93" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">本节将在编码中实现GAN，看看它是如何先于理论基础工作的。为此，我们将使用TensorFlow库。正在使用的版本是TensorFlow v2.3.0和Keras v2.4.3。</p><p id="5ea6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以自己写代码，也可以在<a class="ae ms" href="https://colab.research.google.com/drive/1v8tDvBFBRoN3BL9xECyAY_6ryfue7s41?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google colab </a>上访问完整代码。</p><div class="mx my gp gr mz na"><a href="https://colab.research.google.com/drive/1v8tDvBFBRoN3BL9xECyAY_6ryfue7s41?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd iu gy z fp nf fr fs ng fu fw is bi translated">完整源代码</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">编辑描述</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">colab.research.google.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no ks na"/></div></div></a></div><h1 id="6890" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">导入包</h1><p id="773b" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">需要一些库，让我们通过这些导入来获得它们:</p><pre class="kj kk kl km gt np mw nq nr aw ns bi"><span id="3c11" class="nt lv it mw b gy nu nv l nw nx">import os<br/>import time<br/>import numpy as np<br/>import tensorflow as tf<br/>from tensorflow.keras import layers<br/>import argparse<br/>from IPython import display<br/>import matplotlib.pyplot as plt<br/># %matplotlib inline<br/>from tensorflow import keras</span></pre><h1 id="37d8" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">数据加载和预处理</h1><pre class="kj kk kl km gt np mw nq nr aw ns bi"><span id="1b1e" class="nt lv it mw b gy nu nv l nw nx">(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()<br/>x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')<br/>x_train = (x_train - 127.5) / 127.5 # Normalize the images to [-1, 1]<br/># Batch and shuffle the data<br/>train_dataset = tf.data.Dataset.from_tensor_slices(x_train).\<br/>shuffle(60000).batch(args.batch_size)</span></pre><p id="1e59" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们使用<code class="fe mt mu mv mw b">tf_keras</code>数据集模块来加载时尚MNIST数据集。该模块加载现成的数据。由于不需要标签来解决这个问题，所以我们只使用训练图像<code class="fe mt mu mv mw b">x_train</code>。我们对图像进行整形，并将其转换为float32(数据默认为uint8格式)。</p><p id="152f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们将从<code class="fe mt mu mv mw b">[0, 255]</code>到<code class="fe mt mu mv mw b">[-1, 1]</code>的数据归一化。最后，我们构建TensorFlow输入管道。简而言之，<code class="fe mt mu mv mw b">tf.data.Dataset.from_tensor_slices</code>被输入了训练数据，经过重组，分割成张量，允许我们在训练期间访问指定批量的张量。随机播放中的缓冲区大小参数会影响随机播放的随机性。</p><h1 id="c29a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">创建发电机网络</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="fbb0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们向发生器提供从正态分布采样的100维噪声矢量。接下来，我们定义输入层，形状为(100，)。在TensorFlow中，线性层的默认权重初始化器是<code class="fe mt mu mv mw b">he_uniform</code>。</p><p id="084e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">批规范层的动量值更改为0.1(默认值为0.99)。</p><p id="0643" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们使用<code class="fe mt mu mv mw b">tf.reshape</code>将784-D张量整形为(批量大小，28，28，1)，其中第一个参数是输入张量，第二个参数是张量的新形状。最后，我们通过传递生成器函数的输入和输出层来创建模型。</p><h1 id="09c8" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">创建鉴别器网络</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="63d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">鉴别器是仅由完全连接的层组成的二元分类器。所以，鉴别器期望一个形状张量(批量大小，28，28，1)。但是鉴别器功能仅由致密层组成。因此，我们将张量整形为一个形状向量(批量大小，784)。最后一层有sigmoid激活函数，使输出值介于0(假)和1(真)之间。</p><h1 id="342a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">损失函数</h1><pre class="kj kk kl km gt np mw nq nr aw ns bi"><span id="3ad2" class="nt lv it mw b gy nu nv l nw nx">binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()</span></pre><p id="9420" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是二元交叉熵损失。</p><p id="000d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是发生器和鉴频器各自的损耗。</p><h1 id="849a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">发电机损耗</h1><pre class="kj kk kl km gt np mw nq nr aw ns bi"><span id="6ca2" class="nt lv it mw b gy nu nv l nw nx">def generator_loss(fake_output):<br/>  gen_loss = binary_cross_entropy(tf.ones_like(fake_output), fake_output)<br/>  return gen_loss</span></pre><h1 id="4cbc" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">鉴频器损耗</h1><pre class="kj kk kl km gt np mw nq nr aw ns bi"><span id="9483" class="nt lv it mw b gy nu nv l nw nx">def discriminator_loss(real_output, fake_output):<br/>  real_loss = binary_cross_entropy(tf.ones_like(real_output), real_output)<br/>  fake_loss = binary_cross_entropy(tf.zeros_like(fake_output), fake_output)<br/>  total_loss = real_loss + fake_loss<br/>  return total_loss</span></pre><h1 id="00f6" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">【计算机】优化程序</h1><pre class="kj kk kl km gt np mw nq nr aw ns bi"><span id="d938" class="nt lv it mw b gy nu nv l nw nx">generator_optimizer = tf.keras.optimizers.Adam(learning_rate = args.lr, beta_1 = args.b1, beta_2 = args.b2 )<br/>discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = args.lr, beta_1 = args.b1, beta_2 = args.b2 )</span></pre><p id="0510" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们使用Adam Optimizer来优化生成器和鉴别器，它有两个参数:</p><ol class=""><li id="6274" class="oa ob it la b lb lc le lf lh oc ll od lp oe lt of og oh oi bi translated"><code class="fe mt mu mv mw b">2e-4</code>的学习率。</li><li id="77b1" class="oa ob it la b lb oj le ok lh ol ll om lp on lt of og oh oi bi translated">β系数:<code class="fe mt mu mv mw b">b1</code>和<code class="fe mt mu mv mw b">b2</code>。</li></ol><p id="966b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些计算反向传播过程中梯度的移动平均值。</p><h1 id="efba" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">训练回路(训练GAN的所有功能组合)</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="f46a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe mt mu mv mw b">train_step</code>功能是整个GAN训练的核心。因为在这里，我们结合了上面定义的所有训练函数。</p><p id="635c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe mt mu mv mw b">@tf.function</code>将<code class="fe mt mu mv mw b">train_step</code>函数编译成可调用的张量流图。此外，减少了培训时间。整个培训过程包括以下步骤:</p><ul class=""><li id="83de" class="oa ob it la b lb lc le lf lh oc ll od lp oe lt oo og oh oi bi translated">首先，我们从正态分布中对噪声进行采样，并将其输入到发生器中。</li><li id="6df9" class="oa ob it la b lb oj le ok lh ol ll om lp on lt oo og oh oi bi translated">发生器产生假图像，这些图像被输入鉴别器。鉴别器也给出真实图像。</li><li id="cbac" class="oa ob it la b lb oj le ok lh ol ll om lp on lt oo og oh oi bi translated">鉴别器将图像(来自生成器)分类为真实的(来自训练集)或伪造的(由生成器生成)</li><li id="4de0" class="oa ob it la b lb oj le ok lh ol ll om lp on lt oo og oh oi bi translated">对于这些模型中的每一个，计算损失:gen_loss和disc_loss。</li><li id="8237" class="oa ob it la b lb oj le ok lh ol ll om lp on lt oo og oh oi bi translated">计算梯度后，使用Adam优化器更新生成器和鉴别器参数。</li></ul><h1 id="57c7" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">培养</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="6fbd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">终于，我们可以坐下来看魔术的时候到了。但是请等一下。您必须将两个参数(训练数据和时期数)传递给上面的函数。给它那些，运行程序，放松，看看GANs能为你做什么。</p><h1 id="e7e2" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结果</h1><p id="fbe0" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">下面显示了三个图像网格，每个网格包含16个图像，这些图像是由生成器在训练的三个不同阶段生成的。你可以看到，最初，发生器产生噪声图像。但是随着训练的进行，生成器会改进并开始生成看起来更真实的时尚图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/c730eb56500fd447d2581797324fd0d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A9YSwH8y7Y1LADsa.jpg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的网络生成的图像</p></figure><h1 id="a439" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">摘要</h1><p id="4022" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">简而言之，我们开始介绍甘，为什么我们需要他们，他们的优势，和他们的直觉。然后我们深入挖掘，了解了GAN的组成部分，即发生器和鉴别器。然后详细讨论了两个最重要的方面:训练策略和GAN的目标函数。</p><p id="4fa8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们在TensorFlow框架中用时尚MNIST数据集实现了一个GAN，并取得了令人惊讶的结果。</p><p id="8092" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这都是关于甘和用他们生成图像。这个领域正以惊人的速度前进。但是我相信这篇文章已经为您提供了如此多的关于GANs的理论和实践知识，您可以很容易地跟上正在进行的进步和改进。</p><p id="9c47" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">记住，你可以在<a class="ae ms" href="https://colab.research.google.com/drive/1v8tDvBFBRoN3BL9xECyAY_6ryfue7s41?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌实验室</a>找到所有这些代码的工作示例。</p><p id="54aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读。</p></div></div>    
</body>
</html>
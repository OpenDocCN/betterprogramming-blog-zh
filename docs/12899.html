<html>
<head>
<title>A First Look at DALL-E 2 — How It Works Under the Hood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DALL-E 2的初步研究——它是如何在引擎盖下工作的</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/dall-e-2-and-why-everyone-is-talking-about-it-baae2e41655e?source=collection_archive---------2-----------------------#2022-07-10">https://betterprogramming.pub/dall-e-2-and-why-everyone-is-talking-about-it-baae2e41655e?source=collection_archive---------2-----------------------#2022-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a61e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">知道为什么每个人都在谈论它吗</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1d52b1206488e4750106a99b480f56f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZYP6q7kX0vUpBFaG"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@deepmind?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> DeepMind </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="36f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">OpenAI发布了他们期待已久的模型DALL-E 2，它正在各地创造头条新闻。像<a class="ae kv" href="https://www.youtube.com/watch?v=yCBEumeXY4A" rel="noopener ugc nofollow" target="_blank">马克斯·布朗利</a>和<a class="ae kv" href="https://www.youtube.com/watch?v=SVcsDDABEkM" rel="noopener ugc nofollow" target="_blank"> Vox工作室</a>这样的大型YouTube频道现在也在制作关于它的视频。因此，在这篇文章中，我们将探讨什么是Dall -E2，它的特别之处，以及为什么每个人都在谈论它。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d6d8" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">什么是DALL-E 2？</strong></h1><p id="3d68" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">Dall-E 2是Open AI的Dall-E模型的继任者。Dall-E这个名字是瓦力(皮克斯的科幻电影)和萨瓦尔多·达利(西班牙艺术家，以其绘画中的超现实主义风格而闻名)的组合。该模型用于从给定的文本描述中生成真实感图像。</p><p id="55e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个模型还没有对公众开放，但是开放人工智能团队已经在他们的<a class="ae kv" href="https://openai.com/dall-e-2/#demos" rel="noopener ugc nofollow" target="_blank">网站</a>上做了一个不错的演示。正如你所看到的，这些图像是艺术家/图形设计师需要几个小时甚至几天才能制作出来的，但DALL-E2在几分钟内就完成了，它制作的图像令人印象深刻。它会捕捉提示的所有重要特征，并尝试将它们融入图像中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/ca81045661bf9dd183f344598f53bd58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*q0na3AbFllLzojtM46u79A.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Dall-E 2演示</p></figure><p id="c0f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">受够了这些令人印象深刻的结果，让我们看看引擎盖下是什么，看看我们如何能够生成这些图像。幸运的是，开放AI团队还发布了DALL-E2背后的<a class="ae kv" href="https://arxiv.org/pdf/2204.06125.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，让我们独家了解了DALL-E2的训练过程。DALL-E2包括两个模型剪辑和扩散模型。给定标题(在图2中虚线上方示出)和扩散模型(在虚线下方示出), CLIP用于生成剪辑文本嵌入，该扩散模型首先使用扩散先验生成给定剪辑文本嵌入的图像嵌入。然后，使用扩散解码器对该图像嵌入进行解码，以生成最终图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/1b6ccba67d0598016441ff06cbfe8da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFkp-7WuflwQbe_b4Es7yw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2 DALL-E2培训流程</p></figure><p id="dc6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些术语听起来可能很复杂，但是它们背后的概念很容易理解。因此，为了了解更多，让我们更深入一些。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="57aa" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">什么是剪辑？</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/010c3e51fb0bcb994876ce2ae403c9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uK7ccDMVz74xhbbZSpK9CQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">剪辑概述</p></figure><p id="afe0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2021年1月，这个片段和最初的DALL-E <a class="ae kv" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank">论文</a>一起发布。CLIP代表对比学习图像预训练。CLIP背后的基本思想是将图像和文本作为输入，并尝试将它们连接起来。这是通过使用图像编码器(Resnet/ViT)生成图像嵌入和文本编码器(Transformer)生成文本嵌入来实现的。</p><blockquote class="mz na nb"><p id="e344" class="kw kx nc ky b kz la jr lb lc ld ju le nd lg lh li ne lk ll lm nf lo lp lq lr ij bi translated">基于这些嵌入，我们试图以对比的方式学习哪个图像嵌入对应于哪个文本嵌入。更简单地说，我们尝试最小化图像嵌入和文本嵌入的正确匹配的点积，并尝试最大化图像和文本嵌入的所有不正确组合的点积。</p></blockquote><p id="5b59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在运行推理之前，我们从概述的第2阶段中表示的数据集生成文本提示。这些文本提示是根据数据集的标签生成的简单提示。使用提示背后的想法是它们将包含比标签更多的信息。并且在推断期间，当给定图像时，编码器生成图像嵌入，并且模型试图预测数据集中哪个文本提示最接近该图像嵌入。</p><p id="7f9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">文本嵌入和图像嵌入的这种互连是DALL-E2能够基于文本描述来处理这种图像的原因之一。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="4855" class="ng ma iq bd mb nh ni dn mf nj nk dp mj lf nl nm ml lj nn no mn ln np nq mp nr bi translated"><strong class="ak">什么是扩散模型？</strong></h2><p id="f97a" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">扩散模型是一种新的生成模型，在<a class="ae kv" href="https://proceedings.neurips.cc/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf" rel="noopener ugc nofollow" target="_blank">图像合成和照片真实感任务</a>中优于GANs。惊喜，惊喜他们也是来自Open AI。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/e943886e037dd5c34e7c331681ae9aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R5Ae3B8j_ecJ0zDGmmbj0A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">扩散模型如何工作</p></figure><p id="31ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些扩散模型通过在每个阶段向现有图像添加极小的噪声来工作。如果我们做这一步，无数次我们可以安全地假设，在这些步骤之后，我们将只剩下噪音。这些扩散模型的任务是通过反转这个噪声添加过程来提取图像。</p><p id="eb48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DALL-E2使用剪辑生成的文本嵌入，并在它之前添加一个，以将其转换为图像嵌入。这种嵌入然后被馈送到扩散解码器，以产生那些令人印象深刻的图像。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="9477" class="ng ma iq bd mb nh ni dn mf nj nk dp mj lf nl nm ml lj nn no mn ln np nq mp nr bi translated"><strong class="ak">结果</strong></h2><p id="a3d8" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">关于技术的讨论已经够多了，现在让我们来看一些图片:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/54d99719766addb45c065f18e90a89d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*RS0yeqjMiHMXn73zLfUuNg.jpeg"/></div></figure><p id="edc6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">哇，多么像熊猫疯狂科学家的形象啊。更值得称赞的是，DALL-E2还可以理解反射，因为我们可以在眼镜上看到绿色。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/2f8a785501ea8354d33070fd302449d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*l2PfgkK-pK3QwXzM3boq0Q.jpeg"/></div></figure><p id="8402" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这也是一个用人类灵魂制作咖啡的抽象概念的令人印象深刻的形象。DALL-E2知道什么是咖啡机，咖啡应该从哪里出来，它也知道人类的灵魂应该是什么样子。这简直令人难以置信！！</p><p id="9c38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些结果基本上是OpenAI精心挑选的，以显示最佳的吸引人的结果。然而，这些结果将图像生成的边界从文本描述推向了极致。真的很好奇未来几年我们会在这个领域看到什么型号。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="f7fe" class="ng ma iq bd mb nh ni dn mf nj nk dp mj lf nl nm ml lj nn no mn ln np nq mp nr bi translated">会有达尔-E3吗？</h2><p id="41af" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">DALL-E2虽然令人印象深刻，但仍有许多缺点。</p><h2 id="f923" class="ng ma iq bd mb nh ni dn mf nj nk dp mj lf nl nm ml lj nn no mn ln np nq mp nr bi translated"><strong class="ak">拼写错误</strong></h2><p id="b49c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">作为一个在图像和文本上训练的数十亿参数模型，DALL-E2在拼写上犯错误是非常有趣的。这些图像是由DALL-E2的用户生成的。下图显示了DALL-E2在给出提示“一个表示深度学习的标志”时生成的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/df727d6535a701673d2b2e07116e472e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v3ShKdMI7fFSmUIckWrqNA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">“一个写着深度学习的标志。”信用:<a class="ae kv" href="https://arxiv.org/abs/2204.06125" rel="noopener ugc nofollow" target="_blank"> OpenAI </a></p></figure><h2 id="4b6f" class="ng ma iq bd mb nh ni dn mf nj nk dp mj lf nl nm ml lj nn no mn ln np nq mp nr bi translated"><strong class="ak">关系</strong></h2><p id="b1c7" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">基于Open AI向我们展示的精选结果，DALL-E2被证明对对象之间的关系有很好的理解。然而，有时它只是混淆了简单的提示，如“蓝色立方体上的红色立方体”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/3132e8503eba52925203a0e55a9d5bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*uFcu5rfgoLl77P5-qZmSPw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">"蓝色立方体上的红色立方体."信用:<a class="ae kv" href="https://arxiv.org/abs/2204.06125" rel="noopener ugc nofollow" target="_blank"> OpenAI </a></p></figure><p id="2e23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我不想破坏DALL-E2的结果，它们产生的结果令人印象深刻。然而，他们的失败案例仍然很明显。这些缺点使得我们极有可能在不久的将来看到达尔-E3。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="4e3d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">为什么每个人都在谈论它？</strong></h1><p id="0a41" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">DALL-E2是镇上的话题，因为结果令人印象深刻，流行的媒体都在谈论它。然而，大家提出的问题是“DALL-E2是艺术家/平面设计师的终结吗？”YouTubers现在可以从DALL-E2制作他们的缩略图了，他们不需要图形设计师了。</p><p id="9645" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然这些问题是有关的，但我认为这些是无效的。在艺术这样的抽象技能方面，机器永远不会像人一样好。艺术家经常为提出一个开始的想法而挣扎。DALL-E2可以作为一个很好的起点，艺术家/平面设计师可以在以后修改它，使它变得更好。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="7620" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">结论</h1><p id="3289" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">DALL-E2的结果令人印象深刻，他们将通过文本生成图像的界限推到了极致。有了这些研究，我们应该始终关注这些研究在未来2-3年内会带来什么。很难想象最初的AlexNet论文仅仅在10年前出现，而现在在计算机视觉架构中广泛使用的ResNet仅仅在6年前出现。没有其他研究领域像深度学习领域发展得那么快，我对未来几年的最新发展水平感到非常兴奋。</p></div></div>    
</body>
</html>
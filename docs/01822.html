<html>
<head>
<title>iOS Vision And Highlighting Text With Core ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">iOS视觉和使用Core ML突出显示文本</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/ios-vision-and-highlighting-text-with-core-ml-aaca104e9427?source=collection_archive---------17-----------------------#2019-10-15">https://betterprogramming.pub/ios-vision-and-highlighting-text-with-core-ml-aaca104e9427?source=collection_archive---------17-----------------------#2019-10-15</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="ea6e" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">从图像中查找并突出显示关键词</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/d2df2ec8fa705bb2e5f91a662618cb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EWkB5qe2iaDmriso"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://unsplash.com/@aaronburden?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aaron Burden </a>在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="4e0f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">愿景和核心ML框架是WWDC 2017的亮点。视觉是一个强大的框架，用于实现计算机视觉功能，而无需太多的算法先验知识。</p><p id="d994" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">使用视觉可以轻松检测条形码、人脸、物体和文本。<br/>与此同时，Core ML允许我们在我们的iOS应用程序中集成和运行预先训练好的模型，而无需过于深入地挖掘机器学习。</p><h1 id="2b03" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">我们的目标</h1><p id="5ea6" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">我们今天的目标是构建一个iOS应用程序来识别静态图像中的文本。</p><p id="6e2b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">就像当你使用<code class="fe mt mu mv mw b">cmd + F</code>搜索关键词时，所有匹配的字符串都会在屏幕上高亮显示，我们将在一张图片中高亮显示几个选中的字符串。</p><p id="6975" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在进入正题之前，让我们先浏览一下将要涉及的内容。</p><h1 id="d430" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">涵盖的主题</h1><ul class=""><li id="aaf9" class="mx my iu lc b ld mo lg mp lj mz ln na lr nb lv nc nd ne nf bi translated">使用照相机或图库捕捉图像</li><li id="c38c" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">使用视觉的文本检测</li><li id="09bf" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">使用核心ML的文本识别</li><li id="9e26" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">在某些关键字上绘制边界框</li></ul><h1 id="6e78" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">我们想要达到的目标</h1><p id="45ee" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">我们希望在从相机/图库捕获的图像中识别出一些检测到的文本的名称后，突出显示这些文本，如下所示:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nl"><img src="../Images/37e0344fd09bef26d215eb75b6b5fd85.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/0*1bTs3Rfp639-HOsC.png"/></div></figure><blockquote class="nm nn no"><p id="4cc0" class="la lb np lc b ld le jv lf lg lh jy li nq lk ll lm nr lo lp lq ns ls lt lu lv in bi translated">我们将这个应用程序称为<strong class="lc iv"> FindMyText </strong>。灵感来源于FindMyIphone这个名字！</p></blockquote><p id="912b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">别再浪费时间了，让我们开始吧。启动Xcode并创建一个单一视图应用程序。</p></div><div class="ab cl nt nu hy nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="in io ip iq ir"><h1 id="5f84" class="lw lx iu bd ly lz oa mb mc md ob mf mg ka oc kb mi kd od ke mk kg oe kh mm mn bi translated">图像拾取控制器</h1><p id="8b8c" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">我们不会关注故事板，因为它非常简单(只有一个UIImage和一个按钮)。这个想法是从照片库中上传包含文本的图像。</p><pre class="kk kl km kn gu of mw og oh aw oi bi"><span id="2111" class="oj lx iu mw b gz ok ol l om on">guard UIImagePickerController.isSourceTypeAvailable(.camera) else {<br/>            presentPhotoPicker(sourceType: .photoLibrary)<br/>            return<br/>        }<br/>        let photoSourcePicker = UIAlertController()<br/>        let takePhoto = UIAlertAction(title: "Camera", style: .default) { [unowned self] _ in<br/>            self.presentPhotoPicker(sourceType: .camera)<br/>        }<br/>        let choosePhoto = UIAlertAction(title: "Photos Library", style: .default) { [unowned self] _ in<br/>            self.presentPhotoPicker(sourceType: .photoLibrary)<br/>        }<br/>        photoSourcePicker.addAction(takePhoto)<br/>        photoSourcePicker.addAction(choosePhoto)<br/>        photoSourcePicker.addAction(UIAlertAction(title: "Cancel", style: .cancel, handler: nil))<br/>        <br/>        present(photoSourcePicker, animated: true)</span></pre><p id="bcbc" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe mt mu mv mw b">presentPhotoPicker</code>用于启动适当的应用程序。一旦图像被点击，我们开始<code class="fe mt mu mv mw b">Vision Request</code>。</p><pre class="kk kl km kn gu of mw og oh aw oi bi"><span id="d0d4" class="oj lx iu mw b gz ok ol l om on">extension ViewController: UIImagePickerControllerDelegate, UINavigationControllerDelegate {<br/>    <br/>    func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey: Any]) {<br/>        picker.dismiss(animated: true)<br/>        <br/>        guard let uiImage = info[UIImagePickerController.InfoKey.originalImage] as? UIImage else {<br/>            fatalError("Error!")<br/>        }<br/>        imageView.image = uiImage<br/>        createVisionRequest(image: uiImage)<br/>    }<br/>    <br/>    private func presentPhotoPicker(sourceType: UIImagePickerController.SourceType) {<br/>        let picker = UIImagePickerController()<br/>        picker.delegate = self<br/>        picker.sourceType = sourceType<br/>        present(picker, animated: true)<br/>    }<br/>}</span></pre><p id="bec2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">是时候了解一下愿景框架了！</p><h1 id="e8a5" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">愿景框架</h1><p id="fc01" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">Vision Framework推出了iOS 11。它带来了图像识别和分析的算法，据苹果公司称，比CoreImage框架更准确。对此的一个重要贡献是机器学习、深度学习和计算机视觉的底层使用。</p><p id="5afd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">实现该框架包括三个重要的用例:</p><ul class=""><li id="22b9" class="mx my iu lc b ld le lg lh lj oo ln op lr oq lv nc nd ne nf bi translated"><code class="fe mt mu mv mw b">Request</code> -创建检测对象类型的请求。您可以设置多种类型进行检测。</li><li id="2164" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated"><code class="fe mt mu mv mw b">Request Handler</code> -这用于处理从请求中获得的结果。</li><li id="f854" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated"><code class="fe mt mu mv mw b">Observation</code> -结果以观察的形式存储。</li></ul><p id="a4b8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">作为愿景框架一部分的一些重要类别包括:</p><ul class=""><li id="007e" class="mx my iu lc b ld le lg lh lj oo ln op lr oq lv nc nd ne nf bi translated"><code class="fe mt mu mv mw b">VNRequest</code> -它由一组用于图像处理的请求组成。</li><li id="c10d" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated"><code class="fe mt mu mv mw b">VNObservation</code> -这给了我们结果的输出。</li><li id="5935" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated"><code class="fe mt mu mv mw b">VNImageRequestHandler</code> -在给定图像上处理一个或多个<code class="fe mt mu mv mw b">VNRequest</code>。</li></ul><p id="e3e5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">下面的代码片段显示了如何创建一个<strong class="lc iv">视觉图像请求处理器</strong>。</p><pre class="kk kl km kn gu of mw og oh aw oi bi"><span id="da07" class="oj lx iu mw b gz ok ol l om on">func createVisionRequest(image: UIImage){<br/>        <br/>        currentImage = image<br/>        guard let cgImage = image.cgImage else {<br/>            return<br/>        }<br/>        let requestHandler = VNImageRequestHandler(cgImage: cgImage, orientation: image.cgImageOrientation, options: [:])<br/>        let vnRequests = [vnTextDetectionRequest]<br/>        <br/>        DispatchQueue.global(qos: .background).async {<br/>            do{<br/>                try requestHandler.perform(vnRequests)<br/>            }catch let error as NSError {<br/>                print("Error in performing Image request: \(error)")<br/>            }<br/>        }<br/>        <br/>}</span></pre><p id="c820" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们可以传递多个请求，但是本文的目标是文本检测和识别。</p><p id="9f11" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe mt mu mv mw b">vnTextDetectionRequest</code>在下面的代码中定义:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="or os l"/></div></figure><p id="313c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">上面的代码片段中有很多东西。<br/>我们来分解一下。</p><ul class=""><li id="970b" class="mx my iu lc b ld le lg lh lj oo ln op lr oq lv nc nd ne nf bi translated">观察是请求返回的结果。</li><li id="85ac" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">我们的目标是用边界框突出显示检测到的文本，因此我们将观察结果定型为<br/> <code class="fe mt mu mv mw b">VNTextObservation</code>。</li><li id="4595" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">我们裁剪图像中检测到的文本部分。这些裁剪后的图像充当我们的ML模型的微观输入。</li><li id="7778" class="mx my iu lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">在将这些图像调整到所需的输入尺寸后，我们将它们提供给核心ML模型进行分类。</li></ul><p id="0c30" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">裁剪和预处理的代码可以在本项目末尾的<code class="fe mt mu mv mw b">ImageUtils.swift</code>文件中找到。</p><p id="19d4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">让我们来看看核心ML，以及它与我们现阶段的关系。</p></div><div class="ab cl nt nu hy nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="in io ip iq ir"><h1 id="f2a8" class="lw lx iu bd ly lz oa mb mc md ob mf mg ka oc kb mi kd od ke mk kg oe kh mm mn bi translated">核心ML框架</h1><p id="d76c" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">Core ML是一个框架，让开发者在他们的应用程序中轻松使用ML模型。<br/>在这个框架的帮助下，输入数据可以被处理以返回期望的输出。</p><p id="279e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在这个项目中，我们使用了一个<code class="fe mt mu mv mw b">alphanum_28X28</code> ml模型。<br/>该模型要求输入尺寸为28*28的图像，并返回检测到的文本。</p><p id="f9cf" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">调整图像大小发生在我们前面看到的预处理函数中。<br/> <code class="fe mt mu mv mw b">observationStringLookup</code>是一个查找字典，它将每个观察值绑定到由核心ML模型预测的文本。</p><p id="712c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了确定文本，我们有自己的图像分类器，它在调整大小的图像输入上运行:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="or os l"/></div></figure><p id="d78a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe mt mu mv mw b">textMetadata</code>用于存储所有预测的单词。<br/>现在已经创建了<code class="fe mt mu mv mw b">observationStringLookup</code>，我们可以突出显示所选择的观察结果(正如我们在本文开头看到的，在最终输出中突出显示了单词vision，core ml)。</p></div><div class="ab cl nt nu hy nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="in io ip iq ir"><h2 id="bad8" class="oj lx iu bd ly ot ou dn mc ov ow dp mg lj ox oy mi ln oz pa mk lr pb pc mm pd bi translated">视觉和边界框</h2><p id="59ac" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">现在我们知道了<code class="fe mt mu mv mw b">VNTextObservations</code>中视觉检测到的文本。每个观察都有一个边界框属性。</p><p id="3190" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这些观察值中的每一个的标签都是由来自前一部分的核心ML图像分类器预测的。</p><p id="4ec9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">所以我们可以简单地在文本上画矩形。</p><p id="87e2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">下面的方法为我们完成了实现，并在图像中突出显示了单词“Vision”和“Core ML”。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="or os l"/></div></figure><blockquote class="nm nn no"><p id="6625" class="la lb np lc b ld le jv lf lg lh jy li nq lk ll lm nr lo lp lq ns ls lt lu lv in bi translated">注意:对于不同字体的文本，核心ML模型可能不会给出正确的结果。</p></blockquote><blockquote class="pe"><p id="002e" class="pf pg iu bd ph pi pj pk pl pm pn lv dk translated">在iOS 13中，新升级的Vision框架现在将识别的文本存储在观察实例本身中。</p></blockquote><p id="3b0a" class="pw-post-body-paragraph la lb iu lc b ld po jv lf lg pp jy li lj pq ll lm ln pr lp lq lr ps lt lu lv in bi translated">暂时就这样了。下面是这篇文章的完整源代码。</p><div class="pt pu gq gs pv pw"><a href="https://github.com/anupamchugh/iowncode/tree/master/iOSFindMyText" rel="noopener  ugc nofollow" target="_blank"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">anupamchugh/iowncode</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">github.com</p></div></div><div class="qf l"><div class="qg l qh qi qj qf qk kt pw"/></div></div></a></div><h2 id="4b11" class="oj lx iu bd ly ot ou dn mc ov ow dp mg lj ox oy mi ln oz pa mk lr pb pc mm pd bi translated">资源</h2><div class="pt pu gq gs pv pw"><a href="https://martinmitrevski.com/2017/10/19/text-recognition-using-vision-and-coreml/" rel="noopener  ugc nofollow" target="_blank"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">使用视觉和核心ML的文本识别</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">简介机器学习允许计算机在没有被明确编程的情况下学习和做决定，如何…</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">martinmitrevski.com</p></div></div><div class="qf l"><div class="ql l qh qi qj qf qk kt pw"/></div></div></a></div></div></div>    
</body>
</html>
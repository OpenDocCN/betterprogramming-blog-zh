<html>
<head>
<title>Create a Natural Language Semantic Search to Find GIFs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建自然语言语义搜索来查找gif</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/create-a-natural-language-semantic-search-to-find-gifs-81f9be79850e?source=collection_archive---------3-----------------------#2022-11-05">https://betterprogramming.pub/create-a-natural-language-semantic-search-to-find-gifs-81f9be79850e?source=collection_archive---------3-----------------------#2022-11-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="362b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用自然语言处理和语义搜索增强GIF发现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8f77634e24f50c8c613e8a5d63fb3b9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTQPlRcTHLjCiyqdsMj7yQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.pinecone.io/learn/gif-search/" rel="noopener ugc nofollow" target="_blank">文章最初发布在Pinecone.io </a></p></figure><p id="3687" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">矢量搜索为世界上一些最流行的服务提供了动力。它提供你的谷歌搜索结果，在Spotify上发布<a class="ae ky" href="https://www.pinecone.io/learn/spotify-podcast-search/" rel="noopener ugc nofollow" target="_blank">最好的播客，并在亚马逊[1][2]上占消费者购买量的至少<em class="lv">35%。</em></a></p><p id="5bd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将使用应用于语言的向量搜索，称为<em class="lv">语义</em>搜索，来构建GIF搜索引擎。不像传统的搜索依赖于关键字匹配，语义搜索支持基于文本和图像背后的人类含义的搜索。</p><p id="e37e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着我们可以找到与自然语言提示高度相关的gif。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/09d85b1ebe4f5fa243451f4f4442ab12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*g2roREAxWJuL6Q8JHWOQDQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GIF搜索应用<a class="ae ky" href="https://share.streamlit.io/pinecone-io/playground/gif-search/src/server.py" rel="noopener ugc nofollow" target="_blank">的预览可在此处</a>获得。</p></figure><p id="a2ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像这样一个项目的管道简单而强大。它可以很容易地适应多种多样的任务，如<a class="ae ky" href="https://www.pinecone.io/learn/youtube-search/" rel="noopener ugc nofollow" target="_blank">视频搜索</a>或<a class="ae ky" href="https://www.pinecone.io/learn/question-answering/" rel="noopener ugc nofollow" target="_blank">回答超级碗问题</a>，或者，正如我们将看到的，查找gif。</p><p id="746b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/pinecone-io/examples/tree/master/learn/projects/gif-search" rel="noopener ugc nofollow" target="_blank"> <em class="lv">所有配套的笔记本和脚本都可以在这里找到</em> </a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lx ly l"/></div></figure></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="78fd" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">GIF数据集</h1><p id="5453" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">我们将在这里使用在GitHub上找到的TGIF数据集。为了获得数据集，我们可以使用<code class="fe nd ne nf ng b">wget</code>(或者，手动下载)并解压缩。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="25e6" class="nl mh it ng b gy nm nn l no np">wget https://github.com/raingo/TGIF-Release/archive/master.zip<br/><br/>unzip master.zip</span></pre><p id="f842" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这些解压后的文件中，我们应该能够在<code class="fe nd ne nf ng b">data</code>目录中找到一个名为<code class="fe nd ne nf ng b">tgif-v1.0.tsv</code>的文件。我们将使用<em class="lv">熊猫</em>加载文件，使用<code class="fe nd ne nf ng b">\t</code>作为字段分隔符。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="bee9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集包含GIF URLs及其自然语言描述。我们可以看看前五张gif。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="4085" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们会发现有一些重复的URL，但这些不一定表示重复的记录，因为一个<em class="lv">单个GIF </em>可以被分配多个描述。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><h1 id="ec1c" class="mg mh it bd mi mj nr ml mm mn ns mp mq jz nt ka ms kc nu kd mu kf nv kg mw mx bi translated">搜索</h1><p id="66e2" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">搜索管道将在高层次上采用我们的自然语言查询，如<em class="lv">“一只在电话上说话的狗”</em>，并在现有的GIF描述中搜索任何与该查询具有类似<em class="lv">含义</em>的内容。</p><p id="799f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个上下文中，我们将含义为的<em class="lv">描述为<em class="lv">语义相似度</em>，两者都是加载的术语，可以指代许多事物。比如两个短语<code class="fe nd ne nf ng b">"the dog eats lunch"</code>和<code class="fe nd ne nf ng b">"the dog does not eat lunch"</code>相似吗？在这种情况下，这在很大程度上取决于我们的用例。</em></p><p id="0816" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再比如:下面两句话哪个最像？</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="dd53" class="nl mh it ng b gy nm nn l no np">A: the stock market took a turn for the worse</span><span id="1aa6" class="nl mh it ng b gy nw nn l no np">B: how did the stock market do today?</span><span id="1bc5" class="nl mh it ng b gy nw nn l no np">C: the stock market performed worse than expected</span></pre><p id="116d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想找到意思相似的短语，那么显而易见的选择是<code class="fe nd ne nf ng b">A</code>和<code class="fe nd ne nf ng b">C</code>。将这些与<code class="fe nd ne nf ng b">B</code>相提并论没有什么意义。然而，如果我们搜索相似的<em class="lv">问答对</em>，情况就不是这样了；在这种情况下，<code class="fe nd ne nf ng b">B</code>应该与<code class="fe nd ne nf ng b">A</code>和<code class="fe nd ne nf ng b">C</code>非常匹配。</p><p id="ad80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<em class="lv">、【语义相似度】</em>的定义中，确定用例的需求是很重要的。对我们来说，我们真的想确定一般的相似性。也就是说，我们希望<code class="fe nd ne nf ng b">A</code>和<code class="fe nd ne nf ng b">C</code>匹配，而<code class="fe nd ne nf ng b">B</code>不匹配其中任何一个。</p><p id="e98b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们将把我们的短语转换成<a class="ae ky" href="https://www.pinecone.io/learn/dense-vector-embeddings-nlp/" rel="noopener ugc nofollow" target="_blank"> <em class="lv">密集向量嵌入</em> </a>。这些密集矢量可以存储在<a class="ae ky" href="https://www.pinecone.io/learn/vector-database/" rel="noopener ugc nofollow" target="_blank"> <em class="lv">矢量数据库</em> </a>中，我们可以非常快速地比较矢量，并根据欧几里德距离和余弦相似性等度量来识别最相似的矢量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/edb77c9c3f09f7a9acaecdf07be24dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X-moHl9iYeOteFDNoErMoA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这两种度量都确定了向量的相似性(接近度)，但它们是基于距离(左)或角度相似性(右)来确定的。</p></figure><p id="89d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">向量数据库处理我们的向量嵌入的存储和快速搜索，但是我们仍然需要一种方法来创建这些嵌入。</p><p id="115d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们使用名为<em class="lv">检索器</em>的NLP转换器模型，这些模型被<a class="ae ky" href="https://www.pinecone.io/learn/sentence-embeddings/" rel="noopener ugc nofollow" target="_blank">微调用于创建<em class="lv">句子嵌入</em> </a>。这些句子嵌入/向量可以<em class="lv">在数字上代表</em>它们所代表的文本后面的<em class="lv">含义</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/8590a032630d15d1ac842b223d6af4ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8GcaIwt-9JoP7l73.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">检索器模型能够获取两个语义相似的短语，并将它们编码为相似的向量。</p></figure><p id="8665" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将这两个组件放在一起给我们一个语义搜索管道，我们可以用它来检索给定查询的语义相似的GIF描述。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a77699f1dfbffca69c21b9850ce829a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*MzkEBVvIX-lrByl0XCC_Xw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GIF搜索管道涵盖了一次性索引步骤(左)和查询(右)。</p></figure><p id="22d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看如何将所有这些放在一起。</p><h1 id="6d49" class="mg mh it bd mi mj nr ml mm mn ns mp mq jz nt ka ms kc nu kd mu kf nv kg mw mx bi translated">正在初始化组件</h1><p id="bed1" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">我们将从初始化我们的检索器模型开始。许多最强大的检索器使用一个<em class="lv">句子转换器</em>架构，最好通过<code class="fe nd ne nf ng b">sentence-transformers</code>库支持，通过<code class="fe nd ne nf ng b">pip install sentence-transformers</code>安装。</p><p id="7627" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了找到句子转换模型，我们去<a class="ae ky" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank"><em class="lv">huggingface.co/models</em></a>并且为<em class="lv">官方</em>句子转换模型搜索<code class="fe nd ne nf ng b">sentence-transformers</code>。</p><p id="0698" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我们也可以使用其他模型，比如在1B培训对的<a class="ae ky" href="https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354" rel="noopener ugc nofollow" target="_blank">特别活动中训练的<code class="fe nd ne nf ng b"><a class="ae ky" href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" rel="noopener ugc nofollow" target="_blank">all-MiniLM-L6-v2</a></code>句子转换器。我们将使用这种模式。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="9ed4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有几个重要的细节:</p><ul class=""><li id="7453" class="nz oa it lb b lc ld lf lg li ob lm oc lq od lu oe of og oh bi translated"><code class="fe nd ne nf ng b">max_sequence_length=128</code>表示该型号最多可以读取<em class="lv"> 128个</em>输入令牌。</li><li id="50cb" class="nz oa it lb b lc oi lf oj li ok lm ol lq om lu oe of og oh bi translated"><code class="fe nd ne nf ng b">word_embedding_size=384</code>实际上是指<em class="lv">句的</em>嵌入大小。这意味着模型将输出输入文本的384维向量表示。</li></ul><p id="a55b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们数据集的简短的几个单词的GIF描述，最大序列长度<em class="lv"> 128 </em>比<em class="lv">足够多</em>。</p><p id="2908" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在初始化我们的向量数据库时，我们需要使用<em class="lv">语句</em>嵌入大小，所以我们将它存储在上面的<code class="fe nd ne nf ng b">embed_dim</code>变量中。</p><p id="8310" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了初始化我们的向量数据库，我们首先需要注册一个<a class="ae ky" href="https://app.pinecone.io/" rel="noopener ugc nofollow" target="_blank">免费的Pinecone API密匙</a>，并通过<code class="fe nd ne nf ng b">pip install pinecone-client</code>安装Pinecone Python客户端。准备就绪后，我们初始化:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="7d5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们指定一个索引名<code class="fe nd ne nf ng b">'gif-search'</code>；随意选择你喜欢的任何东西。它只是一个名字。<code class="fe nd ne nf ng b">metric</code>更重要，取决于所用的型号。</p><p id="91b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们选择的模型，我们可以在其<a class="ae ky" href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" rel="noopener ugc nofollow" target="_blank"> <em class="lv">模型卡</em> </a>中看到，它已经被训练使用<em class="lv">余弦相似度</em>，因此我们指定了<code class="fe nd ne nf ng b">metric='cosine'</code>。替代指标包括<code class="fe nd ne nf ng b">euclidean</code>和<code class="fe nd ne nf ng b">dotproduct</code>。</p><p id="42c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经初始化了向量数据库和检索器组件，所以我们可以继续嵌入和索引我们的数据。</p><h1 id="b609" class="mg mh it bd mi mj nr ml mm mn ns mp mq jz nt ka ms kc nu kd mu kf nv kg mw mx bi translated">索引</h1><p id="cfca" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">当我们对多个记录<em class="lv">并行执行这些步骤</em>时，嵌入和索引过程要快得多。然而，我们不能一次处理我们所有的记录，因为检索器模型必须将它嵌入的所有内容转移到片上存储器中，这是有限的。</p><p id="197d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了避免这种限制，同时尽可能快地保持索引时间，我们在<code class="fe nd ne nf ng b">64</code>的批次中处理所有内容。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="1947" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们从数据<code class="fe nd ne nf ng b">df</code>中提取<code class="fe nd ne nf ng b">batch</code>。我们通过我们的检索器模型对描述进行编码，创建元数据(涵盖<em class="lv">描述</em>和<em class="lv"> url </em>)，并创建一些字符串格式id。这样，我们就有了创建<em class="lv">文档</em>所需的一切，它看起来会像这样:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="d334" class="nl mh it ng b gy nm nn l no np">(<br/>   "some-id-value",<br/>   [0.1, 0.2, 0.1, 0.4 ...],<br/>   {<br/>       'description': "something descriptive",<br/>       'url': "https://xyz.com"<br/>   }<br/>)</span></pre><p id="6a63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们<code class="fe nd ne nf ng b">upsert</code>这些<em class="lv">文件</em>到松果索引的时候，我们是分批的<em class="lv"> 64 </em>做的。完成所有这些之后，我们使用<code class="fe nd ne nf ng b">index.describe_index_stats()</code>来检查我们是否已经插入了所有的<em class="lv"> 125，782 </em>文档。</p><h1 id="7936" class="mg mh it bd mi mj nr ml mm mn ns mp mq jz nt ka ms kc nu kd mu kf nv kg mw mx bi translated">询问</h1><p id="7710" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">查询数据的最后一步包括:</p><ol class=""><li id="b89b" class="nz oa it lb b lc ld lf lg li ob lm oc lq od lu on of og oh bi translated">对类似于<em class="lv">“电话中的狗说话”</em>的查询进行编码，以创建<em class="lv">查询向量</em>，</li><li id="2043" class="nz oa it lb b lc oi lf oj li ok lm ol lq om lu on of og oh bi translated">从松果中检索相似的<em class="lv">上下文向量</em>，</li><li id="26ae" class="nz oa it lb b lc oi lf oj li ok lm ol lq om lu on of og oh bi translated">从我们的元数据字段中找到的URL获取相关的gif。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/f93551b06f89bde0229f5a5ea2285a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*x4xh5-Rd_g73g0XFLDSF7Q.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">查询管道。</p></figure><p id="a029" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步骤<em class="lv">一</em>和<em class="lv">二</em>将由一个名为<code class="fe nd ne nf ng b">search_gif</code>的函数执行:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="b034" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了显示gif，我们使用指向正确gif的元数据URL来显示HTML <code class="fe nd ne nf ng b">&lt;img&gt;</code>元素。我们使用<code class="fe nd ne nf ng b">display_gif</code>函数来实现这一点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="0b64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们测试一些查询。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ly l"/></div></figure><p id="dd2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这看起来相当准确，所以我们设法很容易地把这个GIF搜索管道放在一起。通过<a class="ae ky" href="https://github.com/pinecone-io/examples/blob/master/learn/projects/gif-search/app.py" rel="noopener ugc nofollow" target="_blank">一点点额外的努力</a>，我们可以使用类似<a class="ae ky" href="https://www.youtube.com/watch?v=QpISF8gMsjQ" rel="noopener ugc nofollow" target="_blank"> <em class="lv"> Streamlit </em> </a>的东西将这些步骤转化为创建一个网络应用。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="1245" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经成功构建了一个GIF搜索工具，使用一个简单的语义搜索管道和现成的模型和松果。稍加调整，同样的管道可以应用于不同的领域。</p><p id="6977" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">向量搜索和语义搜索的易用性和潜力已经导致了这两种技术在大技术领域之外的大量研究和应用。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="3f8f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">资源</h1><p id="5593" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated"><a class="ae ky" href="https://github.com/pinecone-io/examples/tree/master/learn/projects/gif-search" rel="noopener ugc nofollow" target="_blank">文章笔记本和脚本</a></p><p id="172f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1] M. Osborne，<a class="ae ky" href="https://www.forbes.com/sites/forbesagencycouncil/2017/12/21/how-retail-brands-can-compete-and-win-using-amazons-tactics/" rel="noopener ugc nofollow" target="_blank">零售品牌如何利用亚马逊的策略竞争并获胜</a> (2017)，福布斯</p><p id="3e86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] L. Hardesty，<a class="ae ky" href="https://www.amazon.science/the-history-of-amazons-recommendation-algorithm" rel="noopener ugc nofollow" target="_blank">亚马逊推荐算法的历史</a> (2019)，亚马逊科学</p><p id="0a49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]李彦宏等.艾尔。，<a class="ae ky" href="https://arxiv.org/abs/1604.02748" rel="noopener ugc nofollow" target="_blank"> TGIF:动画GIF描述的新数据集和基准</a> (2016)，CVPR — <em class="lv">批准用于非商业研究目的</em></p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="33e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">*除另有说明外，所有图片均出自作者之手</em></p></div></div>    
</body>
</html>
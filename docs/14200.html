<html>
<head>
<title>Fixing YouTube Search with OpenAI’s Whisper</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用OpenAI的耳语修复YouTube搜索</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/fixing-youtube-search-with-openais-whisper-90bb569073cf?source=collection_archive---------6-----------------------#2022-11-16">https://betterprogramming.pub/fixing-youtube-search-with-openais-whisper-90bb569073cf?source=collection_archive---------6-----------------------#2022-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8ba2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用OpenAI的Whisper进行更好的语音搜索</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/393cfae819fd14eb44374379bc4e9fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQDxas7hib-lIG8u9jDuFQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">电气化搜索。这篇文章中的这张图片和所有其他图片都是作者的。</p></figure><p id="a6b0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">OpenAI的<em class="lu"> Whisper </em>是语音到文本转换中的一种新的最先进的(SotA)模型。它几乎可以完美地转录几十种语言的语音，甚至可以处理糟糕的音频质量或过度的背景噪音。</p><p id="d733" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">口语领域对于ML用例来说总是有些遥不可及。Whisper改变了以语音为中心的用例。我们将通过构建一个新的改进的YouTube搜索来展示Whisper以及其他技术(如变形金刚和矢量搜索)的威力。</p><p id="24fd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">YouTube上的搜索很好，但也有其局限性，尤其是在回答问题的时候。拥有数万亿小时的内容，几乎每个问题都应该有答案。</p><p id="03b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，如果我们有一个特定的问题，比如“<em class="lu">open ai的剪辑是什么？”</em>我们得到的不是一个简洁的答案，而是大量非常长的视频，我们必须从头到尾看完。</p><p id="0133" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们想要的只是一个20秒的简短解释呢？目前的YouTube搜索对此没有解决方案。也许有一个很好的理由来鼓励用户尽可能多地观看视频(更多广告，有人吗？).</p><p id="2daf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">耳语是这个问题<em class="lu">和其他许多涉及口语单词</em>的问题的解决方案。本文将探讨更好的支持语音的搜索背后的想法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="7ec0" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">这个想法</h1><p id="0ec4" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">我们希望获得特定的时间戳来回答我们的搜索查询。YouTube确实支持视频中的特定时间链接，因此使用这些链接进行更精确的搜索应该是可能的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/f4c06e5af7ea19a74cbc9192560d5672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OgGjwbnBcCgCtnJ9JAOnlA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">时间戳网址可以直接从视频中复制，我们可以在我们的搜索应用程序中使用相同的网址格式。</p></figure><p id="3047" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了构建这样的东西，我们首先需要将视频中的音频转录成文本。YouTube会自动为每个视频添加字幕，字幕没问题— <em class="lu">但是</em> OpenAI只是开源了一个叫“耳语”的东西。</p><p id="b862" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Whisper最恰当的描述是语音转文本的GPT-3或DALL-E 2。它是开源的，可以实时转录音频<em class="lu">或更快的</em>，具有<em class="lu">无与伦比的性能</em>。这似乎是最令人兴奋的选择。</p><p id="19ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦我们有了转录的文本和每个文本片段的时间戳，我们就可以进入<a class="ae nc" href="https://www.pinecone.io/learn/question-answering" rel="noopener ugc nofollow" target="_blank">问答(QA) </a>部分。问答是一种搜索形式，给定一个自然语言查询，如“<em class="lu">open ai的耳语是什么？”我们可以返回准确的自然语言答案。</em></p><p id="35f9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以认为问答是搜索信息的最直观的形式，因为这是我们向他人询问信息的方式。唯一的区别是我们在搜索栏中输入问题，而不是口头交流——就目前而言。</p><p id="fcbe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一切看起来怎么样？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/22f53687ca692e814d5ad6202c5c4acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bk2QzcM2eOzpk5i9_0NfVg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们演示中使用的流程概述。涵盖OpenAI的耳语，句子变形金刚，松果矢量数据库，等等。</p></figure><p id="16c7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们给细节上色，并逐步完成。</p><h1 id="ee66" class="me mf it bd mg mh ne mj mk ml nf mn mo jz ng ka mq kc nh kd ms kf ni kg mu mv bi translated">视频数据</h1><p id="9a77" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">第一步是下载我们的YouTube视频数据，并提取每个视频附带的音频。幸运的是，有一个名为<code class="fe nj nk nl nm b">pytube</code>的Python库可以满足这个需求。</p><p id="8ff1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过<code class="fe nj nk nl nm b">pytube</code>，我们提供了一个视频ID(可以在地址栏中找到，如果您有频道，也可以下载)。我直接下载了一个频道内容的概要，包括id，标题，出版日期等。，通过YouTube。同样的数据可以通过一个叫做<code class="fe nj nk nl nm b">jamescalam/channel-metadata</code>的数据集中的<em class="lu">数据集</em>得到。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="ac8f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们对<code class="fe nj nk nl nm b">Title</code>和<code class="fe nj nk nl nm b">Video ID</code>领域最感兴趣。有了视频ID，我们就可以开始下载视频并使用<code class="fe nj nk nl nm b">pytube</code>保存音频文件。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="f232" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在此之后，我们应该可以找到存储在<code class="fe nj nk nl nm b">./mp3</code>目录中的大约108个音频MP3文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/59575ba524bd29d3048435f543858e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-2aqodbpfBzP9R0M_yThw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">下载了<strong class="bd np">中的MP3文件<em class="nq">。/mp3 </em> </strong>目录。</p></figure><p id="9c17" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了这些，我们就可以继续用OpenAI的耳语进行转录了。</p><h1 id="f550" class="me mf it bd mg mh ne mj mk ml nf mn mo jz ng ka mq kc nh kd ms kf ni kg mu mv bi translated">带耳语的语音转文本</h1><p id="d615" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">OpenAI的Whisper语音转文本模型是完全开源的，可以通过GitHub从<code class="fe nj nk nl nm b">pip install</code>获得:</p><pre class="kj kk kl km gt nr nm ns nt aw nu bi"><span id="806f" class="nv mf it nm b gy nw nx l ny nz">pip install git+https://github.com/openai/whisper.git</span></pre><p id="eaca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Whisper依靠另一款名为FFMPEG的软件来转换视频和音频文件。此操作系统的安装因操作系统而异[1]；以下内容涵盖了主要系统:</p><pre class="kj kk kl km gt nr nm ns nt aw nu bi"><span id="07d8" class="nv mf it nm b gy nw nx l ny nz"># on Ubuntu or Debian<br/>sudo apt update &amp;&amp; sudo apt install ffmpeg</span><span id="5600" class="nv mf it nm b gy oa nx l ny nz"># on Arch Linux<br/>sudo pacman -S ffmpeg</span><span id="1644" class="nv mf it nm b gy oa nx l ny nz"># on MacOS using Homebrew (https://brew.sh/)<br/>brew install ffmpeg</span><span id="b9e7" class="nv mf it nm b gy oa nx l ny nz"># on Windows using Chocolatey (https://chocolatey.org/)<br/>choco install ffmpeg</span><span id="2a25" class="nv mf it nm b gy oa nx l ny nz"># on Windows using Scoop (https://scoop.sh/)<br/>scoop install ffmpeg</span></pre><p id="cbde" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">安装后，我们下载并初始化<em class="lu">大型</em>模型，如果CUDA可用的话，将它移动到GPU。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="ccf3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他型号都有，给个小一点的GPU(甚至CPU)都应该考虑。我们这样转录音频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="a11f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由此，我们有一个大约27K转录音频片段的列表，包括开始和结束秒旁边的文本。如果您需要等待很长时间来处理，可以使用数据集的预构建版本。下载说明在以下部分。</p><p id="1fb1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的最后一个单元格缺少从前面初始化的<code class="fe nj nk nl nm b">videos_dict</code>中提取和添加元数据所需的逻辑。我们这样补充:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="3ccb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">处理完所有数据段后，它们将作为JSON lines文件保存到文件中，其中包含:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="cd9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">准备就绪后，让我们构建QA嵌入和矢量搜索组件。</p><h1 id="36b5" class="me mf it bd mg mh ne mj mk ml nf mn mo jz ng ka mq kc nh kd ms kf ni kg mu mv bi translated">问题回答</h1><p id="357e" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">在拥抱脸<em class="lu">数据集</em>上，你可以找到我在一个名为<code class="fe nj nk nl nm b">jamescalam/youtube-transcriptions</code>的数据集中搜集的数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="836f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目前，数据集只包含来自我个人频道的视频，但我将在未来添加更多来自其他ML聚焦频道的视频。</p><p id="4af3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据包括一小段文本(转录的音频)。每个组块都相对没有意义:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="b815" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理想情况下，我们希望文本块比这个大4-6倍，以捕捉足够有用的意思。我们通过简单地迭代数据集并合并每<em class="lu">六个</em>段来实现这一点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="6b7a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里发生了一些事情。首先，如前所述，我们将每六个分段进行合并。然而，单独这样做可能会减少相关部分之间的许多意义。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/b96f338940ff48c3ce4e470a134c2694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tH1mv-oJ8Vqyf897LHTuWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">即使在合并片段的时候，我们仍然会留下一个必须分割文本的点(上面用红色叉号标注)。这会导致我们错过重要信息。</p></figure><p id="ed79" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">避免切割相关片段的一种常见技术是在片段之间添加一些<em class="lu">重叠</em>，这里使用了<code class="fe nj nk nl nm b">stride</code>。对于每一步，我们向前移动<em class="lu">三个</em>段，同时合并<em class="lu">六个</em>段。这样，在一个步骤中切割的任何有意义的段都将包含在下一个步骤中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/2dc6c584e95120e92390f13437d7ce20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkxpHKnTaBaLiurK3FJYXg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们可以通过在合并片段时添加重叠来避免这种意义的损失。它返回更多的数据，但意味着我们不太可能在有意义的片段之间切换。</p></figure><p id="dd22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样，我们就有了更大更有意义的文本。现在我们需要用一个QA嵌入模型对它们进行编码。许多高性能、预训练的QA模型可以通过拥抱脸<em class="lu">变形金刚</em>和<em class="lu">句子变形金刚</em>库获得。我们就用一个叫<code class="fe nj nk nl nm b"><a class="ae nc" href="https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1" rel="noopener ugc nofollow" target="_blank">multi-qa-mpnet-base-dot-v1</a></code>的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="3f0d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用这个模型，我们可以用<code class="fe nj nk nl nm b">model.encode("&lt;some text&gt;")</code>将一段文本编码成一个有意义的<em class="lu">768维向量。一次对我们所有的片段进行编码或者将它们存储在本地需要太多的计算或内存——所以我们首先初始化存储它们的向量数据库:</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="f90e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们应该看到索引(向量数据库)当前是空的，带有<code class="fe nj nk nl nm b">0</code>的<code class="fe nj nk nl nm b">total_vector_count</code>。现在我们可以开始对我们的片段进行编码，并将嵌入内容(和元数据)插入到我们的索引中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="5c5e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是我们准备数据和向vector数据库添加所有内容所需的一切。剩下的就是查询和返回结果。</p><h1 id="bbe1" class="me mf it bd mg mh ne mj mk ml nf mn mo jz ng ka mq kc nh kd ms kf ni kg mu mv bi translated">进行查询</h1><p id="26af" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">查询很简单；我们:</p><ol class=""><li id="727d" class="od oe it la b lb lc le lf lh of ll og lp oh lt oi oj ok ol bi translated">使用我们用来编码片段的相同嵌入模型来编码查询。</li><li id="b86c" class="od oe it la b lb om le on lh oo ll op lp oq lt oi oj ok ol bi translated">传递到我们的索引查询。</li></ol><p id="6fc8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们通过以下方式做到这一点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn lw l"/></div></figure><p id="9119" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些结果与问题相关；特别是，有三个来自同一视频中的相似位置。我们可能希望改进搜索界面，使其比Jupyter笔记本更友好。</p><p id="e5ec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让基于网络的搜索UI运行起来的最简单的方法之一就是使用拥抱脸<em class="lu">空间</em>和Streamlit(或者Gradio，如果喜欢的话)。</p><p id="3b6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们不会在这里讨论代码，但是如果你熟悉Streamlit，你可以在几个小时内非常容易地构建一个搜索应用。或者你可以使用我们的例子，在5-10分钟内完成。</p><p id="b89f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nc" href="https://huggingface.co/spaces/jamescalam/ask-youtube" rel="noopener ugc nofollow" target="_blank">你可以在这里</a>测试应用。当再次查询<code class="fe nj nk nl nm b">"what is OpenAI's clip?"</code>时，我们将从单个视频中返回多个合并的结果。有了这个，我们可以通过点击我们最感兴趣的文本部分跳到每个片段。</p><p id="2b4e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尝试更多的查询，如:</p><pre class="kj kk kl km gt nr nm ns nt aw nu bi"><span id="fd6a" class="nv mf it nm b gy nw nx l ny nz">What is the best unsupervised method to train a sentence transformer?</span><span id="6409" class="nv mf it nm b gy oa nx l ny nz">What is vector search?</span><span id="65e5" class="nv mf it nm b gy oa nx l ny nz">How can I train a sentence transformer with little-to-no data?</span></pre></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="244f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以使用耳语、拥抱脸、句子变形金刚和<a class="ae nc" href="https://www.pinecone.io/learn/vector-database" rel="noopener ugc nofollow" target="_blank">松果的矢量数据库</a>快速构建令人难以置信的支持语音的搜索应用。</p><p id="02f8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Whisper已经解锁了一个完整的模式——口语——我们看到语音搜索和其他以语音为中心的用例显著增加只是时间问题。</p><p id="65ec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">近年来，机器学习和向量搜索都出现了指数级增长。这些技术已经看起来像科幻小说了。然而，尽管我们在这里使用的一切都有令人难以置信的性能，但这一切变得更好只是时间问题。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="af49" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nc" href="https://www.pinecone.io/learn/openai-whisper/" rel="noopener ugc nofollow" target="_blank"> <em class="lu">本文原载Pinecone.io </em> </a></p><h1 id="be30" class="me mf it bd mg mh ne mj mk ml nf mn mo jz ng ka mq kc nh kd ms kf ni kg mu mv bi translated">资源</h1><p id="1797" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated"><a class="ae nc" href="https://github.com/jamescalam/ask-youtube/tree/main/youtube-search" rel="noopener ugc nofollow" target="_blank">所有代码笔记本</a></p><ul class=""><li id="a216" class="od oe it la b lb lc le lf lh of ll og lp oh lt or oj ok ol bi translated"><a class="ae nc" href="https://colab.research.google.com/github/jamescalam/ask-youtube/blob/main/youtube-search/00-download-videos.ipynb" rel="noopener ugc nofollow" target="_blank"> MP3下载</a></li><li id="a3f4" class="od oe it la b lb om le on lh oo ll op lp oq lt or oj ok ol bi translated"><a class="ae nc" href="https://colab.research.google.com/github/jamescalam/ask-youtube/blob/main/youtube-search/01-openai-whisper.ipynb" rel="noopener ugc nofollow" target="_blank">耳语转录</a></li><li id="638d" class="od oe it la b lb om le on lh oo ll op lp oq lt or oj ok ol bi translated"><a class="ae nc" href="https://colab.research.google.com/github/jamescalam/ask-youtube/blob/main/youtube-search/02-build-embeddings.ipynb" rel="noopener ugc nofollow" target="_blank">编码和查询</a></li></ul><p id="a4a5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nc" href="https://huggingface.co/spaces/jamescalam/ask-youtube" rel="noopener ugc nofollow" target="_blank">演示App </a></p><p id="f611" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[1] <a class="ae nc" href="https://github.com/openai/whisper" rel="noopener ugc nofollow" target="_blank"> OpenAI耳语回购</a> (2022)，GitHub</p></div></div>    
</body>
</html>
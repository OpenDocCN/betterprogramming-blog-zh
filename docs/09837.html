<html>
<head>
<title>How To Prepare Text Data for Natural Language Processing (NLP)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何为自然语言处理(NLP)准备文本数据</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-prepare-text-data-for-natural-language-processing-nlp-97dadce77661?source=collection_archive---------8-----------------------#2021-10-19">https://betterprogramming.pub/how-to-prepare-text-data-for-natural-language-processing-nlp-97dadce77661?source=collection_archive---------8-----------------------#2021-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="886a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">句子分割、标记化、停用词移除、词干化和词条化介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/42d34b70b17c323716aa460db6666624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZ4wxuZrgbFQqWUIidNbIg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1170657" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/wild0ne-920941/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1170657" rel="noopener ugc nofollow" target="_blank"> M. Maggs </a>拍摄</p></figure><p id="a0d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于上下文，想象一下聊天机器人或自动文本摘要器的实现。</p><p id="010f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该算法必须找到单词和句子之间的相关性，并从数据中提取知识——这对计算机来说是一项复杂而耗时的任务。</p><p id="5a52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为这是一个复杂的操作，所以程序不能花时间处理那些对理解语义没有太大价值的部分。像“the”、“in”和“an”这样的停用词最好去掉，标点符号和数字也一样。</p><p id="0834" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本还必须以计算机能够最好地工作的方式进行分段和格式化。</p><p id="f021" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将解释在自然语言处理(NLP)的第一步和关键步骤<strong class="lb iu">【预处理】</strong>中应用于书面内容的五个过程。我只考虑英语或类似的语言。</p><h1 id="165c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">句子分割</h1><p id="338f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">它是关于识别一篇文章的每一句话。</p><p id="dd1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了分割英语中的单词，我们可以使用它们之间的空间。例如:“有四个空格的文本”=五个单词。</p><p id="96e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ms">句子呢？</em></p><p id="f627" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它从哪里开始或结束？句号是在句尾吗？如果句子中包含一个数字，比如3.0，怎么办？查看下面的文本，从这个<a class="ae ky" href="https://link.springer.com/content/pdf/10.1007%2F978-0-387-39940-9_421.pdf" rel="noopener ugc nofollow" target="_blank">文档</a>中检索(文本分段部分)。</p><blockquote class="mt mu mv"><p id="98a8" class="kz la ms lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">Clairson International Corp .表示，预计截至3月26日的第二季度将出现净亏损，预计截至9月24日的财年将达不到分析师预计的300万至400万美元的利润，或每股1，276美分至1，279美分。(摘自《华尔街日报》(1988年))</p></blockquote><p id="6e81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您必须解决不明确的句点、逗号和分号。</p><p id="b125" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，Python中有一个库可以为我们做这件事——spaCy。spaCy支持多种语言的标记化。这就是我在这篇文章中用来演示句子分段代码的库，但是也有其他的库。</p><p id="7e49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是使用spaCy 的<a class="ae ky" href="https://www.geeksforgeeks.org/python-perform-sentence-segmentation-using-spacy/" rel="noopener ugc nofollow" target="_blank"> Python代码。要运行，您必须首先安装spaCy和核心英语库。该命令如下所示:</a></p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="a8d8" class="ne lw it na b gy nf ng l nh ni">pip install spacy<br/>python -m spacy download en_core_web_sm</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">句子切分代码。来源:<a class="ae ky" href="https://www.geeksforgeeks.org/python-perform-sentence-segmentation-using-spacy/" rel="noopener ugc nofollow" target="_blank"> Geeksforgeeks </a>。</p></figure><p id="44f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果就是两句话。该算法识别出“Corp .”或“Sept .”中的点是缩写，而不是句子的结尾。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="4ccd" class="ne lw it na b gy nf ng l nh ni">(base) Viniciuss-MacBook-Pro:ML viniciusmonteiro$ python3 sent_seg.py</span><span id="d43e" class="ne lw it na b gy nl ng l nh ni">Clairson International Corp. said it expects to report a net loss for its second quarter ended March 26 and doesn't expect to meet analysts' profit estimates of $3.0 to $4 million, or 1,276 cents a share to 1,279 cents a share, for its year ending Sept. 24.</span><span id="9859" class="ne lw it na b gy nl ng l nh ni">(From the Wall Street Journal (1988))</span></pre><h1 id="2227" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">标记化</h1><p id="23b6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">标记化将文本分成多个部分，也称为“标记”有多种方法和库可以实现这一点，我将在这里展示其中的两种。</p><p id="b2f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解更多细节，你可以看看这篇很棒的文章，<a class="nm nn ep" href="https://medium.com/u/fb44e21903f3?source=post_page-----97dadce77661--------------------------------" rel="noopener" target="_blank"> Frank Andrade </a>写的《<a class="ae ky" href="https://towardsdatascience.com/5-simple-ways-to-tokenize-text-in-python-92c6804edfc4" rel="noopener" target="_blank">用Python </a>标记文本的5种简单方法》。</p><h2 id="6731" class="ne lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated"><strong class="ak">空间</strong></h2><p id="925a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我将使用非小说类书籍<a class="ae ky" href="https://amzn.to/3h5BRHn" rel="noopener ugc nofollow" target="_blank"> Livewired:不断变化的大脑的内幕</a>中的一段文字。</p><blockquote class="mt mu mv"><p id="019d" class="kz la ms lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">想象一下:</em>我们不是向火星发射一辆四百磅重的探测车，而是仅仅向火星发射一个球体，一个可以放在大头针末端的球体。利用周围来源的能量，这个球体将自己分裂成一个由相似球体组成的多样化军队。这些球体彼此相连，并衍生出各种功能:轮子、透镜、温度传感器和一个完整的内部导航系统。看到这样一个系统自动放电，你会大吃一惊。</p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用空间的标记化。来源:<a class="ae ky" href="https://towardsdatascience.com/5-simple-ways-to-tokenize-text-in-python-92c6804edfc4" rel="noopener" target="_blank">Python中标记文本的5种简单方法</a></p></figure><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="866c" class="ne lw it na b gy nf ng l nh ni">['Imagine', 'this', ':', 'instead', 'of', 'sending', 'a', 'four', '-', 'hundred', '-', 'pound', 'rover', 'vehicle', 'to', 'Mars', ',', '\n', 'we', 'merely', 'shoot', 'over', 'to', 'the', 'planet', 'a', 'single', 'sphere', ',', 'one', 'that', 'can', 'fit', 'on', 'the', 'end', 'of', 'a', 'pin', '.', '\n', 'Using', 'energy', 'from', 'sources', 'around', 'it', ',', 'the', 'sphere', 'divides', 'itself', 'into', 'a', 'diversified', 'army', 'of', '\n', 'similar', 'spheres', '.', 'The', 'spheres', 'hang', 'on', 'to', 'each', 'other', 'and', 'sprout', 'features', ':', 'wheels', ',', 'lenses', ',', '\n', 'temperature', 'sensors', ',', 'and', 'a', 'full', 'internal', 'guidance', 'system', '.', 'You', "'d", 'be', 'gobsmacked', 'to', 'watch', '\n', 'such', 'a', 'system', 'discharge', 'itself', '.']</span></pre><h2 id="3c31" class="ne lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated"><strong class="ak"> sklearn和计数矢量器</strong></h2><p id="7cd8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，我将向您展示一种方法，将每个部分标记并转换为数字。数字代表文本中的每个单词计数——这很有用，例如，如果您想要使用<a class="ae ky" href="https://towardsdatascience.com/cosine-similarity-intuition-with-implementation-in-python-51eade2674f6" rel="noopener" target="_blank">余弦相似度</a>来比较两个文本。</p><p id="301e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，来自panda的数据帧存储文本，来自sklearn的CountVectorizer转换它们。我附上了同一本书的另一篇文章，这样你就可以看到它们之间的比较。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用CountVectorizer进行标记化源代码:<a class="ae ky" href="https://towardsdatascience.com/5-simple-ways-to-tokenize-text-in-python-92c6804edfc4" rel="noopener" target="_blank">Python中标记化文本的5种简单方法</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/c2a2bd057e98b586cec3b68b4cbd83ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8clwFb-PJq6lvxC5_7RXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。包含两个文本中每个单词的计数的矩阵。按作者。</p></figure><h1 id="9bf0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">停止单词删除</h1><p id="beb6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">正如我在本文开头提到的，计算机理解文本需要大量的处理能力。你必须减少文本，只包含必要的信息。</p><p id="24a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是停用词删除的目的。Python中的自然语言工具包(NLTK)可以帮助我们。它有一个16种不同语言的停用词列表。</p><p id="b953" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">明确地说，我所说的停用词是指“the”、“in”、“an”等。让我们看看代码和结果。下面的代码还展示了如何使用NLTK进行标记化。</p><p id="b38d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要安装NLKT，请访问https://www.nltk.org/install.html的<a class="ae ky" href="https://www.nltk.org/install.html" rel="noopener ugc nofollow" target="_blank"/>。最后，要运行下面的代码，请运行以下命令:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="8e25" class="ne lw it na b gy nf ng l nh ni">python -m nltk.downloader stopwords<br/>python -m nltk.downloader punkt</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用NLTK停止单词删除。来源:<a class="ae ky" href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/removing-stop-words-nltk-python/</a></p></figure><p id="a1df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="6067" class="ne lw it na b gy nf ng l nh ni">['Clairson', 'International', 'Corp.', 'said', 'expects', 'report', 'net', 'loss', 'second', 'quarter', 'ended', 'March', '26', "n't", 'expect', 'meet', 'analysts', "'", 'profit', 'estimates', '$', '3.0', '$', '4', 'million', ',', '1,276', 'cents', 'share', '1,279', 'cents', 'share', ',', 'year', 'ending', 'Sept.', '24', '.']</span></pre><p id="1bf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你与原文比较，你可以看到“或”、“一”、“到”等。，已被删除。</p><h1 id="ac0a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">词干化和词汇化</h1><p id="daa8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">词干化和词汇化有着相同的目标——将单词转换成它的基本形式。基础或头部形式也被称为引理。</p><p id="17a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，“saw”和“seen”来源于基本词“see”同样适用于“玩过”和“正在玩”。两个<em class="ms">都源于“玩”这个词。词干提取任务试图通过删除单词的最后几个字符来找到基本单词。对于“已播放”和“正在播放”，它工作正常。但是《电锯惊魂》就不一样了。词干提取任务将“saw”变成“s”</em></p><p id="3781" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在大多数情况下，术语化效果更好，但这是一个较慢的过程。</p><p id="a7fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它在一个单独的预定义列表中搜索词根。单独的列表包含“saw”的基本单词是“see”的信息算法只需要在里面查一下。</p><p id="b392" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个使用NLTK的词干化和词汇化的实现。</p><p id="5800" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择在动词(pos="v ")的上下文中进行词汇化对于单词“编码”来说并不合适。在这种情况下，词干处理更有效。也可以选择在名词(pos="n ")的上下文中进行lemmatize，然后保持“编码”不变。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用NLTK的词干分析和词汇化任务。</p></figure><p id="cbd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">词干化任务后的结果:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="13ce" class="ne lw it na b gy nf ng l nh ni"><strong class="na iu">Word                After stemming</strong></span><span id="62fa" class="ne lw it na b gy nl ng l nh ni">She                 she</span><span id="018f" class="ne lw it na b gy nl ng l nh ni">was                 wa</span><span id="fca7" class="ne lw it na b gy nl ng l nh ni">running             run</span><span id="11e5" class="ne lw it na b gy nl ng l nh ni">and                 and</span><span id="7c60" class="ne lw it na b gy nl ng l nh ni"><strong class="na iu">coding              code</strong></span><span id="3c8b" class="ne lw it na b gy nl ng l nh ni">at                  at</span><span id="5e31" class="ne lw it na b gy nl ng l nh ni">the                 the</span><span id="5b61" class="ne lw it na b gy nl ng l nh ni">same                same</span><span id="8585" class="ne lw it na b gy nl ng l nh ni">and                 and</span><span id="a486" class="ne lw it na b gy nl ng l nh ni">I                   i</span><span id="e84b" class="ne lw it na b gy nl ng l nh ni">thought             thought</span><span id="baa5" class="ne lw it na b gy nl ng l nh ni">this                thi</span><span id="d323" class="ne lw it na b gy nl ng l nh ni">was                 wa</span><span id="1071" class="ne lw it na b gy nl ng l nh ni">one                 one</span><span id="2ce8" class="ne lw it na b gy nl ng l nh ni">of                  of</span><span id="c596" class="ne lw it na b gy nl ng l nh ni">the                 the</span><span id="6248" class="ne lw it na b gy nl ng l nh ni">crazy               crazi</span><span id="b105" class="ne lw it na b gy nl ng l nh ni">things              thing</span><span id="08ff" class="ne lw it na b gy nl ng l nh ni">I                   i</span><span id="e6b9" class="ne lw it na b gy nl ng l nh ni">'ve                 've</span><span id="14d6" class="ne lw it na b gy nl ng l nh ni">ever                ever</span><span id="55a0" class="ne lw it na b gy nl ng l nh ni">seen                seen</span></pre><p id="ca3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">词汇化后:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="5291" class="ne lw it na b gy nf ng l nh ni"><strong class="na iu">Word                Lemma</strong></span><span id="4262" class="ne lw it na b gy nl ng l nh ni">She                 She</span><span id="01c4" class="ne lw it na b gy nl ng l nh ni">was                 be</span><span id="8a95" class="ne lw it na b gy nl ng l nh ni">running             run</span><span id="f01c" class="ne lw it na b gy nl ng l nh ni">and                 and</span><span id="2403" class="ne lw it na b gy nl ng l nh ni"><strong class="na iu">coding              cod</strong></span><span id="6bb7" class="ne lw it na b gy nl ng l nh ni">at                  at</span><span id="ab99" class="ne lw it na b gy nl ng l nh ni">the                 the</span><span id="73b0" class="ne lw it na b gy nl ng l nh ni">same                same</span><span id="2158" class="ne lw it na b gy nl ng l nh ni">and                 and</span><span id="d0ce" class="ne lw it na b gy nl ng l nh ni">I                   I</span><span id="cce0" class="ne lw it na b gy nl ng l nh ni">thought             think</span><span id="afa6" class="ne lw it na b gy nl ng l nh ni">this                this</span><span id="3bf4" class="ne lw it na b gy nl ng l nh ni">was                 be</span><span id="cbaa" class="ne lw it na b gy nl ng l nh ni">one                 one</span><span id="e41c" class="ne lw it na b gy nl ng l nh ni">of                  of</span><span id="1b77" class="ne lw it na b gy nl ng l nh ni">the                 the</span><span id="52c1" class="ne lw it na b gy nl ng l nh ni">crazy               crazy</span><span id="ec78" class="ne lw it na b gy nl ng l nh ni">things              things</span><span id="2593" class="ne lw it na b gy nl ng l nh ni">I                   I</span><span id="b783" class="ne lw it na b gy nl ng l nh ni">'ve                 've</span><span id="4737" class="ne lw it na b gy nl ng l nh ni">ever                ever</span><span id="0e2c" class="ne lw it na b gy nl ng l nh ni">seen                see</span></pre><h1 id="e484" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="a24a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这些不是在预处理阶段应用于文本的唯一任务。其他一些是网址，标点符号和数字删除，以及所有字符转换为一个共同的大小写(大写或小写)。</p><p id="f528" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括一下:目标是通过分析文本中无助于提取有用信息的部分来避免浪费存储和处理能力。此外，单词和句子的格式化和分离是必不可少的，以便算法可以理解它们之间的相关性。</p><p id="f07e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读。</p></div></div>    
</body>
</html>
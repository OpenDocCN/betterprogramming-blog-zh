<html>
<head>
<title>Accelerating CPU and GPU Heterogeneous PyTorch Workloads</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">加速CPU和GPU异构PyTorch工作负载</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/accelerating-cpu-gpu-heterogenous-pytorch-workloads-dfc0744f2c6e?source=collection_archive---------4-----------------------#2022-10-30">https://betterprogramming.pub/accelerating-cpu-gpu-heterogenous-pytorch-workloads-dfc0744f2c6e?source=collection_archive---------4-----------------------#2022-10-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ceda" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">…通过流水线处理CPU和GPU的工作</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/d89b90c05ab102b98276fd11b1068bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mOvdl0PyOuCEkzDF"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">照片由<a class="ae kw" href="https://unsplash.com/@lime517?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">约瑟夫·格雷夫</a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="9488" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">深度学习管道涉及在神经阶段产生的结果上运行的CPU操作并不罕见，通常在GPU上运行。无论是度量计算或其他自定义操作尚未移植到GPU，甚至不适合GPU。这种异构性给高效运行此类工作负载带来了额外的挑战。</p><p id="897a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这样的工作负载可能是在给定图像中寻找具有最大单个实例的语义类别，其中单个实例被定义为2D连通分量。该方法包括两个步骤:在GPU上运行语义分割网络，随后在CPU上通过其连接的组件对输出进行聚类。出于演示的目的，我们将假设集群部分还没有移植到GPU，我们将使用<a class="ae kw" href="https://scikit-image.org/" rel="noopener ugc nofollow" target="_blank"> skimage </a>。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/c9afa3a676fbe92b00cae2fc5f2626c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*uYMQsIZ_daf5pvrPeqPMlg.jpeg"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者更改了图像</p></figure><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/11c40c6f89a24e298346c5f63f12be51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*sZ6jX4UulDt2ymosNV9KdA.jpeg"/></div></figure><p id="ed01" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">以上是取自<a class="ae kw" href="https://cocodataset.org/" rel="noopener ugc nofollow" target="_blank"> COCO 2017 </a>数据集的一些图像示例，这些图像叠加了相应的语义分割遮罩。顶部图像中唯一检测到的对象类别是飞机，因此这是具有最大单个实例的类别。最下面一个，人比狗大，所以<code class="fe lu lv lw lx b">person</code>是单个实例最大的类别。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/0b2875688bee61ada5ea5f2de77625ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*yQqSWivy2fcSOFc4OKv7ig.jpeg"/></div></figure><p id="8109" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这个比较棘手。虽然人很多，但没有一个人比摩托车大。</p><p id="91bb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在，让我们看看如何使用PyTorch和skimage解决这个问题。</p><p id="39d8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们首先实例化一个预训练的DeepLabV3模型，以及它相应的转换:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ly lz l"/></div></figure><p id="83d9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">并定义一个函数来寻找给定类别图中最大连通分量的类别，其中每个单元对应于由模型为相应图像像素预测的类别id:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ly lz l"/></div></figure><p id="262e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们分两步处理图像:首先，我们通过DeepLabV3传递图像，并将结果调整为原始大小。我将这个步骤称为GPU步骤，因为模型是在GPU上运行的。之后，我们将类别图复制到CPU，并检测。同样，我将把这个步骤称为CPU步骤:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ly lz l"/></div></figure><p id="ecb0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最后，我们使用<a class="ae kw" href="https://pytorch.org/ignite/index.html" rel="noopener ugc nofollow" target="_blank"> Ignite </a>对整个数据集运行我们的逻辑:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ly lz l"/></div></figure><p id="7d32" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这种方法行得通。然而，我的测试环境导致GPU利用率徘徊在80%左右，因此有很大一部分计算机能力没有得到利用。使用Nsight分析脚本揭示了问题所在:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ma"><img src="../Images/4e843b28f7da7215edc67a1e54e41a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*trTvWhd2NOUPmvVeDq6uqg.png"/></div></div></figure><p id="4957" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当Ignite为数据集中的每个项目按顺序运行GPU和CPU步骤时，GPU处于空闲状态，而CPU正在处理GPU输出，蓝色条中表示GPU利用率的规则中断就是证明。我们可以通过使用多个CUDA流和Python线程来解决这个问题，以便GPU可以在完成当前批处理后立即开始处理下一批，同时CPU在其上运行连接组件集群。</p><p id="72b0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为此，我们放弃Ignite引擎，开始使用自定义引擎，这可以在我在底部链接的源代码中找到:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ly lz l"/></div></figure><p id="9c69" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">其余的代码保持不变。让我们看看分析器时间轴是如何变化的。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi mb"><img src="../Images/376b41a451083ed0f78b61628a47d201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RABx4Ak6ZvmEn8AN9yZpqA.png"/></div></div></figure><p id="9a0d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">那看起来好多了。GPU现在被完全利用，如连续的蓝色条所示。注意这个脚本是如何使用多个Python线程的。</p><p id="9bfa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">总体而言，在采用NVIDIA GeForce RTX 2080 Ti的系统上，这一变化在不改变输出的情况下将吞吐量提高了45%。一个缺点是GPU内存使用量增加。在我的设置中，它从2.4 GB增加到4.2 GB，所以如果你的GPU内存已经很低，这个技巧可能不可用。</p><p id="7ee3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">你可以在这里找到完整的源代码。</p></div></div>    
</body>
</html>
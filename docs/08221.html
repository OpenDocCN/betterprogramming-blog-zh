<html>
<head>
<title>4 Keras Callbacks That Will Change the Way You Train ML Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">4个Keras回调将改变你训练ML模型的方式</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/4-keras-callbacks-that-will-change-the-way-you-train-ml-models-a0df2592d36b?source=collection_archive---------7-----------------------#2021-04-07">https://betterprogramming.pub/4-keras-callbacks-that-will-change-the-way-you-train-ml-models-a0df2592d36b?source=collection_archive---------7-----------------------#2021-04-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f0eb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">添加模型检查点、CSV记录器等等</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/39f5c724510df0aa9e16347720ad7d26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dkBjNLLsHMBY65CG"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@charles_forerunner?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">查尔斯先行者</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="d56a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当编写机器学习代码时，通常每个应用程序都会出现相同的模式，尤其是当每个人都学习相同的课程，并且您不能随意使用什么库时。这就是为什么这些库包含许多我们可能不知道的功能和选项，但却解决了传统问题。</p><p id="39d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Keras回调是在你的纪元的不同阶段执行函数的类——记录数据、绘制数据或保存你的模型。这些回调非常有用，允许您编写更少的代码，并提高代码的效率。</p><p id="2050" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开始吧。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="00ad" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">提前停止</h1><p id="7f24" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">理想情况下，我们的模型不会过度拟合，不管我们为它训练了多少个时期。但通常情况并非如此。很多时候，我们没有应用正确的正则化，或者模型对于我们的应用来说太深。显然，我们应该首先尝试解决这些问题，但很高兴知道，如果我们失败了，我们有一个故障保险。这就是提前停止。</p><p id="ca3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">提前停止有两个参数:</p><ul class=""><li id="82aa" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">耐心</li><li id="f30f" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">测试损失/准确性</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/3ed560f622b40b44d2fe372264e3e0fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N7H9XGPkr0IVMwlX"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5cee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当测试损失或测试准确度在几个步骤(时期)内没有改善时，它停止训练。这背后的原因是，如果测试集的准确性恶化，这意味着模型不够一般化，因此过度拟合训练数据。</p><p id="6726" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">提前停止是我工具箱中的必备工具，您可以简单地用一行代码实现它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="91df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，您只需将它与其他回调函数一起添加到您的<code class="fe nn no np nq b">fit</code>函数中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="9a94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在文档中查看其他参数:<code class="fe nn no np nq b"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="noopener ugc nofollow" target="_blank">EarlyStopping</a></code>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="36f2" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">模型检查点</h1><p id="a666" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这是我的最爱之一。</p><p id="96d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你有没有开始训练一个模型只是为了让你的Jupyter内核死掉？或者您可能不小心停止了脚本，因此培训也停止了？</p><p id="62fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">嗯，这次回调就解决这个了！</p><p id="313a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每当你的模型精度提高时，它会将模型保存到你指定的路径。例如:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="0494" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这段代码将在<code class="fe nn no np nq b">val_loss</code>低于之前的<code class="fe nn no np nq b">val_loss</code>(在纪元结束时)时保存您的模型。</p><p id="9b0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设你没有使用<code class="fe nn no np nq b">EarlyStopping</code>和<code class="fe nn no np nq b">ModelCheckpoint</code>。也许你让脚本运行了几个小时，然后你得到了这个:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/b00d541f35e513cf6edb1664f0efe338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J5NzpKKCvi_9gpXS.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://commons.wikimedia.org/wiki/File:Overfitting.png" rel="noopener ugc nofollow" target="_blank">维基共享资源</a>提供</p></figure><p id="09cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你想打爆你的头。过了这么久，模型明显过拟合，我也没有保存什么好的版本。</p><p id="4bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是对于<code class="fe nn no np nq b">ModelCheckpoint</code>回调来说，这已经不是问题了。</p><p id="1575" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看文档:<code class="fe nn no np nq b"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint" rel="noopener ugc nofollow" target="_blank">ModelCheckpoint</a></code>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d8a0" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">CSVLogger</h1><p id="ea79" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">假设你正在训练一个深度学习模型。假设你在Jupyter笔记本上训练它。假设你这样做:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="a135" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">突然你的内核死了。</p><p id="2fb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，你已经配置了<code class="fe nn no np nq b">ModelCheckpoint</code>，所以你没有丢失训练好的模型。但是您想对存储在<code class="fe nn no np nq b">history</code>变量中的训练历史进行很好的绘图。</p><p id="3baa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是内核已经死了，那个变量也就没了。</p><p id="2680" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是回调变得有用的地方。<code class="fe nn no np nq b">CSVLogger</code>自动记录训练分数。它将它们很好地存储在一个CSV文件中。因此，如果您关闭了您的内核，您已经很好地保存了它，并准备好进行漂亮的绘制。</p><p id="d04a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实现非常简单:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="8ecc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您只需要提供想要保存数据的文件的路径。</p><p id="b30b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更多阅读文档:<code class="fe nn no np nq b"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CSVLogger" rel="noopener ugc nofollow" target="_blank">CSVLogger</a></code>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="5f8a" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">降低高原学习率</h1><p id="b885" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">当指标停止改善时，这种回调会降低学习率。这是避免停滞和动态改变训练参数的有益实践。</p><p id="0683" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主要的优点是它允许你在开始时有一个较大的学习速率，然后动态地降低它。这减少了训练的时间和准确性，因为在开始时使用较高的学习率会更快，当没有改善时减少学习率会使你更接近最小值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/ce2ecfe1c859f92488e69890cfdb7872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dZWjlpA7ikZF4wf7"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="27f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要使用它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="8e66" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以调整的最重要的参数是:</p><ul class=""><li id="8468" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><code class="fe nn no np nq b">monitor</code>:这是我们想要跟踪的指标</li><li id="be6e" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><code class="fe nn no np nq b">patience</code>:没有改善的时期数，在此之后学习率将降低</li><li id="25e6" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><code class="fe nn no np nq b">factor</code>:学习率降低的系数。<code class="fe nn no np nq b">new_lr</code> = <code class="fe nn no np nq b">lr</code> * <code class="fe nn no np nq b">factor</code>。</li><li id="4d4d" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><code class="fe nn no np nq b">min_delta</code>:测量新最佳值的阈值，仅关注重大变化</li><li id="0bd9" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><code class="fe nn no np nq b">min_lr</code>:学习率的下限</li></ul><p id="9f93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在<code class="fe nn no np nq b"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau" rel="noopener ugc nofollow" target="_blank">ReduceLROnPlateau</a></code>查看更多详情。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="c0c6" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">参考</h1><p id="e98f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">[1] <a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback" rel="noopener ugc nofollow" target="_blank">张量流文档</a></p></div></div>    
</body>
</html>
<html>
<head>
<title>Synthetic Data Generation for Computer Vision in Blender</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">搅拌机中计算机视觉的合成数据生成</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/synthetic-data-generation-for-computer-vision-in-blender-part-1-6926819b11e6?source=collection_archive---------0-----------------------#2022-08-09">https://betterprogramming.pub/synthetic-data-generation-for-computer-vision-in-blender-part-1-6926819b11e6?source=collection_archive---------0-----------------------#2022-08-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d7ce" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">(第一部分)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d704584c63f885422914f1f8b9385849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AXdCIkysmmf3-0jRYvQovA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自thiscatdoesnotexist.com、paralleldomain.com和微软的synth数据“伪造它直到你成功”</p></figure><p id="0424" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">内容:</strong>这篇文章介绍了合成数据生成，以及如何通过Blender使用它来训练高性能和健壮的视觉模型。我们将提供Blender设置的概述，并且出于演示的目的，呈现来自时尚领域的具体视觉分类场景。</p><p id="2583" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">为什么:</strong>利用Blender的程序能力，采用以数据为中心的方法，在很少或不需要人工注释的情况下获得更好的机器学习模型。</p><p id="5553" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">谁:</strong>我们就靠<a class="ae lu" href="https://www.blender.org/download/" rel="noopener ugc nofollow" target="_blank"> Blender &gt; 3.1 </a>和Python ≥ 3.7。然后，生成的图像可以用于任何下游任务，而不管可能的依赖框架(例如Tensorflow、PyTorch)。</p><h1 id="d472" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">合成数据生成</h1><p id="74e7" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">合成数据生成(SDG)包括各种旨在以编程方式生成数据以支持下游任务的方法。在统计学和机器学习(ML)中，最终目标是合成具有相同目标域分布的样本，用于模型训练或测试目的。这是<a class="ae lu" href="https://datacentricai.org/" rel="noopener ugc nofollow" target="_blank">以数据为中心的ML方法</a>的一部分，其中为了实现更好的性能，我们积极地处理数据，而不是模型、算法或架构。</p><p id="6b54" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">采用SDG有多种原因，主要是:</p><ul class=""><li id="7c98" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">最大限度地减少对人工标签和治疗的需求</li><li id="62d9" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">促进和/或达到更高容量型号的数据要求</li><li id="805d" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">解决一般性、健壮性、可移植性、偏见等问题</li><li id="f9e8" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">克服真实数据使用限制(隐私和法规)</li></ul><p id="9872" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在计算机视觉(CV)中，我们感兴趣的是<strong class="la iu">合成真实的视觉样本</strong>(最常见的媒体，如图像和视频)。合成该领域数据的两种主要方法是<a class="ae lu" href="https://www.deeplearningweekly.com/p/deep-learning-weekly-generative-modeling" rel="noopener ugc nofollow" target="_blank">生成模型</a>和计算机图形(CG)管道。存在混合方法，其基于目标设置在不同的度量中组合多种方法。</p><p id="69b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，想象一下<a class="ae lu" href="https://thiscatdoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">生成不存在的猫的图像</a>来训练猫狗分类器，或者从游戏和<a class="ae lu" href="https://paralleldomain.com/" rel="noopener ugc nofollow" target="_blank">模拟环境中获取图像来引导自动驾驶系统的训练</a>，或者r <a class="ae lu" href="https://microsoft.github.io/FaceSynthetics/" rel="noopener ugc nofollow" target="_blank">为地标定位提供无限种类的CG人脸</a>。</p><p id="213f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将重点关注CG方法，它依赖于传统的软件和工具来操作3D内容(建模)，应用材料(纹理)，以及合成2D图像(渲染)。让那里有搅拌机。</p><h1 id="22b2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">SDG搅拌机</h1><p id="059d" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">Blender 是一个免费的开源3D CG软件工具集。在过去的几年里，它经历了非凡的改进，特别是2.8版本的改进:重新设计的用户界面和工作空间，实时Eevee渲染器，优化的循环(路径跟踪引擎)，带<a class="ae lu" href="https://towardsdatascience.com/blender-2-8-grease-pencil-scripting-and-generative-art-cbbfd3967590" rel="noopener" target="_blank">油性笔</a>的2D动画，更好的着色器节点和最近超级强大的<a class="ae lu" href="https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/introduction.html" rel="noopener ugc nofollow" target="_blank">几何节点系统</a>。所有这些(以及更多)加上Python API，使它成为对3D环境的编程和程序控制感兴趣的研究人员和爱好者的一个明显受欢迎的选择，而不需要依赖不太用户友好的3D工具或库。</p><p id="6729" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于Blender中脚本的介绍，请参见我之前的一篇文章的第一部分。</p><p id="d6ec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">几行代码就可以展示SDG(以及其他)的编程设置的强大功能。以下Python代码片段允许以可控的方式随机化相机位置。如果你的相机有一个<code class="fe ni nj nk nl b">Track To</code>约束，你也保证它会从不同的角度指向同一个位置。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="4e49" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的片段显示了如何根据背景颜色和光线强度随机化<em class="no">世界</em>(指场景环境)。它只需要一个基本的节点设置，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/4a013d62205c83a949a38402793fcf41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ppWIcTWV-yu0_92dmczlcw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机化的基本世界设置</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="9ce9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此时，放置在场景中的任何对象都已经可以在不同的光照条件和背景下从不同的角度进行渲染。<br/>以下代码是将当前场景渲染到文件所需的全部内容。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="bb0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人们可以扩展这些基本块，并自动/随机处理与他们的需求相关的任何方面。然后，渲染的图像可以用于任何下游任务。实时Eeevee渲染器保证您可以在几秒钟或更短的时间内生成图像，因此可以轻松扩展以适应数据饥渴的情况。如果您需要更高的真实感，Cycles也是一个选项，但您会看到更长的渲染时间和对好的GPU的更强依赖性。</p><p id="ad79" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最重要的是，通过使用Blender，您可以访问所有的3D场景和对象信息，并可以使用<a class="ae lu" href="https://docs.blender.org/manual/en/latest/render/layers/passes.html" rel="noopener ugc nofollow" target="_blank"> <em class="no">通道</em> </a> <em class="no"> </em>将目标内容分割为单独的渲染图像(例如，深度、法线贴图、环境遮挡、通过对象或材质索引的分割贴图)。</p><p id="3140" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，对于这个条目，我们将把重点放在唯一的视觉分类设置上，并使用来自时尚领域的一个简单但具体的分类示例:纺织品图案分类来探索程序性材料。</p><h1 id="9628" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">示例用例:模式分类</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/308465e449be3c3dbcddd59670ebb657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUR0vc8bb_MLBzaWHIoMEg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同图案类型的时尚单品示例。</p></figure><p id="c7a5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来介绍一下用例:我们有一个视觉分类任务，需要对一个时尚物品的图案进行分类。这是一个多类别的问题，我们依赖于一组先前定义的类别(例如，素色、条纹、圆点、花卉、方格、动物纹)。我们对这些类都有直观的理解，它们适用于任何时尚物品，比如一件衣服、一双运动鞋或一个包。我们可以为这项任务手动收集和管理数据，但是通过Blender综合生成数据怎么样？</p><p id="ff07" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们首先需要获得一些适合我们的目标数据分布的3D对象。我们可以很容易地在高级包甚至单个免费模型中找到过多的3D时尚内容。我们甚至可以程序化地处理建模本身，但这是一个将在未来单独的条目中讨论的主题。</p><p id="e3a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦我们有了3D物体，我们就可以开始制作材料了。<br/>我们在这里展示了三种样本材料的节点树:<em class="no">素色</em>、<em class="no">条纹</em>和<em class="no">碎花</em>。前两者完全可以在Blender中获得。对于<em class="no"> floral </em>来说，我们依赖于需要单独下载的外部图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/75b3773bca2e6cd1f2d31ddb21133820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qcCIEXJIAvmtvRstrQ8lPw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nr">普通</em>物料节点树</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/37dae167dd89849521aa901153b9b7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fxN6-LGX6C7TwV3732HX0w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">条纹材料节点树</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/a73b19642941d2fbdfeffe448043d4ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FzDza1indZ1G7IcyaLrFZA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">花卉材料节点树</p></figure><p id="6d29" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">除了这些材料，我们只需要以下代码。我们有一个简单的函数来为每个目标类生成随机颜色和包装函数。</p><p id="3188" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">运行时，这些函数随机化相应的Blender材质(代码中使用的名称必须与Blender中的名称相匹配，这既适用于所有节点树的名称，也适用于特定节点的名称)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="3414" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们将上面的设置与上一节提供的随机化结合起来，我们就可以开始渲染了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/832bbae439242b838a512e75c7dafd3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*cGvzL5_iKqAEbBLMUZtBVw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">渲染图像的随机样本</p></figure><h1 id="2cde" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用生成的合成数据</h1><p id="1b88" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">使用生成的图像，您已经可以尝试训练一个视觉模型，并查看它在真实的目标领域数据上的表现。你不需要收集，刮擦和策划真实的图像，你不需要人工注释和验证，你有一个完全程序化的设置来扩展和进一步利用。</p><p id="f038" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然这是一个玩具用例，但是你的概念/类越复杂、越小众、越缺乏代表性，SDG方法就越能把你从数据收集和管理的痛苦中解救出来。</p><p id="589e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当合成数据集功能多样并且能够概化为真实数据集时，它是一个好的数据集。合成数据可以有多种用途。它可以作为训练期间已经可用的真实数据的补充，在训练期间，经常测试不同比率的合成与真实数据，以了解模型性能的最佳折衷。有时，它甚至可以只是一种测试/验证视觉模型鲁棒性的手段。</p><p id="a6e7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于使用合成数据的有效性，这通常需要经验测试，但是多个<a class="ae lu" href="https://github.com/StoryMY/take-off-eyeglasses" rel="noopener ugc nofollow" target="_blank">最近的</a> <a class="ae lu" href="https://ai.googleblog.com/2021/06/toward-generalized-sim-to-real-transfer.html" rel="noopener ugc nofollow" target="_blank">作品</a>和<a class="ae lu" href="https://microsoft.github.io/FaceSynthetics/" rel="noopener ugc nofollow" target="_blank">论文</a>展示了SDG的力量。</p><p id="1571" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中一个主要限制是<em class="no"> </em>所谓的<em class="no">畴隙</em>，意思是真实图像和合成图像之间的内在差异。对于我们的Blender示例，更多样和更详细的3D对象、更丰富的纹理或使用Cycles渲染器会产生看起来更真实的图像，但与真实的时尚图像相比仍有相当大的差距，如果包括人体模型，差距会更大。像<em class="no">领域适配</em>这样的特定研究领域着眼于如何解决这样的问题。</p><p id="6081" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> SDG还需要专业的领域知识</strong>(与人类注释需要的相同)，以及质量控制的整体设置，以避免更大和更具破坏性的领域差距。在生成过程中，总是存在注入隐含偏见的风险，或者完全错过你的领域中可能的异常(然而相关的)区域。再拿我们的玩具用例来说:我们需要清楚地理解我们的指导方针，即什么使得图案<em class="no">具有花卉图案。</em>是否需要写实花卉描绘？需要足够丰富多彩吗？多少级别的风格化是可以接受的？如果没有对这些问题的明确答案，我们最终将根据我们的偏见和假设来定义合成生成过程，然后很可能无法捕获我们真实数据的要求。</p><h1 id="ca3b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="8961" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在这篇文章中，我们给出了合成数据生成(SDG)的高级介绍，以及如何通过Blender轻松实现它。</p><p id="9322" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">模式分类设置允许我们演示如何将Blender材料和Python脚本结合起来，通过传统的计算机图形管道生成合成数据。</p><p id="16fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一个简单而强大的设置，已经可以作为大量计算机视觉用例的起点。</p><p id="9527" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本系列未来条目的计划是在这里介绍的基础上进行扩展，并探索SDG在视觉领域中不同的和更复杂的场景，同时展示如何使用Blender作为一个强大的工具来解决这些问题。</p><p id="ebf9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们非常欢迎反馈和建议，以推动这种未来的条目。总的来说，我们计划涵盖深度、分割和其他场景信息等方面，这些信息可以在依赖Blender时免费获得。我们还希望超越纯材质节点树来处理程序建模，并查看例如几何节点如何用于操纵SDG的网格。</p><p id="9fdf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从那里，我们将转向SDG的混合方法，考虑计算机图形的机器学习领域最近取得的重要进展，如对象/身体生成和重建，纹理合成的生成模型，以及神经渲染。</p><pre class="kj kk kl km gt nv nl nw nx aw ny bi"><span id="fed7" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">Want to Connect?</strong></span><span id="0538" class="nz lw it nl b gy oe ob l oc od">You can find more of my experiments and explanations on <a class="ae lu" href="https://twitter.com/5agado" rel="noopener ugc nofollow" target="_blank">Twitter</a> and see my graphics results on <a class="ae lu" href="https://www.instagram.com/amartinelli1/" rel="noopener ugc nofollow" target="_blank">Instagram</a>.</span></pre></div></div>    
</body>
</html>
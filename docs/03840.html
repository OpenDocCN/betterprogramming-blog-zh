<html>
<head>
<title>Build Custom Voice Assistants</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建自定义语音助手</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/building-your-custom-voice-assistants-an-overview-of-the-current-solutions-and-integrations-d8db227a325?source=collection_archive---------1-----------------------#2020-03-08">https://betterprogramming.pub/building-your-custom-voice-assistants-an-overview-of-the-current-solutions-and-integrations-d8db227a325?source=collection_archive---------1-----------------------#2020-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9d48" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当前解决方案和集成概述</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b8c26c336dc2de4eac46c4dfff93a180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CUQ_QC5dWio8XiNpS95lxw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@kamesi9?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">西瓦·卡梅什</a>在<a class="ae ky" href="https://unsplash.com/s/photos/speaker?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7373" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">这篇文章的更新版本可以在</em> <a class="ae ky" href="https://blog.platypush.tech/article/Build-custom-voice-assistants" rel="noopener ugc nofollow" target="_blank"> <em class="lv"> Platypush博客</em> </a> <em class="lv">上找到。</em></p><p id="03e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不久前，我写了一篇文章，描述了如何使用RaspberryPi、platypush、扬声器和麦克风制作自己的谷歌语音助手。</p><p id="9924" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它还展示了如果您不想说“Ok Google”，或者如果您希望不同的热门词汇以不同的语言触发不同的助手，如何创建您自己的自定义热门词汇模型来触发助手。它还展示了当某些短语被识别时，如何挂钩您自己的定制逻辑和脚本，而无需编写任何代码。</p><p id="7ce9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自从我写了那篇文章，一些事情已经改变了:</p><ul class=""><li id="74df" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">我写文章的时候，platypush只支持谷歌助手作为语音后端。与此同时，我也致力于支持Alexa 的<a class="ae ky" href="https://github.com/BlackLight/platypush/issues/80" rel="noopener ugc nofollow" target="_blank">工作。如果你是Alexa的粉丝，可以随意使用platypush中的<code class="fe mf mg mh mi b">assistant.echo</code>集成，但要记住，它比现有的基于谷歌助手的选项更有限AVS(亚马逊语音服务)也有限制。例如，它不会提供检测到的文本的副本，这意味着它不可能插入定制的钩子或呈现的响应的副本，因为AVS主要使用音频文件作为输入，并提供音频作为输出。它也可能遇到一些小的音频故障，至少在RasbperryPi上是这样。</a></li><li id="bb96" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">虽然不赞成，<a class="ae ky" href="https://github.com/googlesamples/assistant-sdk-python/releases/tag/0.6.0" rel="noopener ugc nofollow" target="_blank">Google Assistant库的新版本已经可用</a>来修复RaspberryPi 4上的分段错误问题。在过去的一年里，我经常给开发者打电话，我很高兴这已经完成了！这是个好消息，因为助手库拥有我见过的最好的热词检测引擎。我试过的其他SDK——Snowboy、DeepSpeech或pico voice——都没有接近原生的“Ok Google”热词检测准确性和性能。然而，并不是所有的消息都是好的:这个库仍然被弃用，目前还没有替代方案。新版本主要是为了响应用户的请求来修复新的RaspberryPi。但是，至少在一段时间内，构建语音助手的最佳选择之一仍将有效。那些对构建一个100%像原生谷歌助手一样的定制语音助手感兴趣的人可以阅读我的<a class="ae ky" href="https://medium.com/swlh/build-your-own-customizable-voice-assistant-with-platypush-cede33725cba" rel="noopener">前一篇文章</a>。</li><li id="b116" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">与此同时，官方语音助手SDK的不稳定状况促使我研究更多最先进的替代方案。我是<a class="ae ky" href="https://snowboy.kitt.ai/" rel="noopener ugc nofollow" target="_blank"> Snowboy </a>的长期粉丝，它有一个得到很好支持的platypush集成，我已经用它作为一个hotword引擎来触发其他助手集成很长时间了。然而，当谈到实时场景的准确性时，即使是最好的模型也不能令人满意。我还试验了<a class="ae ky" href="https://github.com/mozilla/DeepSpeech" rel="noopener ugc nofollow" target="_blank"> Mozilla DeepSpeech </a>和<a class="ae ky" href="https://github.com/Picovoice" rel="noopener ugc nofollow" target="_blank"> PicoVoice </a>产品，用于语音检测并在platypush中建立集成。在这篇文章中，我将尝试提供一个全面的概述，看看DIY语音助手目前可能实现的功能，并对我已经构建的集成进行比较。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="735c" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">DIY语音助手的案例</h1><p id="0258" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">在廉价的谷歌或Alexa助手随处可见的情况下，为什么还会有人费心打造自己的语音助手呢？尽管这些产品已经变得如此普及，我还是决定用几个DIY助手为我的整个房子供电，原因如下:</p><ul class=""><li id="4649" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><strong class="lb iu">隐私</strong>。最容易猜到的一个！我不确定房子里的一个麦克风，通过互联网连接到一家私营公司，一天五到十次互动，以切换灯泡，打开恒温器，或播放Spotify播放列表，是否是相称的价格。我在platypush中建立了语音助手集成，目标是让人们可以选择语音服务，而不用通过私有的盒子在私有的通道上发送所有的日常语音交互。</li><li id="8561" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><strong class="lb iu">兼容性</strong>。谷歌助手设备只能与支持谷歌助手的设备一起工作。Alexa驱动的设备也是如此。一些设备可能会失去一些语音功能，这可能是暂时的，取决于云连接的可用性，也可能是永久的，因为硬件或软件过时或其他商业因素。我梦想中的语音助手可以在任何设备上自然工作，只要它有一个SDK或API可以与之交互，并且不依赖于商业决策。</li><li id="ac3a" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><strong class="lb iu">灵活性</strong>。即使当一个设备与你的助手一起工作时，你仍然受到双方已经同意并实现的功能的约束。通过语音命令实现更复杂的例程通常很棘手。在大多数情况下，它涉及创建将在云上运行的代码(以Actions或Lambdas或IFTTT规则的形式)，而不是在您自己的网络中运行，这限制了实际的可能性。我梦想中的助手必须能够在我想要的任何设备上运行我想要的任何逻辑，使用我想要的任何自定义快捷方式(即使有正则表达式匹配)，不管有多复杂。我还旨在建立一个助手，可以提供多种服务(谷歌，Alexa，Siri等。)在同一台设备上使用多种语言，只需使用不同的热门词汇。</li><li id="3d4a" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><strong class="lb iu">硬件约束</strong>。我从来都不理解销售嵌入麦克风和扬声器的塑料盒是为了进入语音服务的世界。这是展示想法的好方法。经过几年的实验，可能是时候期待行业提供可以在任何设备上运行的语音助手体验了，只要它有麦克风和可以处理代码的控制器单元。至于兼容性，应该没有兼容谷歌或兼容Alexa的设备。任何设备都应该与任何助手兼容，只要该设备有办法与外界通信。控制该设备逻辑应该能够在该设备所属的同一网络上运行。</li><li id="2e82" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><strong class="lb iu">云端vs .本地处理</strong>。大多数商业语音助手的工作方式是定期捕获音频流，通过云服务扫描音频块中的热门词汇，一旦检测到热门词汇，就打开另一个到云服务的连接，以解析语音并提供响应。在某些情况下，即使是热门词汇检测，至少部分是在云端运行的。换句话说，大多数语音助手都是哑终端，旨在与实际上完成大部分工作的云提供商进行通信，他们通过互联网交换大量信息以进行操作。当您的目标是在快速网络中运行的低功耗设备，并且您不需要太多灵活性时，这可能是明智的。但是，如果您能够负担得起在更强大的CPU上处理音频，或者如果您想要在连接受限的设备上操作，或者如果您想要做一些通常无法使用现成解决方案完成的事情，您可能需要尽可能多地处理设备上的负载。当谈到语音助手时，我理解以云为导向的方法的情况，但不管技术如何，我们应该总是在分散和集中计算之间进行选择。我的梦想助手必须能够在设备上或云上运行热门词汇和语音检测逻辑，这取决于用例以及用户的偏好。</li><li id="1682" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><strong class="lb iu">扩展性</strong>。如果我在另一个房间或房子里需要一个新的语音助手，我只需拿起一个RaspberryPi，将我的助手驱动的操作系统映像的副本闪存到SD卡，插上麦克风和扬声器，就可以完成了。而无需购买新的塑料盒。如果我需要一个语音驱动的音乐扬声器，我只需将现有的扬声器插入RaspberryPi。如果我需要一个语音驱动的显示器，我只需要把现有的显示器插到RaspberryPi上。如果我需要一个语音开关，我只需在我的RaspberryPi上直接编写一个语音命令控制它的规则，而不必担心我的Google Home或Alexa应用程序是否支持它。任何设备都应该被赋予成为智能设备的可能性。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="51ea" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">语音助手集成概述</h1><p id="ef6d" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">语音助手通常由两部分组成:</p><ul class=""><li id="d843" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">一个<strong class="lb iu">音频记录器</strong>，从音频输入设备捕获帧</li><li id="1782" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">一个<strong class="lb iu">语音引擎</strong>跟踪当前上下文。</li></ul><p id="ae9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语音引擎有两个主要类别:热门词汇检测器，扫描音频输入中特定热门词汇的存在(如“Ok Google”或“Alexa”)，以及语音检测器，使用声学和语言模型进行适当的语音到文本的转录。可以想象，连续运行完整的语音检测比只运行热门词检测的开销高得多，后者只需将捕获的语音与通常很短的存储热门词模型列表进行比较。此外还有语音转换引擎，比如PicoVoice的Rhino。这些不是提供文本转录作为输出，而是提供演讲意图的结构化分解<em class="lv">。</em>例如，如果你说“<em class="lv">我能要一杯加很多糖和一些牛奶的小双份浓缩咖啡吗</em>”他们可能会返回类似于<code class="fe mf mg mh mi b">{"type":"espresso", “size”:”small", “numberOfShots":2, “sugar":"a lot", “milk":"some"}</code>的话。</p><p id="1ea8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在platypush中，我构建了集成，为用户提供了语音到文本处理器和引擎的广泛选择。让我们浏览一些可用的集成，并评估它们的优缺点。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="db1a" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">原生谷歌助手库</h1><h2 id="57c4" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated"><strong class="ak">集成</strong></h2><ul class=""><li id="f450" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/plugins/assistant.google.html" rel="noopener ugc nofollow" target="_blank">assistant.google</a></code>插件和<code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/backend/assistant.google.html" rel="noopener ugc nofollow" target="_blank">assistant.google</a></code>后端(启动时持续检测)。</li></ul><h2 id="3788" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated"><strong class="ak">配置</strong></h2><ul class=""><li id="9675" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">创建一个Google项目，并从<a class="ae ky" href="https://console.cloud.google.com/apis/credentials" rel="noopener ugc nofollow" target="_blank"> Google开发者控制台</a>下载<code class="fe mf mg mh mi b">credentials.json</code>文件。</li><li id="0a95" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">安装<code class="fe mf mg mh mi b">google-oauthlib-tool</code>:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="7640" class="ns mw it mi b gy ol om l on oo">pip install --upgrade 'google-auth-oauthlib[tool]'</span></pre><ul class=""><li id="86a0" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">认证使用<code class="fe mf mg mh mi b">assistant-sdk-prototype</code>范围:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="65c9" class="ns mw it mi b gy ol om l on oo">export CREDENTIALS_FILE=~/.config/google-oauthlib-tool/credentials.json</span><span id="b9fd" class="ns mw it mi b gy op om l on oo">google-oauthlib-tool --scope https://www.googleapis.com/auth/assistant-sdk-prototype \<br/>      --scope https://www.googleapis.com/auth/gcm \<br/>      --save --headless --client-secrets $CREDENTIALS_FILE</span></pre><ul class=""><li id="65c1" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">安装带有HTTP后端和Google Assistant库支持的platypush:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="3e66" class="ns mw it mi b gy ol om l on oo">pip install 'platypush[http,google-assistant-legacy]'</span></pre><ul class=""><li id="7478" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">创建或添加行到<code class="fe mf mg mh mi b">~/.config/platypush/config.yaml</code>以启用网络服务器和助手集成:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="4f41" class="ns mw it mi b gy ol om l on oo">backend.http:<br/>    enabled: True</span><span id="2f1f" class="ns mw it mi b gy op om l on oo">backend.assistant.google:<br/>    enabled: True</span><span id="f04b" class="ns mw it mi b gy op om l on oo">assistant.google:<br/>    enabled: True</span></pre><ul class=""><li id="8df1" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">启动<code class="fe mf mg mh mi b">platypush</code>，说“Ok Google”，享受你的助手。在<code class="fe mf mg mh mi b"><a class="ae ky" href="http://localhost:8008" rel="noopener ugc nofollow" target="_blank">http://localhost:8008</a></code>的网络面板上，你应该能够实时看到你的语音交互。</li></ul><h1 id="aae6" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated"><strong class="ak">引擎</strong></h1><ul class=""><li id="f9d4" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv">热词检测</em>:是(“Ok Google”或“嘿Google”)。</li><li id="53b1" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音检测</em>:是(一旦检测到热门词)。</li><li id="e1c4" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">本地运行检测</em>:否</li></ul><h1 id="e6d9" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated">赞成的意见</h1><ul class=""><li id="dd01" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">它实现了你能在任何谷歌助手产品中找到的大部分功能。这包括对定时器、日历的原生支持，基于您的个人资料和位置的定制响应，与Google Home中配置的设备的原生集成，等等。对于更复杂的特性，你必须编写自定义的platypush钩子，例如检测到语音或对话开始/结束事件。</li><li id="50b5" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">热门词汇检测和语音检测都非常可靠，因为它们依赖于谷歌云的功能。</li><li id="b5e6" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">即使在较旧的RaspberryPi模型上也有良好的性能(尽管该库不适用于Zero模型或其他基于arm6的设备)，因为大多数处理任务实际上都发生在云中。在RaspberryPi 4上，音频处理线程占用大约2–3%的CPU。</li></ul><h1 id="9dc5" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated">骗局</h1><ul class=""><li id="038d" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">被集成用作后端的Google Assistant库已经被Google 弃用。只要使用最新版本，它仍然可以在我试过的大多数设备上工作，但请记住，它不再由谷歌维护，它可能会在未来崩溃。不幸的是，我仍在等待官方的替代方案。</li><li id="0508" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">如果您的主要目标是在安全的环境中运行支持语音的服务，而不在其他人的云上进行处理，那么这不是您的最佳选择。assistant library使您的计算机的行为或多或少像一个完整的Google Assistant设备，包括捕获音频并将其发送到Google服务器进行处理，并可能进行审查。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="6a4f" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">谷歌助手一键通集成</h1><h2 id="5034" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">集成</h2><ul class=""><li id="746c" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/plugins/assistant.google.pushtotalk.html" rel="noopener ugc nofollow" target="_blank">assistant.google.pushtotalk</a></code>插件。</li></ul><h2 id="60eb" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">配置</h2><ul class=""><li id="ad1a" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">创建一个项目并从<a class="ae ky" href="https://console.cloud.google.com/apis/credentials" rel="noopener ugc nofollow" target="_blank"> Google开发者控制台</a>下载<code class="fe mf mg mh mi b">credentials.json</code>文件。</li><li id="eda8" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">安装<code class="fe mf mg mh mi b">google-oauthlib-tool</code>:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="a8be" class="ns mw it mi b gy ol om l on oo">pip install --upgrade 'google-auth-oauthlib[tool]'</span></pre><ul class=""><li id="8497" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">认证使用<code class="fe mf mg mh mi b">assistant-sdk-prototype</code>范围:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="2308" class="ns mw it mi b gy ol om l on oo">export CREDENTIALS_FILE=~/.config/google-oauthlib-tool/credentials.json</span><span id="9066" class="ns mw it mi b gy op om l on oo">google-oauthlib-tool --scope <a class="ae ky" href="https://www.googleapis.com/auth/assistant-sdk-prototype" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/assistant-sdk-prototype</a> \<br/>      --scope <a class="ae ky" href="https://www.googleapis.com/auth/gcm" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/gcm</a> \<br/>      --save --headless --client-secrets $CREDENTIALS_FILE</span></pre><ul class=""><li id="a25c" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">安装带有HTTP后端和谷歌助手SDK支持的platypush:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="d1f8" class="ns mw it mi b gy ol om l on oo">pip install 'platypush[http,google-assistant]'</span></pre><ul class=""><li id="9871" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">创建或添加行到<code class="fe mf mg mh mi b">~/.config/platypush/config.yaml</code>以启用web服务器和助手集成:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="79f0" class="ns mw it mi b gy ol om l on oo">backend.http:<br/>    enabled: True</span><span id="5363" class="ns mw it mi b gy op om l on oo">assistant.google.pushtotalk:<br/>    language: en-US</span></pre><ul class=""><li id="3ea6" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">开始<code class="fe mf mg mh mi b">platypush</code>。与原生的谷歌图书馆集成不同，一键通插件没有热词检测引擎。您可以通过编程方式启动或结束对话，例如通过platypush事件挂钩、过程或通过HTTP API:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="b8aa" class="ns mw it mi b gy ol om l on oo">curl -XPOST -H 'Content-Type: application/json' -d '<br/>{<br/>    "type":"request",<br/>    "action":"assistant.google.pushtotalk.start_conversation"<br/>}' http://localhost:8008/execute</span></pre><h2 id="7e66" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">发动机</h2><ul class=""><li id="68a3" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv">热门词汇检测</em>:否(从您的逻辑或从Snowboy、DeepSpeech或PicoVoice等热门词汇集成的上下文中调用<code class="fe mf mg mh mi b">start_conversation</code>或<code class="fe mf mg mh mi b">stop_conversation</code>来触发或停止助手)。</li><li id="9b8e" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音检测</em>:是。</li><li id="cf8d" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">本地运行检测</em>:否</li></ul><h1 id="06c7" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated">赞成的意见</h1><ul class=""><li id="4eae" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">它实现了你可以在任何谷歌助手产品中找到的许多功能，即使没有热词检测功能，并且助手库中目前可用的一些功能也没有提供(如定时器或闹钟)。</li><li id="c23b" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">坚如磐石的语音检测，使用与谷歌助手产品相同的语音模型。</li><li id="3598" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">即使在较旧的RaspberryPi模型上也有相对较好的性能。它还支持arm6架构，因此也适用于RaspberryPi Zero或其他低功耗器件。没有热词引擎运行意味着它只在你调用<code class="fe mf mg mh mi b">start_conversation</code>的时候使用资源。</li><li id="02c3" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">它提供了谷歌助理语音引擎的好处，而不需要在你的麦克风和谷歌服务器之间建立24/7开放的连接。该连接仅在<code class="fe mf mg mh mi b">start_conversation</code>时打开。如果隐私是一个问题，或者如果你想建立更灵活的助手，可以通过不同的热门词汇引擎触发(甚至根据你使用的热门词汇建立不同语言触发的助手)，或者根本不是由热门词汇触发的助手，这是一个很好的选择——例如，你可以在按钮按压、运动传感器事件或网络呼叫时调用<code class="fe mf mg mh mi b">start_conversation</code>。</li></ul><h2 id="dd1c" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">骗局</h2><ul class=""><li id="0690" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">在Google Assistant库被弃用后，我构建了这个集成，但没有提供官方的替代方案。我通过重构Google在其示例(<a class="ae ky" href="https://github.com/googlesamples/assistant-sdk-python/blob/master/google-assistant-sdk/googlesamples/assistant/grpc/pushtotalk.py" rel="noopener ugc nofollow" target="_blank"> pushtotalk.py </a>)中提供的不太精炼的代码，并用它制作了一个合适的插件。它可以工作，但是请记住，它是基于一些丑陋的代码，等待被谷歌取代。</li><li id="d693" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">不支持热门词汇。如果你想获得热门词汇支持，你必须将它连接到Snowboy、PicoVoice或DeepSpeech。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="0ad4" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">Alexa集成</h1><h2 id="ae3a" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">集成</h2><ul class=""><li id="1459" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/plugins/assistant.echo.html" rel="noopener ugc nofollow" target="_blank">assistant.echo</a></code>插件。</li></ul><h2 id="072a" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">配置</h2><ul class=""><li id="41a0" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">安装带有HTTP后端和Alexa支持的platypush:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="a4b5" class="ns mw it mi b gy ol om l on oo">pip install 'platypush[http,alexa]'</span></pre><ul class=""><li id="3fc5" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">运行<code class="fe mf mg mh mi b">alexa-auth</code>。它将在<code class="fe mf mg mh mi b"><a class="ae ky" href="http://localhost:3000." rel="noopener ugc nofollow" target="_blank">http://localhost:3000</a></code> <a class="ae ky" href="http://localhost:3000." rel="noopener ugc nofollow" target="_blank">启动您机器上的本地web服务器。</a>在您的浏览器中打开它，并使用您的亚马逊帐户进行验证。应该在<code class="fe mf mg mh mi b">~/.avs.json</code>下生成一个凭证文件。</li><li id="bce0" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">创建或添加行到您的<code class="fe mf mg mh mi b">~/.config/platypush/config.yaml</code>以启用web服务器和助手集成:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="9b62" class="ns mw it mi b gy ol om l on oo">backend.http:<br/>    enabled: True</span><span id="3ace" class="ns mw it mi b gy op om l on oo">assistant.echo:<br/>    enabled: True</span></pre><ul class=""><li id="3a65" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">开始<code class="fe mf mg mh mi b">platypush</code>。Alexa集成没有热词检测引擎。您可以通过编程方式启动或结束对话，例如通过platypush事件挂钩、过程或通过HTTP API:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="0211" class="ns mw it mi b gy ol om l on oo">curl -XPOST -H 'Content-Type: application/json' -d '<br/>{<br/>    "type":"request",<br/>    "action":"assistant.echo.start_conversation"<br/>}' <a class="ae ky" href="http://localhost:8008/execute" rel="noopener ugc nofollow" target="_blank">http://localhost:8008/execute</a></span></pre><h1 id="51d5" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated">发动机</h1><ul class=""><li id="e945" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv">热门词汇检测</em>:否(从您的逻辑或Snowboy或PicoVoice等热门词汇集成的上下文中调用<code class="fe mf mg mh mi b">start_conversation</code>或<code class="fe mf mg mh mi b">stop_conversation</code>来触发或停止助手)。</li><li id="bee0" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音检测</em>:是(虽然有限:不会提供处理后音频的转录)。</li><li id="437f" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">本地运行检测</em>:否</li></ul><h1 id="cb14" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated">赞成的意见</h1><ul class=""><li id="42df" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">它实现了你会在任何Alexa产品中找到的许多功能，即使热门词汇检测不可用。此外，对技能或媒体控制的支持可能是有限的。</li><li id="958c" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">良好的语音检测能力，虽然在准确性方面不如谷歌助手。</li><li id="1d28" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">即使在低功耗设备上也有良好的性能。没有热词引擎运行意味着它只在你调用<code class="fe mf mg mh mi b">start_conversation</code>时使用资源。</li><li id="eb7b" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">它提供了Alexa设备的一些好处，但不需要你的麦克风和亚马逊服务器之间的24/7开放连接。该连接仅在<code class="fe mf mg mh mi b">start_conversation</code>时打开。</li></ul><h1 id="f7fb" class="mv mw it bd mx my oq na nb nc or ne nf jz os ka nh kc ot kd nj kf ou kg nl nm bi translated">骗局</h1><ul class=""><li id="dff4" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">当涉及到Alexa voice SDKs时，情况是极其分散的。亚马逊最终重新发布了AVS (Alexa语音服务)，主要是出于商业用途的考虑，但与谷歌助理产品相比，其功能仍然相当有限。最大的限制是AVS处理原始音频输入，并传回原始音频响应。这意味着请求或响应的文本转录将不可用。这就限制了你能用它做什么。例如，您将无法通过事件挂钩捕获定制请求。</li><li id="09ae" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">不支持热门词汇。如果你想获得热门词汇支持，你必须将它连接到Snowboy、PicoVoice或DeepSpeech。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="49e6" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">雪球集成</h1><h2 id="f0e4" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">集成</h2><ul class=""><li id="10f5" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/backend/assistant.snowboy.html" rel="noopener ugc nofollow" target="_blank">assistant.snowboy</a></code>后端。</li></ul><h2 id="4c31" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">配置</h2><ul class=""><li id="fb26" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">安装带有HTTP后端和Snowboy支持的platypush:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="a79c" class="ns mw it mi b gy ol om l on oo">pip install 'platypush[http,snowboy]'</span></pre><ul class=""><li id="240f" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">选择您的热门词汇模型。有些在<code class="fe mf mg mh mi b">SNOWBOY_INSTALL_DIR/resources/models</code>下有。否则可以从<a class="ae ky" href="https://snowboy.kitt.ai/" rel="noopener ugc nofollow" target="_blank"> Snowboy网站</a>训练或者下载模型。</li><li id="7265" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">在您的<code class="fe mf mg mh mi b">~/.config/platypush/config.yaml</code>中创建或添加行来启用web服务器和助手集成:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="d86c" class="ns mw it mi b gy ol om l on oo">backend.http:<br/>    enabled: True</span><span id="3ff7" class="ns mw it mi b gy op om l on oo">backend.assistant.snowboy:<br/>    audio_gain: 1.2</span><span id="90f2" class="ns mw it mi b gy op om l on oo">    models:<br/># Trigger the Google assistant in Italian when I say "computer"<br/>        computer:<br/>            voice_model_file: ~/models/computer.umdl<br/>            assistant_plugin: assistant.google.pushtotalk<br/>            assistant_language: it-IT<br/>            detect_sound: ~/sounds/bell.wav<br/>            sensitivity: 0.4</span><span id="bf57" class="ns mw it mi b gy op om l on oo"># Trigger the Google assistant in English when I say "OK Google"<br/>        ok_google:<br/>            voice_model_file: ~/models/OK Google.pmdl<br/>            assistant_plugin: assistant.google.pushtotalk<br/>            assistant_language: en-US<br/>            detect_sound: ~/sounds/bell.wav<br/>            sensitivity: 0.4</span><span id="3313" class="ns mw it mi b gy op om l on oo"># Trigger Alexa when I say "Alexa"<br/>        alexa:<br/>            voice_model_file: ~/models/Alexa.pmdl<br/>            assistant_plugin: assistant.echo<br/>            assistant_language: en-US<br/>            detect_sound: ~/sounds/bell.wav<br/>            sensitivity: 0.5</span></pre><ul class=""><li id="4261" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">开始<code class="fe mf mg mh mi b">platypush</code>。说出与你的一个模型相关的热门词，检查日志中的<code class="fe mf mg mh mi b">HotwordDetectedEvent</code>是否被触发，如果有一个与热门词相关的助手插件，相应的助手会被正确启动。</li></ul><h2 id="b86a" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">发动机</h2><ul class=""><li id="dd9e" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv">热词检测</em>:是。</li><li id="9af6" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音检测</em>:否。</li><li id="4da7" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">本地运行检测</em>:是。</li></ul><h2 id="90c4" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">赞成的意见</h2><ul class=""><li id="dfd2" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">我是Snowboy项目的早期粉丝和支持者。我真的很喜欢众包机器学习的想法。你可以从他们的网站上免费下载任何热门词汇模型，只要你录下三段你说那个词的音频样本，以帮助改进模型。你也可以创建你自己的热门词汇模型，如果有足够多的人对使用它感兴趣，那么他们会贡献他们的样本，这个模型会随着时间的推移变得更加健壮。我相信，更多的机器学习项目可以真正受益于这种“只要你帮助改进模型，就免费使用它”的范式。</li><li id="f2f3" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">Platypush是Snowboy的早期支持者，所以它的集成得到了很好的支持，并有大量的文档。您可以原生配置自定义助手插件，以便在检测到某个热门词汇时执行，从而轻松制作多语言和多热门词汇的语音助手。</li><li id="46be" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">良好的性能，即使在低功耗设备上。我在单核RaspberryPi Zero设备上结合使用Snowboy和Google Assistant一键通集成有一段时间了，hotword处理的CPU使用率从未超过20–25%。</li><li id="f359" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">热门词汇检测在本地运行，在本地下载的模型上运行。这意味着不需要运行网络连接，也不需要与任何云交换数据。</li></ul><h2 id="7695" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">骗局</h2><ul class=""><li id="d8f7" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">尽管众筹声音模型的想法肯定很有趣，并且有很大的潜力扩大规模，但他们网站上最受欢迎的模型已经用最多2000个样本进行了训练。而且(可悲的也是意料之中的)大多数语音样本属于年轻的白人男性，这使得这些模型在处理不属于这一类别的任何个人(以及母语不是英语的人)的语音记录时表现很差。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="98cf" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">Mozilla DeepSpeech</h1><h2 id="9024" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">集成</h2><ul class=""><li id="9052" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/plugins/stt.deepspeech.html" rel="noopener ugc nofollow" target="_blank">stt.deepspeech</a></code>插件和<code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/backend/stt.deepspeech.html" rel="noopener ugc nofollow" target="_blank">stt.deepspeech</a></code>后端(用于持续检测)。</li></ul><h2 id="7cca" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">配置</h2><ul class=""><li id="fcc2" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">安装带有HTTP后端和Mozilla DeepSpeech支持的platypush。记下安装的DeepSpeech版本:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="32f6" class="ns mw it mi b gy ol om l on oo">pip install 'platypush[http,deepspeech]'</span></pre><ul class=""><li id="b26d" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">下载已安装的DeepSpeech版本的模型文件。这可能需要一段时间，具体取决于您的连接:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="3f1f" class="ns mw it mi b gy ol om l on oo">export MODELS_DIR=~/models<br/>export DEEPSPEECH_VERSION=0.6.1</span><span id="49f6" class="ns mw it mi b gy op om l on oo">wget https://github.com/mozilla/DeepSpeech/releases/download/v$DEEPSPEECH_VERSION/deepspeech-$DEEPSPEECH_VERSION-models.tar.gz</span><span id="96b3" class="ns mw it mi b gy op om l on oo">tar zxvf deepspeech-$DEEPSPEECH_VERSION-models.tar.gz<br/>x deepspeech-0.6.1-models/<br/>x deepspeech-0.6.1-models/lm.binary<br/>x deepspeech-0.6.1-models/output_graph.pbmm<br/>x deepspeech-0.6.1-models/output_graph.pb<br/>x deepspeech-0.6.1-models/trie<br/>x deepspeech-0.6.1-models/output_graph.tflite</span><span id="bbdd" class="ns mw it mi b gy op om l on oo">mv deepspeech-$DEEPSPEECH_VERSION-models $MODELS_DIR</span></pre><ul class=""><li id="f5cb" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">在您的<code class="fe mf mg mh mi b">~/.config/platypush/config.yaml</code>中创建或添加行以启用web服务器和DeepSpeech集成:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="ac74" class="ns mw it mi b gy ol om l on oo">backend.http:<br/>    enabled: True</span><span id="8874" class="ns mw it mi b gy op om l on oo">stt.deepspeech:<br/>    model_file: ~/models/output_graph.pbmm<br/>    lm_file: ~/models/lm.binary<br/>    trie_file: ~/models/trie</span><span id="d5f9" class="ns mw it mi b gy op om l on oo">    # Custom list of hotwords<br/>    hotwords:<br/>        - computer<br/>        - alexa</span><span id="1611" class="ns mw it mi b gy op om l on oo">    conversation_timeout: 5</span><span id="62f4" class="ns mw it mi b gy op om l on oo">backend.stt.deepspeech:<br/>    enabled: True</span></pre><ul class=""><li id="8434" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">开始<code class="fe mf mg mh mi b">platypush</code>。语音检测将在启动时开始运行。<code class="fe mf mg mh mi b">SpeechDetectedEvent</code>说话的时候会触发s。<code class="fe mf mg mh mi b">HotwordDetectedEvent</code> s将在您说出一个已配置的热门词汇时触发，<code class="fe mf mg mh mi b">ConversationDetectedEvent</code> s将在您说出一个热门词汇后触发，并提供<code class="fe mf mg mh mi b">speech</code>作为参数。您也可以禁用连续检测，仅通过调用<code class="fe mf mg mh mi b">stt.deepspeech.start_detection</code>和<code class="fe mf mg mh mi b">stt.deepspeech.stop_detection</code>以编程方式启动。您还可以使用它从音频文件中执行离线语音转录:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="c150" class="ns mw it mi b gy ol om l on oo">curl -XPOST -H 'Content-Type: application/json' -d '<br/>{<br/>    "type":"request",<br/>    "action":"stt.deepspeech.detect",<br/>    "args": {<br/>        "audio_file": "~/audio.wav"<br/>    }<br/>}' <a class="ae ky" href="http://localhost:8008/execute" rel="noopener ugc nofollow" target="_blank">http://localhost:8008/execute</a></span><span id="616c" class="ns mw it mi b gy op om l on oo">{<br/>    "type":"response",<br/>    "target":"http",<br/>    "response": {<br/>        "errors":[],<br/>        "output": {<br/>            "speech": "This is a test"<br/>        }<br/>    }<br/>}</span></pre><h2 id="e8bd" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">发动机</h2><ul class=""><li id="2562" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv">热词检测</em>:是。</li><li id="2745" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音检测</em>:是。</li><li id="d086" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">本地运行检测</em>:是。</li></ul><h2 id="45f3" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">赞成的意见</h2><ul class=""><li id="823d" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">老实说，我对DeepSpeech的功能以及它们从0.6.0版本开始取得的进步印象深刻。Mozilla使得在设备上运行热门词汇和语音检测变得很容易，不需要任何第三方服务或网络连接。完整的代码库是开源的，Tensorflow语音和语言模型也非常好。令人惊讶的是，他们已经向社区免费发布了全部内容。这也意味着您可以通过用自己的样本训练Tensorflow模型来轻松扩展它。</li></ul><h2 id="eafc" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">骗局</h2><ul class=""><li id="271a" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">DeepSpeech对CPU资源的要求相当高。它在笔记本电脑或RaspberryPi 4上运行正常(但在我的测试中，它在RaspberryPi 4上花费了100%的内核进行语音检测)。在功能不太强大的机器上运行可能会耗费太多资源。</li><li id="8654" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">DeepSpeech比其他解决方案有更多的延迟。Mozilla的工程师们已经做了很多工作来使这个模型尽可能的小和高性能，他们声称已经在RaspberryPi 4上实现了实时性能。实际上，我所有的测试在语音捕获和检测之间都有2到4秒的延迟。</li><li id="6920" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">DeepSpeech相对擅长检测语音，但不擅长解释语义上下文(这是谷歌仍然轻而易举获胜的地方)。如果你说“这是一个测试”，模型实际上可能会捕捉到“这是一个测试。”“这个”和“这些”在英语中听起来确实几乎一样，但是谷歌助手有一个更好的语义引擎来检测这种模糊情况的正确解释。DeepSpeech非常适合语音到文本的转录，但是在这种模糊的情况下，它缺乏一些语义上下文。</li><li id="9c08" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">尽管可以使用platypush的DeepSpeech作为热词检测引擎，但请记住这不是该引擎的预期用途。热词引擎通常运行在更小、更高性能的模型上，只用于检测一个或几个词，而不是全功能的语言模型。DeepSpeech的最佳用途可能是用于离线文本转录，或者与另一个热门词汇集成并利用DeepSpeech进行语音检测。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="ca79" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">微微之声</h1><p id="ee0a" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/Picovoice/" rel="noopener ugc nofollow" target="_blank"> PicoVoice </a>是一家非常有前途的公司，已经发布了几款用于在设备上执行语音检测的产品。其中包括:</p><ul class=""><li id="d46c" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><a class="ae ky" href="https://github.com/Picovoice/porcupine" rel="noopener ugc nofollow" target="_blank"> <em class="lv">豪猪</em> </a>，一款热门词引擎。</li><li id="0a91" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><a class="ae ky" href="https://github.com/Picovoice/leopard" rel="noopener ugc nofollow" target="_blank"> <em class="lv">豹</em> </a>，语音转文本离线转录引擎。</li><li id="c896" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><a class="ae ky" href="https://github.com/Picovoice/cheetah" rel="noopener ugc nofollow" target="_blank"> <em class="lv">猎豹</em> </a>，实时应用的语音转文本引擎。</li><li id="00dd" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><a class="ae ky" href="https://github.com/Picovoice/rhino" rel="noopener ugc nofollow" target="_blank"> <em class="lv"> Rhino </em> </a>，一个语音到意图引擎。</li></ul><p id="a3c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，platypush提供了与豪猪和猎豹的集成。</p><h2 id="713e" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">集成</h2><ul class=""><li id="84df" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv"> Hotword引擎</em> : <code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/plugins/stt.picovoice.hotword.html" rel="noopener ugc nofollow" target="_blank">stt.picovoice.hotword</a></code>插件和<code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/backend/stt.picovoice.hotword.html" rel="noopener ugc nofollow" target="_blank">stt.picovoice.hotword</a></code>后端(用于持续检测)。</li><li id="acf3" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音引擎</em> : <code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/plugins/stt.picovoice.speech.html" rel="noopener ugc nofollow" target="_blank">stt.picovoice.speech</a></code>插件和<code class="fe mf mg mh mi b"><a class="ae ky" href="https://platypush.readthedocs.io/en/latest/platypush/backend/stt.picovoice.speech.html" rel="noopener ugc nofollow" target="_blank">stt.picovoice.speech</a></code>后端(用于持续检测)。</li></ul><h2 id="37b5" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">配置</h2><ul class=""><li id="4c06" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">安装带有HTTP后端和PicoVoice hotword集成和/或语音集成的platypush:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="27f8" class="ns mw it mi b gy ol om l on oo">pip install 'platypush[http,picovoice-hotword,picovoice-speech]'</span></pre><ul class=""><li id="3478" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">在您的<code class="fe mf mg mh mi b">~/.config/platypush/config.yaml</code>中创建或添加行以启用web服务器和DeepSpeech集成:</li></ul><pre class="kj kk kl km gt oh mi oi oj aw ok bi"><span id="762b" class="ns mw it mi b gy ol om l on oo">stt.picovoice.hotword:<br/>    hotwords:<br/>        - computer<br/>        - alexa</span><span id="6948" class="ns mw it mi b gy op om l on oo"># Enable continuous hotword detection<br/>backend.stt.picovoice.hotword:<br/>    enabled: True</span><span id="d02b" class="ns mw it mi b gy op om l on oo"># Enable continuous speech detection<br/># backend.stt.picovoice.speech:<br/>#     enabled: True</span><span id="380e" class="ns mw it mi b gy op om l on oo"># Start speech detection when a hotword is detected<br/>event.hook.OnHotwordDetected:<br/>    if:<br/>        type: platypush.message.event.stt.HotwordDetectedEvent<br/>    then:<br/># Start a timer that stops the detection in 10 seconds<br/>        - action: utils.set_timeout<br/>          args:<br/>              seconds: 10<br/>              name: StopSpeechDetection<br/>              actions:<br/>                  - action: stt.picovoice.speech.stop_detection</span><span id="c95c" class="ns mw it mi b gy op om l on oo">        - action: stt.picovoice.speech.start_detection</span></pre><ul class=""><li id="7416" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">启动<code class="fe mf mg mh mi b">platypush</code>，享受您的设备语音助手。</li></ul><h2 id="0445" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">发动机</h2><ul class=""><li id="136c" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated"><em class="lv">热词检测</em>:是。</li><li id="30e0" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">语音检测</em>:是。</li><li id="897c" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><em class="lv">本地运行检测</em>:是。</li></ul><h2 id="5781" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">赞成的意见</h2><ul class=""><li id="86bf" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">说到设备上的语音引擎，PicoVoice产品可能是最好的解决方案。他们的hotword引擎比Snowboy更精确，而且它还能减少CPU的使用。他们的语音引擎比DeepSpeech延迟小得多，功耗也低得多——即使在旧型号的RaspberryPi上，它也仍然运行良好，延迟低。</li></ul><h2 id="0311" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">骗局</h2><ul class=""><li id="04fb" class="lw lx it lb b lc nn lf no li oe lm of lq og lu mb mc md me bi translated">虽然PicoVoice提供了Python SDKs，但是它们的原生库是闭源的。这意味着我不能深入了解他们是如何解决这个问题的。</li><li id="5c86" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">他们的hotword引擎(Porcupine)可以在任何设备上免费安装和运行，供个人使用，但如果你想扩展默认提供的关键字集，或者添加更多样本来训练现有模型，那么你必须获得商业许可。相反，他们的语音引擎(Cheetah)只能在x86_64架构的Linux上免费安装和运行，供个人使用。任何其他架构或操作系统，以及任何扩展模型或使用不同模型的机会，都只能通过商业许可来实现。虽然我理解他们的观点和商业模式，但我非常乐意通过更友好的流程购买许可证，而不是依赖老式的“联系我们获得商业许可证/我们会联系您”的模式。</li><li id="faf5" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">在语义上下文/意图检测方面，猎豹的语音引擎仍然存在DeepSpeech的一些问题。“这个/这些”的歧义也发生在这里。然而，这些问题可以通过使用Rhino得到部分解决，这是PicoVoice的语音到意图引擎，它将提供语音意图的结构化表示，而不是逐个字母的转录。然而，我还没有将Rhino整合到platypush中。</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="f058" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated"><strong class="ak">结论</strong></h1><p id="20d1" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">语音技术的民主化是人们梦寐以求的，它终于(慢慢地)到来了。不过，目前的情况仍然相当分散，一些商业SDK可能仍然会在短时间内或根本没有通知的情况下被弃用。但至少一些解决方案正在出现，将语音检测引入所有设备。</p><p id="a8ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在platypush中为所有这些服务建立了集成，因为我相信应该由用户而不是企业来决定人们应该如何使用语音技术并从中受益。此外，在同一产品中拥有如此多的语音集成，尤其是拥有公开所有相同API并生成相同事件的语音集成，这使得编写与助手无关的逻辑变得非常容易，并真正将语音识别任务与语音命令可以运行的业务逻辑分离开来。</p><p id="7404" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看<a class="ae ky" href="https://medium.com/swlh/build-your-own-customizable-voice-assistant-with-platypush-cede33725cba" rel="noopener">我以前的文章</a>，学习如何在platypush中编写自己的关于语音检测、热门词汇检测和语音开始/停止事件的定制钩子。</p><p id="7d08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总结一下我目前的发现:</p><ul class=""><li id="dd73" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">如果你想拥有完整的谷歌体验，如果你对谷歌服务器处理你的音频以及在未来的某个地方废弃的谷歌助手库不再工作的可能性没有意见，请使用原生的<strong class="lb iu">谷歌助手</strong>集成。</li><li id="29a4" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">如果您只想使用助手，而不想检测热门词汇，或者您希望助手由备选热门词汇触发，请使用<strong class="lb iu"> Google一键通</strong>集成。</li><li id="7039" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">如果你已经有一个亚马逊驱动的生态系统，并且你可以接受由于AVS中不可用的语音转录功能而在定制挂钩方面缺乏灵活性，请使用<strong class="lb iu"> Alexa </strong>集成。</li><li id="a357" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">如果你想使用一个灵活的、开源的、众包引擎来检测热门词汇，并在设备上运行和/或通过不同的热门词汇模型同时使用多个助手，即使模型可能不是那么准确，也可以使用<strong class="lb iu"> Snowboy </strong>。</li><li id="adca" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">如果您想要一个由健壮的Tensorflow模型支持的完全在设备上的开源引擎，请使用<strong class="lb iu"> Mozilla DeepSpeech </strong>，即使这需要更多的CPU负载和更多的延迟。</li><li id="4e2e" class="lw lx it lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">如果你想要一个在设备上运行的完整的语音解决方案，它既准确又高性能，即使你需要一个商业许可证才能在一些设备上使用它或扩展/改变模型，也可以使用<strong class="lb iu"> PicoVoice </strong>解决方案。</li></ul><p id="28b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请告诉我您对这些解决方案的想法以及您对这些集成的体验！</p></div></div>    
</body>
</html>
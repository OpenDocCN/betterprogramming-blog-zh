<html>
<head>
<title>Sending Multiple Files to a Data Generator in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python向数据生成器发送多个文件</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/multiple-files-to-data-generator-less-ram-fast-training-5ddfff3e4cbd?source=collection_archive---------15-----------------------#2020-05-25">https://betterprogramming.pub/multiple-files-to-data-generator-less-ram-fast-training-5ddfff3e4cbd?source=collection_archive---------15-----------------------#2020-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9b6f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在Colab中用更少的内存进行更快的训练</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c2a5607bc664ed9c5006d40205e28bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6KiLvhMa0Dkj49r-"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">弗兰基·查马基在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片。</p></figure><p id="ad1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在当前的深度学习时代，数据是最大的问题。如果数据量很小，那么对于训练深度神经网络来说，这显然是一个很大的问题。即使数据量巨大，对于没有足够资源的人来说，仍然是个大问题。</p><p id="0128" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大量数据带来的问题是没有足够的资源将数据加载到内存中。我们大多数人在<a class="ae kv" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Colab </a>中训练我们的模型，它最初只给我们12 GB的内存(有时是25/35 GB)。最近，我面临着同样的问题，仅仅加载一半的数据就使我的运行时崩溃。我们大多数人都知道显而易见的解决方案:使用Python生成器。</p><p id="48ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Python生成器是一个不会将整个输入加载到内存中的函数。它只需要我们当时需要的数据量。对于深度学习，我们不需要某个时刻的所有数据。我们需要特定时间的<code class="fe ls lt lu lv b">batch_size</code>数量的数据。所以它实际上返回了一个迭代器，它给出了我们需要的数据。</p><p id="e7c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设您有一个大小为80 GB的<code class="fe ls lt lu lv b">CSV</code>文件，那么您不能将整个数据集加载到内存中。在Python中，我们有一个可以打开CSV文件并逐行读取的lib。我们将用它来制造我们的发电机:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="4126" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该代码块将打印CSV文件的每一行。但与我们的传统方法不同，它不会将整个数据加载到内存中。它会一行一行地读，然后把那一行扔给我们使用。</p><p id="60e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我知道有些人此刻正在无聊地阅读。每个人都知道Python generator，但这不是本文的全部内容。上述解决方案适用于单个文件。但是，当您有三个、四个或更多CSV文件时，您会怎么做呢？</p><p id="e743" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再次使用Python生成器？</p><p id="4760" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是我之前面临的问题。以我小小的Python经验，我实现了一些功能，今天就和大家分享一下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="e47b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我在最近的研究中使用的代码，用来合并所有四个文件(总共47 GB ),并只获得数据的<code class="fe ls lt lu lv b">batch_size</code>( 16，32，64，128，...).不要被代码的庞大所淹没。我会一步步解释。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="d4f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这部分代码中，我将所有文件名作为参数和<code class="fe ls lt lu lv b">batch_size</code>传递。我用<a class="ae kv" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> pandas </a> ( <code class="fe ls lt lu lv b">pd</code>)读取CSV，但与传统方式不同的是，我在<code class="fe ls lt lu lv b">read_csv</code>上传递了<code class="fe ls lt lu lv b">chunksize</code>参数。然后，它将返回一个reader对象，而不是一个数据帧。我将所有的reader对象追加到一个列表中并返回。我将在后面的代码中使用它。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="bded" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一部分，所有的数据帧对象都被发送。在我的例子中，我必须使用<code class="fe ls lt lu lv b">id</code>作为主值，将所有数据框对象合并到一个数据框中。Pandas已经有了一个内置的功能(<code class="fe ls lt lu lv b">pd.merge</code>)。在此函数中，您需要发送左右数据框、连接类型以及需要用作主要变量的变量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="b070" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，这是我在<code class="fe ls lt lu lv b">model fit</code>函数中使用的主生成器函数。起初，我使用<code class="fe ls lt lu lv b">get_all</code>函数来获取所有的读者。现在该函数将无限期运行。它需要多少数据将取决于模型，而不是数据集中的数据量或生成器函数。所以它会无限运行，循环服务于数据。</p><p id="97c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">reader.get_chunk()</code>将返回<code class="fe ls lt lu lv b">chunksize</code>的数据帧。我们拥有来自所有reader对象的所有块，并使用之前的<code class="fe ls lt lu lv b">merge_all</code>函数合并它们。然后，我在代码末尾使用<code class="fe ls lt lu lv b">yield</code>关键字将这些值分开并返回。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="9552" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我对这部分代码做了什么？深度学习模型不会只对数据进行一次训练。它重复读取数据—传统上每个时期读取一次。如果我们使用来自<code class="fe ls lt lu lv b">numpy</code>数组的数据，它会自己管理数据的重复。但是由于我们使用的是发电机，我们必须手动操作。所以在第一行，我跟踪已经读取的数据数量，在<code class="fe ls lt lu lv b">if</code>条件下，我检查是否已经到达数据的末尾。如果是，那么我只是再次获取所有的reader对象，并将<code class="fe ls lt lu lv b">cnt</code>重置为0。因此，它将再次从文件的开头开始为我提供数据。</p><p id="f467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个话题让我吃了不少苦头，在谷歌搜索了很多次后，我想出了这个解决方案。我希望这篇文章能节省你的时间和网络带宽。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Analyzing Cold Starts on a NodeJS Lambda</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析节点上的冷启动</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/analysing-cold-starts-on-a-nodejs-lambda-360dfb52a08f?source=collection_archive---------2-----------------------#2022-02-27">https://betterprogramming.pub/analysing-cold-starts-on-a-nodejs-lambda-360dfb52a08f?source=collection_archive---------2-----------------------#2022-02-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="37b2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解导致更长冷启动时间的配置类型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4ee2ef0b4aee00c1c8f10a08038656ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XpxVh2PC5ifIqk9W"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@kirklai?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> 𝓴𝓘𝓡𝓚 𝕝𝔸𝕀 </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="ea9f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我决定深入研究Lambda冷启动问题，看看正常的冷启动需要多长时间，以及什么配置会导致更长的冷启动时间。</p><p id="2366" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">TL；Lambda冷启动的最大贡献者是Lambda在S3的总尺寸。这意味着lambda中的代码越多，或者包中包含的库越多，冷启动的时间就越长。内存、VPC、区域、层和指令集架构对Lambda的冷启动时间没有太大影响。</strong></p><h1 id="3923" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">λ冷启动的快速定义</h1><p id="a68f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">当Lambda函数收到请求时，服务首先准备一个执行环境。准备执行环境包括以下任务:</p><ul class=""><li id="28fe" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">从内部AWS S3桶下载代码。</li><li id="8013" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">使用内存、运行时和指定的配置创建环境。</li></ul><h1 id="da36" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">实验</h1><h2 id="04d8" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">λ配置</h2><p id="d249" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我使用下面的配置作为Lambdas的默认配置，然后为每个测试场景更改一个配置:</p><ul class=""><li id="7cde" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">运行时:Node.js 14</li><li id="4215" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">架构:X86_64</li><li id="fb29" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">区域:欧盟-西方-1</li><li id="a043" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">内存:128MB</li><li id="20db" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">不是在VPC里面</li></ul><p id="2e22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Lambda使用内置的<a class="ae kv" href="https://nodejs.org/api/https.html" rel="noopener ugc nofollow" target="_blank"> https </a>库进行简单的HTTP调用，并从下游端点返回数据。</p><h2 id="1a5d" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">我如何收集指标</h2><p id="43ab" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我使用AWS X-Ray来观察和收集Lambda执行的指标。X-Ray测量每个Lambda请求的初始化、调用和开销时间(<a class="ae kv" href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-context.html" rel="noopener ugc nofollow" target="_blank">了解更多信息，请点击</a>)，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/1427064c0103c799b8b0d5f233421ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ji011de5Y0pP8-RzGSyzYQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">AWS X射线度量</p></figure><p id="a09a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个实验，我们感兴趣的是初始化，因为这指的是通常所说的冷启动时间。这是我在这篇文章中称为冷启动时间的指标。</p><h2 id="e161" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">结果呢</h2><p id="8721" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">让我们看看一些数字。下面，我展示了在分析以下配置的冷启动时间时的测试结果:</p><ul class=""><li id="2b86" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">记忆</li><li id="6359" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">指令集体系结构</li><li id="fd26" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">地区</li><li id="02dc" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">VPC</li><li id="40be" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">图书馆</li><li id="dbf6" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">λ层</li></ul><h2 id="2c1e" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated"><strong class="ak">内存</strong></h2><p id="2281" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">增加Lambda的内存是否会减少冷启动时间？</p><p id="e2ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在从128MB到10240MB的不同内存量下部署了lambda。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/175c89f2b84b6883c97f8c1d59c15daa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MueV3vvqsozgRKuK0Y30dw.png"/></div></div></figure><p id="18b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简短的回答是不，不是真的。通过增加Lambda可用的内存，潜在的延迟节省是15毫秒。</p><h2 id="ac82" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated"><strong class="ak">指令集架构</strong></h2><p id="f9c8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">arm64和x86_64架构冷启动有区别吗？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/602d0e293c52e63cf7819668fcf62ba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N35K-602maQh1aPvW9jlaQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按架构划分的冷启动时间</p></figure><p id="1243" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单的回答还是<strong class="ky ir">不，不完全是</strong>。我发现arm64将冷启动时间缩短了1毫秒。</p><h2 id="8976" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated"><strong class="ak">地区</strong></h2><p id="a453" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">某些地区的冷启动时间是否比其他地区短？</p><p id="5647" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我测试了3个AWS地区的冷启动时间:<strong class="ky ir"> eu-west-1 </strong>、<strong class="ky ir"> us-east-1 </strong>和<strong class="ky ir"> ca-central-1 </strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/9db3c82b3ffb6804d79d0527af7d422d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qzYfjNAmZp4gHsSaAb--2A.png"/></div></div></figure><p id="8ce4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，简短的回答是<strong class="ky ir">没有，地区之间没有真正显著的</strong>差异。我测试的区域中没有一个显示出明显更慢或更快的冷启动时间。</p><h2 id="4270" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated"><strong class="ak"> VPC </strong></h2><p id="4893" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我以前听说过，与不开VPC的兰博达相比，开VPC的兰博达冷启动时间更长。我测试的时候看到这个了吗？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/0a9aaeeeac28ec623b461588e9996ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ddjnmsoD0-mStWcq-b0Qog.png"/></div></div></figure><p id="1530" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再次，<strong class="ky ir">否</strong>。λ是否在VPC中似乎不会影响冷启动时间。VPC内部的Lambda多花了1 ms来初始化Lambda环境，这对于延迟来说也不是一个显著的差异。</p><h2 id="e5fb" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated"><strong class="ak">图书馆</strong></h2><p id="9f1c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">Lambda包中包含的库数量会增加冷启动时间吗？</p><p id="891c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用了以下5个包来测试这个场景，并在每个测试中增加了一个包:</p><ul class=""><li id="58b1" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">axios</li><li id="be77" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">温斯顿</li><li id="8a28" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">洛达什</li><li id="b829" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">瞬间</li><li id="5d73" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">拉姆达</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/5e769e78d842622341808c32e6e065b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jE7ENYwooUmt8ONngXPPlw.png"/></div></div></figure><p id="997a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我发现了一种增加冷启动时间的配置。Lambda包中包含的库的数量确实会影响Lambda环境的初始化时间。</p><p id="baed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在没有任何库的情况下，冷启动时间是173 ms，相当短的时间。但是当我们在Lambda中包含5个包时，这个时间会跳到515毫秒，多了将近半秒。这对于一个API来说是一个显著的区别，也是API的消费者会注意到的一个区别。</p><p id="ad37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仔细想想，这是有道理的。冷启动是从S3下载Lambda包的时间。因此，如果我们有一个更大的包大小，它将需要更多的时间来下载该包，导致更长的冷启动时间。</p><h2 id="aa80" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated"><strong class="ak">λ层</strong></h2><p id="e08c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在Lambda上附加一个层会影响冷启动时间吗？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/0db2a2fe9fc1a38533769f2a4cb484e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-tYno2ueO_BLQpYSlLrxpA.png"/></div></div></figure><p id="464e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，在Lambda上添加一层时，冷启动时间没有太大差异。没有Lambda层时，冷启动时间仅快2.5毫秒。</p><h1 id="f32d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="c9b0" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">当使用NodeJS 14运行时，在默认配置下，您将经历大约<strong class="ky ir"> 170ms </strong>的冷启动时间。</p><p id="6f7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对冷启动时间唯一真正重要的贡献者是Lambda中使用的包的数量。其他配置与冷启动时间的差异非常小，但如果结合使用，可能会导致更大的差异。<br/>例如，如果你在一个有多个lambda层的VPC中使用一个Lambda，你可能会看到不同。</p><h2 id="6ae1" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">收集的所有数据的摘要:</h2><p id="8820" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><strong class="ky ir">内存— </strong>与内存为8192MB或10240MB的Lambda相比，内存为2048MB的Lambda的冷启动时间要慢15毫秒</p><p id="0643" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">指令集架构— </strong> x86_64的冷启动时间为173，相比之下，arm64的冷启动时间少1毫秒，为172毫秒。</p><p id="19ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">地区— </strong> us-east-1的冷启动时间最高，为179.5毫秒。ca-central-1的冷启动时间最快，为168.5毫秒。</p><p id="acdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">VPC—</strong>VPC内的Lambda比不在<br/> VPC内的Lambda慢1毫秒。</p><p id="fc49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">库— </strong>没有库的lambda比有5个库的Lambda冷启动快342.5毫秒。</p><p id="c5ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Lambda层— </strong>没有层的Lambda比有1层的Lambda快2.5毫秒。</p><p id="629f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">供应的并发性— </strong>我还要指出，我还对<a class="ae kv" href="https://aws.amazon.com/blogs/aws/new-provisioned-concurrency-for-lambda-functions/" rel="noopener ugc nofollow" target="_blank">供应的并发性</a>进行了试验，结果初始化时间为0毫秒。如果你担心冷启动时间，这可能是一个值得研究的问题。</p></div></div>    
</body>
</html>
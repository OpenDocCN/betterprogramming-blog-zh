<html>
<head>
<title>From Word Blobs to Context</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从单词块到上下文</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/from-word-blobs-to-context-5-steps-in-nlp-and-text-cleaning-db9c15e11a4c?source=collection_archive---------9-----------------------#2020-08-26">https://betterprogramming.pub/from-word-blobs-to-context-5-steps-in-nlp-and-text-cleaning-db9c15e11a4c?source=collection_archive---------9-----------------------#2020-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2f0d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">自然语言处理和文本清理的5个步骤</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a46c6143506243d12defeaa60511047f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xfXoVO5IfvGaoqT6aqu_qQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">帕特里克·托马索在<a class="ae kv" href="https://unsplash.com/s/photos/books?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="61d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你不必说或写很多来表达你的观点。</p><p id="c086" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">许多人欣赏这种直接的方法，当涉及到执行分析时，计算机也是如此。数据清理的目标之一是为计算机提供清晰简明的信息，以获得最有意义的结果。这就是为什么要丢弃空值、纠正重复数据、进行转换以及执行其他技术来获得数据的细化版本。</p><p id="aa39" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">文本数据也不例外，在本文中，我将讨论<a class="ae kv" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">自然语言处理</a> (NLP)。我将使用Python库<a class="ae kv" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>，一个用于处理人类语言数据的库，用我最近的<a class="ae kv" href="https://github.com/MarcelinoV/Twitter-Covid-NLP-KMeans" rel="noopener ugc nofollow" target="_blank"> Twitter情感分析项目</a>中的数据来检查文本清理过程。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="e103" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">自然语言处理</h1><p id="831d" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">通过NLP进行情感分析已经成为一种流行的用于研究或商业目的的文本分析方法。用例示例包括分析客户对某些产品的评论，可视化论坛或评论线程中的政治极性，或挖掘一些社交媒体源的意见。</p><p id="6ef9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像这样的洞察力非常有用，因为它给企业提供了做出有效决策的智慧，并帮助社会科学研究人员通过语言研究人类行为。</p><p id="c383" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，就像数字数据一样，在进行任何分析之前，文本数据也必须经过处理，或者说<em class="mw">清理</em>。Python是一种很好的语言，像NLTK这样的库使得文本清理过程变得平滑而容易。</p><p id="860f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">NLTK，即自然语言工具包，是一个Python库，用于词干、标记化、分类等字处理技术。我们将使用它来回顾常规NLP中的五个实践:</p><ul class=""><li id="2cd4" class="mx my iq ky b kz la lc ld lf mz lj na ln nb lr nc nd ne nf bi translated">小写转换</li><li id="adff" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">标记化</li><li id="808e" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">删除标点符号</li><li id="9718" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">停止单词删除</li><li id="a1da" class="mx my iq ky b kz ng lc nh lf ni lj nj ln nk lr nc nd ne nf bi translated">词干化和词汇化</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/38419907a0858a6a02d62b857577ecb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FzpL7aysvpQKt8GmANSlcw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@morningbrew?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">晨酿</a>在<a class="ae kv" href="https://unsplash.com/s/photos/twitter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">破浪</a></p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f812" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">对新冠肺炎疫苗的看法</h1><p id="20df" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我们将对一组关于新冠肺炎疫苗情绪的推文进行文本清理。这些推文是由<a class="ae kv" href="https://github.com/taspinar/twitterscraper" rel="noopener ugc nofollow" target="_blank"> TwitterScraper </a>抓取的，这是一个基于关键词和标签抓取推文的Python库。</p><p id="91dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您是第一次使用NLTK，那么您需要将它下载到您的虚拟环境或笔记本中。请参见以下单元格:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">取消对“nltk.download()”的注释，并运行代码</p></figure><h2 id="1d37" class="nn ma iq bd mb no np dn mf nq nr dp mj lf ns nt ml lj nu nv mn ln nw nx mp ny bi translated">转换成小写</h2><blockquote class="nz oa ob"><p id="e437" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">当您进行解析时，将所有数据转换为小写有助于预处理过程以及NLP应用程序的后续阶段</p><p id="cc14" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">—<a class="ae kv" href="https://www.oreilly.com/library/view/python-natural-language/9781787121423/9742008f-6384-42a4-9711-2721dd6fd382.xhtml#:~:text=Converting%20all%20your%20data%20to,when%20you%20are%20doing%20parsing." rel="noopener ugc nofollow" target="_blank">Jalaj Thanaki via O ' Reilly</a></p></blockquote><p id="73fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我们NLP流程的第一步。记住，文本处理的全部目的是使数据更容易被计算机理解。将文本数据转换成小写有助于实现这一目标。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">将文本和hashtag列的数据转换为小写</p></figure><p id="bb51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用字符串库和列表理解，我使用<code class="fe of og oh oi b">.lower()</code>函数转换<code class="fe of og oh oi b">text</code>和<code class="fe of og oh oi b">hashtag</code>列中的数据。注意，我必须循环两次<code class="fe of og oh oi b">hashtag</code>列，因为它由列表中的列表组成——或者，换句话说，它是一个嵌套列表。</p><h2 id="585c" class="nn ma iq bd mb no np dn mf nq nr dp mj lf ns nt ml lj nu nv mn ln nw nx mp ny bi translated">标记化</h2><blockquote class="nz oa ob"><p id="5a29" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">由于标记是自然语言的组成部分，处理原始文本的最常见方式发生在标记级。例如，基于Transformer的模型NLP中最先进的(SOTA)深度学习架构——在令牌级别处理原始文本。”</p><p id="cc17" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">—<a class="ae kv" href="https://www.analyticsvidhya.com/blog/author/aravindpai/" rel="noopener ugc nofollow" target="_blank">ara vind Pai via Analytics vid hya</a></p></blockquote><p id="4123" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">记号化就是简单地把我们的文本数据一个字一个字或者一句一句的分解。这进一步将数据翻译成更计算机友好的语法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">单词和句子标记化</p></figure><p id="1208" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于我们的tweet数据，我们将使用NLTK的<code class="fe of og oh oi b">tokenize</code>类，并在我们的<code class="fe of og oh oi b">text</code>列上实现<code class="fe of og oh oi b">word_tokenize()</code>函数，逐词分解文本。我还使用了<code class="fe of og oh oi b"> sent_tokenize()</code>函数来演示句子标记化。</p><h2 id="02d1" class="nn ma iq bd mb no np dn mf nq nr dp mj lf ns nt ml lj nu nv mn ln nw nx mp ny bi translated">删除标点符号</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/30e3b8cee3a6dc4676807d5e3b07566d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WyEtlbhaOj5AeHlZEJnC_A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@enginakyurt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> engin akyurt </a>在<a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ef24" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从我们的文本数据中删除标点符号最终取决于数据所基于的模型的目的。在这种情况下，对于基于新冠肺炎疫苗情绪的聚类推文，标点符号没有多大用处，所以我们将删除它。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用re (regex)库，我们删除了所有标点符号</p></figure><p id="460c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用用于模式识别的<a class="ae kv" href="https://regexlib.com/?AspxAutoDetectCookieSupport=1" rel="noopener ugc nofollow" target="_blank"> re </a>库，我们创建一个regex对象来搜索所有形式的标点符号和非字母数字术语。然后我们调用对象上的<code class="fe of og oh oi b">sub()</code>函数，这样它将检查记号(单词记号化的单个元素/单词)是否是标点符号。如果标记不是标点符号，该标记将被添加到我们的新列表中，<code class="fe of og oh oi b">no_punc</code>。</p><h2 id="5a33" class="nn ma iq bd mb no np dn mf nq nr dp mj lf ns nt ml lj nu nv mn ln nw nx mp ny bi translated">删除停用词</h2><blockquote class="nz oa ob"><p id="78ee" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">“预处理的主要形式之一是过滤掉无用的数据。在自然语言处理中，无用的词(数据)，被称为停用词</p><p id="fdbc" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">— <a class="ae kv" href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python/" rel="noopener ugc nofollow" target="_blank">通过GeeksforGeeks发布的实用程序</a></p></blockquote><p id="bd72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更详细地说，停用词是常用词，如<em class="mw"> is，but，an，to，him，</em>等。并且被认为是无用的数据，因为它们没有给文本数据添加上下文含义。无论是构建数据库还是执行聚类，预处理的文本数据通常没有停用词，NLTK的停用词列表非常适合从我们的推文中删除它们。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">导入NLTK的“停用字词”类来检查英语停用字词</p></figure><p id="6a20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这段代码中，我只是检查我们的文本数据中是否有任何英文停用词，并将那些没有的词添加到我们的新列表中，<code class="fe of og oh oi b">new_term_vector</code>。</p><h2 id="e87e" class="nn ma iq bd mb no np dn mf nq nr dp mj lf ns nt ml lj nu nv mn ln nw nx mp ny bi translated">词干化和词汇化</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/1ddc53e49a3bea080f389066ae9de1a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqqbdH-aoLWYqRl9SWPI1w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">亚历克斯·杜哈诺夫在<a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><blockquote class="nz oa ob"><p id="5c68" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">词干化和词尾化都产生词根形式的词形变化。区别在于词干可能不是一个真实的单词，而lemma是一个真实的语言单词。词干提取遵循一种算法，对单词进行分步处理，这样速度会更快。”</p><p id="3af1" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">—<a class="ae kv" href="https://www.datacamp.com/community/tutorials/stemming-lemmatization-python" rel="noopener ugc nofollow" target="_blank">haf sa Jabeen via data camp</a></p></blockquote><p id="5e0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在NLP中，词干化就是通过去掉后缀来简化一个单词，比如<em class="mw"> -er，-ing，-es，</em>等等。于是<em class="mw"> runner </em>变成了<em class="mw"> runn，</em>T21【句子】变成了<em class="mw"> sentenc，</em>和<em class="mw"> growing </em>变成了<em class="mw">grown。</em></p><p id="cde5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是<em class="mw"> runn </em>和<em class="mw"> sentenc </em>显然不是词。这就是词汇化的用武之地，因为它涉及到查阅英语词典以及将词干与实际语言中的对等词进行匹配。这就用词根替换了带后缀的单词，使得数据对计算机更加友好。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">首先把这个单词加工成一个词干。然后转向它的引理</p></figure><p id="2400" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们首先从NLTK导入<code class="fe of og oh oi b">PorterStemmer</code>和<code class="fe of og oh oi b">WordNetLemmatizer</code>类。然后我们创建<code class="fe of og oh oi b">stemmer</code>和<code class="fe of og oh oi b">lemmatizer</code>对象，并使用它们对文本数据中的每个单词执行<code class="fe of og oh oi b">stem()</code>和<code class="fe of og oh oi b">lemmatize()</code>功能。</p><h2 id="9c76" class="nn ma iq bd mb no np dn mf nq nr dp mj lf ns nt ml lj nu nv mn ln nw nx mp ny bi translated">额外收获:微调</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/a672140b7e766390951b95516500b4fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NsrQ_yAPGibHswnSsZYwaA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@dadaben_?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">本杰明·达达</a>在<a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="30d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我注意到在处理完这些推文后，我仍然有一些带有网络术语的词，比如<code class="fe of og oh oi b">html</code>、<code class="fe of og oh oi b">www</code>、<code class="fe of og oh oi b">http</code>等等。所以我创建了一个新的regex对象来搜索这些特定的术语，并实现了与删除标点符号时相同的方法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">删除由web术语组成的元素</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="7a4f" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">结论</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/12e3c9d1ff6c8500b173e0e19541dcf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DAMXF7qdO0Lcf_w5grIARA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿迪·戈尔茨坦在<a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="nz oa ob"><p id="b431" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">“NLP的最终目标是以一种有价值的方式阅读、破译、理解和理解人类语言。”</p><p id="cb27" class="kw kx mw ky b kz la jr lb lc ld ju le oc lg lh li od lk ll lm oe lo lp lq lr ij bi translated">— <a class="ae kv" href="https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32" rel="noopener ugc nofollow" target="_blank">迈克尔·j·嘉宝博士通过成为人类</a></p></blockquote><p id="5aa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总之，自然语言处理促进了计算机对文本数据的解释。小写转换、标记化、标点/停用词移除、词干化和词汇化是自然语言处理中使用的一些最重要但又最基本的文本处理技术。</p><p id="6af5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更熟悉这门学科的最好方法是亲自尝试！选择一个你真正感兴趣的话题，并就此做一个NLP项目。它可以是分析亚马逊上的客户评论或社交媒体上的意见挖掘。</p><p id="8c4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在处理文本数据时，您还使用了哪些NLP技术？你觉得知道哪些最有用？你想学哪些？</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="4f78" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">资源</h1><p id="1612" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这个由Unfold Data Science 制作的<a class="ae kv" href="https://www.youtube.com/watch?v=KhXU7KOxQcg&amp;t=380s" rel="noopener ugc nofollow" target="_blank">视频归功于<strong class="ky ir"> </strong>，我就是在这里学会了用于我的Twitter集群项目和这篇文章的NLP。</a></p><p id="131a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后一段代码:如何保存我们清理过的文本数据。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用pandas的to_csv()保存你的数据帧</p></figure></div></div>    
</body>
</html>
<html>
<head>
<title>Vision Image Similarity Using Feature Prints in iOS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">iOS中基于特征指纹的视觉图像相似性</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/compute-image-similarity-using-computer-vision-in-ios-75b4dcdd095f?source=collection_archive---------5-----------------------#2019-12-12">https://betterprogramming.pub/compute-image-similarity-using-computer-vision-in-ios-75b4dcdd095f?source=collection_archive---------5-----------------------#2019-12-12</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="2eb0" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">使用图像的特征印迹确定图像之间的欧几里德距离</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/fd10ec936dfd112a8487ff714d0fd1e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i_TSS1dJrORmyCoN"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">内森·杜姆劳在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7c61" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在2019年WWDC奥运会期间，苹果通过增加大量进步，为其愿景框架提供了重大推动。从扩大其图像分类请求的类别数量(术语<em class="lt">分类法</em>用于此),到其人脸技术和文本识别请求的改进，苹果正在为iOS带来一些真正有趣的计算机视觉改进。</p><p id="620b" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">WWDC 2019的主要新增内容之一是在视觉框架中引入了图像相似性请求。图像相似性不同于图像分类，我们将很快看到如何相似和为什么相似。但首先，让我们看看图像相似性有用的一些应用:</p><ul class=""><li id="1c51" class="lu lv ir kz b la lb ld le lg lw lk lx lo ly ls lz ma mb mc bi translated"><strong class="kz is">签名验证</strong> —用于确定一个人的签名是否与签名匹配，从而使您的应用程序在设备上实时检测伪造时更加智能。</li><li id="a170" class="lu lv ir kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated"><strong class="kz is">重复图像查找器</strong> —筛选大量图像，无论是在数据集还是照片库中。有了这个新的视觉请求，通过创建一个自动化任务来过滤掉重复的图像变得更加容易。</li><li id="48cc" class="lu lv ir kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated"><strong class="kz is">分组或查找相似图像</strong> —就像文本相似性使用语义来标记一样，图像相似性在分组或查找呈现相似上下文(如风景、地点、人物、形状等)的图像时非常方便。</li><li id="a152" class="lu lv ir kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated"><strong class="kz is">人脸验证</strong> —图像相似性在视觉识别等情况下极其重要。</li></ul><p id="520f" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在，我们已经很好地了解了确定图像相似性很方便的各种用例，让我们在构建一个基于SwiftUI的iOS应用程序来实现这一特性的同时更深入地挖掘它。</p><h1 id="c314" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">我们的目标</h1><ul class=""><li id="f49b" class="lu lv ir kz b la na ld nb lg nc lk nd lo ne ls lz ma mb mc bi translated">理解图像分类不同于图像相似性。</li><li id="cbfa" class="lu lv ir kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">了解图像相似性在苹果视觉框架中的工作原理。</li><li id="975d" class="lu lv ir kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">构建一个应用程序，计算图像与参考图像的相似程度，并对它们进行排序。我们将使用SwiftUI框架来构建我们的iOS应用程序。</li></ul><h1 id="7c9a" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">视觉图像相似性</h1><p id="75a7" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">图像相似性和分类是不同的，因为类别标签并不表示相似性。图像分类模型通常返回生成的标签作为输出，而图像相似性请求负责计算两幅图像之间的相似性。</p><p id="5c73" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">分类请求属于<em class="lt">监督学习</em>，因为它们遵循来自输入的一组指令来返回输出目标结果。另一方面，图像相似性是<em class="lt">无监督的</em>，因为输入没有一组指令，并且依赖于特征提取来寻找图像之间的相关相似性。</p><p id="9655" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">计算图像相似性的技术有很多，比较图像像素值是最琐碎和无效的一种。不同照明/阴影下的相同图像将给出不同的像素，并且将被确定为与源图像不同，尽管内容非常相似。WWDC视频中的下图描述了这一点:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ni"><img src="../Images/fc6bac12c9ec2b475caa15635c303619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7t2HVtBM7Rvkdc--0HYQ7w.png"/></div></div></figure><h2 id="2b70" class="nj mj ir bd mk nk nl dn mo nm nn dp ms lg no np mu lk nq nr mw lo ns nt my nu bi translated">视觉特征印刷品</h2><p id="9be2" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">幸运的是，视觉框架由一个分类网络组成，该网络经过训练可以确定图像在最上层模型中的特征描述符。这使我们不必创建自己的模型来从图像中提取特征，因为Vision已经在其API中提供了特征打印。<code class="fe nv nw nx ny b">FeaturePrint</code>是图像的矢量描述符。</p><p id="eb5a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">以下代码展示了如何从视觉请求中确定特征印迹，并计算图像之间的欧几里德距离。距离决定了图像在欧氏图上的远近。距离越小，图像越相似。</p><pre class="kh ki kj kk gu nz ny oa ob aw oc bi"><span id="fe4a" class="nj mj ir ny b gz od oe l of og">let requestHandler = VNImageRequestHandler(cgImage: image.cgImage!, options: [:])</span><span id="345e" class="nj mj ir ny b gz oh oe l of og">let request = VNGenerateImageFeaturePrintRequest()</span><span id="ac20" class="nj mj ir ny b gz oh oe l of og">do {</span><span id="2462" class="nj mj ir ny b gz oh oe l of og">try requestHandler.perform([request])</span><span id="9351" class="nj mj ir ny b gz oh oe l of og">let result = request.results?.first as? VNFeaturePrintObservation<br/>var distance = Float(0)<br/>try result?.computeDistance(&amp;distance, to: sourceResult)</span><span id="66f4" class="nj mj ir ny b gz oh oe l of og">}catch{</span><span id="8cc9" class="nj mj ir ny b gz oh oe l of og">}</span></pre><p id="b170" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在上面的代码中，<code class="fe nv nw nx ny b">VNGenerateImageFeaturePrintRequest</code>返回一个<code class="fe nv nw nx ny b">VNFeaturePrintObservation</code>，用于计算与源图像的浮点距离。</p><p id="9aa5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来，在下一节中，我们将开发一个iOS应用程序，该应用程序使用图像的特征打印来按照相似性对它们进行排序。</p><h1 id="a7ce" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">履行</h1><p id="9270" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">首先，我们将设置我们的SwiftUI视图，它包含一个源图像(参考图像)和一个图像列表。这个想法是在每个图像上运行<code class="fe nv nw nx ny b">VNGenerateImageFeaturePrintRequest</code>,并计算它们与源图像的特征打印的距离。随后，我们将对SwiftUI列表进行排序，以在顶部显示最相似的图像。</p><p id="001d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">下面是我们UI的初始状态:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oi"><img src="../Images/f991eb463c171b932598105db459fff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/1*X6QNV8uTvXMp5NK_KMMPtQ.gif"/></div></figure><p id="8ed4" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">所以我们在SwiftUI列表中保留了一张汽车图片作为源图片，以及一些随机图片(包括同一汽车模型不同姿势的图片)。我们很快就会看到，在计算图像的特征打印时，Vision的图像相似性有多准确。但是首先，让我们建立我们的列表和它的模型。</p><h2 id="a3d2" class="nj mj ir bd mk nk nl dn mo nm nn dp ms lg no np mu lk nq nr mw lo ns nt my nu bi translated">为SwiftUI列表创建模型</h2><p id="01bd" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">我们的SwiftUI列表将在一个结构中保存图像和相对于源图像的计算距离，如下所示:</p><pre class="kh ki kj kk gu nz ny oa ob aw oc bi"><span id="eb4b" class="nj mj ir ny b gz od oe l of og">struct ModelData : Identifiable{</span><span id="3c59" class="nj mj ir ny b gz oh oe l of og">public let id: Int</span><span id="8b94" class="nj mj ir ny b gz oh oe l of og">public var imageName : String</span><span id="33fd" class="nj mj ir ny b gz oh oe l of og">public var distance : String = "NA"</span><span id="8ce0" class="nj mj ir ny b gz oh oe l of og">}</span></pre><p id="c794" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">符合<code class="fe nv nw nx ny b">Identifable</code>协议对于列表中的元素拥有唯一的标识符是很重要的。</p><h2 id="ea28" class="nj mj ir bd mk nk nl dn mo nm nn dp ms lg no np mu lk nq nr mw lo ns nt my nu bi translated">构建我们的SwiftUI视图</h2><p id="0f21" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">接下来，我们将设置SwiftUI视图来保存<code class="fe nv nw nx ny b">modelData</code>和源图像，如下所示:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="oj ok l"/></div></figure><p id="4a64" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这里我们的<code class="fe nv nw nx ny b">modelData</code>被定义为一个状态变量。对<code class="fe nv nw nx ny b">modelData</code>或其属性的任何更改都会再次更新视图。按下<code class="fe nv nw nx ny b">NavigationBarItem</code>会触发视觉请求。让我们看看它是如何工作的。</p><h1 id="d032" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">运行愿景请求</h1><p id="0c75" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">以下代码计算<code class="fe nv nw nx ny b">modelData</code>和<code class="fe nv nw nx ny b">sourceImage</code>的每个图像之间的距离，并使用map函数转换数组，然后按距离排序:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="oj ok l"/></div></figure><p id="ee51" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">因此，当运行上述请求时，我们在应用程序中得到以下结果:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/65336bca6db79865213a810e184277be.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/1*oMJn7mUEAZa_3M52IkM-fQ.gif"/></div></figure><p id="cf58" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在上面的结果中，最相似的图像是与参考图像具有最相似姿势的图像。视觉特征印迹比较也考虑了显著性(因此更显著的自行车获得了更高的等级)。</p><p id="318c" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">对于用于计算相似性的图像与源图像相同的情况，返回的距离为0.0。此外，如果视觉请求不能提取特征印迹，它将抛出一个错误。</p><h1 id="31a7" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">结论</h1><p id="77dd" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nf li lj lk ng lm ln lo nh lq lr ls ik bi translated">在本教程中，我们探讨了苹果的视觉框架如何通过一个易于使用的API抽象复杂的计算机视觉算法，使iOS开发人员更加轻松。</p><p id="7f1d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">通过提取图像的特征指纹，我们可以分析图像之间的相似性。接下来，您可以尝试使用多个参考图像来计算图像，例如判断图像是否模糊、暗/亮等。看看视觉请求在这种情况下有多准确会很有趣。本文的完整源代码可以在这个<a class="ae kw" href="https://github.com/anupamchugh/iowncode/tree/master/iOSImageSimilarityUsingVision" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>中找到。</p><p id="1668" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这一次到此为止。我希望你喜欢阅读。</p></div></div>    
</body>
</html>
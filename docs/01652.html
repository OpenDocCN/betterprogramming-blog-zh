<html>
<head>
<title>Generative Adversarial Networks and Creating Reality With AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络与人工智能创造现实</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/generative-adversarial-networks-creating-reality-with-ai-59fbb5b113c0?source=collection_archive---------12-----------------------#2019-10-01">https://betterprogramming.pub/generative-adversarial-networks-creating-reality-with-ai-59fbb5b113c0?source=collection_archive---------12-----------------------#2019-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="aba1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">探索甘的过去、现在和未来</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d8b47216952d70a3d02df5d262f1d523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4VyiyZBxIYmoBQST12j7KQ.png"/></div></div></figure><p id="3eee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最近，我们看到各种工具越来越受欢迎，这些工具自动创建从未存在过的人、物体或场景的图像，或者通过添加它们从未有过的品质来修改现有物体的表示。</p><p id="26f2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种解决方案的一个典型例子是FaceApp。该应用程序可以拍摄一个人的照片，并创建带有额外功能的面部图像。例如，它可以添加胡须，使人看起来更老或更年轻，或者添加通常不存在的面部特征。</p><p id="192c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所有这一切都要归功于生成性对抗网络(GAN)。今天，我想探讨一下这个话题，让大家熟悉一下GAN及其相关技术。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="0341" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">GAN——生成性对抗网络</h1><p id="0d2b" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">首先，我们来研究一下GAN背后的机制。想象两个独立的神经网络:第一个被称为<em class="mu">鉴别器</em>被训练识别图像，而第二个被称为<em class="mu">生成器</em>学习如何生成图像。</p><p id="1922" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">两个模型都基于博弈论进行博弈。生成器的目标是欺骗鉴别器，而鉴别器试图阻止它使用真实和人工(生成)图像的样本作为武器。</p><p id="13ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着双方的学习，他们在游戏中变得更加熟练。发生器产生更准确的图像，鉴别器在区分真假样品方面变得更好。当生成器生成的伪造图像如此逼真以至于鉴别器不再能够辨别它们时，生成模型被认为是经过完全训练的。这意味着该模型已经能够生成高度逼真的按需图像。</p><p id="1ac9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">GAN是由Ian Goodfellow和他的团队在2014年发明的。他们一起发表了<a class="ae mv" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">一篇有趣的研究论文</a>描述这个概念。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4bcba039696349c293c47fbc087c75e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*8A-waQ_3fOnYetBdJD469Q.png"/></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="dda3" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">更高的稳定性、速度和分辨率—增强GAN</h1><p id="fa5e" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">甘虽然具有破坏性，但也面临着挑战。生成的图像很清晰，但分辨率较低，不够多样。尽管正在进行研究和开发，学习过程仍然缺乏稳定性。</p><p id="9257" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">甘出现三年后，泰罗·卡拉斯和他的团队想出了一种新的网络训练方法，并在他们的作品“<a class="ae mv" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">为了提高质量、稳定性和变化而逐步培养甘”</a>中描述了这种方法该方法包括在训练发生器和鉴别器时对它们的不断改进。</p><p id="2fab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">研究人员开始使用低分辨率图像训练网络模型，通过应用连续层逐渐提高分辨率。增量方法允许学习机制首先发现图像分解的大规模结构，然后关注每个图像的更细粒度的细节，而不是一次性学习所有内容。这种方法在生成高度逼真的人脸图像方面取得了一些惊人的成果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/f12283e9e65709740d2b80c5062a81f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d1EGpj00PNxjGNaKQiS4ww.png"/></div></div></figure><p id="f162" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，该机制显著减少了训练时间，根据目标分辨率的不同，训练时间从2倍减少到6倍。由于生成图像的高照片真实感，该方法还加速了该技术的发展并导致其新的应用。</p><p id="0547" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的图片摘自<a class="ae mv" href="https://arxiv.org/pdf/1802.07228.pdf" rel="noopener ugc nofollow" target="_blank">一篇关于人工智能和人工智能发展的研究论文</a>，最好地展示了Karras的突破如何在过去几年里影响了GANs的发展。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c291710305368cb77c923dcd6b3add54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*MhKPZIXI4K8cbYgfYM7h8A.png"/></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="6ebb" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">年龄增长</h1><p id="5f33" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">现在让我们来讨论一下最新的应用热潮——年龄增长/回归。2017年，就该主题开展了多项研究。<a class="ae mv" href="https://trace.tennessee.edu/utk_graddiss/5257/" rel="noopener ugc nofollow" target="_blank">在其中一篇文章中，</a>田纳西大学的一组研究人员提到了<em class="mu">条件对抗自动编码器</em> (CAAE)的使用。</p><p id="874a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与目前可用的模型不同，CAAE机制不需要大量收集不同年龄的人脸图像作为输入。取而代之的是，它假设每张脸都可以用多维度来表示，我们可以通过导航选定的维度来使它看起来更老或更年轻，而不会导致任何特征的损失。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/88c0bec74a058bbc195304b85962cf93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*QBsRCfQSVAzZtTYTTh-RHw.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">条件对抗自动编码器</p></figure><p id="e39e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CAAE网络由两个鉴别器组成，可以提供不同年龄的任何人脸的难以置信的逼真表现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/324ef74527a890e159234e074e4b0d2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*hE-Lxa99mZSNe08nz6AGPg.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">CAAE图</p></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="92ca" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">条件对抗性自动编码器是如何工作的？</h1><p id="fe00" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated"><em class="mu">“E”</em>编码器将人脸图像映射到“<em class="mu">z”</em>矢量(个性)。通过将'<em class="mu"> l' </em>年龄标签添加到'<em class="mu"> z' </em>向量，它还创建了一个新的潜在向量<em class="mu">【z，l】</em>，为生成器'<em class="mu"> G.' </em>提供输入</p><p id="f515" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">编码器和生成器都基于输入和输出面之间的差异'<em class="mu"> L2' </em>进行更新。'<em class="mu"> Dz' </em>鉴别器对'<em class="mu">z '</em>施加均匀分布，而鉴别器'<em class="mu"> Dimg' </em>要求输出人脸对于给定的年龄标签是照片级真实可信的。</p><p id="4a26" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在这里找到这个机制的详细解释以及描述它的研究论文<a class="ae mv" href="https://arxiv.org/pdf/1702.08423.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a0e9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CAAE在任何给定的时间点(年龄)提供高度逼真的人脸进展，这导致其在人脸识别系统、娱乐和营销中的广泛应用。</p><h1 id="449e" class="lx ly it bd lz ma nd mc md me ne mg mh jz nf ka mj kc ng kd ml kf nh kg mn mo bi translated">文本到照片的翻译</h1><p id="f082" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">我想提到的GAN的另一个令人兴奋的应用是从文本生成图像的能力，这些图像描述了它们应该表示的内容。</p><p id="cb4a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">2016年，张寒在他的一部作品《<a class="ae mv" href="https://arxiv.org/abs/1612.03242" rel="noopener ugc nofollow" target="_blank"> StackGAN:利用堆叠生成对抗网络进行文本到照片的逼真图像合成</a>》中提出了使用GAN进行文本到照片翻译的概念。现在，我们称他的发现为<em class="mu">堆叠生成对抗网络</em> (StackGAN)。</p><p id="176c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">StackGAN网络可以从文本描述中生成分辨率为256 x 256 px的照片级真实感图像。这一复杂的过程包括两个阶段:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/af34e77e5f39bfa246a318d986e81fed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*HO16eaUadWmaSxuDBie6NQ.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">斯塔克甘过程</p></figure><p id="93bf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一阶段GAN(图的上半部分)根据提供的文本描述，绘制一个对象的原始形状，并对其应用颜色，从而生成一个低分辨率的图像。</p><p id="6d25" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第二阶段GAN将此图像和原始描述作为输入，生成具有逼真细节的高分辨率图像。此外，它可以消除第一阶段产生的各种故障和像差，并通过添加微小而重要的细节来完善图像。</p><p id="909b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是该方法的一个示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/8eba404a60ecc3786f947856d5ca92c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*JyB7_nYnOoUPjeEGYrJVFw.png"/></div></figure><h1 id="30e5" class="lx ly it bd lz ma nd mc md me ne mg mh jz nf ka mj kc ng kd ml kf nh kg mn mo bi translated">生成视频</h1><p id="8ab0" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">最近，我一直在考虑在电影制作中使用甘。想象一下，有一天，整个电影将由人工智能生成，并实时交付给我们。你会得到你所期待的电影，根据你的独特品味量身定制，电影角色将能够表演任何没有特效的特技。</p><p id="85c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正在进行研究以实现这一愿景。2016年，Carl Vondrick发表了一篇题为“<a class="ae mv" href="https://arxiv.org/pdf/1609.02612.pdf" rel="noopener ugc nofollow" target="_blank">用场景动态</a>生成视频”的研究论文，他在论文中描述了一种由他开发的机制，可以一个接一个地动态生成电影帧。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/f4de1b230f9446d86ba4a23e1310eef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*5We2ZFkS5Azr2uWvxhgH_w.png"/></div></figure><p id="859f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了实现这一点，Vondrick使用了GAN和时空卷积架构，可以将每个场景的前景从背景中分离出来。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/aecab31c38ba3b0641b4ebbd7d7cbce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*U7SKwTsFVPWJcw6S8aehTg.png"/></div></figure><p id="f3b9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Vondrick发明的技术仍然需要一些工作，但我们已经可以想象它在未来会带来的机会。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="bf3c" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">未来可能的氮化镓应用</h1><p id="8304" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">在不久的将来，氮化镓几乎可以有无限的应用。它将提高娱乐、机器设计、建筑、销售和广告等众多任务和流程的效率。以下是一些可能的情况。</p><h2 id="fdfb" class="ni ly it bd lz nj nk dn md nl nm dp mh ld nn no mj lh np nq ml ll nr ns mn nt bi translated">娱乐</h2><p id="1d53" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">事情是这样的:你进入你的网飞账户，获得专门为你生成的内容。没有场景和演员是真实的——他们从来没有存在过——但是他们是如此的真实，以至于你无法把他们和真实的东西区分开来。对我们现实的逼真再现赋予了角色人类无法拥有的技能和能力，并允许他们在没有任何CGI的情况下做不可思议的事情。</p><p id="3fc3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，尽管整部电影非常逼真，但其制作时间和成本却大幅下降。更进一步，当基于人工智能的解决方案掌握了所有人类特征和手势时，它将能够按需动态地创建令人惊叹的图片。</p><h2 id="e023" class="ni ly it bd lz nj nk dn md nl nm dp mh ld nn no mj lh np nq ml ll nr ns mn nt bi translated">建筑和室内设计</h2><p id="23d3" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">第二个例子是GAN在工程和建筑上的应用。这里我们至少可以想象几个实际的用例。例如，让我们假设你想设计或重新装修你的公寓。</p><p id="ce3b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，你打开一个手机应用程序，通过智能手机镜头扫描你的公寓。然后，你选择设计风格。底层机制生成实时预览，显示设计在您的空间中的外观。同时，它为您提供了设计中使用的家具和电器的列表，以及价格表和可以购买所有物品的商店。</p><p id="11e0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在建筑中，我们可以应用类似的解决方案来更快地生成计划和可视化，并且比目前由人类制作的计划和可视化具有更高的细节水平。</p><h2 id="54a7" class="ni ly it bd lz nj nk dn md nl nm dp mh ld nn no mj lh np nq ml ll nr ns mn nt bi translated">电子商务</h2><p id="5570" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">电子商务是另一个可以大大受益于GAN的行业。想象一个在线时尚企业。作为顾客，你可以把你的照片上传到商店的应用程序上，然后足不出户就可以虚拟试穿各种服装，看看自己穿起来会是什么样子。这种解决方案允许更容易和更快地做出决策；一些品牌已经在他们的电子商店中实现了。</p><h2 id="3154" class="ni ly it bd lz nj nk dn md nl nm dp mh ld nn no mj lh np nq ml ll nr ns mn nt bi translated">3D设计和模型</h2><p id="69ce" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">GAN也为3D设计和建模提供了巨大的机会。目前手动执行的所有设计过程都可以通过创成式模型实现自动化。</p><p id="dbe7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我们将它们与3D打印结合起来时，我们将能够为各种物体和设备的设计和制造建立一个完全自主的系统。它将如何工作？这很简单。您将启动一个应用程序，告诉系统您需要什么输出，然后等待它创建想要的工件。</p></div></div>    
</body>
</html>
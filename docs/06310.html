<html>
<head>
<title>Intro to RNN: Character-Level Text Generation With PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RNN简介:用PyTorch生成字符级文本</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/intro-to-rnn-character-level-text-generation-with-pytorch-db02d7e18d89?source=collection_archive---------1-----------------------#2020-09-20">https://betterprogramming.pub/intro-to-rnn-character-level-text-generation-with-pytorch-db02d7e18d89?source=collection_archive---------1-----------------------#2020-09-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1264" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在Amazon SageMaker中训练和部署PyTorch模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/46f5c5f0ab3c6b2bb0c8dbf605c7f9fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5k5SguBod8HdI7FE"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克林特·王茂林在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a3c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天，我们将通过介绍递归神经网络的操作和使用来从一个小的初始文本生成文本，继续我们在自然语言处理(NLP)的迷人世界中的旅程。这种类型的问题被称为<em class="lv">语言建模</em>，当我们想要预测单词或字符输入序列中的下一个单词或字符时使用。</p><p id="559a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是在语言建模问题中，单词的存在并不是唯一重要的事情，它们的顺序也很重要——例如，当出现在文本序列中时<em class="lv">。换句话说，围绕每个单词的上下文成为预测下一个单词的基础。</em></p><p id="af5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，基于单词频率和概率的传统NLP方法不是很有效，因为它们基于单词相互独立的前提。</p><p id="79c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是RNN网络可以成为一个基本工具的地方，因为它们有能力记住一系列输入的不同部分，这意味着它们可以考虑句子的前面部分来解释上下文。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="9c32" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">RNN简介</h1><p id="785f" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">总之，在一个普通的神经网络中，一个层的输出是它的输入应用一些可学习的权重的函数或变换。</p><p id="82ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相比之下，在RNN中，不仅考虑输入，还考虑网络本身的上下文或先前状态。当我们在网络中向前传递时，它构建其状态的表示，旨在收集在先前步骤中获得的信息，这被称为<em class="lv">隐藏状态。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/e800d82b72be5ccd687ad1efd18046d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2pMVdBB-15TprOt6iKfgvg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://cs230.stanford.edu/" rel="noopener ugc nofollow" target="_blank">斯坦福CS230深度学习</a>课程</p></figure><blockquote class="nb nc nd"><p id="f079" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">这里，对于每个时间步长<em class="it"> t </em>，我们有一个激活<em class="it">a&lt;t&gt;T15】和一个输出<em class="it"> y &lt; t &gt;。</em>我们有一组权重将输入转换为隐藏层表示，第二组权重将信息从先前的隐藏状态带入下一个时间步，第三组权重控制有多少信息从实际状态传输到输出。”</em></p><p id="6788" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">[3] <a class="ae ky" href="https://www.jeremyjordan.me/introduction-to-recurrent-neural-networks/" rel="noopener ugc nofollow" target="_blank">“递归神经网络简介</a>”作者杰瑞米·乔登</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/fcb944978a5103f8e62e7645ee831da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcJKHG6NGP_dcrEsEoNqHQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">斯坦福CS-230深度学习课程的RNN操作</p></figure><p id="a841" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">序列中的每个元素都对当前状态有贡献，输入和先前的隐藏状态为任意长的观察序列更新隐藏状态的值。rnn可以记住以前的条目，但这种能力在时间或步骤上受到限制，这是这些网络首先要解决的挑战之一。</p><blockquote class="nb nc nd"><p id="85aa" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">“输入序列越长，网络‘遗忘’越多。随着时间的推移，不相关的数据积累起来，它会屏蔽掉网络对文本模式做出准确预测所需的相关数据。这被称为<a class="ae ky" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度问题</a>—维基百科</p></blockquote><p id="aeb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以通过这个<a class="ae ky" href="https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484" rel="noopener" target="_blank">链接</a>更深入地了解这个问题。这是深度神经网络的常见问题。在NLP和RNN领域，为了解决这个问题，已经开发了一些高级架构，如LSTM和GRUs。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="dd86" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><em class="ni">长短期记忆</em> (LSTM)</h1><p id="11ff" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">LSTM网络试图保留来自更早步骤的相关信息，为此它们包含多个门，这些门控制从输入和先前状态保留或删除多少信息:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/129896862399d6fe151f52c83bbd28a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSNuFRMbb1qDEROGrVcIhg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自<a class="ae ky" href="https://scholar.google.com/citations?user=MIxOsDoAAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank"> Savvas Varsamopoulos </a>的“设计基于神经网络的表面码解码器”</p></figure><p id="8ac2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> W </em>是前一个隐藏层和当前隐藏层之间的递归连接。<em class="lv"> U </em>是将输入连接到隐藏层的权重矩阵，<em class="lv"> C </em>是基于当前输入和先前隐藏状态计算的候选隐藏状态。<em class="lv"> C </em>是本机的内部存储器。</p><ul class=""><li id="b70f" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">忘记盖茨:现在应该考虑多少来自过去的信息？</li><li id="ffc7" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">输入门+细胞门:我们是否应该从输入中给状态增加信息，增加多少？</li><li id="2237" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">输出门:我们应该从前一个状态输出多少信息？</li></ul><blockquote class="nb nc nd"><p id="4443" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated"><strong class="lb iu">“以类似的方式，LSTM工作如下:</strong></p><p id="b453" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">它不仅记录短期记忆，还记录长期记忆</p><p id="6483" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">在序列的每一步中，长时记忆和短时记忆会合并</p><p id="8970" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">由此，我们获得了新的长期记忆、短期记忆和预测”</p><p id="096c" class="kz la lv lb b lc ld ju le lf lg jx lh ne lj lk ll nf ln lo lp ng lr ls lt lu im bi translated">— <a class="ae ky" href="http://Recurrent Neural Networks &amp; LSTMs" rel="noopener ugc nofollow" target="_blank"> Peter Foy，“递归神经网络简介&amp;lst ms”</a></p></blockquote></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="f6e0" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">在Amazon SageMaker中创建和部署一个ML模型</h1><p id="b384" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">首先，我们使用一个笔记本实例来列举SageMaker项目概要中的步骤(Amazon的笔记本描述了这些步骤):</p><ol class=""><li id="54bf" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu ny nq nr ns bi translated">下载或以其他方式检索数据。</li><li id="d161" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu ny nq nr ns bi translated">处理/准备数据。</li><li id="ec73" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu ny nq nr ns bi translated">将处理后的数据上传到S3。</li><li id="9765" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu ny nq nr ns bi translated">训练选定的模型。</li><li id="a6b9" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu ny nq nr ns bi translated">测试训练好的模型(通常使用批处理转换作业)。</li><li id="b011" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu ny nq nr ns bi translated">部署训练好的模型。</li><li id="aafc" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu ny nq nr ns bi translated">使用部署的模型。</li></ol><p id="15c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这个项目，您将按照概要中的步骤进行一些修改，我们将在部署的模型上测试模型。</p><p id="56ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">源代码在<a class="ae ky" href="https://github.com/edumunozsala/Character-Level-Text-Generation" rel="noopener ugc nofollow" target="_blank">我的github库</a>公开，这是<a class="ae ky" href="https://github.com/edumunozsala/Character-Level-Text-Generation/blob/master/char-level-text-generator-pytorch-SageMaker.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>到完整的笔记本。这里我们将只显示更相关的部分。</p><h2 id="b078" class="nz me it bd mf oa ob dn mj oc od dp mn li oe of mp lm og oh mr lq oi oj mt ok bi translated">下载并准备数据集</h2><p id="75df" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">步骤1和2并不特定于SageMaker工具；不管平台如何，它们本质上都是一样的。所以我们不打算讨论它们。我们将只提及我们数据集的来源。</p><p id="f9c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将定义我们希望模型在输入第一个单词或前几个字符时输出的句子。我们的数据集是一个包含莎士比亚戏剧或书籍的文本文件，我们将从中提取一系列字符作为模型的输入。然后我们的模型将学习如何完成像“莎士比亚会做的”这样的句子这个数据集可以从<a class="ae ky" href="https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt" rel="noopener ugc nofollow" target="_blank">卡帕西的GitHub账户</a>下载。</p><p id="d1ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们只需要将文本小写，并创建相应的字典:char2int将单词转换为整数，int2char进行相反的过程。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><h2 id="38a0" class="nz me it bd mf oa ob dn mj oc od dp mn li oe of mp lm og oh mr lq oi oj mt ok bi translated">对文本进行编码，并创建输入和目标数据集</h2><p id="c6b2" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">现在我们可以对文本进行编码，用字典中的整数值替换每个字符。当我们统一并准备好数据集后，我们应该做一个快速检查，看看我们的模型将要训练的数据的例子。这通常是一个好主意，因为它允许您看到每个进一步的处理步骤是如何影响审查的，并且它还确保数据已经被正确地加载。</p><p id="2932" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们要在每个时间步预测序列中的下一个字符，我们必须将每个句子分成:</p><ul class=""><li id="e601" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated"><strong class="lb iu">输入数据</strong>:应排除最后一个输入字符，因为它不需要输入到模型中(它是最后一个输入字符的目标标签)</li><li id="713d" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><strong class="lb iu">目标/地面实况标签</strong>:比输入数据超前一个时间步长。因为这将是模型在对应于输入数据的每个时间步长的正确答案。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="3bdb" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">将数据上传到亚马逊S3</h1><p id="29f5" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">现在，我们需要将训练数据集上传到S3，以便我们的训练代码能够访问它。事实上，我们将把它保存在本地，稍后在运行培训时，它将被上传到S3。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="c2b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>上面的单元格上传了我们数据目录的全部内容。这包括<code class="fe on oo op oq b">char_dict.pkl</code> (char2int)和<code class="fe on oo op oq b">int_dict.pkl</code> (int2char)文件。这很幸运，因为我们稍后在创建接受任意输入文本的端点时会用到它。现在，我们将只注意到它驻留在数据目录中的事实(因此也在S3培训桶中),并且我们将需要确保它被保存在模型目录中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/cce214ff2e5361a23df7ff89ede8b2a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*MzljuN7xpBYzUaQNQ8fbHg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自沃纳·威格尔的《<a class="ae ky" href="https://www.allthingsdistributed.com/2018/03/Infinitely-scalable-machine-learning-with-Amazon-SageMaker.html" rel="noopener ugc nofollow" target="_blank">用亚马逊SageMaker进行无限可扩展的机器学习</a></p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="81fc" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">构建并训练PyTorch模型</h1><p id="59eb" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">特别地，SageMaker框架中的模型包括三个对象:</p><ul class=""><li id="d420" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">模型人工制品，</li><li id="0fca" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">培训代码</li><li id="35f0" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">推理代码</li></ul><p id="7eba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些都是相互作用的。</p><p id="e95b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将从在PyTorch中实现我们自己的神经网络以及一个训练脚本开始。出于这个项目的目的，我们需要在<code class="fe on oo op oq b">train</code>文件夹内的<code class="fe on oo op oq b">model.py</code>文件中提供模型对象实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="89b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个模型非常简单，只有几层:</p><ul class=""><li id="ec1b" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">充当编码器的LSTM层</li><li id="02e9" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">减少过度拟合的脱落层</li><li id="3eeb" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">解码器或全连接或密集层，返回每个字符成为下一个字符的概率</li></ul></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="ee41" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">在SageMaker上训练模型</h1><p id="c3df" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">当在SageMaker中构造PyTorch模型时，必须指定一个入口点。这是将在模型训练时执行的Python文件。在<code class="fe on oo op oq b">train</code>目录中有一个名为<code class="fe on oo op oq b">train.py</code>的文件，它包含了训练我们的模型所需的大部分代码。</p><p id="5714" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意</strong>:需要的地方必须将<code class="fe on oo op oq b">train_main()</code>函数粘贴到<code class="fe on oo op oq b">train/train.py</code>文件中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="9a39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SageMaker将超参数传递给训练脚本的方式是通过参数。然后，这些参数可以被解析并在训练脚本中使用。要了解这是如何做到的，请看一下提供的<code class="fe on oo op oq b">train/train.py</code>文件。</p><p id="1a9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，<code class="fe on oo op oq b">train.py file</code>中的主函数执行以下步骤:</p><ul class=""><li id="1572" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">加载数据集</li><li id="01d5" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">创建批处理数据生成器</li><li id="3b35" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">从以前的执行中创建或恢复模型</li><li id="0edc" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">训练和评估模型</li><li id="2b93" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">保存模型和字典用于推理</li></ul><h2 id="a6fd" class="nz me it bd mf oa ob dn mj oc od dp mn li oe of mp lm og oh mr lq oi oj mt ok bi translated"><strong class="ak">主列车算法</strong></h2><p id="a5ac" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">一旦我们有了<code class="fe on oo op oq b">train.py</code>文件，我们就可以在SageMaker中创建一个培训任务了。首先，我们需要设置哪种类型的实例将运行我们的培训:</p><ul class=""><li id="2f28" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">我们没有启动一个真正的计算实例，只是一个运行脚本的容器。这个场景对于测试训练脚本是否工作正常非常有用，因为运行容器比运行计算实例更快。但是，最后，当我们确认一切正常时，我们必须为一个真实的训练实例更改实例类型。</li><li id="07ba" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><code class="fe on oo op oq b"><strong class="lb iu">ml.m4.4xlarge</strong></code> <strong class="lb iu"> : </strong>这是CPU实例</li><li id="eb26" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><code class="fe on oo op oq b"><strong class="lb iu">ml.p2.xlarge</strong></code> <strong class="lb iu"> : </strong>管理大量数据进行训练时使用的GPU实例。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="8d32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，SageMaker启动一个计算实例，在那里执行我们的训练代码，根据数据和模型的复杂性，通常需要几个小时或几天的时间(在我们的例子中，大约需要45-60分钟)。如果打印出来，你可以在亚马逊CloudWatch上跟踪训练进度。最后，模型工件被存储在S3，它们将在部署步骤中被加载。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/806853f6997e56af422442e718d2726e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zTMjXrhIVLNr1WSTjfeRw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">安德鲁·布坎南在<a class="ae ky" href="https://unsplash.com/s/photos/text-prediction?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="2e37" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">定义推理算法</h1><p id="7c9f" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">现在是时候创建一些定制的推理代码了，这样我们就可以向模型发送一个未被处理的初始字符串，并确定字符串中的下一个字符。</p><p id="d648" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下，我们创建的评估器在部署时，将使用我们在创建模型时提供的条目脚本和目录。然而，由于我们希望接受一个字符串作为输入，并且我们的模型需要一个经过处理的文本，所以我们需要编写一些定制的推理代码。</p><p id="e3c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将把推理代码存储在<code class="fe on oo op oq b">serve</code>目录中。这个目录中提供了我们用来构建模型的<code class="fe on oo op oq b">model.py</code>文件，一个包含我们在初始数据处理过程中使用的<code class="fe on oo op oq b">one-hot-encode</code>和<code class="fe on oo op oq b">encode_text</code>预处理函数的<code class="fe on oo op oq b">utils.py</code>文件，以及一个包含我们的定制推理代码的<code class="fe on oo op oq b">predict.py</code>文件。还要注意<code class="fe on oo op oq b">requirements.txt</code>的存在，它将告诉SageMaker我们的定制推理代码需要哪些Python库。</p><p id="d826" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在SageMaker中部署PyTorch模型时，您需要提供SageMaker推理容器将使用的四个函数。</p><ul class=""><li id="2674" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">这个函数与我们在训练脚本中使用的函数相同，它告诉SageMaker如何加载我们的模型。这个函数必须被调用<code class="fe on oo op oq b">model_fn()</code>,并将模型工件存储目录的路径作为唯一的参数。这个函数也必须存在于我们指定为入口点的Python文件中。它还读取保存的字典，因为它们应该在推理过程中使用。</li><li id="842d" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><code class="fe on oo op oq b">input_fn</code>:这个函数接收已经发送到模型端点的原始序列化输入，它的工作是反序列化输入并使其可用于推理代码。稍后我们会提到我们的<code class="fe on oo op oq b">input_fn</code>函数在做什么。</li><li id="0e78" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><code class="fe on oo op oq b">output_fn</code>:这个函数获取推理代码的输出，它的工作是序列化这个输出，并将其返回给模型端点的调用者。</li><li id="563b" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><code class="fe on oo op oq b">predict_fn</code>:推理脚本的核心，这是完成实际预测的地方，也是您需要完成的功能。</li></ul><p id="bae6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在亚马逊文档中可以找到详尽的解释。</p><p id="ca28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们在这个项目中构建的简单示例，<code class="fe on oo op oq b">input_fn</code>和<code class="fe on oo op oq b">output_fn</code>方法相对简单。我们需要接受一个字符串作为输入，由输出的期望长度和初始字符串组成。我们希望返回一个字符串作为输出，即生成的新文本。但是，您可能会想到，在一个更复杂的应用程序中，输入或输出可能是图像数据或其他一些需要序列化的二进制数据。</p><p id="5e9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们必须构建一个<code class="fe on oo op oq b">predict_fn</code>方法，它将接收输入字符串，对其进行编码(char2int)，一次性编码，并将其发送给模型。每个输出都将被解码(int2char)并附加到最终的输出字符串中。</p><p id="9179" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">确保将完成的文件作为<code class="fe on oo op oq b">predict.py</code>保存在<code class="fe on oo op oq b">serve</code>目录中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="1ce3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，<em class="lv">推理过程</em>包括处理和编码输入字符串，初始化模型的状态，为每个字符执行模型的向前传递，以及更新模型的状态。每次迭代的输出返回每个字符成为下一个字符的概率。我们对这些概率进行采样以提取下一个字符，并将其加入到输出文本字符串中。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="1e78" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">部署用于推理的模型</h1><p id="6532" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">既然已经编写了定制推理代码，我们将创建并部署我们的模型。首先，我们需要构建一个新的<code class="fe on oo op oq b">PyTorchModel</code>对象，它指向训练期间创建的模型工件，也指向我们希望使用的推理代码。然后我们可以调用deploy方法来启动部署容器。</p><p id="a9d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>已部署PyTorch模型的默认行为是假设传递给预测器的任何输入都是一个<code class="fe on oo op oq b">numpy</code>数组。在我们的例子中，我们想要发送一个字符串，所以我们需要围绕<code class="fe on oo op oq b">RealTimePredictor</code>类构造一个简单的包装器来容纳简单的字符串。在更复杂的情况下，您可能希望提供一个序列化对象，例如，如果您希望发送图像数据。</p><p id="a778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以部署我们训练过的模型</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="1707" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>在部署模型时，您要求SageMaker启动一个计算实例，该实例将等待数据发送给它。因此，这个计算实例将继续运行，直到<em class="lv">您</em>将其关闭。了解这一点很重要，因为部署端点的成本取决于它运行的时间。</p><p id="51bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，如果您不再使用已部署的端点，请将其关闭！</p><p id="b500" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试我们模型的时候到了——非常简单:</p><pre class="kj kk kl km gt ot oq ou ov aw ow bi"><span id="5d89" class="nz me it oq b gy ox oy l oz pa">init_text <strong class="oq iu">=</strong> sentences[963:1148]<br/>test_text <strong class="oq iu">=</strong> str(len(init_text))<strong class="oq iu">+</strong>'-'<strong class="oq iu">+</strong>init_text<br/>new_text <strong class="oq iu">=</strong> predictor.predict(test_text).decode('utf-8')<br/>print(new_text)</span><span id="6e95" class="nz me it oq b gy pb oy l oz pa"><strong class="oq iu">Text</strong>:  he did content to say it was for his country he did it to please his mother and to be partly proud; which he is, even till the altitude of his virtue. what he cannot help in his nature,</span><span id="9b6e" class="nz me it oq b gy pb oy l oz pa"><strong class="oq iu">Init text</strong>:  he did content to say it was for his country he did it to</span><span id="3d16" class="nz me it oq b gy pb oy l oz pa"><strong class="oq iu">Text predicted</strong>: he did content to say it was for his country he did it to please his mother and to be partly proud which he is even till the altitude of his virtue what he cannot help in his nature of</span></pre><p id="8edb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所观察到的，预测文本实际上与原始文本相同，这意味着我们的网络能够生成它在训练阶段收到的文本——它的记忆工作正常！</p><p id="724d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，当服务不被使用时，您必须关闭它。</p><pre class="kj kk kl km gt ot oq ou ov aw ow bi"><span id="8fe8" class="nz me it oq b gy ox oy l oz pa">predictor.delete_endpoint()</span></pre></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="af6c" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">参考</h1><ul class=""><li id="79b5" class="nk nl it lb b lc mv lf mw li pc lm pd lq pe lu np nq nr ns bi translated">[1] <a class="ae ky" href="https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/" rel="noopener ugc nofollow" target="_blank">“使用Python和TensorFlow/Keras生成文本”</a>，作者Dan Nelson</li><li id="4f5e" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">[2] <a class="ae ky" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks" rel="noopener ugc nofollow" target="_blank">“递归神经网络备忘单”斯坦福CS-230深度学习</a>作者<a class="ae ky" href="https://twitter.com/afshinea" rel="noopener ugc nofollow" target="_blank"> Afshine Amidi </a>和<a class="ae ky" href="https://twitter.com/shervinea" rel="noopener ugc nofollow" target="_blank"> Shervine Amidi </a></li><li id="e3f4" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">[3] <a class="ae ky" href="https://www.jeremyjordan.me/introduction-to-recurrent-neural-networks/" rel="noopener ugc nofollow" target="_blank">“递归神经网络简介</a>”作者杰瑞米·乔登</li><li id="38f0" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank">“递归神经网络的不合理有效性</a>”作者Andrej Karpathy</li><li id="532b" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484" rel="noopener" target="_blank">《消失的渐变问题</a>》，作者池汪锋</li><li id="f7da" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4" rel="noopener ugc nofollow" target="_blank">“用代码</a>从零开始理解LSTM细胞的结构”，作者Manik Soni</li><li id="31d3" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://www.mlq.ai/guide-to-recurrent-neural-networks-lstms/" rel="noopener ugc nofollow" target="_blank">“递归神经网络简介&amp; LSTMs </a>”作者彼得·福伊</li><li id="b89b" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://www.researchgate.net/publication/329362532_Designing_neural_network_based_decoders_for_surface_codes" rel="noopener ugc nofollow" target="_blank">“设计基于神经网络的表面码解码器</a>”，作者:Savvas Varsamopoulos、Koen Bertels和Carmen G. Almudever</li></ul></div></div>    
</body>
</html>
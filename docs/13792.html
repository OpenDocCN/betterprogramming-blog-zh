<html>
<head>
<title>Convert Podcasts to Text With OpenAI’s Whisper API Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python通过OpenAI的Whisper API将播客转换为文本</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/openais-whisper-tutorial-42140dd696ee?source=collection_archive---------2-----------------------#2022-09-28">https://betterprogramming.pub/openais-whisper-tutorial-42140dd696ee?source=collection_archive---------2-----------------------#2022-09-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cf93" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本教程一步一步地指导新的开源模型Whisper！这是最先进的语音识别技术！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ef20090c0e30e34972f65bd0488fe5aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4LcKdsdcZXh5P7U3"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@apellaes?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">亚历山大·佩莱斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="9727" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenAI开源Whisper模型——最先进的语音识别系统。</p><p id="f1b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们测试了一下，印象深刻！</p><p id="3192" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们拍了最新的RealPython一集，时长1小时10分钟。我们用一个基本的CPU花了56分钟，用最小的耳语模型将音频文件转换成几乎完美的文本转录。</p><p id="4830" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们用几行Python代码展示了在实践中使用Whisper的步骤。</p><h1 id="34e8" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">教程</strong></h1><p id="f172" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本教程用一段代码解释了在本地机器和云环境中使用Whisper模型的方法。</p><p id="a86f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GitHub上有whisper模型。我们使用下面的命令直接在Jupyter笔记本中下载它:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="af43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Whisper模型使用<code class="fe mu mv mw mx b"><a class="ae ky" href="https://ffmpeg.org" rel="noopener ugc nofollow" target="_blank">ffmpeg</a></code>程序作为需求。一些云环境可能已经包含了它，但是很可能您的本地机器需要安装这个程序。</p><p id="1142" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenAI指的是安装这个包的多种方法，我们在这里通过使用<a class="ae ky" href="https://scoop.sh/" rel="noopener ugc nofollow" target="_blank"> Scoop </a>包管理器来应用其中的一种。在我们看来，这很简单，因为您可以通过在终端窗口中运行以下两个命令来让它工作:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="31cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一行安装勺子。第二行使用Scoop包管理器安装<code class="fe mu mv mw mx b">ffmpeg</code>程序。</p><p id="2fa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一步在本地机器中是必需的，但是我们不需要在我们的云环境中执行这一步。</p><p id="8bfa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们重启内核以确保安装生效。</p><p id="4743" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以导入库:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="78d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Whisper使用GPU运行速度更快。我们用Whisper转录了一个1小时10分钟的播客。花了:</p><ul class=""><li id="1fa5" class="my mz it lb b lc ld lf lg li na lm nb lq nc lu nd ne nf ng bi translated">在本地机器上用CPU运行它需要56分钟</li><li id="c9bc" class="my mz it lb b lc nh lf ni li nj lm nk lq nl lu nd ne nf ng bi translated">在云环境下用GPU运行4分钟。</li></ul><p id="30b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用下面的代码测试了GPU的可用性。如果兼容Cuda的Nvidia GPU不可用，则第一行结果为False，如果可用，则为<code class="fe mu mv mw mx b">True</code>。第二行代码将模型设置为首选GPU，只要它可用。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="bcef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以加载Whisper模型。我们在load_model中包含了两个变量。“基础”是具有7400万个参数的版本的耳语模型名称。3900万到15.5亿个参数之间，每个模型都有对应的模型名称。这里的<a class="ae ky" href="https://github.com/openai/whisper" rel="noopener ugc nofollow" target="_blank">指的是每个型号的名称和特性</a>。我们在上一节中定义了第二个“设备”变量。代码的第二行让我们打印模型语言和参数的总数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="383d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用Whisper模型来录制从互联网下载的播客。音频文件可以在本地目录中找到。</p><p id="5a0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用<code class="fe mu mv mw mx b">“load_audio” </code>命令加载这个音频。<code class="fe mu mv mw mx b"> “pad_or_trim”</code>命令将音频填充并修剪成30秒的时间段。最后一行为我们的本地设备创建了<code class="fe mu mv mw mx b">log-Mel</code>声谱图。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="aa2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mu mv mw mx b">detect_language</code>检测音频文件语言:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="85cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用<code class="fe mu mv mw mx b">DecodingOptions</code>和<code class="fe mu mv mw mx b">decode</code>命令转录音频。我们可以打印前30秒的音频。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="d9ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用<code class="fe mu mv mw mx b">transcribe</code>命令转录整个音频文件并打印结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="c22b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">执行这段代码将得到音频文件的完整副本，我们在这里打印了它的简短部分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/6a2dedbf78ed04e896dfb97eac78a3af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMQE-exjLBwv_BVR8Kvojg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://realpython.com/podcasts/rpp/" rel="noopener ugc nofollow" target="_blank"> RealPython-podcast </a>第126集的<strong class="bd nn">播客抄本</strong>的示例片段。[图片由作者提供]</p></figure><p id="4015" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转录用GPU产生us用了4分钟，CPU用了56分钟。</p><p id="2f44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="b6f7" class="lv lw it bd lx ly nv ma mb mc nw me mf jz nx ka mh kc ny kd mj kf nz kg ml mm bi translated"><strong class="ak">参考文献</strong></h1><p id="6039" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">[1] <a class="ae ky" href="https://cdn.openai.com/papers/whisper.pdf" rel="noopener ugc nofollow" target="_blank">拉德福德等，2022 </a>。基于大规模弱监督的鲁棒语音识别。OpenAI。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Computer Vision: How to Set Up Your CNN Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉:如何建立你的CNN架构</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/computer-vision-how-to-set-up-your-cnn-architecture-229c014db7fb?source=collection_archive---------5-----------------------#2021-01-08">https://betterprogramming.pub/computer-vision-how-to-set-up-your-cnn-architecture-229c014db7fb?source=collection_archive---------5-----------------------#2021-01-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="be00" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何为您的下一个计算机视觉项目设计架构，并查看PyTorch中的示例代码</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ccd95bbb029b484e88f044bd628c6a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*W1KHOU4curRzcsdS"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">美国宇航局在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的<a class="ae kv" href="https://unsplash.com/@nasa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">照片</a></p></figure><p id="9b93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在创建一个新的计算机视觉项目时，您必须做出许多决定，这些决定将最终影响您的模型的最终性能。您可以在不同类型的图层之间进行选择，例如卷积图层、池化图层、完全连接图层、softmax图层和分离图层。此外，同一类型有多个层是很常见的。</p><p id="fc26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，大多数不同类型的图层都可以自定义，通常需要设置输入和输出节点的数量，以及其他参数。本文将帮助您为不同类型的图层选择合适的数量，并设置合理的参数值。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="4480" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">卷积层</h1><p id="004f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">卷积层执行卷积，卷积是在输入图像上移动过滤器的操作，计算结果特征图中的值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4f08f91c3f20aa81e20b4c447a264391.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*baNJmuDoe5HSGtLJ1dWfUA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图</p></figure><p id="417b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个卷积层通常由多个滤波器组成，这将产生多个特征图。在CNN的训练期间，该模型将学习将什么权重应用于不同的特征图，并且因此能够识别要从输入图像中提取哪些特征。</p><p id="3c2a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过增加CNN中卷积层的数量，该模型将能够检测图像中更复杂的特征。</p><p id="ab64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，随着层数的增加，训练模型将花费更多的时间，并增加过度拟合的可能性。在设置一个相当简单的分类任务时，两个卷积层通常就足够了。然后如果结果精度太低，可以增加层数。</p><p id="2d13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">节点的适当数量也高度依赖于图像和手头任务的复杂性。通过改变节点的数量和评估结果的准确性，该模型可以运行多次，直到获得满意的结果。</p><p id="2509" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在完成多个计算机视觉项目后，开发人员将能够更好地猜测某个特定类型的项目需要多少个节点，从而减少所需的迭代次数。</p><p id="0ef1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用PyTorch，卷积层通常在开发人员定义的CNN模型类的<code class="fe mx my mz na b">__init__</code>函数中定义。将<code class="fe mx my mz na b">torch.nn</code>作为<code class="fe mx my mz na b">nn</code>输入，可以这样定义两个卷积层:</p><pre class="kg kh ki kj gt nb na nc nd aw ne bi"><span id="afd3" class="nf ma iq na b gy ng nh l ni nj">self.conv1 = nn.Conv2d(1, 10, 3)<br/>self.conv2 = nn.Conv2d(10, 32, 3)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="c6dc" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">汇集层</h1><p id="37a3" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">池层是一个减少模型计算成本的层，通过减少其输入的维度来帮助防止过度拟合。有不同类型的池层:</p><ul class=""><li id="0a87" class="nk nl iq ky b kz la lc ld lf nm lj nn ln no lr np nq nr ns bi translated"><strong class="ky ir">最大池:</strong>选择矩阵中的最大值</li><li id="0b85" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">最小池:</strong>选择矩阵中的最小值</li><li id="0b12" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">平均池:</strong>选择矩阵中值的平均值</li></ul><p id="8b4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在池层中，滤镜应用于图像的不同区域。窗口大小和步幅将决定输出的大小以及滤波器如何在输入矩阵上移动。最常见的是选择窗口大小<code class="fe mx my mz na b">(2, 2)</code>和步幅<code class="fe mx my mz na b">2</code>。</p><p id="3614" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于应该多长时间应用一个池层，没有教科书上的答案，开发者将再次被鼓励迭代，直到达到一个可接受的答案。然而，众所周知的计算机视觉模型VGG-16在池层之间使用两到三个卷积层，而VGG-19使用多达四层。</p><p id="694f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用PyTorch，池层通常在开发人员定义的CNN模型类的<code class="fe mx my mz na b">__init__</code>函数中定义。将<code class="fe mx my mz na b">torch.nn</code>作为<code class="fe mx my mz na b">nn</code>导入，可以这样定义一个池层:</p><pre class="kg kh ki kj gt nb na nc nd aw ne bi"><span id="b25b" class="nf ma iq na b gy ng nh l ni nj">self.pool = nn.MaxPool2d(2, 2)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="dc56" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">全连接层</h1><p id="ebfb" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">完全连接的层将其输入转换为所需的输出格式。在分类任务中，这通常包括将图像特征矩阵转换为<em class="ny"> 1xC </em>向量，其中<em class="ny"> C </em>是类的数量。</p><p id="b9b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于在CNN模型中应该选择多少个完全连接的层，不一定有正确的答案。然而，对于大多数模型，从一个或两个完全连接的层开始就足够了，以后根据最终的性能调整数量。</p><p id="b227" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用PyTorch，完全连接的层通常定义在开发人员定义的CNN模型类的<code class="fe mx my mz na b">__init__</code>函数中。将<code class="fe mx my mz na b">torch.nn</code>作为<code class="fe mx my mz na b">nn</code>导入，可以像这样定义两个完全连接的层:</p><pre class="kg kh ki kj gt nb na nc nd aw ne bi"><span id="7bb9" class="nf ma iq na b gy ng nh l ni nj">self.fc1 = nn.Linear(20*32*5*5, 120)<br/>self.fc2 = nn.Linear(120, 60)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="1aac" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">Softmax层</h1><p id="f624" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">softmax层通常在完全连接的层之后应用。这一层接受一个大小为<em class="ny"> 1xC </em>的向量作为输入，其中<em class="ny"> C </em>是类的数量，所有的数字加起来是1。</p><p id="2b63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，softmax层使用该向量并创建一个新向量，其中每个输入表示图像属于该特定类别的概率。因此，softmax主要用于分类任务。</p><p id="a18a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于大多数计算机视觉项目，一个softmax层就足够了。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="406a" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">脱落层</h1><p id="9e07" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">丢弃层涉及在训练期间以概率<em class="ny"> p </em>随机关闭节点。这种层特别有助于在非常复杂的模型中防止过度拟合。</p><p id="472d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">脱落层可以方便地应用于全连接层和卷积层。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="b9c6" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">原则</h1><p id="d05c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">适当的层数和节点数通常通过应用以下一组方法来找到:</p><ul class=""><li id="abc7" class="nk nl iq ky b kz la lc ld lf nm lj nn ln no lr np nq nr ns bi translated"><strong class="ky ir">实验:</strong>尝试不同的层数和节点数</li><li id="9056" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">直觉:</strong>利用以前的经验选择层数和节点数</li><li id="5484" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">追求深度:</strong>深度神经网络通常比浅层神经网络表现更好</li><li id="1108" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">借鉴思路:</strong>从描述类似项目的文章中借鉴思路</li><li id="ce93" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">搜索:</strong>创建一个自动搜索来测试不同的架构</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a271" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">资源</h1><p id="7cf0" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">【1】<a class="nz oa ep" href="https://medium.com/u/d2800f290ddf?source=post_page-----229c014db7fb--------------------------------" rel="noopener" target="_blank">Yash Upadhyay</a>。<strong class="ky ir"><em class="ny"/></strong><a class="ae kv" href="https://medium.com/alumnaiacademy/introduction-to-computer-vision-4fc2a2ba9dc" rel="noopener">计算机视觉:不同CNN架构及其应用研究<em class="ny"/>(2019年1月)</a>。</p><p id="d3dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">杰森·布朗利。"<a class="ae kv" href="https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">卷积层在深度学习神经网络中是如何工作的？"(2019年4月)。</a></p><p id="58b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]堆栈溢出。"如何决定用于图像分类的卷积神经网络的参数？"(2014年8月)。</p><p id="3055" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] <a class="nz oa ep" href="https://medium.com/u/d1cc5ee46383?source=post_page-----229c014db7fb--------------------------------" rel="noopener" target="_blank">阿迪特·德什潘德</a>。"<a class="ae kv" href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/" rel="noopener ugc nofollow" target="_blank">理解卷积神经网络的初学者指南第二部分"(2016年7月)。</a></p><p id="9ada" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">杰森·布朗利。<a class="ae kv" href="https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/" rel="noopener ugc nofollow" target="_blank">如何配置神经网络的层数和节点数(2018年7月)。</a></p></div></div>    
</body>
</html>
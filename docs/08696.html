<html>
<head>
<title>Perform XGBoost, KNN Modeling With Dimension Reduction Technique</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用降维技术执行XGBoost、KNN建模</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/perform-xgboost-knn-modeling-with-dimension-reduction-technique-9f4ca52feeaf?source=collection_archive---------7-----------------------#2021-06-01">https://betterprogramming.pub/perform-xgboost-knn-modeling-with-dimension-reduction-technique-9f4ca52feeaf?source=collection_archive---------7-----------------------#2021-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1535" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于MNIST数据集的机器学习算法建模</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2d1422576016c419aa8865d54fad015c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B277wqbAByDNfPW6iDICoA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="23ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将在MNIST数据集(手写数字图像)上建立一个分类机器学习算法模型。数据集包含灰度格式的从0到9的图像。每个图像的大小为28 x 28，总共784个像素。数据集已经被分成训练和测试CSV文件。</p><p id="0ac0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以从Kaggle下载数据集。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f15b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">简要定义</h1><ul class=""><li id="a100" class="mu mv it la b lb mw le mx lh my ll mz lp na lt nb nc nd ne bi translated"><a class="ae lu" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> XGBoost </strong> </a> <strong class="la iu"> : </strong>用于实现梯度增强技术下的ML算法。梯度推进决策树(GBDT)是一种精确有效的并行树推进，可用于分类和回归问题。</li><li id="5b19" class="mu mv it la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated"><strong class="la iu"> KNN: </strong>这是一种有监督和无监督的算法。在监督学习中，它可以用于离散和连续标签的分类和回归。在分类问题中，当决策边界不规则时，经常使用这种方法。在这篇<a class="ae lu" href="https://pub.towardsai.net/fully-explained-k-nearest-neighbors-with-python-ebbe27f93ba9" rel="noopener ugc nofollow" target="_blank">文章</a>中阅读更多关于KNN的信息。</li><li id="920b" class="mu mv it la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated"><strong class="la iu"> SVM: </strong>这是一种机器学习分类以及基于区分类别的支持向量和超线的回归算法。当数据中有噪音或异常值时，这非常有用。当数据集的维度被很好地定义时，它是非常有效的。你可以在这篇<a class="ae lu" href="https://pub.towardsai.net/fully-explained-svm-classification-with-python-eda124997bcd" rel="noopener ugc nofollow" target="_blank">文章</a>中了解更多关于SVM的信息。</li><li id="0dc3" class="mu mv it la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated"><strong class="la iu"> PCA: </strong>用于减少数据集中的维度或列特征，这样就不会出现多重共线性问题。LDA和t-SNE也用于降维技术。你可以在这篇<a class="ae lu" href="https://pub.towardsai.net/principal-component-analysis-in-dimensionality-reduction-with-python-1a613006d531" rel="noopener ugc nofollow" target="_blank">文章</a>中找到更多关于PCA的信息。</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="1d38" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">用Python实现XGBoost</h1><p id="ff1e" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">首先，我们需要导入库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="defb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们将在pandas <code class="fe np nq nr ns b">read_csv</code>函数的帮助下读取训练和测试CSV文件。</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="1b0b" class="nx md it ns b gy ny nz l oa ob">d0 = pd.read_csv('train.csv')</span><span id="7527" class="nx md it ns b gy oc nz l oa ob">l = d0['label']<br/>d = d0.drop("label",axis=1)</span></pre><p id="0239" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在<em class="od"> d </em>和<em class="od"> l </em>变量中分别分配了特征和标签，即数据和标签。检查数据和标签的形状:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="e571" class="nx md it ns b gy ny nz l oa ob">print(d.shape)<br/>print(l.shape)</span><span id="2307" class="nx md it ns b gy oc nz l oa ob">#output:<br/>(42000, 784)<br/>(42000,)</span></pre><p id="9422" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要打印数字图像:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/603d8af88b9201919f913a010ce268f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*j0MAmxHwxxbsg7XwQXqmDQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="97d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们会从数据和标签中的数据中抽取一个样本，因为数据非常庞大。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="e56e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">计算数据中的位数:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="42e0" class="nx md it ns b gy ny nz l oa ob">count_table = d0.label.value_counts()<br/>count_table = count_table.reset_index().sort_values(by='index')<br/>count_table</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/252c707502c9c21ef7c79864855c46ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*ztuVhAMTGxOP7ff2nXURNw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="63e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用条形图可视化计数:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="d34f" class="nx md it ns b gy ny nz l oa ob">plt.figure(figsize=(10, 5))<br/>sns.barplot(x='index', y='label', data=count_table)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/2a03d9fc91d86bdac4280748f78ff364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*6PHksYXWNmrIHw4K9gkPCg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="513a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们将对XGBoost算法进行建模:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="a88e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们将拟合XGBoost模型:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="fa18" class="nx md it ns b gy ny nz l oa ob">clftre = XGBClassifier()<br/>clftre.fit(X_train,y_train)</span></pre><p id="be20" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">检查分类报告:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="09cb" class="nx md it ns b gy ny nz l oa ob">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, clftre.predict(X_test)))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/afac97576638e6cf88ecda5788d68219.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*hPoaatxB2i8uHxsiAKzAjQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">无PCA数据的分类报告。(图片由作者提供)</p></figure><p id="f0b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将尝试借助PCA技术来降低维度:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="a190" class="nx md it ns b gy ny nz l oa ob">#Using PCA technique<br/>pca = PCA(svd_solver='randomized', random_state=42)<br/>pca.fit(X_train)</span></pre><p id="5e2e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">制作屏幕图—绘制相对于组件数量的累积方差:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/e0d567b3543f4db48578aa47f9f4acaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*el7Jb8Zrg8uAMlEkT-ES5w.png"/></div></figure><p id="cbbd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从上面的图中，我们可以得到大约100个维度，解释了70%的差异。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="491a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以看到特征维数从784减少到100。是时候用PCA数据重新训练XGBoost模型了。</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="4dbd" class="nx md it ns b gy ny nz l oa ob">X_train, X_test, y_train, y_test = train_test_split(pca_data, labels, stratify=labels, test_size=0.22, random_state=42)</span><span id="8bd9" class="nx md it ns b gy oc nz l oa ob">clftre = XGBClassifier()<br/>clftre.fit(X_train,y_train)</span></pre><p id="4086" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">检查分类报告:</p><pre class="kj kk kl km gt nt ns nu nv aw nw bi"><span id="1900" class="nx md it ns b gy ny nz l oa ob">print(classification_report(y_test, clftre.predict(X_test)))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/8379fd307428d5e3c40027a0de473e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*oxMEtIIrt52wdm-3BeIzSQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">含五氯苯甲醚数据的分类报告(图片由作者提供)</p></figure><p id="f98f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们比较不使用和使用PCA的准确度，使用PCA数据的准确度降低到95%。我们选择<code class="fe np nq nr ns b">n_components</code> 10后，准确率下降到90%。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="2631" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">XGBoost的比较</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/4da303c2ea143b6401f64c0fbddc2f1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*engRGhhQ3lzS7bWQBOcPBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">XGBoost(图片由作者提供)对比</p></figure><p id="75b9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用t-SNE技术可视化数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/180ded6c7b8cce9c433ca6abfb63fceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*yFbdngWvldgreebuBtL_tg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d0d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在t-SNE中使用更多参数进行可视化:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/2541d658fa953d3a7e43094f1957a872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*z8PYGI-eYadug7Xu9SZImQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d8d5" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">用Python实现KNN</h1><p id="76ca" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">一切都和XGBoost中一样。用一个<code class="fe np nq nr ns b">for</code>回路精确地知道<em class="od"> k </em>的值:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7bf51b5afe2f93c37110e1bbc4ad8cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*5cRN0krE2I29p4a0YLy-Og.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8a51" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在用k=5的值重新训练模型，得到没有PCA的分类报告。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a962d0e064c5c60272d6cc73a0e20e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*Fyvb4X4l7GyqX6AHfvBd2Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不含五氯苯甲醚的KNN分类报告(图片由作者提供)</p></figure><p id="38ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将找到400个PCA组件的精度。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/a1d38982adf9a8ca29e4892896a8b6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*h2z0FJEJMNTZZwlsenIusA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KNN的五氯苯甲醚分类报告(图片由作者提供)</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="73c1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论<strong class="ak">融合</strong></h1><p id="1456" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">正如我们比较的那样，当我们使用任何维数约减技术时，准确性总是下降，因为我们在约减过程中丢失了一些信息。</p><p id="d5de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你喜欢这篇文章。通过我的<a class="ae lu" href="https://www.linkedin.com/in/data-scientist-95040a1ab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lu" href="https://twitter.com/amitprius" rel="noopener ugc nofollow" target="_blank"> twitter </a>联系我。</p><h1 id="2c7e" class="mc md it bd me mf oq mh mi mj or ml mm jz os ka mo kc ot kd mq kf ou kg ms mt bi translated">推荐文章</h1><p id="76ed" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated"><a class="ae lu" href="https://medium.com/towards-artificial-intelligence/nlp-zero-to-hero-with-python-2df6fcebff6e?sk=2231d868766e96b13d1e9d7db6064df1" rel="noopener"> 1。NLP —零到英雄与Python </a> <br/> 2。<a class="ae lu" href="https://medium.com/towards-artificial-intelligence/python-data-structures-data-types-and-objects-244d0a86c3cf?sk=42f4b462499f3fc3a160b21e2c94dba6" rel="noopener"> Python数据结构数据类型和对象</a>T5】3 .<a class="ae lu" href="https://pub.towardsai.net/exception-handling-concepts-in-python-4d5116decac3?source=friends_link&amp;sk=a0ed49d9fdeaa67925eac34ecb55ea30" rel="noopener ugc nofollow" target="_blank">Python中的异常处理概念</a> <br/> 4。<a class="ae lu" href="https://pub.towardsai.net/deep-learning-88e218b74a14?source=friends_link&amp;sk=540bf9088d31859d50dbddab7524ba35" rel="noopener ugc nofollow" target="_blank">为什么LSTM在深度学习方面比RNN更有用？</a> <br/> 5。<a class="ae lu" href="https://pub.towardsai.net/neural-networks-the-rise-of-recurrent-neural-networks-df740252da88?source=friends_link&amp;sk=6844935e3de14e478ce00f0b22e419eb" rel="noopener ugc nofollow" target="_blank">神经网络:递归神经网络的兴起</a> <br/> 6。<a class="ae lu" href="https://medium.com/towards-artificial-intelligence/fully-explained-linear-regression-with-python-fe2b313f32f3?source=friends_link&amp;sk=53c91a2a51347ec2d93f8222c0e06402" rel="noopener">用Python </a> <br/> 7全面讲解了线性回归。<a class="ae lu" href="https://medium.com/towards-artificial-intelligence/fully-explained-logistic-regression-with-python-f4a16413ddcd?source=friends_link&amp;sk=528181f15a44e48ea38fdd9579241a78" rel="noopener">用Python </a> <br/>充分解释了Logistic回归8。<a class="ae lu" href="https://pub.towardsai.net/differences-between-concat-merge-and-join-with-python-1a6541abc08d?source=friends_link&amp;sk=3b37b694fb90db16275059ea752fc16a" rel="noopener ugc nofollow" target="_blank">concat()、merge()和join()与Python </a> <br/>的区别9。<a class="ae lu" href="https://pub.towardsai.net/data-wrangling-with-python-part-1-969e3cc81d69?source=friends_link&amp;sk=9c3649cf20f31a5c9ead51c50c89ba0b" rel="noopener ugc nofollow" target="_blank">与Python的数据角力—第一部分</a> <br/> 10。<a class="ae lu" href="https://medium.com/analytics-vidhya/confusion-matrix-in-machine-learning-91b6e2b3f9af?source=friends_link&amp;sk=11c6531da0bab7b504d518d02746d4cc" rel="noopener">机器学习中的混淆矩阵</a></p></div></div>    
</body>
</html>
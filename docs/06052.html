<html>
<head>
<title>5 Steps to Building a Faster Web Crawler</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建更快网络爬虫的5个步骤</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/5-tips-to-build-a-faster-web-crawler-f2bbc90cf233?source=collection_archive---------0-----------------------#2020-08-29">https://betterprogramming.pub/5-tips-to-build-a-faster-web-crawler-f2bbc90cf233?source=collection_archive---------0-----------------------#2020-08-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fa3f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让你的Python铲运机快100倍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6b6f43bbbe94e4516f73832a75ee5c72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dd1xU8upH6wu7FRCFZH24w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">YouTube上来自<a class="ae ky" href="https://www.youtube.com/watch?v=0Z0BEOnGREQ" rel="noopener ugc nofollow" target="_blank">网站开发者忍者</a>的照片。</p></figure><p id="600a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">抓取大量数据需要你有一个<em class="lv">非常</em>快的网页抓取器。如果你想刮1000万件物品，而你的刮刀每分钟刮50件物品，那么你要等130天才可以刮完。那太长了！</p><p id="1934" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本指南提供了一个结构化的方法来建立一个超快速的网页刮刀。</p><p id="b41e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我来告诉你:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/72229b8ae3f36398060eb3ef5882c51c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGYQB1HihqwqmYSPzS2QTg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">平均速率低于50件/分钟的刮刀</p></figure><p id="8642" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对此:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lx"><img src="../Images/c084857d6e3f7cc247158373bfc7ffe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9bKGQvOiE4FofJijYR14pw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">平均速率大于2000件/分钟的刮刀</p></figure></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="544b" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">1.设置</h1><p id="fbf3" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">如果你在Python中进行抓取，并且想要更快，只有一个库可以使用:<a class="ae ky" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> Scrapy </a>。如果你要做任何实质性的抓取，这是一个很棒的网络抓取框架。BeautifulSoup、Requests和Selenium对于大型项目来说太慢了。如果你不熟悉Scrapy，我建议你先学习它，然后再来看这篇文章。</p><p id="84d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在开始刮之前，我们需要做两件事:</p><ol class=""><li id="668a" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated">更改您的用户代理。你的用户代理告诉服务器谁在访问他们的网站。默认情况下，Scrapy告诉服务器有一个机器人正在爬他们的网站。如果你不改变这个设置，你将在分钟内被禁止。要改变它，谷歌“用户代理”，并设置其中一个等于<code class="fe nl nm nn no b">settings.py</code>中的<code class="fe nl nm nn no b">USER_AGENT</code>变量。也可以轮换您的用户代理。然而，我发现这是不必要的。如果你想做到这一点，只需谷歌如何——我相信设置相对容易。</li><li id="0a1f" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu nh ni nj nk bi translated">为你的爬虫选择和设置代理。选择代理时，您应该考虑代理的定价结构。你按每GB带宽付费吗？你按代理付费吗？你按线程付费吗？对于大型项目，我总是按线程付费，并使用StormProxies。对于较小的项目，我推荐<a class="ae ky" href="https://prf.hn/click/camref:1011leixZ" rel="noopener ugc nofollow" target="_blank"> SmartProxy </a>。他们按GB的带宽收费，并提供无限的线程。接下来，您想要设置您的代理，这可以通过在如下所示的<code class="fe nl nm nn no b">middleware.py</code>文件中创建一个新的中间件来完成。这将为项目中的所有蜘蛛设置代理。然后，您需要将中间件添加到您的<code class="fe nl nm nn no b">settings.py</code>文件中。或者，您可以为每个蜘蛛单独设置代理。下面有一个关于如何做到这一点的简短视频:</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3776bbd5870c0eca5d5d06aa8fa99da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*rBsKk3vzNK1xXHnJyyQxMg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代理中间件(所有蜘蛛)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为每个蜘蛛单独设置代理</p></figure></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="aaa1" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">2.优化你的刮痧策略</h1><p id="58b9" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">更聪明地工作，而不是更努力。</p><p id="7cbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一节讲的是三种刮削技术，它们将对你的速度产生巨大的<em class="lv">T2差异。</em></p><h2 id="1c18" class="nx mg it bd mh ny nz dn ml oa ob dp mp li oc od mr lm oe of mt lq og oh mv oi bi translated">分步解决</h2><p id="0e13" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">如果你使用一只大蜘蛛，把它分成许多小蜘蛛。你这样做是为了可以利用<a class="ae ky" href="https://scrapyd.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> Scrapyd </a>(更多细节在第4步)。Scrapyd允许你同时运行许多蜘蛛(使用Scrapy，你一次只能运行一个蜘蛛)。每只较小的蜘蛛会爬行大蜘蛛爬行过的部分。这些迷你蜘蛛不应该在它们爬行的内容上重叠，因为这将浪费时间。如果你把一个蜘蛛分成十个更小的，你的抓取过程将会快十倍左右(假设没有其他瓶颈——见步骤5)。</p><h2 id="1212" class="nx mg it bd mh ny nz dn ml oa ob dp mp li oc od mr lm oe of mt lq og oh mv oi bi translated">尽量减少发送的请求数量</h2><p id="d870" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">发送请求和等待响应是使用scraper最慢的部分。如果你能减少发送请求的数量，你的scraper会快很多。例如，如果你从一个电子商务网站搜集价格和标题，那么你就不需要访问每个商品的页面。您可以从结果页面获得所需的所有数据。如果你每页有30个条目，那么使用这种技术将使你的scraper速度提高30倍(它现在只需要发送一个请求，而不是30个)。总是寻找减少请求数量的方法。以下是你可以尝试的一些事情。如果你能想到任何其他的，请留下评论。</p><p id="2a6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">减少请求的常用方法:</p><ul class=""><li id="54ee" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu oj ni nj nk bi translated">增加结果页面上的结果数量(例如，从10个增加到100个)。</li><li id="f0d2" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu oj ni nj nk bi translated">在刮擦之前应用过滤器(例如价格过滤器)。</li><li id="1656" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu oj ni nj nk bi translated">使用普通的蜘蛛，而不是爬行蜘蛛。</li></ul><h2 id="0483" class="nx mg it bd mh ny nz dn ml oa ob dp mp li oc od mr lm oe of mt lq og oh mv oi bi translated">将项目批量上传到数据库</h2><p id="9c15" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">慢抓取的另一个原因是人们倾向于抓取他们的数据，然后立即将这些数据添加到他们的数据库中。这很慢有两个原因。首先，批量处理总是比逐项相加要快。其次，通过批处理，您可以利用Python提供的许多工具批量上传到数据库。例如，<a class="ae ky" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> pandas </a>库可用于将数据放入dataframe，然后将数据上传到SQL数据库。那就是<em class="lv">快得多</em>！如果你有兴趣了解更多，我强烈推荐你阅读<a class="ae ky" href="https://medium.com/analytics-vidhya/speed-up-bulk-inserts-to-sql-db-using-pandas-and-python-61707ae41990" rel="noopener">这篇关于批量上传到SQL数据库的文章</a>。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="3509" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">3.设置</h1><ol class=""><li id="21e2" class="nc nd it lb b lc mx lf my li ok lm ol lq om lu nh ni nj nk bi translated"><code class="fe nl nm nn no b">CONCURRENT_REQUESTS</code>:</li></ol><blockquote class="on"><p id="9db6" class="oo op it bd oq or os ot ou ov ow lu dk translated">" Scrapy下载程序将执行的并发(即同时)请求的最大数量."— <a class="ae ky" href="https://docs.scrapy.org/en/latest/topics/settings.html" rel="noopener ugc nofollow" target="_blank">刺儿头的文档</a></p></blockquote><p id="1da0" class="pw-post-body-paragraph kz la it lb b lc ox ju le lf oy jx lh li oz lk ll lm pa lo lp lq pb ls lt lu im bi translated">这是您的蜘蛛将发送的同时请求的数量。你可能想用不同的值做一些实验，看看哪个值能给你最好的刮擦率。一个好的起点是50岁。如果您得到许多超时错误，那么您已经设置得太高了。减少10%，再试一次。</p><p id="0a3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<code class="fe nl nm nn no b">DOWNLOAD_TIMEOUT</code>:</p><blockquote class="on"><p id="5747" class="oo op it bd oq or pc pd pe pf pg lu dk translated">"下载程序在超时前等待的时间(秒). "— <a class="ae ky" href="https://docs.scrapy.org/en/latest/topics/settings.html" rel="noopener ugc nofollow" target="_blank">刺儿头的文件</a></p></blockquote><p id="7f3b" class="pw-post-body-paragraph kz la it lb b lc ox ju le lf oy jx lh li oz lk ll lm pa lo lp lq pb ls lt lu im bi translated">这是蜘蛛在发送请求后重试前等待响应的时间。设置太低，你会得到无尽的超时错误。设置的太高，你的蜘蛛将会等待而不是重试请求，浪费时间并减慢你的速度。从100秒开始，通过实验找到最佳值。</p><p id="6a57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<code class="fe nl nm nn no b">DOWNLOAD_DELAY</code>:</p><blockquote class="on"><p id="b2d5" class="oo op it bd oq or pc pd pe pf pg lu dk translated">"下载程序在从同一网站下载连续页面之前应该等待的时间(秒)。"— <a class="ae ky" href="https://docs.scrapy.org/en/latest/topics/settings.html" rel="noopener ugc nofollow" target="_blank">刺儿头的文档</a></p></blockquote><p id="e61f" class="pw-post-body-paragraph kz la it lb b lc ox ju le lf oy jx lh li oz lk ll lm pa lo lp lq pb ls lt lu im bi translated">这是您的蜘蛛在下载响应之间等待的时间。对于最大速度，将其设置为零。如果您一直得到响应代码400、403或502，那么您的速度太快了。稍微增加下载延迟并重试(一个好的起点是0.5)。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="518e" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">4.scrappy d</h1><p id="f8c9" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">根据<a class="ae ky" href="https://scrapyd.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">它的文档</a>，Scrapyd是一个部署和运行Scrapy蜘蛛的应用。</p><p id="6ab3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scrapyd允许你同时运行多个蜘蛛。这将使我们能够显著提高刮擦过程的整体速度。如果您希望spider部署免费且易于设置，请使用Scrapyd。<a class="ae ky" href="https://scrapy-cluster.readthedocs.io/en/latest/topics/advanced/comparison.html" rel="noopener ugc nofollow" target="_blank"> Scrapy集群文档</a>包含了许多备选方案，但我仍然会推荐Scrapyd。</p><p id="6f2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用废料的好处:</p><ol class=""><li id="7c1a" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated">如果您的项目包含一个或多个大型蜘蛛，将它们分开(如本指南第2步所述)。</li><li id="447a" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu nh ni nj nk bi translated">不需要拆分的小蜘蛛，可以原样运行。</li></ol><p id="37b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你只是阅读文档，Scrapyd的设置可能会显得令人生畏，但下面的视频使它非常容易理解和实现:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="91be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:用一个命令就可以运行一个项目中的所有蜘蛛。设置它需要少量的工作，但是对于有十个或更多蜘蛛的项目，我推荐这样做。了解如何在 <a class="ae ky" href="https://stackoverflow.com/questions/10801093/run-multiple-scrapy-spiders-at-once-using-scrapyd/10804324" rel="noopener ugc nofollow" target="_blank"> <em class="lv">上叠加溢出</em> </a> <em class="lv">。</em></p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="9713" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">5.找到并消除瓶颈</h1><p id="fcf8" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">您已经遵循了该指南，并且您的铲运机正在以令人尊敬的速度运行。现在有一个最后的步骤让你的爬虫从令人尊敬到快如闪电:处理瓶颈！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/fdb342195c5d16eb0e28686cdc0fa96f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-YuJoI4nM7vVafKd.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://blog.indigovision.com/identifying-and-solving-data-bottlenecks-in-your-surveillance-network" rel="noopener ugc nofollow" target="_blank"> IndigoVision </a>。</p></figure><p id="dab4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">什么是瓶颈？</p><p id="cb39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是你的过程速度的限制因素。如果解决了这个问题，它将使您的流程在下一个瓶颈处得到显著的加速。</p><p id="302f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理瓶颈是一个迭代过程，如下所示:</p><ol class=""><li id="35d0" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated">你有一个减慢你的过程的瓶颈。</li><li id="5223" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu nh ni nj nk bi translated">你会发现瓶颈是什么。</li><li id="98e1" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu nh ni nj nk bi translated">你解决了瓶颈，你的过程变得更快。</li><li id="9dc1" class="nc nd it lb b lc np lf nq li nr lm ns lq nt lu nh ni nj nk bi translated">你有一个新的瓶颈。</li></ol><p id="de64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个你要不断重复的过程，直到你从铲运机中挤出最后一点速度。</p><p id="44e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下表包含了一些常见的抓取瓶颈。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/b4a778caa7ed383ffb7f79b72b8fa2ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*XVzvKkn1Oy4B6Y3JYxKrgw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">常见抓取瓶颈及解决方案表(作者提供)</p></figure></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="1bac" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">结论</h1><p id="8470" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">干得好。您已经学习了用Python构建快速web抓取器的来龙去脉。我希望这篇文章对你有用，并希望听到你的任何想法。你在做什么项目？你喜欢编码/抓取的什么？你最高的物品/分钟价格是多少？</p><p id="d010" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读。一如既往，如果你有任何问题，只需留下评论。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Build a Machine Learning Model API Using YOLOv5 With FAST API In 5 steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YOLOv5和FAST API分5步构建机器学习模型API</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/machine-learning-model-api-using-yolov5-with-fast-api-192f1290a982?source=collection_archive---------0-----------------------#2021-12-04">https://betterprogramming.pub/machine-learning-model-api-using-yolov5-with-fast-api-192f1290a982?source=collection_archive---------0-----------------------#2021-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1371" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你好。今天我们将利用YOLOv5和FAST api来构建一个机器学习API。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/fd8c20a09da32d1bb6cfb5a6e142bcc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CX1gFJHknRzvRZ7c"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">jet dela cruz 在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="cd13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您以前使用过Flask，您会发现使用FAST API很容易，因为它提供了生产就绪代码，只需进行少量调整。</p><p id="ca05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">FAST API还附带了与OpenAPI的自动交互文档。除了更好的开发者体验之外，ASGI(异步服务器网关接口)使得FAST API成为可用的最快的Python框架之一<a class="ae lb" href="https://www.techempower.com/benchmarks/#section=test&amp;runid=7464e520-0dc2-473d-bd34-dbdfd7e85911&amp;hw=ph&amp;test=query&amp;l=zijzen-7" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="a2f0" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">YOLOv5是什么？</h2><blockquote class="lv lw lx"><p id="3b6a" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">YOLOv5是在COCO数据集上预先训练的一系列对象检测架构和模型，代表了对未来视觉人工智能方法的<a class="ae lb" href="https://ultralytics.com/" rel="noopener ugc nofollow" target="_blank"> Ultralytics </a>开源研究，融合了经过数千小时的研究和开发而获得的经验教训和最佳实践。</p></blockquote><div class="mc md gp gr me mf"><a href="https://ultralytics.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd ir gy z fp mk fr fs ml fu fw ip bi translated">超lytics</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">YOLOv5🚀和视觉人工智能⭐</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">ultralytics.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt kv mf"/></div></div></a></div><p id="aa6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">YOLO代表“你只看一次”，这是一种快速高效的深度学习模型，因为它使用单镜头检测器(SSD)和YOLO对象检测器来将输入图像划分到SxS网格系统中。</p><p id="a879" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可能会看到以下YOLOv5的令人印象深刻的对比:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mu"><img src="../Images/adf804b32f0347b36078dcb0baaf2801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bpnCPnatSx8mlHqs.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">来自<a class="ae lb" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a></p></figure></div><div class="ab cl mv mw hu mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ij ik il im in"><h1 id="34a2" class="nc ld iq bd le nd ne nf lh ng nh ni lk nj nk nl ln nm nn no lq np nq nr lt ns bi translated">使用的技术</h1><ol class=""><li id="d029" class="nt nu iq jp b jq nv ju nw jy nx kc ny kg nz kk oa ob oc od bi translated"><a class="ae lb" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank"> FastAPI </a>用于以异步模式提供认证API。</li><li id="6af4" class="nt nu iq jp b jq oe ju of jy og kc oh kg oi kk oa ob oc od bi translated"><a class="ae lb" href="https://github.com/OAI/OpenAPI-Specification" rel="noopener ugc nofollow" target="_blank"> OpenAPI </a>(以前称为swagger)用于记录API规范。</li><li id="9510" class="nt nu iq jp b jq oe ju of jy og kc oh kg oi kk oa ob oc od bi translated"><a class="ae lb" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>用于构建容器图像。</li></ol></div><div class="ab cl mv mw hu mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ij ik il im in"><h1 id="5aef" class="nc ld iq bd le nd ne nf lh ng nh ni lk nj nk nl ln nm nn no lq np nq nr lt ns bi translated">步骤0:准备您定制的YOLOv5模型</h1><p id="4fe5" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">要使用YOLOv5训练自定义对象识别，您可以查看下面的链接:</p><div class="mc md gp gr me mf"><a href="https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd ir gy z fp mk fr fs ml fu fw ip bi translated">谷歌联合实验室</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">编辑描述</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">colab.research.google.co</p></div></div><div class="mo l"><div class="om l mq mr ms mo mt kv mf"/></div></div></a></div><blockquote class="lv lw lx"><p id="8e50" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">您可以使用我自己的定制ML模型，而不需要这一步。该模型支持检测6种食品，包括鸡翅、甜甜圈、薯条、gyoza、热狗和华夫饼。</p></blockquote><h1 id="5a23" class="nc ld iq bd le nd on nf lh ng oo ni lk nj op nl ln nm oq no lq np or nr lt ns bi translated">步骤1:克隆或下载Github项目</h1><p id="fdb5" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">去<a class="ae lb" href="https://github.com/DanielChuDC/yolov5-fastapi" rel="noopener ugc nofollow" target="_blank">https://github.com/DanielChuDC/yolov5-fastapi</a>克隆或下载项目。解压下载的zip文件。</p><h2 id="957e" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">目录解释:</h2><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="e8aa" class="lc ld iq ot b gy ox oy l oz pa">.<br/>├── Dockerfile # For containerised this application<br/>├── README.md<br/>├── main.py # The entry point of the program<br/>├── model<br/>│   ├── __init__.py<br/>│   └── best.pt # Where you custom training model place<br/>├── requirements.in # To generate requirements.txt<br/>├── requirements.txt # Usage: pip install -r requirements.txt<br/>├── segmentation.py # for import local yolov5 and scale image<br/>└── yolov5 # Get from <a class="ae lb" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a></span></pre><p id="6a84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe pb pc pd ot b">main.py</code>是应用程序的入口点。在这里，我们将定义3个端点，并允许在FAST API中以字节为单位上传文件:</p><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="68f0" class="lc ld iq ot b gy ox oy l oz pa">from fastapi import FastAPI, File<br/>from segmentation import get_yolov5, get_image_from_bytes<br/>from starlette.responses import Response<br/>import io<br/>from PIL import Image<br/>import json<br/>from fastapi.middleware.cors import CORSMiddleware</span><span id="347f" class="lc ld iq ot b gy pe oy l oz pa">model = get_yolov5()</span><span id="9e25" class="lc ld iq ot b gy pe oy l oz pa">app = FastAPI(<br/>    title="Custom YOLOV5 Machine Learning API",<br/>    description="""Obtain object value out of image<br/>    and return image and json result""",<br/>    version="0.0.1",<br/>)</span><span id="c65c" class="lc ld iq ot b gy pe oy l oz pa">origins = [<br/>    "http://localhost",<br/>    "http://localhost:8000",<br/>    "*"<br/>]</span><span id="d7e2" class="lc ld iq ot b gy pe oy l oz pa">app.add_middleware(<br/>     CORSMiddleware,<br/>     allow_origins=origins,<br/>     allow_credentials=True,<br/>     allow_methods=["*"],<br/>     allow_headers=["*"],<br/>)</span><span id="abec" class="lc ld iq ot b gy pe oy l oz pa"><br/>@app.get('/notify/v1/health')<br/>def get_health():<br/>    return dict(msg='OK')</span><span id="5549" class="lc ld iq ot b gy pe oy l oz pa"><br/>@app.post("/object-to-json")<br/>async def detect_food_return_json_result(file: bytes = File(...)):<br/>    input_image = get_image_from_bytes(file)<br/>    results = model(input_image)<br/>    detect_res = results.pandas().xyxy[0].to_json(orient="records")<br/>    detect_res = json.loads(detect_res)<br/>    return {"result": detect_res}</span><span id="69b1" class="lc ld iq ot b gy pe oy l oz pa"><br/>@app.post("/object-to-img")<br/>async def detect_food_return_base64_img(file: bytes = File(...)):<br/>    input_image = get_image_from_bytes(file)<br/>    results = model(input_image)<br/>    results.render()  # updates results.imgs with boxes and labels<br/>    for img in results.imgs:<br/>        bytes_io = io.BytesIO()<br/>        img_base64 = Image.fromarray(img)<br/>        img_base64.save(bytes_io, format="jpeg")<br/>    return Response(content=bytes_io.getvalue(),<br/>media_type="image/jpeg")</span></pre><p id="d6d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe pb pc pd ot b">segmentation.py</code>定义了两种方法:</p><ol class=""><li id="dfe2" class="nt nu iq jp b jq jr ju jv jy pf kc pg kg ph kk oa ob oc od bi translated"><code class="fe pb pc pd ot b">get_yolov5()</code>:这就是yolov5可以使用定制模型的地方。请注意<code class="fe pb pc pd ot b">model.conf=0.5</code>，它意味着只有置信度大于0.5的被检测对象才会出现在返回结果中。</li><li id="5a02" class="nt nu iq jp b jq oe ju of jy og kc oh kg oi kk oa ob oc od bi translated"><code class="fe pb pc pd ot b">get_image_from_bytes()</code>:是调整图像大小的地方。</li></ol><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="4ab4" class="lc ld iq ot b gy ox oy l oz pa">import torch<br/>from PIL import Image<br/>import io</span><span id="2415" class="lc ld iq ot b gy pe oy l oz pa">def get_yolov5():<br/>    model = torch.hub.load('./yolov5', 'custom', path='./model/best.pt', source='local')<br/>    model.conf = 0.5<br/>    return model</span><span id="cf39" class="lc ld iq ot b gy pe oy l oz pa">def get_image_from_bytes(binary_image, max_size=1024):<br/>    input_image =Image.open(io.BytesIO(binary_image)).convert("RGB")<br/>    width, height = input_image.size<br/>    resize_factor = min(max_size / width, max_size / height)<br/>    resized_image = input_image.resize((<br/>        int(input_image.width * resize_factor),<br/>        int(input_image.height * resize_factor)<br/>    ))<br/>    return resized_image</span></pre><h1 id="cd93" class="nc ld iq bd le nd on nf lh ng oo ni lk nj op nl ln nm oq no lq np or nr lt ns bi translated">第2步:将自定义的best.pt放到项目目录下的model文件夹中</h1><p id="7bf9" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">在你训练好你的定制模型之后，你就有了名为<code class="fe pb pc pd ot b">best.pt</code>的定制模型。替换<code class="fe pb pc pd ot b">model</code>文件夹中的best.pt。</p><h1 id="c39f" class="nc ld iq bd le nd on nf lh ng oo ni lk nj op nl ln nm oq no lq np or nr lt ns bi translated">步骤3:通过以下命令启动项目</h1><p id="043f" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">在终端中运行以下命令</p><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="65a7" class="lc ld iq ot b gy ox oy l oz pa">uvicorn main:app --reload --host 0.0.0.0 --port 8000</span></pre><blockquote class="lv lw lx"><p id="f451" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">如果您看到下面类似的结果，这意味着成功地启动了项目。</p></blockquote><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi pi"><img src="../Images/1acb3d7440e96637cd5188df6c3f9e93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mySpB5mXEZRCi4rK44leMw.png"/></div></div></figure><blockquote class="lv lw lx"><p id="ba12" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">如果您遇到任何关于软件包丢失的错误，您可以通过运行<code class="fe pb pc pd ot b">pip install -r requirements.txt</code>来安装所需的软件包。</p></blockquote><h1 id="d297" class="nc ld iq bd le nd on nf lh ng oo ni lk nj op nl ln nm oq no lq np or nr lt ns bi translated">第四步:测试结果</h1><p id="c86c" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">在浏览器中导航至<a class="ae lb" href="http://0.0.0.0:8000/docs#/" rel="noopener ugc nofollow" target="_blank">http://0 . 0 . 0 . 0:8000/docs #/</a>。您应该看到开放API方案有3个端点:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi pj"><img src="../Images/b650da614808cb2d7c31c7dca2127e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fPcjaRTvM0bRJJWxto8JKA.png"/></div></div></figure><ol class=""><li id="b82b" class="nt nu iq jp b jq jr ju jv jy pf kc pg kg ph kk oa ob oc od bi translated"><code class="fe pb pc pd ot b">/notify/v1/health </code> —该端点用于检查Kubernetes的<code class="fe pb pc pd ot b">readinessProbe</code>和<code class="fe pb pc pd ot b">livenessProbe</code>。</li></ol><p id="1aa0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以通过点击<code class="fe pb pc pd ot b">try it out</code>按钮来执行端点。</p><blockquote class="lv lw lx"><p id="8cae" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">预期结果是状态代码为200的<code class="fe pb pc pd ot b">{"msg": "OK"}</code>。</p></blockquote><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi pk"><img src="../Images/3f74209620c7772e745d2e119e8ea07f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idMW1GgtWg2qs4xSDKFLrQ.png"/></div></div></figure><p id="7af1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.<code class="fe pb pc pd ot b">/object-to-json </code> —此端点用于以JSON格式返回检测到的对象值</p><p id="a5d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以点击<code class="fe pb pc pd ot b">try it out</code>按钮执行端点并上传图像。</p><blockquote class="lv lw lx"><p id="03ee" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">预期结果是带有200状态代码的<code class="fe pb pc pd ot b"><em class="iq">{"result": []}</em></code>。如果模型检测到大于0.5的东西，它将追加到数组中。</p></blockquote><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi pl"><img src="../Images/6cf3179b686ec74bb4c7cab4969c256a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dblMeyO9hZVdqRYT1BaByA.png"/></div></div></figure><blockquote class="lv lw lx"><p id="b7be" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">注意:如果您使用了您的海关<code class="fe pb pc pd ot b"><em class="iq">best.pt</em></code>，检测的对象可能会有所不同。</p></blockquote><p id="97c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.<em class="ly"> </em> <code class="fe pb pc pd ot b">/object-to-img</code> <em class="ly"> — </em>此端点用于返回图像格式的检测对象值</p><p id="ef5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以点击<code class="fe pb pc pd ot b">try it out</code>按钮执行端点并上传图像。</p><blockquote class="lv lw lx"><p id="e8e8" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">预期的结果是带有200状态代码的检测到的食物对象的标签图像。如果模型检测到大于0.5的东西，它会显示一个标签和方框。</p></blockquote><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi pm"><img src="../Images/fd3a17c844e4ddcf47d0417e1b937b6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GjiFrb84mzoohMBFOEQvdA.png"/></div></div></figure><blockquote class="lv lw lx"><p id="f85d" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">注意:如果您使用了您的海关<code class="fe pb pc pd ot b">best.pt</code>，检测到的对象可能会有所不同。</p></blockquote><h1 id="1d11" class="nc ld iq bd le nd on nf lh ng oo ni lk nj op nl ln nm oq no lq np or nr lt ns bi translated">步骤5:将该项目构建为微服务的容器映像</h1><p id="2d85" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">我们已经走了这么远！让我们将这个项目构建成一个容器映像。</p><p id="b177" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">打开<code class="fe pb pc pd ot b">docker desktop</code>并等待其准备就绪。</p><h2 id="593e" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">Dockerfile文件</h2><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="82da" class="lc ld iq ot b gy ox oy l oz pa">FROM tiangolo/uvicorn-gunicorn:python3.9-slim<br/>LABEL maintainer="danielchu"ENV WORKERS_PER_CORE=4<br/>ENV MAX_WORKERS=24<br/>ENV LOG_LEVEL="warning"<br/>ENV TIMEOUT="200"<br/>RUN mkdir /yolov5-fastapi<br/>COPY requirements.txt /yolov5-fastapi<br/>COPY . /yolov5-fastapi<br/>WORKDIR /yolov5-fastapi<br/>EXPOSE 8000<br/>CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]</span></pre><p id="604a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在通过运行以下命令来构建映像</p><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="9b4a" class="lc ld iq ot b gy ox oy l oz pa">docker build -t yolov5-fastapi:0.0.1 .</span></pre><p id="7ef5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果看到类似下面截图的结果，图像已经构建成功了！</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi pn"><img src="../Images/1c92d60025bbbc895b7d3fb21a27a47c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmMBU0xHABcEIy-Tar0AtQ.png"/></div></div></figure><p id="1849" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以通过以下方式运行容器映像</p><pre class="km kn ko kp gt os ot ou ov aw ow bi"><span id="6670" class="lc ld iq ot b gy ox oy l oz pa">docker run -p 8080:8000 yolov5-fastapi:0.0.1</span></pre></div><div class="ab cl mv mw hu mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ij ik il im in"><h1 id="5047" class="nc ld iq bd le nd ne nf lh ng nh ni lk nj nk nl ln nm nn no lq np nq nr lt ns bi translated">结论</h1><p id="903f" class="pw-post-body-paragraph jn jo iq jp b jq nv js jt ju nw jw jx jy oj ka kb kc ok ke kf kg ol ki kj kk ij bi translated">在本文中，我们使用YOLOv5和FAST API创建了一个机器学习模型API。这个应用程序将适合对象检测，允许你上传图像，并以JSON或image格式返回结果。</p><p id="85f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个应用程序也适合使用容器映像进行云部署。</p><p id="10c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以通过将检测结果存储到数据库中来进一步增强这个项目，以用于机器学习改进。但那是以后的事了。</p></div><div class="ab cl mv mw hu mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ij ik il im in"><blockquote class="lv lw lx"><p id="86ad" class="jn jo ly jp b jq jr js jt ju jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj kk ij bi translated">如果您对使用FAST api构建身份验证API感兴趣，可以查看下面的链接:</p></blockquote><div class="mc md gp gr me mf"><a href="https://dc1888.medium.com/build-simple-authentication-api-using-fast-api-with-es256-encryption-in-10-mins-f8c0113937a" rel="noopener follow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd ir gy z fp mk fr fs ml fu fw ip bi translated">使用带ES256加密的FAST API在10分钟内构建简单的身份验证API</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">大家好！在本文中，我们将了解如何使用FAST API创建一个身份验证API…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">dc1888.medium.com</p></div></div><div class="mo l"><div class="po l mq mr ms mo mt kv mf"/></div></div></a></div></div></div>    
</body>
</html>
<html>
<head>
<title>Estimate Point Clouds From Depth Images in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中从深度图像估计点云</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/point-cloud-computing-from-rgb-d-images-918414d57e80?source=collection_archive---------1-----------------------#2022-09-13">https://betterprogramming.pub/point-cloud-computing-from-rgb-d-images-918414d57e80?source=collection_archive---------1-----------------------#2022-09-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="933e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于RGB-D图像的点云计算</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/35448f1e41aaf190c8deb9b1113f1f81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Thye0QMhLhTfKCmn"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@r3dmax?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔纳森派</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="545f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我的“点云处理”教程的第二篇文章。“点云处理”教程是初学者友好的，其中我们将简单介绍从数据准备到数据分割和分类的点云处理流水线。</p><ul class=""><li id="9279" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" href="https://medium.com/@chimso1994/introduction-to-point-cloud-processing-dbda9b167534" rel="noopener">第一篇:点云处理简介</a></li><li id="ea16" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://medium.com/better-programming/point-cloud-computing-from-rgb-d-images-918414d57e80" rel="noopener">文章2:用Python从深度图像中估计点云</a></li><li id="bf7f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener ugc nofollow" target="_blank" href="/understand-point-clouds-a-simple-ground-detection-algorithm-71aaa0dd2b2d">第三篇:理解点云:使用Python实现地面检测</a></li><li id="662f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://medium.com/@chimso1994/point-cloud-filtering-in-python-e8a06bbbcee5" rel="noopener">第4篇:Python中的点云过滤</a></li><li id="edea" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://medium.com/@chimso1994/point-cloud-segmentation-in-python-2fdbf5ea0617" rel="noopener">第五篇:Python中点云分割</a></li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="1c03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://medium.com/@chimso1994/introduction-to-point-cloud-processing-dbda9b167534" rel="noopener">之前的教程</a>中，我们介绍了点云并展示了如何创建和可视化它们。在本教程中，我们将学习如何在不使用Open3D库的情况下从深度图像计算点云。我们还将展示如何优化代码以获得更好的性能。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="eb3c" class="ms mt iq mo b gy mu mv l mw mx"><strong class="mo ir">Table of contents:</strong><br/>· <a class="ae kv" href="#3de9" rel="noopener ugc nofollow">1. Depth Image</a><br/>· <a class="ae kv" href="#9424" rel="noopener ugc nofollow">2. Point cloud</a><br/> ∘ <a class="ae kv" href="#fa35" rel="noopener ugc nofollow">2.2 Depth camera calibration</a><br/> ∘ <a class="ae kv" href="#2c78" rel="noopener ugc nofollow">2.3 Point cloud computing</a><br/>· <a class="ae kv" href="#288f" rel="noopener ugc nofollow">3. Colored point cloud</a><br/>· <a class="ae kv" href="#4391" rel="noopener ugc nofollow">4. Code optimization</a><br/> ∘ <a class="ae kv" href="#4eaa" rel="noopener ugc nofollow">4.1 Point cloud</a><br/> ∘ <a class="ae kv" href="#7ec8" rel="noopener ugc nofollow">4.2 Colored point cloud</a><br/>· <a class="ae kv" href="#d75f" rel="noopener ugc nofollow">5. Conclusion</a></span></pre></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="3de9" class="my mt iq bd mz na nb nc nd ne nf ng nh jw ni jx nj jz nk ka nl kc nm kd nn no bi translated">1.深度图像</h1><p id="6ed7" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">深度图像(也称为深度图)是一种图像，其中每个像素提供其相对于传感器坐标系的距离值。深度图像可以通过结构光或飞行时间传感器来捕捉。为了计算深度数据，结构化光传感器，如微软Kinect V1，比较投影光和接收光之间的失真。至于像微软Kinect V2这样的飞行时间传感器，它们投射光线，然后计算投射和接收光线之间的时间。</p><p id="6f6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了深度图像之外，一些传感器提供它们相应的RGB图像以形成RGB-D图像。后者使得计算彩色点云成为可能。本教程将以微软Kinect V1 RGB-D图像为例。</p><p id="0dce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从导入库开始:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="5543" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以导入深度图像并打印其分辨率和类型:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="a1dd" class="ms mt iq mo b gy mu mv l mw mx">Image resolution: (480, 640)<br/>Data type: int32<br/>Min value: 0<br/>Max value: 2980</span></pre><p id="3465" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">深度图像是一个大小为<em class="nw"> 640 </em> × <em class="nw"> 480 </em>的矩阵，其中每个像素是一个<em class="nw"> 32 </em>(或<em class="nw"> 16 </em>)位整数，以毫米为单位表示距离，因此深度图像在打开时看起来是黑色的(见下图)。最小值<em class="nw"> 0 </em>代表噪声(没有距离)，而最大值<em class="nw"> 2980 </em>代表最远像素的距离。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3934e8c7b75f576bbaf11dd0a0c2a8c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*oYUfOQ1kTUf_AnlRnz5QQw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由微软Kinect V1生成的深度图像。</p></figure><p id="7cf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更好的可视化，我们计算它的灰度图像:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="1990" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算灰度图像意味着将深度值缩放到<code class="fe ny nz oa mo b">[0, 255]</code>。现在图像更清晰了:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/8a9df1c73677663afc26b5101aa9cd76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*LImUmj8uAwBx98xfeY25hA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计算出的灰度图像。黑色像素代表噪声。</p></figure><p id="f713" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，Matplotlib在可视化深度图像时做同样的事情:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/90af8131814f924220e745725a95d65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*AWUz71tV7kWxu23bqmuh1g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Matplotlib自动缩放深度图像的像素。</p></figure><h1 id="9424" class="my mt iq bd mz na oc nc nd ne od ng nh jw oe jx nj jz of ka nl kc og kd nn no bi translated">2.点云</h1><p id="ecd8" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">现在我们已经导入并显示了深度图像，如何从中估算点云呢？第一步是校准深度相机，以估计相机矩阵，然后用它来计算点云。所获得的点云也被称为2.5D点云，因为它是根据2D投影(深度图像)而不是诸如激光传感器的3D传感器来估计的。</p><h2 id="fa35" class="ms mt iq bd mz oh oi dn nd oj ok dp nh lf ol om nj lj on oo nl ln op oq nn or bi translated">2.2深度相机校准</h2><p id="c582" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">校准相机意味着通过找到失真系数和相机矩阵(也称为内在参数)来估计镜头和传感器参数。一般来说，有三种方法可以校准相机:使用工厂提供的标准参数，使用校准研究中获得的结果或手动校准Kinect。手动校准摄像机包括应用一种校准算法，如棋盘算法[1]。该算法在机器人操作系统(ROS)和OpenCV上实现。校准矩阵<em class="nw"> M </em>是一个<em class="nw"> 3 </em> × <em class="nw"> 3 </em>矩阵；</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/ca32bb06f21e0570ebe1ddba94c1293f.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*lizW_Umomcnp0xIklhuPlw.png"/></div></figure><p id="5078" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="nw"> fx，fy </em>和<em class="nw"> cx，cy </em>分别为焦距和光心。对于本教程，我们将使用从<a class="ae kv" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2数据集</a>获得的结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="00e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想自己校准相机，可以参考OpenCV教程。</p><h2 id="2c78" class="ms mt iq bd mz oh oi dn nd oj ok dp nh lf ol om nj lj on oo nl ln op oq nn or bi translated">2.3点云计算</h2><p id="008e" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">这里计算点云就是将深度像素从深度图像2D坐标系转换到深度相机3D坐标系(<em class="nw"> x，y </em>和<em class="nw"> z </em>)。使用以下公式[2]计算3D坐标，其中<em class="nw"> depth(i，j) </em>是行<em class="nw"> i </em>和列<em class="nw"> j </em>处的深度值:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c7f6b4a25a1e988d69894c7c41537a5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:334/format:webp/1*ugq6ujIVstG3CKhdUu2JDA.png"/></div></figure><p id="de77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该公式适用于每个像素:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="35ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们使用Open3D库来显示它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e1a1beedb308799790ab8ae34ef5b3e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*FkwmmGCVPYmF0aUxd-N_wQ.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由深度图像计算得到的点云。</p></figure><h1 id="288f" class="my mt iq bd mz na oc nc nd ne od ng nh jw oe jx nj jz of ka nl kc og kd nn no bi translated">3.彩色点云</h1><p id="f35e" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">如果我们想从RGB-D图像中计算彩色点云呢？颜色信息可以增强像点云配准这样的许多任务的性能。在这种情况下，如果输入传感器也提供RGB图像，则最好使用它。彩色点云可以定义如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d42538d488d6fd33348cd03ece6288dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*p9PL_2rJ6jJQYKU98We2Kw.png"/></div></figure><p id="adc6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="nw"> x，y </em>和<em class="nw"> z </em>是3D坐标，<em class="nw"> r，g </em>和<em class="nw"> b </em>代表RGB系统中的颜色。</p><p id="ceaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们从导入先前深度图像的相应RGB图像开始:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/a945a1c1213e6aaabcce86d484073caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*1cBB12S_9TbgP-V61IeC_g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">深度图像及其对应的RGB图像</p></figure><p id="e703" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了找到在深度传感器3D坐标系中定义的给定点<em class="nw"> p(x，y，z) </em>的颜色:</p><p id="4455" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 1。我们将其转换到RGB相机坐标系[2]: </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/a6cb3e4ad21a4466aaf68f93fd154704.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*0bvPnKERhmYkXAWtaBV3CA.png"/></div></figure><p id="108e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="nw"> R </em>和<em class="nw"> T </em>分别是两个摄像机之间的外部参数:旋转矩阵和平移向量。</p><p id="e57f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类似地，我们使用来自<a class="ae kv" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2数据集</a>的参数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9bd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">RGB相机坐标系中的点计算如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9e1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2。使用RGB摄像机的固有参数，我们将其映射到彩色图像坐标系[2]: </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/4fe7865e3394e8df9d6ce58d62d9e917.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*o-Ue6EQTLpuRmjlqVegMyw.png"/></div></figure><p id="aa5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些是获取彩色像素的索引。</p><p id="67b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，在前面的公式中，焦距和光学中心是RGB相机参数。同样，我们使用来自<a class="ae kv" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2数据集</a>的参数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c16a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相应像素的指数计算如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="130d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们把所有的放在一起，显示点云:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/d3bbaad89de52c88782e5fcfb313a262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*K9Buz1z4KrK1_qDI6BbeZA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从RGB-D图像计算彩色点云</p></figure><h1 id="4391" class="my mt iq bd mz na oc nc nd ne od ng nh jw oe jx nj jz of ka nl kc og kd nn no bi translated">4.代码优化</h1><p id="af67" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">在这一节中，我们将解释如何优化您的代码，使其更高效，更适合实时应用程序。</p><h2 id="4eaa" class="ms mt iq bd mz oh oi dn nd oj ok dp nh lf ol om nj lj on oo nl ln op oq nn or bi translated">4.1点云</h2><p id="31c5" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">使用嵌套循环计算点云非常耗时。对于一幅分辨率为<em class="nw"> 480×640 </em>的深度图像，在一台拥有<em class="nw"> 8GB </em> RAM和<em class="nw">i7–4500</em>CPU的机器上，计算点云大约需要<strong class="ky ir"> <em class="nw"> 2.154秒</em> </strong>。</p><p id="9c2a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了减少计算时间，可以用向量化操作代替嵌套循环，计算时间可以减少到大约0.024秒<strong class="ky ir"><em class="nw"/></strong>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="5042" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以通过在开始时计算一次常数来将计算时间减少到大约0.015秒<strong class="ky ir"><em class="nw"/></strong>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="7ec8" class="ms mt iq bd mz oh oi dn nd oj ok dp nh lf ol om nj lj on oo nl ln op oq nn or bi translated">4.2彩色点云</h2><p id="c625" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">至于彩色点云，在同一台机器上，执行前面的例子大约需要<strong class="ky ir"> <em class="nw"> 36.263秒</em> </strong>。通过应用矢量化，运行时间减少到<strong class="ky ir"> 0.722秒</strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="d75f" class="my mt iq bd mz na oc nc nd ne od ng nh jw oe jx nj jz of ka nl kc og kd nn no bi translated">5.结论</h1><p id="e818" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">在本教程中，我们学习了如何从RGB-D数据计算点云。在<a class="ae kv" href="https://medium.com/@chimso1994/understand-point-clouds-a-simple-ground-detection-algorithm-71aaa0dd2b2d" rel="noopener">下一篇教程</a>中，我们将以一个简单的地面探测为例，来仔细分析点云。</p><p id="daa7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谢谢，我希望你喜欢读这篇文章。你可以在我的<a class="ae kv" href="https://github.com/Chim-SO/pointcloudprocessing" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到例子。</p><h1 id="bd23" class="my mt iq bd mz na oc nc nd ne od ng nh jw oe jx nj jz of ka nl kc og kd nn no bi translated">参考</h1><p id="c1a0" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">[1]张，张，黄，张(2006).一种新的结构光系统标定方法。<em class="nw">光学工程</em>，<em class="nw"> 45 </em> (8)，083601。</p><p id="6c93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]周，谢(2012).微软Kinect校准研究。费尔法克斯乔治梅森大学计算机科学系。</p><h1 id="ee70" class="my mt iq bd mz na oc nc nd ne od ng nh jw oe jx nj jz of ka nl kc og kd nn no bi translated">图像制作者名单</h1><p id="fbc3" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">本文中所有图片和数字的来源未在标题中提及，均由作者提供。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Build a Toxic Comments Classifier in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python构建有毒注释分类器</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/build-a-toxic-comments-classifier-in-python-fab1f0504631?source=collection_archive---------9-----------------------#2021-06-09">https://betterprogramming.pub/build-a-toxic-comments-classifier-in-python-fab1f0504631?source=collection_archive---------9-----------------------#2021-06-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1e9c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解社交媒体平台如何检测有害评论</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f2abf0532c654dde8e5f5bd04b19aead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xLTyy6SUSrquRqSe9KkSwA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@shvetsa?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">安娜·施韦茨</a>从<a class="ae ky" href="https://www.pexels.com/photo/happy-woman-removing-face-mask-after-taking-bath-3852159/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><p id="34f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仇恨的话语或评论会伤害许多人的感情。许多社交媒体网站，如脸书、推特和Instagram，使用机器学习方法来检测和分类有害或仇恨的评论。</p><p id="36dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天，我将带你经历一个制作有毒评论分类器的类似过程。最后，我们将获得一个模型，该模型将接受用户定义的输入，并将生成一个评论是否有毒的信号。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="5c32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用Python编程来完成这项任务，并将使用Jupyter Notebook来运行我们的代码片段。</p><h1 id="c05d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤1:定义Python库</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="2593" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用<code class="fe mw mx my mz b">nltk</code>进行文本处理和清理。我们有文本数据，但机器只理解数字数据，因此，我们将使用word2vec模型将文本数据转换为数字向量。</p><p id="8690" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，为了训练出文本模型，我们将使用长短期记忆(LSTM)。</p><h1 id="1821" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤2:加载训练和测试数据</h1><p id="c68a" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">熊猫图书馆可以帮助我们加载数据集进行模型训练。</p><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="134d" class="nj md it mz b gy nk nl l nm nn">train=pd.read_csv("train.csv")<br/>test=pd.read_csv("test.csv",encoding="ISO-8859-1")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/92a506ab8bde3c851d02039e639c842b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TvwYuCiguM-fruMSdo9z1g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料截图</p></figure><h1 id="fecb" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤3:定义文本清理和处理步骤</h1><p id="ac72" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">我们的任务是删除所有的特殊字符，重复的单词，将所有的单词转换成小写，并删除所有的链接和不需要的文本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="4abf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NLTK为我们提供了可以导入的停用词列表，如下所示:</p><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="37f2" class="nj md it mz b gy nk nl l nm nn">stop_words = set(stopwords.words('english'))</span></pre><p id="8f3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们创建一个函数来删除所有的停用词。</p><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="d039" class="nj md it mz b gy nk nl l nm nn">def CleanText(comment):<br/>    comment=processQues(comment)<br/>    comment = nltk.word_tokenize(comment)<br/>    w = [wd for wd in comment if wd not in stop_words]<br/>    return " ".join(w)</span></pre><p id="8d8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义函数后，是时候将它们应用到我们的数据框中了。</p><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="cd84" class="nj md it mz b gy nk nl l nm nn">train["comment_text"]=train["comment_text"].apply(CleanText)<br/>test["comment_text"]=test["comment_text"].apply(CleanText)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/5c3fa0b8ae200add9509c03edaefd613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UuXIbv56t2SysHpQnfAq2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">文本清理结果</p></figure><h1 id="a337" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤4:定义word2vec模型</h1><p id="91c6" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">我们将使用一个预训练的word2vec模型来将我们的文本转换成数字向量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/9f5ab84c70bc9f2fe5ce765e47268c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*S-YuBSu5mld07BZ77xDgBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">字索引</p></figure><h1 id="bf18" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤5:利用手套word2vec模型</h1><p id="f0d1" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">在定义了我们的word2vec模型之后，我们可以根据我们的文本数据使用相同的模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="bc7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将为数据集中的所有单词获得一个大小为100的向量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/3ff5ed4ce3ca2126fad037f900395d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nt5jZ87aguD5sKmVw8GmRQ.png"/></div></div></figure><h1 id="1769" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤6:定义我们的数据训练模型</h1><p id="2df9" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">我们将在Keras中使用一个序列模型，LSTM图层后面是一个密集图层，作为我们的最终输出。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h1 id="b0ce" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤7:训练我们定义的模型</h1><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="5454" class="nj md it mz b gy nk nl l nm nn">model.fit(X_train, y, batch_size=32, epochs=10, validation_split=0.2, verbose=2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/06d2389c6f736f9f46885103daaadc7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaZUx3piMQXv66PjcXlDgg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模特培训</p></figure><h1 id="4b52" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">步骤8:保存并加载我们定义的推理模型</h1><p id="4be8" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">我们可以使用一行Python代码保存我们的模型，如下所示:</p><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="5779" class="nj md it mz b gy nk nl l nm nn">model.save("model_final.h5")<br/>print("Saved model to disk")</span></pre><p id="40ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，为了加载保存的模型，我们可以使用Keras中的<code class="fe mw mx my mz b">load_model</code>函数。</p><pre class="kj kk kl km gt nf mz ng nh aw ni bi"><span id="060e" class="nj md it mz b gy nk nl l nm nn">#Load Model<br/>from tensorflow.keras.models import load_model<br/>model_loaded = load_model('model_final.h5')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/c5f1eb5027ec769a9948c38aa831d50b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LqXtgO8iBT1WKmvrPY3Ukg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">加载的模型摘要</p></figure><h1 id="8766" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="9721" class="pw-post-body-paragraph kz la it lb b lc na ju le lf nb jx lh li nc lk ll lm nd lo lp lq ne ls lt lu im bi translated">好了，这篇文章就到这里。我们已经介绍了一个用于分类有害评论的现成的Keras模型。</p><p id="0804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢这篇文章。敬请关注后续文章。</p><p id="0e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谢谢你的阅读！</p></div></div>    
</body>
</html>
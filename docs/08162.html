<html>
<head>
<title>Introduction to Natural Language Processing With Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python自然语言处理简介</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/introduction-to-natural-language-processing-with-python-913f618021a?source=collection_archive---------8-----------------------#2021-04-01">https://betterprogramming.pub/introduction-to-natural-language-processing-with-python-913f618021a?source=collection_archive---------8-----------------------#2021-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b176" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python学习NLP的基础知识，并赋予文本意义</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9d6a67ba804207f864a7b478416e9461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqgYHlafbBkJfLGFaEaPIQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供。</p></figure><blockquote class="ky"><p id="aaee" class="kz la it bd lb lc ld le lf lg lh li dk translated"><em class="lj">“我语言的极限意味着我世界的极限。”——</em><a class="ae lk" href="https://www.azquotes.com/quote/319126" rel="noopener ugc nofollow" target="_blank"><em class="lj"/></a></p></blockquote><p id="a5b3" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt lu lv lw lx ly lz ma mb mc md me mf li im bi translated">计算机说自己的语言:二进制语言。因此，它们与我们人类互动的方式受到了限制。扩展他们的语言和理解我们自己的语言对于让他们从他们的边界中解放出来是至关重要的。</p><p id="afe3" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">NLP是自然语言处理的缩写，它包括一组计算机可以用来处理和理解人类交流的工具、例程和技术。不要与语音识别混淆，NLP处理的是理解单词的含义，而不仅仅是解释来自这些单词的音频信号。</p><p id="58c4" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">如果你认为NLP只是一个未来的想法，你可能会震惊地知道，当我们在谷歌中执行查询时，我们很可能每天都要与NLP进行交互(例如，当我们在与谷歌助理或Siri交谈时使用在线翻译器)。NLP无处不在，由于NLTK等库提供了对复杂性的巨大抽象，现在在您的项目中实现它是非常容易的。</p><p id="c1d6" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">在本文中，我们将讨论如何通过Python使用<a class="ae lk" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>库来处理NLP。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="f890" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">设置环境</h1><p id="c049" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">为了方便起见，我们将使用<a class="ae lk" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>和<a class="ae lk" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>。您可以通过访问补充源代码来遵循每个步骤:</p><div class="np nq gp gr nr ns"><a href="https://colab.research.google.com/drive/1JlyzJEXCeoFgt52cBoNd77lrDSrj8ISi?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">谷歌联合实验室</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">使用python colab.research.google.com的自然语言处理</h3></div></div><div class="oa l"><div class="ob l oc od oe oa of ks ns"/></div></div></a></div><p id="68d1" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">一旦设置了Jupyter笔记本或您选择的任何环境，请确保使用以下命令安装NLTK库:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="097d" class="ol mt it oh b gy om on l oo op">!pip3 install nltk</span></pre><p id="97e5" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated"><em class="oq">注意:如果你不是在Jupyter笔记本环境下，一开始就不需要</em> <code class="fe or os ot oh b"><em class="oq">!</em></code> <em class="oq">。</em></p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="38f5" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">标记化</h1><p id="00db" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">NLTK是一个巨大的库，它提供了许多不同的工具来处理语言。虽然库本身提供了一些功能，但有些模块需要额外下载。<code class="fe or os ot oh b">punkt</code>是一个处理标记化的模块，标记化是将一个段落分成组块或单词的过程。这通常是文本分析过程的第一步。开始之前，请确保下载了该模块:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="f58d" class="ol mt it oh b gy om on l oo op">import nltk<br/>nltk.download('punkt')</span></pre><p id="2f4c" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">现在，让我们来看看它的运行情况:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="3d9d" class="ol mt it oh b gy om on l oo op">from nltk.tokenize import word_tokenize<br/>Text = "Good morning, How you doing? Are you coming tonight?"<br/>Tokenized = word_tokenize(Text)<br/>print(Tokenized)</span></pre><p id="7716" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="9356" class="ol mt it oh b gy om on l oo op">['Good', 'morning', ',', 'How', 'you', 'doing', '?', 'Are', 'you', 'coming', 'tonight', '?']</span></pre><p id="8173" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">第一个函数<code class="fe or os ot oh b">word_tokenize</code>，将把一个文本分割成单词和符号。然而，你可以用<code class="fe or os ot oh b">punkt</code>做更多的事情，比如把一个段落分成句子。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="1006" class="ol mt it oh b gy om on l oo op">from nltk.tokenize import sent_tokenize<br/>Text = "Good morning, How you doing? Are you coming tonight?"<br/>Tokenized = sent_tokenize(Text)<br/>print(Tokenized)</span></pre><p id="4a69" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="b955" class="ol mt it oh b gy om on l oo op">['Good morning, How you doing?', 'Are you coming tonight?']</span></pre><p id="85fb" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">如果第一个例子不是很令人印象深刻，这个例子肯定是。在这里，我们开始看到一种更智能的方法，试图将文本分割成更简单、更有意义的块。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="c16d" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">停止言语</h1><p id="f9ea" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">停用词是搜索引擎已经被编程忽略的常用词(例如“the”、“a”、“an”、“in”)，无论是在为搜索建立条目索引时还是在作为搜索查询的结果检索它们时。在某些情况下，忽略这些单词是很重要的，因此拥有一本关于它们的字典会变得非常方便——尤其是当我们需要处理多种语言时。</p><p id="cfa8" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">NLTK提供了一个处理停用词的模块。接下来我们来下载一下:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="73ba" class="ol mt it oh b gy om on l oo op">import nltk<br/>nltk.download('stopwords')</span></pre><p id="8329" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">停用词由简单的单词列表组成，所以我们可以很容易地使用它们。例如，我们可以编写一个小的路由来获得一个没有停用词的单词列表:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="fb4b" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="866e" class="ol mt it oh b gy om on l oo op">Good<br/>morning<br/>How<br/>Are<br/>coming<br/>tonight</span></pre><p id="0bca" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">由于我们得到了一个简单的单词列表，我们可以简单地打印它来查看特定语言的所有单词:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="952f" class="ol mt it oh b gy om on l oo op">from nltk.corpus import stopwords<br/>stopwords = stopwords.words("english")<br/>print(stopwords)</span></pre></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="6f52" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">词干</h1><p id="8f51" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">词干是单词的基础或词根形式。例如，“爱”这个词来源于“爱”词干提取是我们将一个给定的单词转换成它的词干的过程。这是一项非常复杂的任务。单词可以有多种写法，不同的单词有不同的取词干方式。</p><p id="c9fa" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">谢天谢地，NLTK让我们很容易实现这一点。让我们看看如何:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="41b8" class="ol mt it oh b gy om on l oo op">from nltk.stem import PorterStemmer<br/>ps = PorterStemmer()<br/>words = ["Loving", "Chocolate", "Retrieved", "Being"]<br/>for i in words:<br/>   print(ps.stem(i))</span></pre><p id="cb8f" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="a4fa" class="ol mt it oh b gy om on l oo op">love<br/>chocol<br/>retriev<br/>be</span></pre><p id="a326" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">单词的这种简化在搜索引擎中非常有用，可以防止相同单词的不同写法在搜索标准中被忽略。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="15ba" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">计数单词</h1><p id="d6df" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">计算每个单词出现的次数在文本分析中非常有用。NLTK为我们提供了一种简洁的方法来计算名为<code class="fe or os ot oh b">FreqDist</code>的文本中的单词频率。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="aba9" class="ol mt it oh b gy om on l oo op">import nltk<br/>words = ["men", "teacher", "men", "woman"]<br/>FreqDist = nltk.FreqDist(words)<br/>for i,j in FreqDist.items():<br/>   print(i, "---", j)</span></pre><p id="209f" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="3513" class="ol mt it oh b gy om on l oo op">men --- 2<br/>teacher --- 1<br/>woman --- 1</span></pre></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="182f" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">单词组</h1><p id="2c9f" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">我们经常会看到一些词被一起使用来表达特定的意思(例如，“我们走吧”、“最佳表现”等)。).在文本分析中，将这些单词成对捕获是很重要的，因为将它们放在一起看会对文本的理解产生很大的影响。</p><h2 id="9bbc" class="ol mt it bd mu ow ox dn my oy oz dp nc lu pa pb ne ly pc pd ng mc pe pf ni pg bi translated">二元模型</h2><p id="834c" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">NLTK提供了一些方法来做到这一点，我们将从二元模型开始。这是一种提取成对连接单词的方法:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="e1a0" class="ol mt it oh b gy om on l oo op">words = "Learning python was such an amazing experience for me"<br/>word_tokenize = nltk.word_tokenize(words)<br/>print(list(nltk.bigrams(word_tokenize)))</span></pre><p id="c979" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="a90f" class="ol mt it oh b gy om on l oo op">[('Learning', 'python'), ('python', 'was'), ('was', 'such'), ('such', 'an'), ('an', 'amazing'), ('amazing', 'experience'), ('experience', 'for'), ('for', 'me')]</span></pre><p id="e5cf" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">我们可以对三个或更多的单词做同样的事情。</p><h2 id="5ae4" class="ol mt it bd mu ow ox dn my oy oz dp nc lu pa pb ne ly pc pd ng mc pe pf ni pg bi translated">三元模型</h2><p id="1a5b" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">当两个词总是一起出现时，就构成了双字。三元模型和二元模型一样，但是有三个单词。代码几乎没有区别:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="074d" class="ol mt it oh b gy om on l oo op">words = "Learning python was such an amazing experience for me"<br/>print(list(nltk.trigrams(word_tokenize)))</span></pre><p id="cb7e" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="cb1a" class="ol mt it oh b gy om on l oo op">[('Learning', 'python', 'was'), ('python', 'was', 'such'), ('was', 'such', 'an'), ('such', 'an', 'amazing'), ('an', 'amazing', 'experience'), ('amazing', 'experience', 'for'), ('experience', 'for', 'me')]</span></pre><h2 id="948b" class="ol mt it bd mu ow ox dn my oy oz dp nc lu pa pb ne ly pc pd ng mc pe pf ni pg bi translated">Ngrams</h2><p id="f28b" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">Ngrams也是一些在单个短语或文档中一起出现的单词、字母或符号，但是您可以指定词频。让我们看一个例子:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="b704" class="ol mt it oh b gy om on l oo op">print(list(nltk.ngrams(word_tokenize, 4)))</span></pre><p id="93ed" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="5e10" class="ol mt it oh b gy om on l oo op">[('Learning', 'python', 'was', 'such'), ('python', 'was', 'such', 'an'), ('was', 'such', 'an', 'amazing'), ('such', 'an', 'amazing', 'experience'), ('an', 'amazing', 'experience', 'for'), ('amazing', 'experience', 'for', 'me')]</span></pre><p id="aa71" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">虽然这个特定文本的结果可能不太令人印象深刻，但有许多用例可以有效地使用Ngrams(例如，用于垃圾邮件检测)。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="d751" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">词汇化</h1><p id="884b" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">词汇化的概念非常类似于词干化。但后者只是去掉了单词的前缀或后缀，有时会出现一些拼写错误。词汇化将它转换成真正的基本词。让我们看一个例子，但是在此之前，我们需要使用NLTK下载WordNet包:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="e440" class="ol mt it oh b gy om on l oo op">nltk.download('wordnet')<br/>from nltk.stem import WordNetLemmatizer<br/>Lem = WordNetLemmatizer()<br/>print(Lem.lemmatize("believes"))<br/>print(Lem.lemmatize("stripes"))</span></pre><p id="dc80" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="0a94" class="ol mt it oh b gy om on l oo op">belief<br/>stripe</span></pre><p id="77cb" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">当您运行代码时，它会将每个单词转换为它的基本单词(例如，“相信”转换为“信念”，“条纹”转换为“条纹”)。这个名为WordNetLemmatizer的包的好处是它有一个名为<code class="fe or os ot oh b">pos</code>的参数，代表“词性”，你可以指定你是否想要获得单词的动词或形容词。</p><p id="2dc4" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">让我们看一个例子:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="7852" class="ol mt it oh b gy om on l oo op">from nltk.stem import WordNetLemmatizer<br/>Lem = WordNetLemmatizer()<br/>print(Lem.lemmatize("believes", pos="v"))<br/>print(Lem.lemmatize("stripes", pos="v"))</span></pre><p id="f23f" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="66e8" class="ol mt it oh b gy om on l oo op">believe<br/>strip</span></pre><p id="848a" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">注意到结果的不同了吗？</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="36d1" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">POS标签</h1><p id="1666" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">当你在学校的时候，你可能学会了将单词分为动词、名词、形容词等。今天，这个任务对于我们人类来说是相当琐碎的，但是如果计算机想要理解人类语言，它们需要理解这些概念。他们需要区分动作和目标，动词和名词。NLTK为我们提供了POS(词性)来对单词进行分类。</p><p id="116d" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">它非常容易使用，所以让我们看看代码:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="fc9e" class="ol mt it oh b gy om on l oo op">nltk.download('averaged_perceptron_tagger')<br/>words = "Learning python was such an amazing experience for me"<br/>word_tokenize = nltk.word_tokenize(words)<br/>print(nltk.pos_tag(word_tokenize))</span></pre><p id="9b05" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="76fc" class="ol mt it oh b gy om on l oo op">[('Learning', 'VBG'), ('python', 'NN'), ('was', 'VBD'), ('such', 'JJ'), ('an', 'DT'), ('amazing', 'JJ'), ('experience', 'NN'), ('for', 'IN'), ('me', 'PRP')]</span></pre><p id="431d" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">结果是一个单词列表以及与每个单词相关联的POS标签。标签是首字母缩写，您可以在下表中找到完整的参考资料:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/d483961ddd9b07fb46feb0f32a37ff68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LN9jKb1_uC1Lg3Ou.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">POS标签列表(来源:<a class="ae lk" href="https://www.researchgate.net/figure/POS-tagging-categories_fig2_234753173" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/figure/POS-tagging-categories _ fig 2 _ 234753173</a>)</p></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="c93c" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">命名实体识别</h1><p id="1d5f" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">现在我们可以开始使用更强大的功能了。NER(命名实体识别)用于捕获命名实体的所有文本提及。命名实体可以是任何东西，从一个地方或一个人到一个组织、金钱等等。</p><p id="f38b" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">这种方法与其他方法相结合，可以非常有效地回答诸如“谁是美国总统？”直接来自文本源，而没有结构化格式的答案。如果你经常使用谷歌，你会看到很多这样的例子。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="d202" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="0b58" class="ol mt it oh b gy om on l oo op">(S<br/>  The/DT<br/>  russian/JJ<br/>  president/NN<br/>  (PERSON Vladimir/NNP Putin/NNP)<br/>  is/VBZ<br/>  in/IN<br/>  the/DT<br/>  (FACILITY Kremlin/NNP))</span></pre><p id="3071" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">我们现在已经开始组合我们所学的函数来收集更多关于文本的信息。通过识别文本中的结构和实体，我们可以赋予文本更多的意义。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="8a5b" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">情感分析</h1><p id="0b61" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">到目前为止，我们已经将文本分解成了更小的单元，然后可以用于处理。情感分析与此不同，因为它是一个确定文本的情感或情绪成分的过程。例如，它以对应用程序、电影等的正面和负面评论进行分类而闻名。</p><p id="c69a" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">尽管可以通过使用我们已经学习过的函数直接使用NLTK进行情感分析，但这仍然是一个不必要的、乏味的过程。幸运的是，Python提供了<a class="ae lk" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> TextBlob </a>，这是一个构建在NLTK之上的文本处理库，可以为我们处理所有复杂的情感分析。</p><p id="da7f" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">它非常容易使用，接下来我们将通过分析美国第46任总统乔·拜登的一条推特来展示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="bcd0" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="2ec8" class="ol mt it oh b gy om on l oo op">Sentiment(polarity=0.0625, subjectivity=0.26666666666666666)</span></pre><p id="b3ec" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">情感分析产生两个变量:极性和主观性。极性是一个介于<em class="oq"> -1 </em>和<em class="oq"> 1 </em>之间的值，其中<em class="oq"> -1 </em>为非常负，<em class="oq"> 1 </em>为非常正。主观性的范围在<em class="oq"> 0 </em>和<em class="oq"> 1 </em>之间，指的是人的观点、情感，甚至是判断。数字越高，文本越主观。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="b4e9" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">拼写纠正</h1><p id="bafe" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">我们提到TextBlob有多种用途，拼写纠正是其中的另一种。TextBlob可以帮助我们消除文本中的拼写错误。让我们来看看它的实际应用:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="826d" class="ol mt it oh b gy om on l oo op">from textblob import TextBlob<br/>Text = "Smalle businesses neede relief"<br/>spelling_mistakes = TextBlob(Text)<br/>print(spelling_mistakes.correct())</span></pre><p id="a0c0" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">输出:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="ddca" class="ol mt it oh b gy om on l oo op">Small business need relief</span></pre><p id="ad9c" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">不出所料，TextBlob发现了我们的错误，并在结果文本中进行了更正。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="0e92" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">结论</h1><p id="e351" class="pw-post-body-paragraph ll lm it ln b lo nk ju lq lr nl jx lt lu nm lw lx ly nn ma mb mc no me mf li im bi translated">NLP是一个复杂而迷人的世界。今天，我们介绍了几个概念和一些代码，但是我们仅仅触及了可以做的事情的表面。</p><p id="3db1" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">NLTK是一个巨大的库，有大量的用例及潜力，值得详细阅读。在接下来的文章中，我们将继续学习NLP，新趋势，新算法，以及人工智能如何让我们生产出可以与人类无缝交互的机器。</p><p id="9511" class="pw-post-body-paragraph ll lm it ln b lo mg ju lq lr mh jx lt lu mi lw lx ly mj ma mb mc mk me mf li im bi translated">感谢阅读！</p></div></div>    
</body>
</html>
<html>
<head>
<title>Winks and Head Turns — Build a Tinder-Swipe iOS App Using ML Kit’s Face Detection API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">眨眼和转头——使用ML Kit的面部检测API构建一个打火刷iOS应用程序</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/build-a-touchless-swipe-ios-app-using-ml-kits-face-detection-api-da40d1e2cb86?source=collection_archive---------16-----------------------#2020-02-13">https://betterprogramming.pub/build-a-touchless-swipe-ios-app-using-ml-kits-face-detection-api-da40d1e2cb86?source=collection_archive---------16-----------------------#2020-02-13</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="1efc" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">利用ML Kit的人脸检测API来执行无接触刷卡</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/ab37b48d390fe1109f38965788cc806a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vlPWJD3pv2pR80Kx"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kw" href="https://unsplash.com/@alexas_fotos?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Alexas_Fotos </a>拍摄的照片</p></figure><p id="e295" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">随着3D运动感应技术已经在Pixel 4上推出，看起来我们与手机的交互方式将很快改变。随着苹果迄今为止最雄心勃勃的产品——AR眼镜——已经在开发中，无触摸交互肯定有着光明的未来。</p><p id="ab48" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">虽然iPhone前置摄像头上的真正深度技术确实允许您在应用程序中添加眼球追踪功能，但它仅在iPhone X和更高版本上可用。幸运的是，我们可以利用Firebase的ML工具包来帮助我们。具体来说，ML Kit的人脸检测API不仅仅是在设备上进行人脸检测。ML Kit的面部检测支持的一些功能有:</p><ul class=""><li id="8d3f" class="lt lu ir kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated"><strong class="kz is">面部跟踪</strong> —这将面部检测技术扩展到视频序列中，根据运动和位置跟踪一段时间内出现的面部。然而，这绝不意味着面部识别(识别显示的特定面部)。</li><li id="3828" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz is">面部朝向</strong>—API返回欧拉角X、Y和Z，以确定在现实空间中的位置。欧拉X角为正的面意味着它朝上；正的欧拉Y角表示脸向左转；并且正的欧拉Z角相对于相机逆时针旋转。</li><li id="b997" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz is">面部分类</strong> —面部检测器具有将面部分类为<em class="mh">微笑</em>的能力，并返回眼睛是否睁开的概率。</li></ul><p id="5366" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在我们深入研究实现之前，让我们列出本教程的目标。</p><h1 id="6e3f" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">我们的目标</h1><ul class=""><li id="741b" class="lt lu ir kz b la na ld nb lg nc lk nd lo ne ls ly lz ma mb bi translated">我们将首先使用Swift在我们的iOS应用程序中创建一个类似Tinder的刷卡界面。左右滑动是现在许多应用程序中常见的一种流行的UI设计。</li><li id="7637" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">接下来，我们将使用AVFoundation框架来设置我们的摄像机以进行帧处理。</li><li id="b355" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">最后，我们将集成ML Kit，并使用上述人脸分类/定向结果来处理无触摸的滑动。</li></ul><h2 id="6677" class="nf mj ir bd mk ng nh dn mo ni nj dp ms lg nk nl mu lk nm nn mw lo no np my nq bi translated">我们的最终目的地</h2><p id="1a57" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">本教程结束时，你将能够眨眼或转动头部来执行刷卡。下图是我完成此应用程序后所取得的成果:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj nu"><img src="../Images/20828b4bd4304d77137abc688f969653.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/1*3sGqBt8KK_1gr9ZV33BAlg.gif"/></div></figure><h1 id="d5b4" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">创建一个类似火绒的滑动界面</h1><p id="da82" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">启动Xcode，使用UIKit创建一个新的单视图应用程序。我不太喜欢故事板，所以我将以编程方式创建所有的视图。</p><blockquote class="nv nw nx"><p id="ba01" class="kx ky mh kz b la lb js lc ld le jv lf ny lh li lj nz ll lm ln oa lp lq lr ls ik bi translated">披露<em class="ir"> : </em>在这个项目的开发过程中，我偶然发现了<a class="ae kw" href="https://medium.com/@phillfarrugia/building-a-tinder-esque-card-interface-5afa63c6d3db" rel="noopener">这个优秀的作品</a>，它展示了如何构建一堆类似Tinder的具有滑动手势功能的卡片，并将其用作kickstarter。</p></blockquote><p id="b746" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">首先，让我们创建一个自定义视图—<code class="fe ob oc od oe b">TinderCard.swift</code>—如下所示:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="e3f1" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">除了设置我们的<code class="fe ob oc od oe b">swipeView</code>之外，我们还从<code class="fe ob oc od oe b">DataModel</code>中设置了一种独特的颜色(接下来会有更多的介绍)，我们已经将<code class="fe ob oc od oe b">UIPanGestureRecognizer</code>添加到上面的自定义视图中，并设置了一个阈值，超过这个阈值，刷卡将被考虑在内，并且调用自定义委托函数(<code class="fe ob oc od oe b">swipeDidEnd</code>)将该卡从堆栈中移除。</p><h2 id="6273" class="nf mj ir bd mk ng nh dn mo ni nj dp ms lg nk nl mu lk nm nn mw lo no np my nq bi translated">数据模型</h2><p id="fb25" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">数据模型目前只保存一个颜色属性。您可以通过添加图像和文本来进一步定制，使其类似于实际的Tinder卡片:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="5c74" class="nf mj ir oe b gz ol om l on oo">import UIKit</span><span id="e515" class="nf mj ir oe b gz op om l on oo">struct DataModel {<br/>    <br/>    var bgColor: UIColor<br/>      <br/>    init(bgColor: UIColor) {<br/>        self.bgColor = bgColor<br/>    }<br/>}</span></pre><h2 id="38ea" class="nf mj ir bd mk ng nh dn mo ni nj dp ms lg nk nl mu lk nm nn mw lo no np my nq bi translated">自定义协议</h2><p id="dc53" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">我们需要创建几个协议。一个用于数据源，另一个用于处理滑动手势操作。它们的定义如下:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="59b0" class="nf mj ir oe b gz ol om l on oo">import UIKit</span><span id="8dcc" class="nf mj ir oe b gz op om l on oo">protocol SwipeCardsDataSource {<br/>    func numberOfCardsToShow() -&gt; Int<br/>    func card(at index: Int) -&gt; TinderCardView<br/>    func emptyView() -&gt; UIView?<br/>    <br/>}</span><span id="4ac6" class="nf mj ir oe b gz op om l on oo">protocol SwipeCardsDelegate {<br/>    func <strong class="oe is">swipeDidEnd</strong>(on view: TinderCardView)<br/>}</span></pre><p id="9a79" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们之前看到的自定义视图中的委托上调用的<code class="fe ob oc od oe b">swipeDidEnd</code>函数触发了stack容器(包含一叠刷卡)。我们来看看<code class="fe ob oc od oe b">StackContainerView.swift</code>类:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="16d5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">上面的<code class="fe ob oc od oe b">StackContainerView</code>班负责抱<code class="fe ob oc od oe b">TinderCardViews</code>组。每次刷卡时，它都会检查数据源(在<code class="fe ob oc od oe b">ViewController</code>中定义)中剩余的牌(如果有)，并将它们添加到牌堆的底部。</p><p id="29ed" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在我们将上面的容器视图插入到我们的<code class="fe ob oc od oe b">ViewController</code>中之前，这里有一个类似Tinder的刷卡界面:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oq"><img src="../Images/6cabc085e31b74c6ea8149f340d6896f.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/1*z0pVCXRU5AlyGaYbexvNXg.gif"/></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">接下来，设置按钮！</p></figure><p id="fe11" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来，我们需要用上面的<code class="fe ob oc od oe b">StackContainer</code>和按钮来设置我们的<code class="fe ob oc od oe b">ViewController</code>，这些按钮可以在按下时模拟滑动手势动画。让我们在下一节做这件事。</p><h1 id="3b91" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">以编程方式模拟滑动手势</h1><p id="10c0" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">为了模拟点击按钮时的滑动手势，我们需要用仿射变换来模拟真实生活中向右或向左滑动的角度，从而将Tinder卡片视图水平动画化。</p><p id="1be7" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在下面的<code class="fe ob oc od oe b">ViewController.swift</code>代码中，我们将设置我们的喜欢和不喜欢按钮，并将数据源插入堆栈容器自定义视图。</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="a5ab" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了将<code class="fe ob oc od oe b">modelData</code>从<code class="fe ob oc od oe b">ViewController</code>传递到<code class="fe ob oc od oe b">StackContainerView</code>，我们遵循了协议:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="2016" class="nf mj ir oe b gz ol om l on oo">stackContainer.dataSource = self</span></pre><p id="9ffb" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">随后，我们需要实现<code class="fe ob oc od oe b">SwipeCardsDataSource</code>协议的方法，如下所示:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="f786" class="nf mj ir oe b gz ol om l on oo">extension ViewController : SwipeCardsDataSource {<br/>    <br/>    func numberOfCardsToShow() -&gt; Int {<br/>        return modelData.count<br/>    }<br/>    <br/>    func card(at index: Int) -&gt; TinderCardView {<br/>        let card = TinderCardView()<br/>        card.dataSource = modelData[index]<br/>        return card<br/>    }<br/>    <br/>    func emptyView() -&gt; UIView? {<br/>        return nil<br/>    }<br/>}</span></pre><h2 id="32c4" class="nf mj ir bd mk ng nh dn mo ni nj dp ms lg nk nl mu lk nm nn mw lo no np my nq bi translated">创建我们的自定义按钮</h2><p id="e3f6" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">在<code class="fe ob oc od oe b">viewDidLoad</code>方法中调用的<code class="fe ob oc od oe b">addButtons</code>函数的实现如下:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="62e1" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe ob oc od oe b">onButtonPress</code>选择器功能是我们模拟左右滑动手势的地方，如下所示:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="dd5b" class="nf mj ir oe b gz ol om l on oo"><a class="ae kw" href="http://twitter.com/objc" rel="noopener ugc nofollow" target="_blank">@objc</a> func onButtonPress(sender: UIButton){<br/>        <br/>        if let firstView = stackContainer.subviews.last as? TinderCardView{<br/>            if sender.tag == 0{<br/>                firstView.leftSwipeClicked(stackContainerView: stackContainer)<br/>            }<br/>            else{<br/>                firstView.rightSwipeClicked(stackContainerView: stackContainer)<br/>            }<br/>        }<br/>}</span></pre><p id="543c" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe ob oc od oe b">leftSwipeClicked</code>和<code class="fe ob oc od oe b">rightSwipeClicked</code>函数在<code class="fe ob oc od oe b">TinderCardView</code>类中实现。<code class="fe ob oc od oe b">leftSwipeClicked</code>功能的代码如下所示:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="2171" class="nf mj ir oe b gz ol om l on oo">func leftSwipeClicked(stackContainerView: StackContainerView)<br/>{<br/>    let finishPoint = CGPoint(x: <strong class="oe is">center.x - frame.size.width * 2</strong>, y: center.y)<br/>    UIView.animate(withDuration: 0.4, animations: {() -&gt; Void in</span><span id="1d32" class="nf mj ir oe b gz op om l on oo">self.center = finishPoint<br/>        self.transform = CGAffineTransform(rotationAngle: <strong class="oe is">-1</strong>)</span><span id="a092" class="nf mj ir oe b gz op om l on oo">}, completion: {(_ complete: Bool) -&gt; Void in<br/>        stackContainerView.swipeDidEnd(on: self)<br/>        self.removeFromSuperview()</span><span id="c86b" class="nf mj ir oe b gz op om l on oo">})<br/>}</span></pre><p id="0265" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">向右滑动类似于上面的代码。您不需要在旋转角度设置为-1的情况下进行仿射变换，而是需要在旋转角度设置为+ 1的情况下进行仿射变换，以显示向右侧的倾斜。</p><p id="1798" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们看看迄今为止我们已经取得的成就:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oq"><img src="../Images/7f69df33b133d8534e6308c1570e101f.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/1*TlNdmYNUutaIjE66GvrH1A.gif"/></div></figure><p id="a0f4" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">既然我们类似Tinder的刷卡原型已经完成，让我们继续讨论相机部分。如果您已经从上一节中注意到了，我们需要设置我们的<code class="fe ob oc od oe b">CameraView</code>类。我们将在屏幕底部执行此操作。</p><h1 id="0dad" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">使用AVFoundation设置摄像机</h1><p id="56db" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">在你设置你的摄像机之前，在<code class="fe ob oc od oe b">info.plist</code>文件中添加<code class="fe ob oc od oe b">NSCameraUsageDescription</code>以避免以后运行时崩溃。</p><p id="e4e4" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">苹果的<strong class="kz is"> AVFoundation </strong>框架帮助我们做了以下事情:</p><ul class=""><li id="7b8f" class="lt lu ir kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">设置我们摄像机的输入设备。在这个用例中，我们将使用前置摄像头。</li><li id="4edc" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">初始化摄像机会话。</li><li id="aac1" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">从输出中捕获一个样本缓冲区。我们将把样本缓冲区从实时帧传递到ML Kit的视觉实例，以检测面部，然后是眨眼和面部定位。</li></ul><p id="5526" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe ob oc od oe b">CameraView.swift</code>类的代码如下所示:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="2f34" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">按下导航条按钮时，将从<code class="fe ob oc od oe b">ViewController</code>调用<code class="fe ob oc od oe b">beginSession</code>功能。</p><p id="48ce" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们以编程方式将刚刚创建的<code class="fe ob oc od oe b">CameraView</code>添加到我们的<code class="fe ob oc od oe b">ViewController</code>视图中，如下所示:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="d36a" class="nf mj ir oe b gz ol om l on oo">func addCameraView()<br/>{<br/>    cameraView = CameraView()<br/><strong class="oe is">    cameraView.blinkDelegate = self</strong><br/>    view.addSubview(cameraView)</span><span id="506c" class="nf mj ir oe b gz op om l on oo">cameraView.translatesAutoresizingMaskIntoConstraints = false<br/>    cameraView.bottomAnchor.constraint(equalTo: view.bottomAnchor).isActive = true<br/>    cameraView.centerXAnchor.constraint(equalTo: view.centerXAnchor).isActive = true<br/>    cameraView.widthAnchor.constraint(equalToConstant: 150).isActive = true<br/>    cameraView.heightAnchor.constraint(equalToConstant: 150).isActive = true<br/>}</span></pre><p id="2e13" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">注意设置在<code class="fe ob oc od oe b">CameraView</code>上的<code class="fe ob oc od oe b">blinkDelegate</code>代表。让我们定义自定义协议<code class="fe ob oc od oe b">BlinkSwiperDelegate</code>，它由两种方法组成:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="2d8d" class="nf mj ir oe b gz ol om l on oo">protocol BlinkSwiperDelegate {</span><span id="c72b" class="nf mj ir oe b gz op om l on oo">func leftBlink()<br/>func rightBlink()</span><span id="28d9" class="nf mj ir oe b gz op om l on oo">}</span></pre><p id="1414" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">每当检测到相应的闪烁时，我们将调用这些方法，以便在<code class="fe ob oc od oe b">TinderCardView</code>上执行滑动。</p><p id="9917" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们继续本教程的最后一部分，将ML Kit集成到我们的iOS应用程序中，并利用它的人脸检测API。</p><h1 id="07f7" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">在我们的IOS应用程序中集成ML工具包</h1><p id="5b34" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">为了开始ML工具包集成，<a class="ae kw" href="https://firebase.google.com/docs/ios/setup" rel="noopener ugc nofollow" target="_blank"> Firebase的文档</a>是一个很好的起点。以下是在应用程序中集成Firebase时需要做的重点工作:</p><ul class=""><li id="c57e" class="lt lu ir kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">创建一个新的Firebase项目，并注册您的应用程序的捆绑包ID。</li><li id="9f25" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">下载<code class="fe ob oc od oe b">GoogleService-Info.plist</code> <strong class="kz is"> </strong>文件，放入你的Xcode项目中。</li><li id="71b1" class="lt lu ir kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">使用Cocoapods或Swift Package Manager添加相关的Firebase依赖项。在我们的案例中，它们是:</li></ul><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="3ee6" class="nf mj ir oe b gz ol om l on oo">pod 'Firebase/MLVision'<br/>pod 'Firebase/MLVisionFaceModel'</span></pre><ul class=""><li id="e964" class="lt lu ir kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">最后，使用<code class="fe ob oc od oe b">FirebaseApp.configure()</code>初始化<code class="fe ob oc od oe b">AppDelegate</code>中的Firebase。</li></ul><p id="3b19" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在我们已经完成了Firebase的设置，<code class="fe ob oc od oe b">import FirebaseMLVision</code>进入你的<code class="fe ob oc od oe b">CameraView.swift</code>班级。是时候对来自摄像机的实时帧执行人脸检测了。</p><p id="c0ea" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在您的<code class="fe ob oc od oe b">CameraView.swift</code>类中初始化以下属性:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="72a0" class="nf mj ir oe b gz ol om l on oo">private lazy var vision = Vision.vision()</span><span id="f1fd" class="nf mj ir oe b gz op om l on oo">lazy var options : VisionFaceDetectorOptions = {<br/>        let o = VisionFaceDetectorOptions()<br/>        o.performanceMode = .accurate<br/>        o.landmarkMode = .none<br/><strong class="oe is">        o.classificationMode = .all</strong><br/>        o.isTrackingEnabled = false<br/>        o.contourMode = .none<br/>        <br/>        return o<br/>    }()</span></pre><blockquote class="nv nw nx"><p id="4db3" class="kx ky mh kz b la lb js lc ld le jv lf ny lh li lj nz ll lm ln oa lp lq lr ls ik bi translated">注意:为了加快眨眼检测，我们已经禁用了地标、轮廓和面部跟踪检测。</p></blockquote><p id="c91d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了检测眼睛睁开的概率和面部方向，在视觉面部检测器选项上设置<code class="fe ob oc od oe b">classificationMode</code>到<code class="fe ob oc od oe b">all</code>很重要。</p><p id="1d3f" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了运行人脸检测，我们需要传递<code class="fe ob oc od oe b">faceDetector</code>方法中的选项。传递给这个<code class="fe ob oc od oe b">faceDetector</code>的图像应该是类型<code class="fe ob oc od oe b">VisionImage</code>。以下代码片段展示了iOS中ML Kit的人脸检测的要点。</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="0645" class="nf mj ir oe b gz ol om l on oo">let faceDetector = vision.faceDetector(options: options)<br/>faceDetector.process(image, completion : {})</span></pre><p id="31b3" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在，让我们从AVFoundation的<code class="fe ob oc od oe b">captureOutput</code>委托方法中检索样本缓冲区，并将其传递给面部检测:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="0c47" class="nf mj ir oe b gz ol om l on oo">func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {<br/>        <br/>        guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {<br/>            print("Failed to get image buffer from sample buffer.")<br/>            return<br/>        }<br/><strong class="oe is">        let visionImage = VisionImage(buffer: sampleBuffer)</strong><br/>        let metadata = VisionImageMetadata()<br/>        let visionOrientation = <strong class="oe is">visionImageOrientation</strong>(from: <strong class="oe is">imageOrientation</strong>())<br/>        metadata.orientation = visionOrientation<br/>        visionImage.metadata = metadata<br/>        let imageWidth = CGFloat(CVPixelBufferGetWidth(imageBuffer))<br/>        let imageHeight = CGFloat(CVPixelBufferGetHeight(imageBuffer))<br/>        <br/>        DispatchQueue.global().async {<br/>            self.detectFacesOnDevice(in: visionImage, width: imageWidth, height: imageHeight)<br/>        }<br/>}</span></pre><p id="6ef4" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe ob oc od oe b">imageOrientation</code>和<code class="fe ob oc od oe b">visionImageOrientation</code>是两个实用函数(可在最后获得源代码),用于确定从摄像机检索的图像的方向，并在调用面部检测器之前在元数据中设置它。</p><h2 id="717e" class="nf mj ir bd mk ng nh dn mo ni nj dp ms lg nk nl mu lk nm nn mw lo no np my nq bi translated">针对眨眼和面部方向执行面部检测</h2><p id="c974" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated"><code class="fe ob oc od oe b">detectFacesOnDevice</code>在<code class="fe ob oc od oe b">VisionImage</code>上为我们进行人脸检测，并返回检测到的<code class="fe ob oc od oe b">VisionFace</code>的列表。使用这些，我们可以找到脸部的包围盒、<code class="fe ob oc od oe b">leftEyeOpenProbability</code>、<code class="fe ob oc od oe b">rightEyeOpenProbability</code>等等。以下代码片段包含该函数的完整实现:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="of og l"/></div></figure><p id="1d0b" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在上面的代码中，当检测到眨眼时，我们触发相关的委托函数。注意<code class="fe ob oc od oe b">restingFace</code>布尔属性。它用于防止多次触发代理功能，并让用户在下一次滑动时通过眨眼返回到正常状态(不闪烁)。</p><p id="febb" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">或者，您可以使用<code class="fe ob oc od oe b">headEulerAngleZ</code>使用面部位置来执行手势滑动——当您向左倾斜头部时会出现正值，应触发向左滑动。您可以设置角度的阈值。以下代码片段显示了处理眨眼和头部姿势的条件:</p><pre class="kh ki kj kk gu oh oe oi oj aw ok bi"><span id="2652" class="nf mj ir oe b gz ol om l on oo">if headPose &gt; 25 || (rightEyeOpenProbability &gt; 0.95 &amp;&amp; leftEyeOpenProbability &lt; 0.1){</span><span id="085e" class="nf mj ir oe b gz op om l on oo">swipeLeft()<br/>}</span></pre><p id="ecf9" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">委托函数<code class="fe ob oc od oe b">rightBlink</code>和<code class="fe ob oc od oe b">leftBlink</code>以编程方式调用各自的滑动，就像我们在上一节模拟滑动手势中看到的那样。</p><p id="ea1e" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">就是这样！您应该会获得类似于开始时看到的结果。</p><p id="dc7d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这个应用程序的完整源代码可以在这个<a class="ae kw" href="https://github.com/anupamchugh/iowncode/tree/master/BlinkPoseAndSwipeiOSMLKit" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>中找到。只需集成Firebase，将<code class="fe ob oc od oe b">GoogleService-Info.plist</code>文件复制到项目中，就可以使用<strong class="kz is">了。</strong></p><h1 id="c5d6" class="mi mj ir bd mk ml mm mn mo mp mq mr ms jx mt jy mu ka mv kb mw kd mx ke my mz bi translated">下一个在哪里？</h1><p id="d962" class="pw-post-body-paragraph kx ky ir kz b la na js lc ld nb jv lf lg nr li lj lk ns lm ln lo nt lq lr ls ik bi translated">使用动作感应的非接触式手势交互有着光明的未来，随着增强现实眼镜已经投入使用，这项技术应该会继续获得大量投资。</p><p id="9c41" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">从这里开始，您可以创建自己的手势检测核心ML模型，在您的应用程序<em class="mh">中执行无触摸滑动<em class="mh"> </em>。</em>或者您可以在此 <em class="mh">处重复使用现有的<a class="ae kw" href="https://github.com/hanleyweng/Gesture-Recognition-101-CoreML-ARKit" rel="noopener ugc nofollow" target="_blank">型号。</a></em></p><p id="1b6d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这一次到此为止。感谢阅读。</p></div></div>    
</body>
</html>
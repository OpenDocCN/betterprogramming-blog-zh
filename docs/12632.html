<html>
<head>
<title>Through iOS 16 APIs, Apple Lays the Foundation For Mixed Reality Development</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过iOS 16 APIs，苹果为混合现实开发奠定基础</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/through-ios-16-apis-apple-lays-the-foundation-for-mixed-reality-development-affc2c3d439e?source=collection_archive---------11-----------------------#2022-06-17">https://betterprogramming.pub/through-ios-16-apis-apple-lays-the-foundation-for-mixed-reality-development-affc2c3d439e?source=collection_archive---------11-----------------------#2022-06-17</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="3e4a" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">不用说这个词，苹果正在准备开发人员为其期待已久的AR/VR设备开发应用程序</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/57c9150e6e2ee4e227c0b106487bc380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DusJ4EjrSJ9E820biWvN0g.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:苹果</p></figure><p id="c5ed" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">当苹果公司的WWDC 2022主题演讲kickstarted时，世界急切地等待着关于备受谈论的混合现实耳机的一些公告。</p><p id="def6" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">至少，一个类似于M1的开发人员DTK的工具包是被期待的。更有甚者，因为有很多关于<a class="ae lv" href="https://twitter.com/ParkerOrtolani/status/1530731346716409864?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1530731346716409864%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fmashable.com%2Farticle%2Fwhat-to-expect-from-apple-wwdc-2022" rel="noopener ugc nofollow" target="_blank"> realityOS </a>可能发布的传言。但是另一个WWDC活动却没有提及苹果最雄心勃勃的项目。</p><p id="9201" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">更让人不解的是？今年，<code class="fe lw lx ly lz b">RealityKit</code>和<code class="fe lw lx ly lz b">SceneKit</code>框架几乎没有任何更新。相反，迎接我们的是M2驱动的MAC电脑、iPadOS的舞台管理器、改进的iOS以及Carplay的重大升级。</p><p id="0812" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这款混合现实耳机曾预计在2020年发布，最终被推迟到2023年，现在只是进一步推迟了——2024年发布。</p><p id="5dd7" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在苹果的辩护中，谨慎的进展是可以理解的。为了让他们的新生产品获得大规模采用，它需要在他们的生态系统中进行更紧密的集成，并让开发人员兴奋地为元宇宙开发产品。</p><p id="0143" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">由于他们在连续性方面的巨大进步，今天苹果的生态系统比以往任何时候都更加统一。如果不提到iOS 16的新功能，我会很疏忽，该功能可以让你将iPhone用作Mac的网络摄像头(看起来这是对苹果耳机如何与iPhone一起操作的测试)。</p><p id="e576" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">与此同时，尽管没有realityOS开发的消息，但iPhone制造商一直在对其API和框架进行重大增强，以塑造开发者的混合现实未来。</p><p id="c97a" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">让我们看看WWDC 2022期间发布的一些新API。其中一些是众所周知的，并在WWDC 22期间受到了极大的关注。然而，从AR/VR开发的角度来看，这些API在活动中扮演的角色并不明显。</p></div><div class="ab cl ma mb hy mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="in io ip iq ir"><h1 id="38d5" class="mh mi iu bd mj mk ml mm mn mo mp mq mr ka ms kb mt kd mu ke mv kg mw kh mx my bi translated">Live Text API和升级的PDFKit，用于扫描媒体中的文本</h1><p id="66df" class="pw-post-body-paragraph kz la iu lb b lc mz jv le lf na jy lh li nb lk ll lm nc lo lp lq nd ls lt lu in bi translated">在iOS 15中，苹果引入了动态文本功能，从图像中提取文本。在iOS 16中，他们通过发布一个实时文本API来轻松从图像和视频帧中抓取文本，从而将事情推向了一个新的高度。作为<code class="fe lw lx ly lz b">VisionKit</code>框架的一部分，<code class="fe lw lx ly lz b">DataScannerViewController</code>类允许您配置各种扫描参数。在幕后，Live Text API使用<code class="fe lw lx ly lz b">VNRecognizeTextRequest</code>来检测文本。</p><p id="996e" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">乍看之下，Live Text API特性就像是注射了类固醇的谷歌镜头。然而，只要想想当苹果的下一个大玩意出现在你眼前时，它会带来什么样的可能性。对于初学者来说，想象转动你的头来用你的眼睛快速提取信息。是的，在iOS 15中已经可以通过AirPods的空间感知来利用<code class="fe lw lx ly lz b">CMHeadphoneMotionManager</code>进行头部跟踪。现在，将iOS 16新的个性化空间音频融入其中，我已经可以看到VR机制的展开。</p><p id="8a2e" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">同样，<code class="fe lw lx ly lz b">PDFKit</code>框架中的两个增强功能——解析文本字段和将文档页面转换为图像的能力——将在构建丰富的AR镜头体验中发挥重要作用。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ne"><img src="../Images/643f7cdaa37a855ca4d797b5a84647d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IDCpdgmF0AV6AVLsUAQBow.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:WWDC 2022视频PDFKit</p></figure><p id="fd98" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">为了确保苹果的混合现实设备不仅仅是你脸上的智能手表，提供一个与文本、图像和图形交互的工具集是很重要的。</p><p id="fe28" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">随着两个强大的图像识别API的推出，我认为iPhone制造商正走在正确的道路上。一条通向具有丰富交互界面的AR/VR应用的道路。</p></div><div class="ab cl ma mb hy mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="in io ip iq ir"><h1 id="43f5" class="mh mi iu bd mj mk ml mm mn mo mp mq mr ka ms kb mt kd mu ke mv kg mw kh mx my bi translated">听写和更好的语音识别</h1><p id="6c8c" class="pw-post-body-paragraph kz la iu lb b lc mz jv le lf na jy lh li nb lk ll lm nc lo lp lq nd ls lt lu in bi translated">暂时忘记文本和图像，iOS 16还改进了听写功能，让用户在语音和触摸之间无缝切换。</p><p id="681b" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">所以，你可能正在走廊里走着，可能想在手机上快速编辑一条短信。在iOS 16中，你可以快速使用语音轻松修改一段文字。</p><p id="a513" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">想要更多吗？<code class="fe lw lx ly lz b">Speech</code>框架有了一点改进——能够从<code class="fe lw lx ly lz b">SFSpeechRecognitionRequest</code>到<code class="fe lw lx ly lz b">addsPunctation</code>切换标点符号。我很乐观，这将带来丰富的通信应用，因为它已经在FaceTime通话中的直播字幕中找到了自己的方式。</p><p id="cad8" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">从混合现实的角度来看，这些是巨大的变化。使用语音输入文本将减少我们在虚拟世界中对键盘的依赖。苹果还使用新的<code class="fe lw lx ly lz b">App Intents</code>框架，让Siri更容易集成到我们的应用程序中。</p></div><div class="ab cl ma mb hy mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="in io ip iq ir"><h1 id="b2e5" class="mh mi iu bd mj mk ml mm mn mo mp mq mr ka ms kb mt kd mu ke mv kg mw kh mx my bi translated">对用户界面的更好控制</h1><p id="623f" class="pw-post-body-paragraph kz la iu lb b lc mz jv le lf na jy lh li nb lk ll lm nc lo lp lq nd ls lt lu in bi translated">在iOS 16中，宣布了大量新的UI控件——主要是在SwiftUI中——这是一个声明性框架，有望成为在所有苹果平台上构建应用的一站式解决方案。</p><p id="2a0f" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在SwiftUI的众多特性中，<code class="fe lw lx ly lz b">WidgetKit</code>框架的变化最能激起我的兴趣。有了iOS 16，开发者现在可以为锁屏构建小工具了。此外，使用相同的代码，您也可以为不同的手表表面构建小部件。我们还可以在<code class="fe lw lx ly lz b">WidgetKit</code>中创建实时活动，为用户提供实时更新。</p><p id="6687" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我真的觉得widgets将成为应用程序的未来——至少在AR/VR领域是如此，因为用户会希望在不打开应用程序的情况下消费信息和浏览内容。</p><p id="8e2e" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">除WidgetKit之外，我们还推出了一个新的<code class="fe lw lx ly lz b">WeatherKit</code>框架，帮助您的应用和小部件更新最新的天气信息。<a class="ae lv" href="https://twitter.com/dejager/status/1534634067953876992" rel="noopener ugc nofollow" target="_blank">让我们来看一下</a>它在锁定屏幕上会是什么样子。</p><p id="a9cc" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">除了框架之外，SwiftUI还为我们提供了许多小型控件——比如<code class="fe lw lx ly lz b">Gauges</code>,它们可以与小部件完美集成。然后是<code class="fe lw lx ly lz b"><a class="ae lv" href="https://developer.apple.com/documentation/swiftui/spatialtapgesture?changes=latest_minor" rel="noopener ugc nofollow" target="_blank">SpatialTapGesture</a></code>——一种在SwiftUI视图中跟踪点击位置的手势。</p><p id="b897" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我特别喜欢让您将SwiftUI视图转换成图像的<code class="fe lw lx ly lz b">ImageRenderer</code> API。再加上<code class="fe lw lx ly lz b">Transferable</code>协议，跨应用程序拖放媒体元素将变得更加简单——因为我们现在在SwiftUI中有一个原生的share sheet控件。下面我们来看看拖放操作是如何让从照片中剪切主题并在其他应用程序中分享变得如此容易的:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ng"><img src="../Images/ad82d89d410b8dab48b043e036d009e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*YMsqEyDZD1Hr-Vto_HRg9g.gif"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:苹果</p></figure><p id="76a0" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">为了构建混合现实耳机的交互式应用，我们与文本、图像、语音、图形和其他形式的媒体进行交互的方式需要变得更加高效。</p><p id="8555" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我认为苹果已经在这个方向上迈出了值得注意的步伐，不仅仅是通过上面提到的UI和手势控制，还通过升级的<code class="fe lw lx ly lz b">SharedPlay</code> API、新的<code class="fe lw lx ly lz b">Shared With You</code>框架和<code class="fe lw lx ly lz b">Collaboration</code> API。</p><p id="f880" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这些看起来都像是苹果期待已久的耳机的有前途的组成部分。</p></div><div class="ab cl ma mb hy mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="in io ip iq ir"><h1 id="ae18" class="mh mi iu bd mj mk ml mm mn mo mp mq mr ka ms kb mt kd mu ke mv kg mw kh mx my bi translated">RoomPlan API和后台资产框架</h1><p id="493a" class="pw-post-body-paragraph kz la iu lb b lc mz jv le lf na jy lh li nb lk ll lm nc lo lp lq nd ls lt lu in bi translated"><code class="fe lw lx ly lz b">Background Assets</code>框架是另一个还没有得到太多关注的工具。引入它是为了处理跨不同应用程序状态的大文件下载，我认为它的可能性超出了这个实用程序。</p><p id="f6b0" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">通过从云中下载3D资产，我们可以快速构建和发布体积更小的增强现实应用。</p><p id="df6b" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">类似地，<code class="fe lw lx ly lz b">RealityKit</code>框架也没有得到任何显著的改变。但是苹果悄悄地发布了一个新的RoomPlan API。</p><p id="d8f4" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">由ARKit 6(今年确实得到了一些显著的改进)提供支持，Swift-only API为扫描房间和构建3D模型提供了开箱即用的支持。</p><p id="7371" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">现在，人们可以将RoomPlan API视为对象捕捉API的扩展，但从AR/VR的角度来看，考虑到苹果的混合现实耳机将拥有激光雷达传感器和多个摄像头，RoomPlan将成为开发者的游戏规则改变者。预计会有很多让你重建房屋的AR应用。</p></div><div class="ab cl ma mb hy mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="in io ip iq ir"><p id="1706" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">虽然这些是我认为将很好地适应混合现实未来的主要API，但<code class="fe lw lx ly lz b">Spatial</code>是另一个新的框架，它支持使用3D数学图元。它可能会在处理虚拟空间中的图形方面证明它的金属。</p><p id="117a" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">最终，苹果对其AR/VR耳机计划只字未提，但他们今年发布的新API将在元宇宙开发的所有环节中发挥关键作用。</p><p id="0958" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">重要的是让开发人员做好准备，为当今的新生态系统开发应用。毕竟，一个产品要想被广泛采用，需要有一个成熟的应用生态系统——这需要开发人员的参与。</p></div></div>    
</body>
</html>
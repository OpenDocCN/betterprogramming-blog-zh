<html>
<head>
<title>Image Classification on Android with TensorFlow Lite and CameraX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于TensorFlow Lite和CameraX的Android图像分类</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/image-classification-on-android-with-tensorflow-lite-and-camerax-4f72e8fdca79?source=collection_archive---------5-----------------------#2019-11-18">https://betterprogramming.pub/image-classification-on-android-with-tensorflow-lite-and-camerax-4f72e8fdca79?source=collection_archive---------5-----------------------#2019-11-18</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="519c" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">利用GPU代理在边缘进行机器学习</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/d526474316a1d5f348496e359478070e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Eo4xf6yOCClvPf5v"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">照片由<a class="ae kw" href="https://unsplash.com/@garett3?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Garett Mizunaka </a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="fc1f" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">TensorFlow Lite是TensorFlow Mobile的轻量级版本。它旨在释放智能手机上的机器学习能力，同时确保模型二进制文件的大小不会太大，并且延迟较低。此外，它还支持使用神经网络API的硬件加速，在GPU的支持下，运行速度注定会提高4倍。</p><p id="74df" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><strong class="kz is"> CameraX </strong>是Jetpack支持库发布的最新相机API。它的目的是让相机的开发变得更加容易，通过谷歌的自动化实验室测试，它努力让所有Android设备保持一致，Android设备有很多。在易用性和简单性方面，CameraX代表了Camera 2 API的巨大改进。</p><p id="6133" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">本文的目标是通过使用TensorFlow Lite模型处理用于图像分类的CameraX帧来合并相机和ML世界。我们将使用Kotlin构建一个Android应用程序，利用智能手机的GPU功能。</p><h1 id="0ba5" class="lt lu ir bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">CameraX:简要概述</h1><p id="defd" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">CameraX具有生命周期意识。因此，它消除了在<code class="fe mq mr ms mt b">onResume</code>和<code class="fe mq mr ms mt b">onPause</code>方法中处理状态的需要。</p><p id="d2e5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">API是基于用例的。目前支持的三种主要用例是:</p><ul class=""><li id="37c0" class="mu mv ir kz b la lb ld le lg mw lk mx lo my ls mz na nb nc bi translated"><strong class="kz is">预览</strong> —显示摄像机画面。</li><li id="d6d4" class="mu mv ir kz b la nd ld ne lg nf lk ng lo nh ls mz na nb nc bi translated"><strong class="kz is">分析</strong> —为计算机视觉或其他机器学习相关任务处理图像。</li><li id="d1aa" class="mu mv ir kz b la nd ld ne lg nf lk ng lo nh ls mz na nb nc bi translated"><strong class="kz is">捕捉</strong> —保存高质量图像。</li></ul><p id="6ddc" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">此外，CameraX还提供了<strong class="kz is">扩展</strong>来轻松访问支持设备上的HDR、人像和夜间模式等功能。</p></div><div class="ab cl ni nj hv nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ik il im in io"><h2 id="8e80" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">张量流Lite转换器</h2><p id="f4b3" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">TensorFlow Lite转换器采用TensorFlow模型并生成TensorFlow Lite <code class="fe mq mr ms mt b"><a class="ae kw" href="https://google.github.io/flatbuffers/" rel="noopener ugc nofollow" target="_blank">FlatBuffer</a></code>文件。的。然后可以将tflite模型部署在移动或嵌入式设备上，使用张量流解释器在本地运行。</p><p id="c163" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">以下代码片段描述了一种将Keras模型转换为移动兼容的<code class="fe mq mr ms mt b">.tflite</code>文件的方法:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="77ed" class="np lu ir mt b gz of og l oh oi">from tensorflow import lite</span><span id="7a78" class="np lu ir mt b gz oj og l oh oi">converter = lite.TFLiteConverter.from_keras_model_file( 'model.h5')</span><span id="1b75" class="np lu ir mt b gz oj og l oh oi">tfmodel = converter.convert()</span><span id="b968" class="np lu ir mt b gz oj og l oh oi">open ("model.tflite" , "wb") .write(tfmodel)</span></pre><p id="069a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在接下来的部分中，我们将使用Kotlin通过MobileNet TensorFlow Lite模型演示CameraX的实际实现。您可以创建自己的定制训练模型，或者在<a class="ae kw" href="https://www.tensorflow.org/lite/guide/hosted_models" rel="noopener ugc nofollow" target="_blank">托管的预训练模型</a>中进行选择。</p><h1 id="726f" class="lt lu ir bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">履行</h1><h2 id="313a" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">在后台</h2><p id="4e42" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">流程真的很简单。我们将位图图像从CameraX中的分析用例传递给TensorFlow解释器，后者使用MobileNet模型和标签类对图像进行推理。下面是CameraX和TensorFlow Lite如何相互交互的图示。</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj ok"><img src="../Images/5c3be87b14c8f20783ff0399f3e25e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*jTcRWi5yVYExsQSuKY6K7Q.jpeg"/></div></figure></div><div class="ab cl ni nj hv nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ik il im in io"><h2 id="d6c3" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">设置</h2><p id="2677" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">启动一个新的Android Studio Kotlin项目，并在应用程序的<code class="fe mq mr ms mt b">build.gradle</code>文件中添加以下依赖项。</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="f53e" class="np lu ir mt b gz of og l oh oi">//CameraX<br/>implementation 'androidx.camera:camera-core:1.0.0-alpha02'<br/>implementation 'androidx.camera:camera-camera2:1.0.0-alpha02'</span><span id="4d14" class="np lu ir mt b gz oj og l oh oi">// Task API<br/>implementation "com.google.android.gms:play-services-tasks:17.0.0"<br/><br/>implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'<br/>implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'</span></pre><p id="44b5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">每夜TensorFlow Lite构建为GPU提供实验性支持。Google Play服务任务API用于处理异步方法调用。</p><p id="6a1d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来，在assets目录下添加MVP文件、标签和<code class="fe mq mr ms mt b">.tflite</code>模型文件。另外，您需要通过在<code class="fe mq mr ms mt b">build.gradle</code>文件中设置下面的<code class="fe mq mr ms mt b">aaptOptions</code>来确保模型没有被压缩:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="99d5" class="np lu ir mt b gz of og l oh oi">android{<br/>aaptOptions {<br/>    noCompress <strong class="mt is">"tflite"<br/>    </strong>noCompress <strong class="mt is">"lite"<br/></strong>}</span></pre><p id="5a7b" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在您的<code class="fe mq mr ms mt b">AndroidManifest.xml</code>文件中添加摄像机的必要权限:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="fe80" class="np lu ir mt b gz of og l oh oi">&lt;uses-permission android:name="android.permission.CAMERA" /&gt;</span></pre><p id="be9d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在设置已经完成，是时候建立布局了！</p><h2 id="93a9" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">布局</h2><p id="648b" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">布局在<code class="fe mq mr ms mt b">activity_main.xml</code>文件中定义，它由一个显示相机预览的TextureView和一个显示图像分类模型预测输出的TextView组成。</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ol om l"/></div></figure><h2 id="01b5" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">请求摄像机权限</h2><p id="a74e" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">在访问摄像机之前，您需要请求运行时权限。下面来自<code class="fe mq mr ms mt b">MainActivity.kt</code>类的代码展示了这是如何实现的。</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ol om l"/></div></figure><p id="05df" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">一旦获得许可，我们就开始拍摄！</p><h2 id="55ae" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">设置相机使用案例</h2><p id="2306" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">如前一节代码所示，<code class="fe mq mr ms mt b">startCamera</code>是从<code class="fe mq mr ms mt b">TextureView</code>上的<code class="fe mq mr ms mt b">post</code>方法中调用的。这确保了只有当<code class="fe mq mr ms mt b">TextureView</code>放在屏幕上时，摄像机才会启动。在<code class="fe mq mr ms mt b">updateTransform</code>方法中，我们相对于设备的方向固定视图的方向。</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ol om l"/></div></figure><p id="4dad" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在上面的代码中，我们做了相当多的事情。让我们逐一看一下:</p><ul class=""><li id="ba47" class="mu mv ir kz b la lb ld le lg mw lk mx lo my ls mz na nb nc bi translated">使用<code class="fe mq mr ms mt b">PreviewConfig.Builder</code>设置我们的预览用例。</li><li id="a029" class="mu mv ir kz b la nd ld ne lg nf lk ng lo nh ls mz na nb nc bi translated"><code class="fe mq mr ms mt b">setOnPreviewOutputUpdateListener</code>是我们将相机预览的表面纹理添加到<code class="fe mq mr ms mt b">TextureView</code>的地方。</li><li id="9577" class="mu mv ir kz b la nd ld ne lg nf lk ng lo nh ls mz na nb nc bi translated">在分析器用例中，我们将图像代理转换为位图，并将其传递给<code class="fe mq mr ms mt b">TFClassifier</code>的<code class="fe mq mr ms mt b">classify</code>方法。如果这看起来不合适，现在跳过它，因为我们将在下一节详细讨论<code class="fe mq mr ms mt b">TFClassifier</code>类。</li></ul><p id="062c" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">以下代码片段用于将ImageProxy转换为位图:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="ae57" class="np lu ir mt b gz of og l oh oi">fun ImageProxy.toBitmap(): Bitmap {<br/>    val yBuffer = <em class="on">planes</em>[0].<em class="on">buffer </em>// Y<br/>    val uBuffer = <em class="on">planes</em>[1].<em class="on">buffer </em>// U<br/>    val vBuffer = <em class="on">planes</em>[2].<em class="on">buffer </em>// V<br/><br/>    val ySize = yBuffer.remaining()<br/>    val uSize = uBuffer.remaining()<br/>    val vSize = vBuffer.remaining()<br/><br/>    val nv21 = ByteArray(ySize + uSize + vSize)<br/>    <br/>    yBuffer.get(nv21, 0, ySize)<br/>    vBuffer.get(nv21, ySize, vSize)<br/>    uBuffer.get(nv21, ySize + vSize, uSize)<br/><br/>    val yuvImage = YuvImage(nv21, ImageFormat.<em class="on">NV21</em>, this.<em class="on">width</em>, this.<em class="on">height</em>, null)<br/>    val out = ByteArrayOutputStream()<br/>    yuvImage.compressToJpeg(Rect(0, 0, yuvImage.<em class="on">width</em>, yuvImage.<em class="on">height</em>), 100, out)<br/>    val imageBytes = out.toByteArray()<br/>    return BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size)<br/>}</span></pre><p id="874b" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">现在是运行图像分类的时候了！让我们跳到下一部分。</p><h1 id="509c" class="lt lu ir bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">张量流精简解释程序</h1><p id="2d96" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">TensorFlow Lite解释器遵循以下步骤，以便根据输入返回预测。</p><h2 id="6a9d" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">1.将模型转换成字节缓冲区</h2><p id="2d53" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">我们必须从Assets文件夹中对模型进行内存映射，以获得一个ByteBuffer，它最终被加载到解释器中:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="8bea" class="np lu ir mt b gz of og l oh oi">@Throws(IOException::class)<br/>private fun loadModelFile(assetManager: AssetManager, filename: String): ByteBuffer {<br/>    val fileDescriptor = assetManager.openFd(filename)<br/>    val inputStream = FileInputStream(fileDescriptor.<em class="on">fileDescriptor</em>)<br/>    val fileChannel = inputStream.<em class="on">channel<br/>    </em>val startOffset = fileDescriptor.<em class="on">startOffset<br/>    </em>val declaredLength = fileDescriptor.<em class="on">declaredLength<br/>    </em>return fileChannel.map(FileChannel.MapMode.<em class="on">READ_ONLY</em>, startOffset, declaredLength)<br/>}</span></pre><h2 id="1179" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">2.将标签类加载到数据结构中</h2><p id="4c61" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">标签文件由来自ImageNet的数千个不同的类组成。我们将把这些标签加载到一个数组中。最后，解释器将根据这些标签字符串返回预测。</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="d1f6" class="np lu ir mt b gz of og l oh oi">@Throws(IOException::class)<br/>fun loadLines(context: Context, filename: String): ArrayList&lt;String&gt; {<br/>    val s = Scanner(InputStreamReader(context.<em class="on">assets</em>.open(filename)))<br/>    val labels = ArrayList&lt;String&gt;()<br/>    while (s.hasNextLine()) {<br/>        labels.add(s.nextLine())<br/>    }<br/>    s.close()<br/>    return labels<br/>}<br/>var labels = loadLines(context, "labels.txt")</span></pre><h2 id="9eea" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">3.初始化我们的解释器</h2><p id="e31c" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">现在我们已经有了ByteBuffer和标签列表，是时候初始化我们的解释器了。在下面的代码中，我们在我们的<code class="fe mq mr ms mt b">Interpreter.Options()</code>方法中添加了<code class="fe mq mr ms mt b">GPUDelegate</code>:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ol om l"/></div></figure><p id="c207" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在上面的代码中，一旦模型的设置在解释器中完成，我们就检索模型的输入张量形状。这样做是为了将位图预处理成模型接受的相同形状。</p><p id="d1ff" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe mq mr ms mt b">Callable</code>接口类似于<code class="fe mq mr ms mt b">Runnable</code>，但是允许我们返回一个结果。<code class="fe mq mr ms mt b">ExecutorService</code>用于管理线程池中的多个线程。</p><p id="1415" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在我们的<code class="fe mq mr ms mt b">MainActivity</code>的<code class="fe mq mr ms mt b">onCreate</code>方法中调用了<code class="fe mq mr ms mt b">initialize</code>方法，如下所示:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="dc62" class="np lu ir mt b gz of og l oh oi">private var tfLiteClassifier: TFLiteClassifier = TFLiteClassifier(this@MainActivity)</span><span id="7cae" class="np lu ir mt b gz oj og l oh oi">tfLiteClassifier<br/>    .initialize()<br/>    .addOnSuccessListener <strong class="mt is">{ }<br/>    </strong>.addOnFailureListener <strong class="mt is">{ </strong>e <strong class="mt is">-&gt; </strong>Log.e(TAG, "Error in setting up the classifier.", e) <strong class="mt is">}</strong></span></pre><h2 id="5170" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">4.预处理输入并运行推理</h2><p id="6fbd" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">我们现在可以调整位图的大小来适应模型输入的形状。然后，我们将把新的位图转换成ByteBuffer，以便执行模型:</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="ol om l"/></div></figure><p id="d598" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在上面的代码中，<code class="fe mq mr ms mt b">convertBitmapToByteBuffer</code>屏蔽了每个像素的8个最低有效位，以忽略alpha通道。</p><p id="7c7a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">除了ByteBuffer之外，我们还为每个图像类传递一个浮点数组，在这个数组上将计算和返回预测。</p><h2 id="52db" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">5.计算参数最大值</h2><p id="75c3" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">最后，<code class="fe mq mr ms mt b">getMaxResult</code>函数返回可信度最高的标签，如下面的代码片段所示:</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="ef76" class="np lu ir mt b gz of og l oh oi">private fun getMaxResult(result: FloatArray): Int {<br/>    var probability = result[0]<br/>    var index = 0<br/>    for (i in result.<em class="on">indices</em>) {<br/>        if (probability &lt; result[i]) {<br/>            probability = result[i]<br/>            index = i<br/>        }<br/>    }<br/>    return index<br/>}</span></pre><p id="1f03" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">由于有了<code class="fe mq mr ms mt b">Callable</code>接口，在分析器用例中运行的<code class="fe mq mr ms mt b">classifyAsync</code>方法通过<code class="fe mq mr ms mt b">onSuccessListener</code>获得一个由预测和推断时间组成的字符串。</p><pre class="kh ki kj kk gu ob mt oc od aw oe bi"><span id="df59" class="np lu ir mt b gz of og l oh oi">tfLiteClassifier<br/>    .classifyAsync(bitmap)<br/>    .addOnSuccessListener <strong class="mt is">{ </strong>resultText <strong class="mt is">-&gt; </strong>predictedTextView?.<em class="on">text </em>= resultText <strong class="mt is">}</strong></span></pre><p id="5eeb" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">作为回报，我们在屏幕上显示预测标签和推断时间，如下所示:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oo"><img src="../Images/15a599f4c7d448134c0926a8a9ba6c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/1*kWnN1ayhShg9QVDboez43Q.gif"/></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">我们应用程序的屏幕截图</p></figure><h2 id="3f83" class="np lu ir bd lv nq nr dn lz ns nt dp md lg nu nv mf lk nw nx mh lo ny nz mj oa bi translated">结论</h2><p id="0ad9" class="pw-post-body-paragraph kx ky ir kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ik bi translated">这就总结了这篇文章。我们使用TensorFlow Lite和CameraX构建了一个使用MobileNet的图像分类Android应用程序，同时利用了GPU delegate——我们很快就得到了一个相当准确的结果。从这里开始，您可以尝试构建自己的定制TFLite模型，并看看它们在CameraX上的表现如何。CameraX仍处于alpha阶段，但你已经可以用它做很多事情了。</p><p id="8dd5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">该指南的完整源代码是<a class="ae kw" href="https://github.com/anupamchugh/AndroidTfLiteCameraX/tree/master" rel="noopener ugc nofollow" target="_blank">，可在此处</a>获得。</p><p id="a79f" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这一次到此为止。我希望你喜欢阅读。</p></div></div>    
</body>
</html>
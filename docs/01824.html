<html>
<head>
<title>PencilKit Meets Core ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PencilKit遇上Core ML</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/pencilkit-meets-core-ml-aefe3cde6a96?source=collection_archive---------19-----------------------#2019-10-15">https://betterprogramming.pub/pencilkit-meets-core-ml-aefe3cde6a96?source=collection_archive---------19-----------------------#2019-10-15</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="6bba" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">用MNIST识别图形中的数字</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/c414fe11e60111d7b380b8c504e0b09b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1LSLrP8jtP0bpdBl2WVj5w.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来自我们的iOS应用程序的草图</p></figure><p id="dc5b" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在WWDC 19期间引入的<a class="ae lv" href="https://medium.com/better-programming/an-introduction-to-pencilkit-in-ios-4d40aa62ba5b" rel="noopener"> PencilKit </a>框架对于希望在iOS和iPadOS 13应用中利用绘图框架的开发人员来说是一个福音。在我们的应用程序中，三个角色在设置PencilKit框架中扮演着重要的角色。它们是:</p><ul class=""><li id="d439" class="lw lx iu lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><code class="fe mf mg mh mi b">PKCanvasView</code></li><li id="d97e" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><code class="fe mf mg mh mi b">PKDrawingView</code></li><li id="5691" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated"><code class="fe mf mg mh mi b">PKToolPicker</code></li></ul><p id="613f" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在下面的部分中，我们将一起使用PencilKit框架和Core ML框架来识别绘图中的数字。</p><h1 id="d2a5" class="mo mp iu bd mq mr ms mt mu mv mw mx my ka mz kb na kd nb ke nc kg nd kh ne nf bi translated">我们的目标</h1><ul class=""><li id="8d2a" class="lw lx iu lb b lc ng lf nh li ni lm nj lq nk lu mb mc md me bi translated">设置基于PencilKit框架的iOS应用程序。</li><li id="ca2a" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">使用著名的MNIST数据集来识别在PencilKit画布上绘制的数字。</li><li id="53da" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">利用核心ML框架来预测和显示抽取的数字。</li></ul></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="612f" class="mo mp iu bd mq mr ns mt mu mv nt mx my ka nu kb na kd nv ke nc kg nw kh ne nf bi translated">一句简短的话</h1><p id="3736" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">MNIST数据集是一个图像数据集，由大约60，000个尺寸为28 x 28的灰度手写数字图像组成。</p><p id="0008" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这些图像的大小为20 x 20，并且被标准化以适合盒子的中心。当数字在输入图像中居中时，精确度最好。</p><p id="1e43" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在本文中，我们不会深入研究模型层和训练数据集。假设我们得到了一个现成的核心ML MNSIT模型。</p></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="879e" class="mo mp iu bd mq mr ns mt mu mv nt mx my ka nu kb na kd nv ke nc kg nw kh ne nf bi translated">我们的最终目的地</h1><p id="4634" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">一幅图像胜过千言万语。GIF由成千上万的图片组成。这是你在这篇文章结束时得到的最终结果。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oa"><img src="../Images/8c2eeb9c071259f0c0fe140b95744594.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/0*OH__OyY7xqps_Z2L.gif"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">最后结局</p></figure></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="3c5c" class="mo mp iu bd mq mr ns mt mu mv nt mx my ka nu kb na kd nv ke nc kg nw kh ne nf bi translated">安装</h1><p id="cb83" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">在Core ML与PencilKit框架约会之前，让我们穿上PencilKit框架。</p><h2 id="040e" class="ob mp iu bd mq oc od dn mu oe of dp my li og oh na lm oi oj nc lq ok ol ne om bi translated">搭建画布</h2><p id="82a9" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">在我们的应用程序中设置<code class="fe mf mg mh mi b">PKCanvasView</code>非常容易，如下面的代码所示:</p><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="8aa9" class="ob mp iu mi b gz or os l ot ou">let canvasView = PKCanvasView(frame: .zero)<br/>canvasView.backgroundColor = .black<br/>canvasView.translatesAutoresizingMaskIntoConstraints = false<br/>view.addSubview(canvasView)<br/>NSLayoutConstraint.activate([<br/>   canvasView.topAnchor.constraint(equalTo: navigationBar.bottomAnchor),<br/>   canvasView.bottomAnchor.constraint(equalTo: view.bottomAnchor),<br/>   canvasView.leadingAnchor.constraint(equalTo: view.leadingAnchor),<br/>   canvasView.trailingAnchor.constraint(equalTo: view.trailingAnchor),<br/>])</span></pre><h2 id="253b" class="ob mp iu bd mq oc od dn mu oe of dp my li og oh na lm oi oj nc lq ok ol ne om bi translated">设置我们的工具选择器</h2><p id="3c42" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">ToolPicker负责在我们的应用程序中显示各种画笔。它提供了墨水、铅笔、选区、橡皮擦工具以及撤销和重做选项(由于屏幕尺寸的原因，这仅在iPadOS上可用)。</p><p id="98ef" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">以下代码显示了如何在我们的应用程序中设置ToolPicker UI:</p><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="9f0d" class="ob mp iu mi b gz or os l ot ou">override func viewDidAppear(_ animated: Bool) {<br/>    super.viewDidAppear(animated)</span><span id="0100" class="ob mp iu mi b gz ov os l ot ou">guard<br/>     let window = view.window,<br/>     let toolPicker = PKToolPicker.shared(for: window) else {return}</span><span id="4c80" class="ob mp iu mi b gz ov os l ot ou">toolPicker.setVisible(true, forFirstResponder: canvasView)<br/>    toolPicker.addObserver(canvasView)<br/>    canvasView.becomeFirstResponder()<br/>}</span></pre><h2 id="2610" class="ob mp iu bd mq oc od dn mu oe of dp my li og oh na lm oi oj nc lq ok ol ne om bi translated">设置我们的导航栏按钮</h2><p id="1443" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">导航栏已经添加到情节提要中。在下面的代码中，我们添加了几个动作按钮。</p><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="4bb8" class="ob mp iu mi b gz or os l ot ou">func setNavigationBar() {<br/>        if let navItem = navigationBar.topItem{<br/>            <br/>            let detectItem = UIBarButtonItem(title: "Detect", style: .done, target: self, action: #selector(detectImage))<br/>            let clearItem = UIBarButtonItem(title: "Clear", style: .plain, target: self, action: #selector(clear))</span><span id="f2f6" class="ob mp iu mi b gz ov os l ot ou">navItem.rightBarButtonItems = [clearItem,detectItem]<br/>            navItem.leftBarButtonItem = UIBarButtonItem(title: "", style: .plain, target: self, action: nil)<br/>            <br/>        }<br/>}</span></pre><p id="f6a6" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">左栏按钮是显示最终预测输出的地方。</p></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="7384" class="mo mp iu bd mq mr ns mt mu mv nt mx my ka nu kb na kd nv ke nc kg nw kh ne nf bi translated">预处理绘图输入</h1><p id="4c29" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">以便将PencilKit绘图提供给CoreML框架。我们首先需要从画布中提取图像。让我们看看这是怎么做到的。</p><ul class=""><li id="9fe5" class="lw lx iu lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">将<code class="fe mf mg mh mi b">PKDrawing</code>实例转换成<code class="fe mf mg mh mi b">UIImage</code>很简单。真正的挑战是为核心ML模型进行预处理。</li><li id="d962" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">我们从PKDrawing获得的UIImage只包含绘制的图像，没有填充。</li><li id="3c17" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu mb mc md me bi translated">我们需要创建一个具有视图大小的图像，并将中心的<code class="fe mf mg mh mi b">PKDrawing</code>叠加到<code class="fe mf mg mh mi b">UIImage</code>上。基本上是UIImage中的UIImage。</li></ul><p id="5c27" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">以下代码为您完成了这项工作:</p><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="0529" class="ob mp iu mi b gz or os l ot ou">func preprocessImage() -&gt; UIImage{<br/>        var image = canvasView.drawing.image(from: canvasView.drawing.bounds, scale: 10.0)<br/>        if let newImage = UIImage(color: .black, size: CGSize(width: view.frame.width, height: view.frame.height)){</span><span id="efb5" class="ob mp iu mi b gz ov os l ot ou">if let overlayedImage = newImage.image(byDrawingImage: image, inRect: CGRect(x: view.center.x, y: view.center.y, width: view.frame.width, height: view.frame.height)){<br/>                image = overlayedImage<br/>            }<br/>        }<br/>}</span></pre><p id="5176" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">上述代码中使用了以下助手扩展函数:</p><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="d626" class="ob mp iu mi b gz or os l ot ou">extension UIImage {<br/>    <br/>    public convenience init?(color: UIColor, size: CGSize = CGSize(width: 1, height: 1)) {<br/>        let rect = CGRect(origin: .zero, size: size)<br/>        UIGraphicsBeginImageContextWithOptions(rect.size, false, 0.0)<br/>        color.setFill()<br/>        UIRectFill(rect)<br/>        let image = UIGraphicsGetImageFromCurrentImageContext()<br/>        UIGraphicsEndImageContext()</span><span id="054a" class="ob mp iu mi b gz ov os l ot ou">guard let cgImage = image?.cgImage else { return nil }<br/>        self.init(cgImage: cgImage)<br/>    }</span><span id="57df" class="ob mp iu mi b gz ov os l ot ou">func image(byDrawingImage image: UIImage, inRect rect: CGRect) -&gt; UIImage! {<br/>        UIGraphicsBeginImageContext(size)</span><span id="20dd" class="ob mp iu mi b gz ov os l ot ou">draw(in: CGRect(x: 0, y: 0, width: size.width, height: size.height))<br/>        image.draw(in: rect)<br/>        let result = UIGraphicsGetImageFromCurrentImageContext()<br/>        UIGraphicsEndImageContext()<br/>        return result<br/>    }<br/>}</span><span id="c7d9" class="ob mp iu mi b gz ov os l ot ou">extension CGRect {<br/>    var center: CGPoint { return CGPoint(x: midX, y: midY) }<br/>}</span></pre></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="9a01" class="mo mp iu bd mq mr ns mt mu mv nt mx my ka nu kb na kd nv ke nc kg nw kh ne nf bi translated">使用核心ML进行预测</h1><p id="8577" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">既然映像已经可以输入了，我们需要做以下三件事:</p><ol class=""><li id="0084" class="lw lx iu lb b lc ld lf lg li ly lm lz lq ma lu ow mc md me bi translated">将其调整为输入尺寸28 x 28。</li><li id="d42d" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu ow mc md me bi translated">将其转换成灰度色彩空间中的<code class="fe mf mg mh mi b">CVPixelBuffer</code>。</li><li id="6bf8" class="lw lx iu lb b lc mj lf mk li ml lm mm lq mn lu ow mc md me bi translated">喂给核心ML模型。</li></ol><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="88a2" class="ob mp iu mi b gz or os l ot ou">private let trainedImageSize = CGSize(width: 28, height: 28)</span><span id="df21" class="ob mp iu mi b gz ov os l ot ou">func predictImage(image: UIImage){<br/>        if let resizedImage = image.resize(newSize: trainedImageSize), let pixelBuffer = resizedImage.toCVPixelBuffer(){</span><span id="46e1" class="ob mp iu mi b gz ov os l ot ou">guard let result = try? MNIST().prediction(image: pixelBuffer) else {<br/>            return<br/>        }<br/>            navigationBar.topItem?.leftBarButtonItem?.title = "Predicted: \(result.classLabel)"<br/>            print("result is \(result.classLabel)")<br/>        }<br/>}</span></pre><p id="0a68" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">上述代码使用了以下扩展函数:</p><pre class="kk kl km kn gu on mi oo op aw oq bi"><span id="32b9" class="ob mp iu mi b gz or os l ot ou">extension UIImage{<br/>func resize(newSize: CGSize) -&gt; UIImage? {<br/>        UIGraphicsBeginImageContextWithOptions(newSize, false, 0.0)<br/>        self.draw(in: CGRect(x: 0, y: 0, width: newSize.width, height: newSize.height))<br/>        let newImage = UIGraphicsGetImageFromCurrentImageContext()<br/>        UIGraphicsEndImageContext()<br/>        return newImage<br/>    }<br/>    <br/>    <br/>    func toCVPixelBuffer() -&gt; CVPixelBuffer? {<br/>       var pixelBuffer: CVPixelBuffer? = nil</span><span id="7574" class="ob mp iu mi b gz ov os l ot ou">let attr = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,<br/>        kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue] as CFDictionary<br/>        <br/>       let width = Int(self.size.width)<br/>       let height = Int(self.size.height)</span><span id="e95d" class="ob mp iu mi b gz ov os l ot ou">CVPixelBufferCreate(kCFAllocatorDefault, width, height, kCVPixelFormatType_OneComponent8, attr, &amp;pixelBuffer)<br/>       CVPixelBufferLockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue:0))</span><span id="dace" class="ob mp iu mi b gz ov os l ot ou">let colorspace = CGColorSpaceCreateDeviceGray()<br/>       let bitmapContext = CGContext(data: CVPixelBufferGetBaseAddress(pixelBuffer!), width: width, height: height, bitsPerComponent: 8, bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer!), space: colorspace, bitmapInfo: 0)!</span><span id="4902" class="ob mp iu mi b gz ov os l ot ou">guard let cg = self.cgImage else {<br/>           return nil<br/>       }</span><span id="932e" class="ob mp iu mi b gz ov os l ot ou">bitmapContext.draw(cg, in: CGRect(x: 0, y: 0, width: width, height: height))</span><span id="e9ed" class="ob mp iu mi b gz ov os l ot ou">return pixelBuffer<br/>    }<br/>}</span></pre></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="756e" class="mo mp iu bd mq mr ns mt mu mv nt mx my ka nu kb na kd nv ke nc kg nw kh ne nf bi translated">结论</h1><p id="3a1e" class="pw-post-body-paragraph kz la iu lb b lc ng jv le lf nh jy lh li nx lk ll lm ny lo lp lq nz ls lt lu in bi translated">所以我们设法使用CoreML和PencilKit框架来确定使用MNIST数据集绘制的草图。设备上的机器学习有大量的用例，推断图纸只是其中之一。你可以在<a class="ae lv" href="https://github.com/anupamchugh/iowncode/tree/master/iOSPencilKitCoreMLMNIST" rel="noopener ugc nofollow" target="_blank"> Github库</a>中找到完整的源代码。</p><p id="9dc4" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">这一次到此为止。我希望你喜欢阅读。</p></div></div>    
</body>
</html>
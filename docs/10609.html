<html>
<head>
<title>Performance Tuning of AWS EMR Spark Job With Hands-on Demo</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS EMR Spark作业的性能调整和实际操作演示</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/performance-tuning-of-aws-emr-spark-job-with-hands-on-demo-48469e139826?source=collection_archive---------4-----------------------#2022-01-18">https://betterprogramming.pub/performance-tuning-of-aws-emr-spark-job-with-hands-on-demo-48469e139826?source=collection_archive---------4-----------------------#2022-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f617" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当我们需要优化我们的spark工作时，我们经常会遇到这样的情况，这篇文章通过实际操作的例子深入探讨了细节</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2a76dce019daf24950026514f6a891e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*svuZVkM5uGIp7VeC-NObIw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="6ec7" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">我们将学到什么:</h1><p id="6d0e" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">火花优化通过:</p><ol class=""><li id="8100" class="mm mn it ls b lt mo lw mp lz mq md mr mh ms ml mt mu mv mw bi translated">识别和设置正确的Apache Spark配置</li><li id="caec" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">执行人编号</li><li id="c472" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">贮藏</li><li id="14ea" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">优化连接</li><li id="e4b2" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">减少工作和阶段的数量</li></ol><h1 id="2c6c" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">先决条件:</h1><p id="dd46" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在EMR上设置一个快速笔记本。如果你不确定如何做，请点击下面的链接。</p><div class="nc nd gp gr ne nf"><a href="https://medium.com/@sumoaps/setup-jupyter-notebook-with-emr-to-run-spark-job-in-5-minutes-21c23de4fdf3" rel="noopener follow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">用EMR设置Jupyter笔记本，在5分钟内运行spark作业</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">我们经常喜欢使用spark进行临时数据分析。本教程指导我们快速入门Jupyter…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt ks nf"/></div></div></a></div><h1 id="7211" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">查看和设置Apache Spark配置</h1><p id="91b2" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们先看看如何设置查找，然后优化改变火花配置。了解如何找到spark作业的配置、理解它们并更改它们以实现最佳性能非常重要。</p><h2 id="8e8b" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">获取配置</h2><p id="6028" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们可以通过Spark UI的环境选项卡访问Spark的当前配置:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/46bd393727161844c8742ca824c88cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*h59BraITv1lVGePj.png"/></div></div></figure><p id="aed6" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">您还可以只查看Spark SQL特定的Spark配置:</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="3a77" class="nu kz it ol b gy op oq l or os">// In Scala<br/>spark.sql("SET -v").select("key",<!-- --> <!-- -->"value").show(5,<!-- --> <!-- -->false)</span><span id="42e4" class="nu kz it ol b gy ot oq l or os"># In Python<br/>spark.sql("SET -v").select("key",<!-- --> <!-- -->"value").show(n=5,<!-- --> <!-- -->truncate=False)</span></pre><p id="2d05" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">在我们的笔记本中，输出如下所示</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/ee7eff299ef4831e1acd1cdfb6580897.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*euXHT8vgwl8XqUE608VHPw.png"/></div></div></figure><blockquote class="ov ow ox"><p id="7ca2" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">若要以编程方式设置或修改现有配置，请首先检查属性是否可修改。<code class="fe pc pd pe ol b">spark.conf.isModifiable("<em class="it">&lt;config_name&gt;</em>")</code>将返回<code class="fe pc pd pe ol b">true</code>或<code class="fe pc pd pe ol b">false</code></p></blockquote><p id="c189" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">让我们试试我们的笔记本:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/9b19b1a59c35a9f64cbbaeba1e773940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mb8tzjXLh9IWaSrK6KqhCA.png"/></div></div></figure><p id="2a26" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">我们也可以通过spark.conf.get(" &lt;<configuration>&gt; ")获得一个conf。让我们在笔记本上找到随机分区</configuration></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/4cd899a62dc95e3a563d85f70699dbbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ml8j1lFbTJ1cxm_XbDkjXA.png"/></div></div></figure><h2 id="dd3a" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">要设置配置</h2><p id="6ad8" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">设置配置最常见的方式是在Spark应用程序中直接指定Spark配置，或者在使用<code class="fe pc pd pe ol b">spark-submit</code>提交应用程序时在命令行上指定，使用<code class="fe pc pd pe ol b">--conf</code>标志:</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="2eba" class="nu kz it ol b gy op oq l or os">spark-submit --conf spark.sql.shuffle.partitions=5 --conf<br/>"spark.executor.memory=2g" --class com.spark.SparkConfig jars/my_spark.jar</span></pre><p id="f78b" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">另一种方法是在应用程序本身中指定。下面是一个代码示例:</p><p id="55db" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">注意:我们已经在笔记本电脑中开展了spark会议。以下代码更适合独立的spark应用程序</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="3cf3" class="nu kz it ol b gy op oq l or os">// In Scala<br/><br/> val spark = SparkSession.builder<br/>   .config("spark.sql.shuffle.partitions", 5)<br/>   .config("spark.executor.memory", "2g")<br/>   .master("local[*]")<br/>   .appName("SparkConfig")<br/>   .getOrCreate()<br/></span></pre><h2 id="9491" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">好了，让我们来看看我们应该注意的配置:</h2><h2 id="545a" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">动态资源分配</h2><p id="51d4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">当我们将计算资源指定为<code class="fe pc pd pe ol b">spark-submit</code>的命令行参数时，正如我们之前所做的，我们设置了上限。这意味着，如果由于工作负载超出预期，任务在驱动程序中排队时需要更多的资源，Spark将无法容纳或分配额外的资源。</p><p id="58a7" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">相反，如果您使用Spark的动态资源分配配置，Spark驱动程序可以随着大型工作负载需求的增减而请求更多或更少的计算资源。在工作负载是动态的情况下，也就是说，它们对计算能力的需求是变化的，使用动态分配有助于适应突然出现的峰值。</p><p id="3679" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">这可能有所帮助的一个用例是流，其中数据流量可能不均匀。另一个是按需数据分析，在这种情况下，您可能会在高峰时段有大量的SQL查询</p><p id="533f" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">要启用和配置动态分配，我们可以使用如下设置。</p><p id="50d7" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">注意:这里的数字是任意的；适当的设置将取决于您的工作负载的性质，并且应该相应地进行调整。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="8a7f" class="nu kz it ol b gy op oq l or os">spark.dynamicAllocation.enabled true<br/>spark.dynamicAllocation.minExecutors 2<br/>spark.dynamicAllocation.schedulerBacklogTimeout 1m<br/>spark.dynamicAllocation.maxExecutors 20<br/>spark.dynamicAllocation.executorIdleTimeout 2min</span></pre><p id="14b5" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">默认情况下<code class="fe pc pd pe ol b">spark.dynamicAllocation.enabled</code>被设置为<code class="fe pc pd pe ol b">false</code></p><h2 id="10a6" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">配置Spark执行器的内存和shuffle服务</h2><p id="467f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">每个执行器可用的内存量由<code class="fe pc pd pe ol b">spark.executor.memory</code>控制。这分为三个部分:执行内存、存储内存和保留内存。</p><blockquote class="ov ow ox"><p id="5421" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">默认的spark内存划分是60%用于执行内存，40%用于存储，并预留了300 MB的保留内存，以防止OOM错误。</p></blockquote><p id="a748" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">在map和shuffle操作期间，Spark写入和读取本地磁盘的shuffle文件，因此存在大量I/O活动。这可能会导致瓶颈，因为默认配置对于大规模Spark作业来说不是最佳的。在Spark工作的这个阶段，知道调整什么配置可以减轻这种风险。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/de9db1218d764e945933832c4ec58816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y7iBaKFruuuoJn-NErlkpg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Apache spark的推荐设置</p></figure><p id="66bb" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated"><a class="ae pi" href="https://docs.google.com/spreadsheets/d/1BymTmfhUK8zAlP8KEiNK0PMu3LwLBxSUMSiHxuB_uVM/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">电子表格链接</a></p><h1 id="d46f" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">有多少遗嘱执行人</h1><p id="d73f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这是一个很普通却很重要的问题。</p><p id="dbc6" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">Spark在并行处理任务方面非常高效。对于大规模工作负载，Spark作业将有许多阶段，并且在每个阶段中，将有许多任务。Spark最多为每个内核的每个任务调度一个线程，每个任务处理一个不同的分区。</p><blockquote class="ov ow ox"><p id="2131" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">为了优化资源利用和最大化并行性，理想的情况是至少要有与执行器上的内核一样多的分区。</p><p id="a54a" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">如果每个执行器上的分区数量多于核心数量，那么所有的核心都会保持忙碌状态。您可以将分区视为并行性的原子单位:在单个内核上运行的单个线程可以在单个分区上工作。</p></blockquote><h1 id="92c6" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">缓存怎么样</h1><h2 id="be7b" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">何时缓存</h2><p id="ff6f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">缓存的常见用例是您希望重复访问大型数据集以进行查询或转换的场景。一些例子包括:</p><ul class=""><li id="37e5" class="mm mn it ls b lt mo lw mp lz mq md mr mh ms ml pj mu mv mw bi translated">迭代机器学习训练中常用的数据帧</li><li id="11a5" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml pj mu mv mw bi translated">在ETL或构建数据管道期间，经常访问数据帧以进行频繁转换</li></ul><h2 id="bd49" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">何时不缓存:</h2><ul class=""><li id="b02f" class="mm mn it ls b lt lu lw lx lz pk md pl mh pm ml pj mu mv mw bi translated">数据帧<strong class="ls iu"> <em class="oy">太大，无法在内存中容纳</em> </strong></li><li id="3a94" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml pj mu mv mw bi translated">一种不需要频繁使用的廉价的数据帧变换，无论大小如何</li></ul><h1 id="6d6a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">优化连接</h1><p id="a6ae" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">连接操作是大数据分析中一种常见的转换类型，在这种转换中，表或数据帧形式的两个数据集通过一个通用匹配键进行合并。与关系数据库类似，Spark DataFrame和Dataset APIs以及Spark SQL提供了一系列连接转换:内部连接、外部连接、左连接、右连接等。所有这些操作都会触发Spark执行器之间的大量数据移动。</p><p id="b6ca" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">Spark有五种不同的连接策略，通过这五种策略，它可以跨执行器交换<em class="oy">、</em>移动、排序、分组和合并数据:</p><p id="1f9f" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">广播散列连接(BHJ)、混洗散列连接(SHJ)、混洗排序合并连接(SMJ)、广播嵌套循环连接(BNLJ)以及混洗复制嵌套循环</p><h2 id="4948" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">使用广播散列连接优化查询:</h2><blockquote class="ov ow ox"><p id="8223" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">当两个数据集，一个很小(适合驱动程序和执行程序的内存)，另一个足够大，理想情况下不会移动，需要在某些条件或列上连接时，使用广播散列连接。使用Spark广播变量，较小的数据集由驱动程序广播给所有Spark执行器，然后在每个执行器上与较大的数据集合并。这种策略避免了大量的交换。</p></blockquote><p id="7ddd" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">默认情况下，如果较小的数据集小于10 MB，Spark将使用广播连接。该配置在<code class="fe pc pd pe ol b">spark.sql.autoBroadcastJoinThreshold.</code>中设置</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="dd5c" class="nu kz it ol b gy op oq l or os">// In Scala <br/>import<!-- --> <!-- -->org.apache.spark.sql.functions.broadcast<br/>val<!-- --> <!-- -->joinedDF<!-- --> <!-- -->=<!-- --> <!-- -->playersDF.join(broadcast(clubsDF),<!-- --> <!-- -->"key1 === key2")</span></pre><p id="0910" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">BHJ是Spark提供的最简单、最快速的连接，因为它不涉及数据集的任何洗牌；在广播之后，所有的数据都可以在本地提供给执行者。您只需要确保在Spark驱动程序和执行程序端都有足够的内存来保存较小的数据集。</p><p id="529c" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">在下列情况下使用这种类型的连接可以获得最大的好处:</p><ul class=""><li id="6fb7" class="mm mn it ls b lt mo lw mp lz mq md mr mh ms ml pj mu mv mw bi translated">当较小和较大数据集中的每个键被Spark散列到<strong class="ls iu"> <em class="oy">的相同分区</em> </strong>时</li><li id="4e90" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml pj mu mv mw bi translated">当一个数据集<strong class="ls iu"> <em class="oy">比另一个数据集</em> </strong>小得多时(在默认配置10 MB内，如果有足够的内存，也可以更大)</li></ul><h2 id="58f2" class="nu kz it bd la nv nw dn le nx ny dp li lz nz oa lk md ob oc lm mh od oe lo of bi translated">优化无序排序合并连接</h2><blockquote class="ov ow ox"><p id="7f61" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">排序-合并算法是一种有效的方法，可以通过一个可排序的、唯一的、可以分配或存储在同一分区中的公共键来合并两个大型数据集，也就是说，两个具有公共哈希键的数据集最终位于同一分区中。</p></blockquote><p id="e2d3" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">从Spark的角度来看，这意味着每个数据集内具有相同键的所有行都在同一执行器的同一分区上进行散列。显然，这意味着数据必须<strong class="ls iu"> <em class="oy">在同一地点</em> </strong>或在执行者之间交换。</p><p id="a4a7" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">顾名思义，这个连接方案有两个阶段:排序阶段和合并阶段。排序阶段根据所需的连接键对每个数据集进行排序；合并阶段遍历每个数据集的行中的每个键，如果两个键匹配，就合并这些行。</p><p id="8d74" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">在下列情况下使用这种类型的连接可以获得最大的好处:</p><ul class=""><li id="eb56" class="mm mn it ls b lt mo lw mp lz mq md mr mh ms ml pj mu mv mw bi translated">当两个大型数据集中的每个键都可以通过Spark排序和散列到同一个分区时</li><li id="fe7a" class="mm mn it ls b lt mx lw my lz mz md na mh nb ml pj mu mv mw bi translated">当您希望只执行等价连接来根据匹配的排序键组合两个数据集时</li></ul><h1 id="6550" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">减少工作和阶段的数量</h1><p id="88e6" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们应该尽量减少应用程序使用的作业和阶段的数量。</p><p id="d340" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">让我们用一个例子来学习:思考一下</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="3f06" class="nu kz it ol b gy op oq l or os">spark.read.parquet("abc.parquet").show()</span></pre><p id="2c0a" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">和</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="a9b3" class="nu kz it ol b gy op oq l or os">spark.read.schema(StructType(List(StructField("id",IntType,false)))).parquet("abc.parquet")</span></pre><p id="c582" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">我们来看看两者对应的spark UI:</p><p id="d6f9" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">首先:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/0f81399c70f3ab0c1a8be50548d39cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*LGqtqxbKV4-QQ7lZ6MGuXg.png"/></div></figure><p id="b470" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">第二:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi gj"><img src="../Images/406280b47fc5f308cea6ed7d866483d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5GDM7WkZs2QDIXQLCxTMHQ.png"/></div></div></figure><p id="5ee5" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">所以，你现在已经得到了答案，但只是重申:</p><blockquote class="ov ow ox"><p id="8c02" class="lq lr oy ls b lt mo ju lv lw mp jx ly oz oh mb mc pa oi mf mg pb oj mj mk ml im bi translated">总是在创建数据帧时提供模式，如果您不提供，spark必须运行一个额外的作业来获取模式，如果数据集很大，性能会非常下降</p></blockquote><h1 id="83d0" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated"><strong class="ak">结论</strong></h1><p id="2e04" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">因此，我们研究了可能的优化和推理。请在评论中告诉我你的反馈。</p><p id="2ace" class="pw-post-body-paragraph lq lr it ls b lt mo ju lv lw mp jx ly lz oh mb mc md oi mf mg mh oj mj mk ml im bi translated">参考:</p><div class="nc nd gp gr ne nf"><a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">性能调整</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">对于某些工作负载，可以通过在内存中缓存数据或打开某些…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">spark.apache.org</p></div></div><div class="no l"><div class="po l nq nr ns no nt ks nf"/></div></div></a></div><div class="nc nd gp gr ne nf"><a href="https://spark.apache.org/" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd iu gy z fp nk fr fs nl fu fw is bi translated">Apache Spark用于大规模数据分析的统一引擎</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">Apache Spark是一个多语言引擎，用于执行数据工程、数据科学和机器学习</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">spark.apache.org</p></div></div><div class="no l"><div class="pp l nq nr ns no nt ks nf"/></div></div></a></div></div></div>    
</body>
</html>
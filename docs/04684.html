<html>
<head>
<title>Exploring Core Image: Apple’s First Computer Vision Framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索核心图像:苹果的第一个计算机视觉框架</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/exploring-core-image-apples-first-computer-vision-framework-160f4a589413?source=collection_archive---------11-----------------------#2020-04-29">https://betterprogramming.pub/exploring-core-image-apples-first-computer-vision-framework-160f4a589413?source=collection_archive---------11-----------------------#2020-04-29</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="5dee" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">从首选计算机视觉框架到图像过滤工具的旅程</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/88ae9ac3c5e4bf1a389dcbe51371f331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kb4xMY5du-9pffoo"/></div></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae kw" href="https://unsplash.com/@mukukostudio?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Mukuko工作室</a>拍摄的照片</p></figure><p id="be17" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">多年来，苹果在每年的WWDC大会上发布了一些突破性的功能。除了iOS社区，全世界的开发者都热切期待苹果的年度大会。难怪要找出哪个WWDC会议与众不同总是一个两难的选择。</p><p id="1448" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">有人说，由于推出了一系列新功能和重要工具，WWDC 2019年是多年来最好的开发者大会。SwiftUI是一个强大的构建用户界面的新框架，核心ML和Vision框架的重大升级使得淡化苹果在2019年取得的成就变得很棘手——我也不会这样做。</p><p id="d623" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">因此，在不对过去的WWDC会议进行比较的情况下，我将带你回到三年前(WWDC 2017)，当时苹果发布了两个强大的框架，从而大大推动了人工智能应用。</p><p id="99c0" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">对于外行来说，Core ML是苹果的机器学习框架，它让你可以将预先训练好的和定制的模型集成到你的应用程序中，只需几行代码就可以运行推理。</p><p id="4f31" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">另一方面，Vision是一个功能强大、易于使用的框架，构建在Core ML之上，为各种计算机视觉任务提供解决方案，包括人脸和地标检测、文本识别、条形码识别、图像相似性和显著性。</p><p id="e830" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">但是这些解决方案中的很多——特别是人脸、矩形、条形码检测和显著性——在视觉出现之前就已经存在了。苹果实际上已经首次发布了带有核心图像框架的人脸检测API。</p><p id="e365" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><a class="ae kw" href="https://developer.apple.com/documentation/coreimage" rel="noopener ugc nofollow" target="_blank"> Core Image </a>，用苹果自己的话说就是<em class="lt">一种图像处理和分析技术，为静态和视频图像</em>提供高性能处理。鉴于多年来Core Image的显著增强，可以说该框架是未来设备上视觉任务的领跑者，苹果在这方面投入了大量资金，以推动计算机视觉领域的发展。</p><p id="1976" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">那么，是什么导致了从核心图像成为首选框架，到视觉框架突然出现并最终占据主导地位的转变呢？</p><blockquote class="lu"><p id="1eab" class="lv lw ir bd lx ly lz ma mb mc md ls dk translated"><strong class="ak">两个字:深度学习。</strong></p></blockquote><p id="7126" class="pw-post-body-paragraph kx ky ir kz b la me js lc ld mf jv lf lg mg li lj lk mh lm ln lo mi lq lr ls ik bi translated">深度学习的出现不仅大大提高了人脸检测和图像识别等任务的最先进精度，还使解决其他计算机视觉问题变得更加容易。</p><p id="daf2" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">例如，核心图像中的人脸检测基于OpenCV的<a class="ae kw" href="https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework" rel="noopener ugc nofollow" target="_blank"> Viola-Jones算法</a>。该算法进行类似Haar的特征选择，这类似于CNN中的内核——一个用于应用变换和效果的小矩阵。</p><p id="2225" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">与CNN不同，在CNN中，内核值很容易通过训练来确定，Haar特性需要手动计算(大量的数学计算)，因此带来了可扩展性和定制问题。</p><p id="ef82" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">例如，在Core Image中执行面部识别(或任何自定义图像分类任务)需要识别特定面部的Haar，如果面部被部分覆盖或方向(头部倾斜)改变，这很容易遇到准确性问题。</p><p id="c7b2" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">另一方面，训练图像数据集并通过Vision API集成模型使识别更加准确和高效。</p><p id="3404" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">因此，尽管岩心图像具有较高的执行速度(由于计算量较小)和相对较小的数据集，但其在计算机视觉领域的应用仍然受到限制。强大的边缘设备的出现只是导致了向视觉框架的转变，这缓解了手动选择和提取特征的问题。</p><p id="c5dc" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">核心图像框架现在主要用于将变换和视觉效果(滤镜)应用于图像和视频。</p><p id="8035" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们深入研究核心图像API，看看它如何让我们创建和应用这些过滤器。</p><h1 id="f4b3" class="mj mk ir bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated">核心映像框架的关键类</h1><h2 id="eb33" class="nb mk ir bd ml nc nd dn mp ne nf dp mt lg ng nh mv lk ni nj mx lo nk nl mz nm bi translated">杀虫剂检测器</h2><p id="d2ac" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated"><code class="fe ns nt nu nv b">CIDetector</code>类用于处理图像以检测面部、矩形、条形码和文本。例如，使用以下方法检测人脸:</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="8e73" class="nb mk ir nv b gz oa ob l oc od">let faceDetector = CIDetector(ofType: CIDetectorTypeFace, context: nil, options: [CIDetectorAccuracy: CIDetectorAccuracyHigh])</span><span id="517a" class="nb mk ir nv b gz oe ob l oc od">let faces = faceDetector?.features(in: <strong class="nv is">CIImage</strong>(image: inputImage)!) as! [CIFaceFeature]</span><span id="1fbf" class="nb mk ir nv b gz oe ob l oc od">for face in faces{<br/>print(faces.hasSmile)<br/>print(faces.leftEyeClosed)<br/>print(faces.hasMouthPosition)<br/>}</span></pre><p id="7187" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">使用面部检测器，我们可以确定微笑概率、头部姿势、执行眨眼检测等等。此外，我们可以过滤<code class="fe ns nt nu nv b">CIDetector</code>以仅返回具有特定属性的面部，如下所示:</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="7259" class="nb mk ir nv b gz oa ob l oc od">let faceDetector = CIDetector(ofType: CIDetectorTypeFace, <strong class="nv is">context</strong>: nil, options: [CIDetectorSmile: true])</span></pre><p id="0d09" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">接下来让我们看看<code class="fe ns nt nu nv b">CIImage</code>。</p><h2 id="e43f" class="nb mk ir bd ml nc nd dn mp ne nf dp mt lg ng nh mv lk ni nj mx lo nk nl mz nm bi translated">CIImage</h2><p id="2653" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated"><code class="fe ns nt nu nv b">CIImage</code>是核心图像自己的数据类型，包含了图像的所有信息。与听起来相反的是，<code class="fe ns nt nu nv b">CIImage</code>并不能代替图像。它更像是一种能够产生图像的“配方”。</p><p id="034e" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe ns nt nu nv b">CIImages</code>可以从<code class="fe ns nt nu nv b">UIImage</code>、图像文件或像素数据中创建。从<code class="fe ns nt nu nv b">UIImage</code>创建<code class="fe ns nt nu nv b">CIImage</code>非常简单，如下面的代码片段所示:</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="3a74" class="nb mk ir nv b gz oa ob l oc od">let inputImage = CIImage(image: uiImage)</span></pre><p id="fe15" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">一个<code class="fe ns nt nu nv b">CIImage</code>是一个轻量级的对象，在这个意义上，对它应用任何滤镜都不会渲染任何图像。它只是将滤镜添加到如何生成最终图像的指令配方中。</p><h2 id="f6b4" class="nb mk ir bd ml nc nd dn mp ne nf dp mt lg ng nh mv lk ni nj mx lo nk nl mz nm bi translated"><strong class="ak"> CIContext </strong></h2><p id="84ef" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated"><code class="fe ns nt nu nv b">CIContext</code>是图像渲染和分析实际发生的处理环境。这是一个绘图目的地，在这里编译过滤器以生成输出图像。</p><p id="dcc1" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">实例化一个<code class="fe ns nt nu nv b">CIContext</code>是一个昂贵的操作——因此，重用实例是一个好主意——特别是因为它们是不可变的和线程安全的。</p><p id="c2cb" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">一个<code class="fe ns nt nu nv b">CIContext</code>使用应用了滤镜的<code class="fe ns nt nu nv b">CIImage</code>创建输出图像。这里有一个简单的方法来创建一个<code class="fe ns nt nu nv b">CIContext</code>:</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="84b4" class="nb mk ir nv b gz oa ob l oc od">let ciContext = CIContext(options: nil)</span></pre><p id="1611" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们传递属性类似于<code class="fe ns nt nu nv b">allowLowPower</code>、<code class="fe ns nt nu nv b">outputColorSpace</code>(默认情况下接受默认的RGB颜色空间，但您可以将其更改为Quartz2D或任何其他颜色空间)、<code class="fe ns nt nu nv b">highQualityDownsample</code>和<a class="ae kw" href="https://developer.apple.com/documentation/coreimage/cicontextoption" rel="noopener ugc nofollow" target="_blank">的</a>。</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="fccd" class="nb mk ir nv b gz oa ob l oc od"><strong class="nv is">let</strong> cgimg = context.createCGImage(filter.image, from: filter.image.extent)</span></pre><p id="1fd5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">在<code class="fe ns nt nu nv b">CIContext</code>中，<code class="fe ns nt nu nv b">CGImage</code>(另一种图像数据类型)是通过传入图像及其<code class="fe ns nt nu nv b">extent</code>创建的，这意味着完整的图像。</p><h2 id="3074" class="nb mk ir bd ml nc nd dn mp ne nf dp mt lg ng nh mv lk ni nj mx lo nk nl mz nm bi translated">CIFilter</h2><p id="f61a" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated"><code class="fe ns nt nu nv b">CIFilter</code>是一个可变对象，负责根据输入图像和指定的<code class="fe ns nt nu nv b">attributes</code>范围创建最终的<code class="fe ns nt nu nv b">CIImage</code>。</p><p id="310a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated"><code class="fe ns nt nu nv b">CIFilters</code>不能在线程间安全共享，不像<code class="fe ns nt nu nv b">CIContext</code>。我们可以使用<code class="fe ns nt nu nv b">CIKernel</code>创建自己的定制过滤器，或者将多个<code class="fe ns nt nu nv b">CIFilters</code>链接在一起构建一个复合过滤器。</p><p id="7122" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">此外，<code class="fe ns nt nu nv b">CIFilter</code>类提供了按类别查询内置过滤器的方法，并返回给定过滤器可用的<code class="fe ns nt nu nv b">inputKeys</code>和<code class="fe ns nt nu nv b">outputKeys</code>的列表。</p><p id="ec8a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">以下代码片段显示了如何查询核心映像的内置过滤器:</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="55e1" class="nb mk ir nv b gz oa ob l oc od">//All filters<br/>CIFilter.filterNames(inCategories: nil)</span><span id="9387" class="nb mk ir nv b gz oe ob l oc od">CIFilter.filterNames(inCategory: kCICategoryBlur)</span><span id="d29b" class="nb mk ir nv b gz oe ob l oc od">//The blur category consists of filters like gaussian, zoom blur etc.</span></pre><p id="5dac" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">以下是如何为图像创建显著性滤镜的示例(突出显示感兴趣的区域):</p><pre class="kh ki kj kk gu nw nv nx ny aw nz bi"><span id="8670" class="nb mk ir nv b gz oa ob l oc od">guard let inputImage = UIImage(named: image_name_here) <br/>else { return }</span><span id="79cb" class="nb mk ir nv b gz oe ob l oc od">let beginImage = CIImage(image: inputImage)<br/>let context = CIContext()<br/>let currentFilter = CIFilter.saliencyMap()</span><span id="5a4f" class="nb mk ir nv b gz oe ob l oc od">currentFilter.inputImage = beginImage<br/>        <br/>guard let outputImage = currentFilter.outputImage <br/>else {return }</span><span id="771d" class="nb mk ir nv b gz oe ob l oc od">if let cgimg = context.createCGImage(outputImage, from: outputImage.extent) {</span><span id="4eb0" class="nb mk ir nv b gz oe ob l oc od">let uiImage = UIImage(cgImage: cgimg)</span><span id="6c2e" class="nb mk ir nv b gz oe ob l oc od">}</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj of"><img src="../Images/73902870ddb16633f869c7424d4d87f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*t87lG6wRsjSjF9QWlkx77w.png"/></div><p class="ks kt gk gi gj ku kv bd b be z dk translated">右边的图像应用了显著性滤镜</p></figure><h2 id="89eb" class="nb mk ir bd ml nc nd dn mp ne nf dp mt lg ng nh mv lk ni nj mx lo nk nl mz nm bi translated">CIKernel</h2><p id="a003" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated">每个核心图像过滤器的核心是一个由<code class="fe ns nt nu nv b">CIKernel</code>类管理的内核函数。内核函数告诉过滤器如何变换输入图像的每个像素。</p><p id="73cd" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">本质上，有三种不同类型的内核:颜色内核、扭曲内核和混合内核。定制颜色内核需要创建一个<code class="fe ns nt nu nv b">CIColorKernel</code>的实例并传递内核代码，或者利用<a class="ae kw" href="https://developer.apple.com/documentation/metal/mtllibrary" rel="noopener ugc nofollow" target="_blank">金属着色器库</a>。</p><h2 id="2ef9" class="nb mk ir bd ml nc nd dn mp ne nf dp mt lg ng nh mv lk ni nj mx lo nk nl mz nm bi translated">创建自定义过滤器</h2><p id="72a2" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated">让我们来看一个自定义滤镜，它根据阴影将灰色转换为黑色和白色(较暗的阴影会转换为白色，反之亦然):</p><figure class="kh ki kj kk gu kl"><div class="bz fq l di"><div class="og oh l"/></div></figure><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj oi"><img src="../Images/e4b80f0956cbfbcba056ea3550764f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*HN2seXeuzQncgIDvUiQjcg.png"/></div></figure></div><div class="ab cl oj ok hv ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ik il im in io"><h1 id="1a9b" class="mj mk ir bd ml mm oq mo mp mq or ms mt jx os jy mv ka ot kb mx kd ou ke mz na bi translated">结论</h1><p id="c062" class="pw-post-body-paragraph kx ky ir kz b la nn js lc ld no jv lf lg np li lj lk nq lm ln lo nr lq lr ls ik bi translated">我们看到，尽管Core Image代表了一个强大的近实时处理框架，但由于它支持的定制化水平，它最终为苹果的深度学习驱动的视觉框架铺平了道路。尽管如此，核心图像仍然是基于照片和视频的过滤应用程序的重要框架。</p><p id="f2f5" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">iOS 13不仅在Core Image中引入了一堆新的滤镜，还让它们的使用更加类型安全。在下一篇文章中，我们将探索一系列核心图像过滤器，并了解如何使用金属着色器语言来更容易地创建和合成我们自己的自定义过滤器。</p><p id="ceac" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这一次到此为止。感谢阅读。</p></div></div>    
</body>
</html>
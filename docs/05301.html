<html>
<head>
<title>SwiftUI + Vision Contour Request — Coin Detection in iOS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SwiftUI +视觉轮廓请求iOS中的硬币检测</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/new-in-ios-14-vision-contour-detection-68fd5849816e?source=collection_archive---------0-----------------------#2020-06-27">https://betterprogramming.pub/new-in-ios-14-vision-contour-detection-68fd5849816e?source=collection_archive---------0-----------------------#2020-06-27</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="992e" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">WWDC20</h2><div class=""/><div class=""><h2 id="667d" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">苹果公司通过一系列新的视觉要求来推进其计算机视觉野心</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/48e5a6bdca2beb40617f720ab9aed717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDoph36kyGFt_usBFA_Vtg.jpeg"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">照片由<a class="ae li" href="https://unsplash.com/@rahul_design?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Rahul Bhosale </a>在<a class="ae li" href="https://unsplash.com/@rahul_design?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="17ef" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">苹果的WWDC 2020(纯数码)活动轰轰烈烈地开始了。SwiftUI、ARKit、PencilKit、Create ML和Core ML带来了许多新的惊喜。但是对我来说最突出的是计算机视觉。</p><p id="bce9" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">苹果的视觉框架得到了一系列令人兴奋的新API的支持，这些API以一种相当简单的方式执行一些复杂而关键的计算机视觉算法。</p><p id="718a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">从iOS 14开始，视觉框架现在支持手和身体姿势估计、光流、轨迹检测和轮廓检测。</p><p id="078f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们将在以后的某个时间对每一项进行深入研究，现在，让我们更深入地研究一个特别有趣的附加功能——轮廓检测视觉要求。</p><h1 id="48ec" class="mf mg iu bd mh mi mj mk ml mm mn mo mp kj mq kk mr km ms kn mt kp mu kq mv mw bi translated">我们的目标</h1><ul class=""><li id="bcd1" class="mx my iu ll b lm mz lp na ls nb lw nc ma nd me ne nf ng nh bi translated">理解视觉的轮廓检测要求。</li><li id="00c8" class="mx my iu ll b lm ni lp nj ls nk lw nl ma nm me ne nf ng nh bi translated">在iOS 14 SwiftUI应用程序中运行它，以检测硬币的轮廓。</li><li id="63ab" class="mx my iu ll b lm ni lp nj ls nk lw nl ma nm me ne nf ng nh bi translated">在将图像传递给视觉请求之前，利用核心图像过滤器对图像进行预处理，从而简化轮廓。我们将设法掩盖图像，以减少纹理噪声。</li></ul></div><div class="ab cl nn no hy np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="in io ip iq ir"><h1 id="0158" class="mf mg iu bd mh mi nu mk ml mm nv mo mp kj nw kk mr km nx kn mt kp ny kq mv mw bi translated">视觉轮廓检测</h1><p id="d6a5" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated">轮廓检测检测图像中边缘的轮廓。本质上，它连接了所有具有相同颜色或强度的连续点。</p><p id="fb67" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">该计算机视觉任务对于形状分析、边缘检测是有用的，并且在需要在图像中找到相似类型的对象的情况下是有帮助的。</p><p id="c5f4" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">硬币检测和分割是OpenCV中一个相当常见的用例，现在通过使用Vision的新<code class="fe oc od oe of b">VNDetectContoursRequest</code>，我们可以在我们的iOS应用程序中轻松执行相同的操作(无需第三方库)。</p><p id="3973" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">为了处理图像或帧，视觉框架需要一个<code class="fe oc od oe of b">VNRequest</code>，它被传递到图像请求处理器或序列请求处理器。我们得到的回报是一个<code class="fe oc od oe of b">VNObservation</code>类。</p><p id="4ad5" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">您可以根据正在运行的请求类型使用各自的<code class="fe oc od oe of b">VNObservation</code>子类。在我们的例子中，我们将使用<code class="fe oc od oe of b">VNContoursObservation</code>，它提供了从图像中检测到的所有轮廓。</p><p id="8298" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以从<code class="fe oc od oe of b">VNContoursObservation</code>中检查以下属性:</p><ul class=""><li id="a70a" class="mx my iu ll b lm ln lp lq ls og lw oh ma oi me ne nf ng nh bi translated"><code class="fe oc od oe of b"><a class="ae li" href="https://developer.apple.com/documentation/vision/vncontoursobservation/3548363-normalizedpath" rel="noopener ugc nofollow" target="_blank">normalizedPath</a></code> —返回归一化坐标中检测轮廓的路径。我们必须把它转换成UIKit坐标，我们很快就会看到。</li><li id="5ea7" class="mx my iu ll b lm ni lp nj ls nk lw nl ma nm me ne nf ng nh bi translated"><code class="fe oc od oe of b">contourCount</code> —视觉请求返回的检测轮廓数。</li><li id="d7ad" class="mx my iu ll b lm ni lp nj ls nk lw nl ma nm me ne nf ng nh bi translated"><code class="fe oc od oe of b">topLevelContours</code>——一组不包含在任何轮廓内的<code class="fe oc od oe of b">VNContours</code>。</li><li id="803a" class="mx my iu ll b lm ni lp nj ls nk lw nl ma nm me ne nf ng nh bi translated"><code class="fe oc od oe of b">contour(at:)</code> —使用此功能，我们可以通过传递其索引或<code class="fe oc od oe of b">IndexPath</code>来访问子轮廓。</li><li id="c47a" class="mx my iu ll b lm ni lp nj ls nk lw nl ma nm me ne nf ng nh bi translated"><code class="fe oc od oe of b">confidence</code> —总体的信心水平<code class="fe oc od oe of b">VNContoursObservation</code>。</li></ul><blockquote class="oj ok ol"><p id="b960" class="lj lk om ll b lm ln ke lo lp lq kh lr on lt lu lv oo lx ly lz op mb mc md me in bi translated">注意:当您需要从最终观察中修改/移除子轮廓时，使用<code class="fe oc od oe of b">topLevelContours</code>和访问子轮廓非常方便。</p></blockquote><p id="fcbd" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">现在我们已经对视觉轮廓检测请求有了一个概念，让我们来探索它在iOS 14应用程序中是如何工作的。</p><h1 id="c441" class="mf mg iu bd mh mi mj mk ml mm mn mo mp kj mq kk mr km ms kn mt kp mu kq mv mw bi translated">入门指南</h1><p id="367c" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated">首先，你至少需要Xcode 12 beta。就这些，因为您可以在SwiftUI预览中直接运行视觉图像请求。</p><p id="0bc8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">在Xcode向导中创建新的SwiftUI应用程序，注意新的<code class="fe oc od oe of b">SwiftUI App</code>生命周期:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oq"><img src="../Images/6a0517558920ce4d026a659ec27bbf45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b-1INld9G6RyGdvKPBmlkg.png"/></div></div></figure><p id="f24c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">完成项目设置后，您将看到以下代码:</p><pre class="kt ku kv kw gu or of os ot aw ou bi"><span id="d4e5" class="ov mg iu of b gz ow ox l oy oz">@main<br/>struct iOS14VisionContourDetection: App {<br/>    var body: some Scene {<br/>        WindowGroup {<br/>            ContentView()<br/>        }<br/>    }<br/>}</span></pre><blockquote class="oj ok ol"><p id="4fb4" class="lj lk om ll b lm ln ke lo lp lq kh lr on lt lu lv oo lx ly lz op mb mc md me in bi translated">注意:从iOS 14开始，<code class="fe oc od oe of b">SceneDelegate</code>已经被弃用，取而代之的是SwiftUI <code class="fe oc od oe of b">App</code>协议，特别是对于基于SwiftUI的应用。<code class="fe oc od oe of b">struct</code>顶部的<code class="fe oc od oe of b">@main</code>注释表示它是应用程序的起点。</p></blockquote></div><div class="ab cl nn no hy np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="in io ip iq ir"><h1 id="dea2" class="mf mg iu bd mh mi nu mk ml mm nv mo mp kj nw kk mr km nx kn mt kp ny kq mv mw bi translated">使用视觉轮廓请求检测硬币</h1><p id="fc40" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated">为了执行我们的视觉请求，让我们快速设置一个SwiftUI视图，如下所示:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pa pb l"/></div></figure><p id="cb81" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">在上面的代码中，我们使用了随SwiftUI for iOS 14发布的<code class="fe oc od oe of b">if let</code>语法。忽略<code class="fe oc od oe of b">preprocessImage</code>状态；现在，让我们直接跳到<code class="fe oc od oe of b">detectVisionContours</code>函数，该函数将在视觉请求完成时更新<code class="fe oc od oe of b">outputImage</code>状态:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pa pb l"/></div></figure><p id="fdf1" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">在上面的代码中，我们在<code class="fe oc od oe of b">VNDetectContoursRequest</code>上设置了<code class="fe oc od oe of b">contrastAdjustment</code>(用于增强图像)和<code class="fe oc od oe of b">detectDarkOnLight</code>(用于更好的轮廓检测，因为我们的图像具有浅色背景)属性。</p><p id="bef8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">在使用输入图像(存在于资产文件夹中)运行<code class="fe oc od oe of b">VNImageRequestHandler</code>时，我们取回了<code class="fe oc od oe of b">VNContoursObservation</code>。</p><p id="b3b6" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">最后，我们将绘制<code class="fe oc od oe of b">normalizedPoints</code>作为输入图像的覆盖图。</p><h1 id="df5d" class="mf mg iu bd mh mi mj mk ml mm mn mo mp kj mq kk mr km ms kn mt kp mu kq mv mw bi translated">在图像上绘制轮廓</h1><p id="96a9" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated"><code class="fe oc od oe of b">drawContours</code>功能的代码如下所示:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pa pb l"/></div></figure><p id="a926" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">上述函数返回的<code class="fe oc od oe of b">UIImage</code>被设置为<code class="fe oc od oe of b">contouredImage</code> SwiftUI状态，随后我们的视图得到更新:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pc"><img src="../Images/df33cd638f3e9333785a7ffa65cbcb89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEijelLTwx_uS_bC6J_Qgw.png"/></div></div></figure><p id="a259" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">考虑到我们是在模拟器上运行的，结果相当不错，但如果我们在装有iOS 14的设备上运行，并且可以访问神经引擎，结果肯定会更好。</p><p id="feb8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">但是，仍然有太多的轮廓(主要是由于硬币的纹理)是我们喜欢的。我们可以通过预处理图像来简化(或者说减少)它们。</p><h1 id="4b03" class="mf mg iu bd mh mi mj mk ml mm mn mo mp kj mq kk mr km ms kn mt kp mu kq mv mw bi translated">使用核心图像预处理视觉图像请求</h1><p id="066d" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated"><a class="ae li" href="https://developer.apple.com/documentation/coreimage" rel="noopener ugc nofollow" target="_blank">核心图像</a>是苹果的图像处理和分析框架。虽然它对于简单的人脸和条形码检测任务工作良好，但对于复杂的计算机视觉用例来说，它是不可扩展的。</p><p id="68da" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">该框架实际上拥有超过200个图像过滤器，在摄影应用程序中以及在机器学习模型训练中进行数据扩充时非常方便。</p><p id="3f76" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">但更重要的是，Core Image是一个方便的工具，可用于预处理图像，然后将这些图像提供给视觉框架进行分析。</p><p id="467b" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">现在，如果你看过<a class="ae li" href="https://developer.apple.com/videos/play/wwdc2020/10673" rel="noopener ugc nofollow" target="_blank"> WWDC 2020计算机视觉API</a>视频，你会看到苹果公司利用Core Image的单色过滤器进行预处理，同时展示他们的打孔卡轮廓检测示例。</p><p id="49be" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">在我们的例子中，对于硬币遮罩，单色效果不会给出好的结果。特别是对于颜色强度相似但不同于背景的硬币，使用黑白颜色滤镜来遮罩硬币是一个更好的选择。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pd"><img src="../Images/5bbd68d98137cd6003f7e16f971410e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oycNP8qYvVZbONbJGnsLWw.png"/></div></div></figure><p id="f4ed" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">对于上述每一种预处理类型，我们还设置了一个高斯滤波器来平滑图像。请注意单色预处理滤镜实际上是如何为我们提供更多轮廓的。</p><p id="e3dc" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">因此，在进行预处理时，注意你正在处理的图像的种类是很重要的。</p><p id="c748" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">预处理后得到的<code class="fe oc od oe of b">outputImage</code>馈入视觉图像请求。在这个<a class="ae li" href="https://github.com/anupamchugh/iOS14-Resources/tree/master/iOS14VisionContourDetection" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中可以找到创建和应用核心图像过滤器的代码块，以及完整的源代码。</p></div><div class="ab cl nn no hy np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="in io ip iq ir"><h1 id="3ed2" class="mf mg iu bd mh mi nu mk ml mm nv mo mp kj nw kk mr km nx kn mt kp ny kq mv mw bi translated">分析轮廓</h1><p id="e6c5" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated">通过使用<code class="fe oc od oe of b">VNGeometryUtils</code>类，我们可以观察轮廓的直径、边界圆、面积周长和纵横比等属性。简单地传递轮廓，如下所示:</p><pre class="kt ku kv kw gu or of os ot aw ou bi"><span id="994f" class="ov mg iu of b gz ow ox l oy oz">VNGeometryUtils.boundingCircle(for: VNContour)</span></pre><p id="2e4a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这可以在确定图像中可用的不同种类的形状方面开辟新的计算机视觉可能性。</p><p id="02b3" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">此外，通过调用<code class="fe oc od oe of b">VNContour</code>上的<code class="fe oc od oe of b">polygonApproximation(withEpsilon:)</code>方法，我们可以通过过滤掉边缘周围的小噪声部分来进一步简化我们的轮廓。</p></div><div class="ab cl nn no hy np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="in io ip iq ir"><h1 id="4562" class="mf mg iu bd mh mi nu mk ml mm nv mo mp kj nw kk mr km nx kn mt kp ny kq mv mw bi translated">结论</h1><p id="e09c" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nz lu lv lw oa ly lz ma ob mc md me in bi translated">计算机视觉在苹果的混合现实未来中发挥着巨大的作用。作为ARKit框架的一部分，手和身体姿势API的引入将为构建智能计算机视觉应用程序开辟新的机会。</p><p id="1e3a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">WWDC 2020有很多令人兴奋的东西。我对手机上机器学习的新可能性感到兴奋。敬请关注更多更新，感谢您的阅读。</p></div></div>    
</body>
</html>
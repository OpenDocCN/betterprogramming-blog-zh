<html>
<head>
<title>Audio Visualization in Swift Using Metal and Accelerate (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Metal和Accelerate在Swift中实现音频可视化(第1部分)</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/audio-visualization-in-swift-using-metal-accelerate-part-1-390965c095d7?source=collection_archive---------0-----------------------#2020-04-24">https://betterprogramming.pub/audio-visualization-in-swift-using-metal-accelerate-part-1-390965c095d7?source=collection_archive---------0-----------------------#2020-04-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0ce5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">信号处理</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6136fc956879bb01fbee850f820ac627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2_a9uDbsYtpcYtUNmvSvhw.png"/></div></div></figure><p id="4601" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们都见过各种形式的音频可视化，但是我们如何在Cocoa应用程序中实现呢？如果你对数字格式的信号处理或音频没有什么了解，本教程非常适合你。本教程将帮助您导航和理解苹果的加速框架，以及如何将图形渲染到屏幕上。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/779554ad3aac58b4658689ee2bf218b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*kvXRXYzpQOSrZfx5NCTVLQ.gif"/></div></figure><p id="4087" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个项目直接建立在我之前的教程之上:</p><div class="lo lp gp gr lq lr"><a href="https://medium.com/@barbulescualex/making-your-first-circle-using-metal-shaders-1e5049ec8505" rel="noopener follow" target="_blank"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">使用金属着色器创建第一个圆</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">一般来说，一开始使用金属框架和着色语言会让人不知所措，但是它并没有…</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">medium.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf kp lr"/></div></div></a></div><p id="388f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不幸的是，该教程已经是19分钟的读物了，因为对于本教程的实际可视化部分来说，有许多基础知识是必不可少的，所以这次我不会深入讨论这些概念。如果你想继续学习，请阅读前面的教程。</p><p id="22c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本教程分为两部分——输入(信号处理)和输出(可视化)。</p><p id="1a6e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本教程的目的是:</p><p id="f778" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">a)建立对音频处理如何工作的直觉</p><p id="7fce" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">b)提高我们使用金属的技能</p><p id="c819" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">老实说，一旦我们到了可视化部分(教程的第二部分)，我们会看到我们方法的一些缺点。这将在第二部分进一步阐述。但是希望，在这些教程结束时，你将能够识别缺点，并提出你自己的变通办法和解决方案。不幸的是，在这篇“初学者”教程中，我无法深入涵盖围绕音频可视化的所有错综复杂的内容。</p><p id="c8a8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以留下来，准备学习一些新的东西，希望你可以带走所有必要的技能，做任何你想做的事情，包括音频可视化。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="4fa2" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">项目要求</h1><p id="9766" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">嗯，什么是音频可视化？从技术角度来说，它是指您使用音频信号中的标记(如音量和频谱)来产生特定的视觉效果(实时)。</p><p id="9c37" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们今天将制作的音频可视化工具类型将由一个圆形缩放(弹跳)到当前音量和频率线组成，描述不同频率仓的平均幅度。如果你不知道我刚才说了什么，不要担心，后面会讲到。</p><p id="265e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个问题可以分成两部分:输入和输出。</p><h2 id="c01f" class="nk mo iq bd mp nl nm dn mt nn no dp mx la np nq mz le nr ns nb li nt nu nd nv bi translated"><strong class="ak">输入</strong></h2><p id="1237" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">对于输入，我们需要以离散的间隔对音频信号进行采样，并执行一些数学运算来提取我们想要使用的标记。</p><p id="7960" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们应该有两个问题:</p><ul class=""><li id="62ca" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ob oc od oe bi translated">我们如何对音频信号进行采样？</li><li id="d41b" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ob oc od oe bi translated">我们如何快速地对数据执行操作？</li></ul><p id="4436" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了对音频信号进行采样，我们将使用AVFoundation的AVAudioEngine类，该类允许我们设置一个回调，在该回调中，我们将以离散的时间间隔从音频信号接收缓冲数据。为了处理音频信号，我们将使用Accelerate框架，该框架用于基于高性能CPU的计算。</p><h2 id="0609" class="nk mo iq bd mp nl nm dn mt nn no dp mx la np nq mz le nr ns nb li nt nu nd nv bi translated"><strong class="ak">输出</strong></h2><p id="a3b0" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">我们有我们的投入；现在怎么办？我们必须把它呈现在屏幕上！从技术上来说，你可以使用任何你想要的视觉效果(CALayer/Shape或者甚至是一个普通的UIView)，但是它在性能上会很糟糕。因此，我们将把输入传递到图形管道并在我们的着色器函数中处理显示就不足为奇了！</p><p id="eee9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，在高层次上，我们需要:</p><ol class=""><li id="ac2e" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ok oc od oe bi translated">设置音频引擎</li><li id="1952" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ok oc od oe bi translated">在主混音器节点上设置一个抽头以获取缓冲区数据</li><li id="457a" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ok oc od oe bi translated">在CPU上处理音频缓冲数据</li><li id="4d9a" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ok oc od oe bi translated">沿着图形管道把它送到GPU</li></ol><p id="7f87" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">是时候开始了😄</p><h2 id="7888" class="nk mo iq bd mp nl nm dn mt nn no dp mx la np nq mz le nr ns nb li nt nu nd nv bi translated">建立</h2><p id="ad4d" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">项目启动代码在我的Github <a class="ae ol" href="https://github.com/barbulescualex/MetalAudioVisualizer" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="79f2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这里和<a class="ae ol" href="https://medium.com/@barbulescualex/making-your-first-circle-using-metal-shaders-1e5049ec8505" rel="noopener">之前的</a>教程的成品没有太大区别。我已经将MetalCircleView类重命名为AudioVisualizer，以便更好地与本教程保持一致。我还包含了一个music.mp3文件，它将包含我们将要可视化的音频。你想换什么都可以。</p><p id="1133" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我选择了一首EDM歌曲，因为它更好地展示了我们正在做的事情背后的力量。我们将在signal processing类中进行所有的信号处理，在AudioVisualizer类中使用ViewController类作为两者之间的媒介进行所有的金属处理。</p><p id="ce80" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">花些时间查看一下启动代码。如果你运行这个程序，你应该会得到上次在蓝色背景上的美丽的白色圆圈！</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="f4df" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">第1部分:获取输入(信号处理)</h1><p id="6ad9" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">我们将在ViewController类中完成这一部分的前半部分。在这里，我们希望实例化我们的AVAudioEngine，从中获取必要的信息，并将其传递给我们的SignalProcessing类——这是我们将在这一部分的后半部分工作的地方。</p><h2 id="2687" class="nk mo iq bd mp nl nm dn mt nn no dp mx la np nq mz le nr ns nb li nt nu nd nv bi translated">第1部分:音频引擎和音频数据的工作原理</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/5cb3b5d28766309b9cae0b28a3934fc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tHrTiB0DwcIHiYtItabLGg.png"/></div></div><p class="on oo gj gh gi op oq bd b be z dk translated">来源:<a class="ae ol" href="https://www.raywenderlich.com/5154-avaudioengine-tutorial-for-ios-getting-started" rel="noopener ugc nofollow" target="_blank">https://www . raywenderlich . com/5154-avaudioengine-tutorial-for-IOs-getting-started</a></p></figure><p id="aeae" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">那么我们如何在Cocoa应用程序中播放音乐呢？我们使用AVFoundation框架。我们对玩家职业的类型只有一个要求。我们需要取回当前的音频数据，以便进行处理。AVPlayer和AVAudioPlayer貌似不错；它们很容易使用，在堆栈溢出的一分钟内，你可以复制粘贴你的应用程序中的音频！</p><p id="7436" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不幸的是，这些类不支持音频数据点击。接下来我们有AVAudioEngine，一个更加通用的基于节点的类。它支持音频数据抽头吗？没错。我们也可以直接使用CoreAudio，它也支持音频taps。虽然这并不可取…但对我们的目的来说，复杂程度太高了。</p><p id="3f9c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudioengine" rel="noopener ugc nofollow" target="_blank">T3】AVAudioEngineT5】</a></p><p id="8137" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="or">一组相连的音频节点对象，用于生成和处理音频信号，并执行音频输入和输出。</em></p><p id="ed2e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它是如何工作的？这个类可以被认为是一个图。默认情况下，我们有一个连接到输出节点(设备的默认音频输出播放器)的mainMixerNode。要播放音乐，我们需要将一个播放器节点连接到mainMixerNode，并告诉该节点播放一种声音。但不止于此！</p><p id="364b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudionode" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> AVAudioNode </strong> </a></p><p id="edd8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="or">音频生成、处理或I/O块的抽象类。</em></p><p id="8824" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">AVAudioNode类型是我们可以附加到音频引擎的类型。AVAudioNode是不同类型节点的父类，您可以以任何方式附加这些节点来产生、处理(添加效果)和输出。对于我们的例子，我们只需要一个<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudioplayernode" rel="noopener ugc nofollow" target="_blank">AVAudioPlayerNode</a></code>来播放我们的音乐。节点有输入总线和输出总线，总线在节点之间传输数据，所以它们可以被认为是连接点。</p><p id="547d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看看一旦将它添加到我们的项目中，它会是什么样子。我们将进入ViewController类，首先设置引擎本身。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在ViewController类内部</p></figure><p id="ad3b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如您所见，我们首先导入了AVFoundation库，添加了引擎作为ViewController类的实例属性，然后启动了它。现在<code class="fe os ot ou ov b">_ = engine.mainMixerNode</code>似乎是一条奇怪的线，但是我们知道AVAudioEngine有一个默认的mainMixerNode连接到默认的输出节点。可能不太明显的是，因为它是单例的，所以只有当我们第一次访问它时，它才会被初始化。</p><p id="af36" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，让我们添加我们的播放器，看看我们是否可以播放一些音乐！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在视图控制器类内部</p></figure><p id="a2bf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果您运行该程序，您应该会看到我们上一个教程中的美丽圆圈，并听到您的music.mp3文件。</p><p id="0446" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在让我们获取正在播放的音频数据。这是使用AVAudioNode的实例方法<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudionode/1387122-installtap" rel="noopener ugc nofollow" target="_blank">installTapOnBus</a></code>来完成的。</p><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="5915" class="nk mo iq ov b gy pc pd l pe pf"><strong class="ov ir">func</strong> installTap(onBus bus: AVAudioNodeBus,</span><span id="4668" class="nk mo iq ov b gy pg pd l pe pf">               bufferSize: AVAudioFrameCount,</span><span id="2f44" class="nk mo iq ov b gy pg pd l pe pf">                   format: AVAudioFormat?,</span><span id="67d4" class="nk mo iq ov b gy pg pd l pe pf">           block tapBlock: <strong class="ov ir">@escaping</strong> AVAudioNodeTapBlock)</span></pre><p id="3519" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="or">这在总线上安装了一个音频抽头来记录、监控和观察节点的输出。</em></p><p id="9493" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">onBus——描述您想要从哪个<em class="or">输出</em>总线获取数据(因为节点有时可能有多条总线)。0总是一个安全的赌注，因为通常只有一个输出总线。在节点之间建立连接时，还有各种函数重载，您可以在这些重载中指定要建立连接的总线。</p><p id="6f65" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">bufferSize —描述您想要从音频数据中取回的字节数。</p><p id="933e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">format —对我们来说是nil，它会自己找出答案</p><p id="9aca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">block —这是回调中传递的数据，由AVAudioPCMBuffer和AVAudioTime(音轨所在的时间)组成</p><p id="dc9f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们在player节点上调用play之前安装tap(这一步非常容易)。</p><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="ae28" class="nk mo iq ov b gy pc pd l pe pf">engine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: nil) { (buffer, time) in</span><span id="fc20" class="nk mo iq ov b gy pg pd l pe pf">}</span></pre><p id="aace" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们窃听了引擎的mainMixerNode——为什么？嗯，没关系。抽头在输出总线上工作，由于我们的音乐在整个回放管道中都是相同的(AVAudioPlayerNode-&gt; AVAudioMixerNode-&gt; AVAudioOutputNode)，所以我们抽头到哪个部分并不重要。</p><p id="084a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> AVAudioPCMBuffer </strong></p><p id="4471" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是我们的缓冲区，但是<em class="or">这到底是什么意思呢？首先，让我们从这门课的特殊之处开始:</em></p><p id="a680" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="or"/><code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudiobuffer" rel="noopener ugc nofollow" target="_blank"><em class="or">AVAudioBuffer</em></a></code><em class="or">的一个子类，用于PCM音频格式。</em></p><p id="4d56" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">嗯，那不是很有帮助。什么是AVAudioBuffer？</p><p id="a911" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="or">音频数据的缓冲区及其格式。</em></p><p id="cde7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们可以推断该类以PCM格式保存音频数据。一、什么是PCM？来自维基百科:</p><blockquote class="ph pi pj"><p id="4fc7" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated"><strong class="kt ir">脉码调制</strong> ( <strong class="kt ir"> PCM </strong>)是一种用<a class="ae ol" href="https://en.wikipedia.org/wiki/Digital_signal_(signal_processing)" rel="noopener ugc nofollow" target="_blank">数字</a>表示采样<a class="ae ol" href="https://en.wikipedia.org/wiki/Analog_signal" rel="noopener ugc nofollow" target="_blank">模拟信号</a>的方法。它是计算机、<a class="ae ol" href="https://en.wikipedia.org/wiki/Compact_disc" rel="noopener ugc nofollow" target="_blank">光盘、</a>、<a class="ae ol" href="https://en.wikipedia.org/wiki/Digital_telephony" rel="noopener ugc nofollow" target="_blank">数字电话和其他数字音频应用中</a><a class="ae ol" href="https://en.wikipedia.org/wiki/Digital_audio" rel="noopener ugc nofollow" target="_blank">数字音频</a>的标准形式。</p></blockquote><p id="3ec9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这只是一种标准格式，任何音频都可以解码成这种格式，以便在硬件上运行。例如，mp3格式是压缩和有损的。这意味着当它从PCM编码为mp3时，它被压缩(这不会改变数据的质量)，但是编码也丢弃了“不太重要”的数据以节省空间(这确实改变了数据的质量)。</p><p id="a632" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">无论你提供给框架的数字音频格式是什么，都将被解码成PCM格式，无论是通过硬件还是软件。</p><p id="efcd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们已经解决了一些语义问题，让我们从类中取出实际的数据，并弄清楚它的含义。当我们在tap上指定bufferSize时，我们指定了我们想要的音频帧的数量。音频帧包含关于离散时间点的信号幅度的信息。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/45a705800812df43fb95a16d9be50561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6eq_aRDdkpzeDo9ofrJ54g.jpeg"/></div></div></figure><p id="aeed" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">音频帧是上图中的一个小点，而音频缓冲区包含样本大小内的所有帧，由图上的圆圈表示。</p><p id="5b62" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果我们查看AVAudioPCMBuffer文档中的“访问PCM缓冲器数据”部分，我们可以看到有三个不同的选项:</p><p id="0c03" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe os ot ou ov b">1. <a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudiopcmbuffer/1386212-floatchanneldata" rel="noopener ugc nofollow" target="_blank">var floatChannelData: UnsafePointer&lt;UnsafeMutablePointer&lt;Float&gt;&gt;?</a></code></p><p id="b0ea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe os ot ou ov b">2. <a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudiopcmbuffer/1388925-int16channeldata" rel="noopener ugc nofollow" target="_blank">var int16ChannelData: UnsafePointer&lt;UnsafeMutablePointer&lt;Int16&gt;&gt;?</a></code></p><p id="66b2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe os ot ou ov b">3. <a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudiopcmbuffer/1389756-int32channeldata" rel="noopener ugc nofollow" target="_blank">var int32ChannelData: UnsafePointer&lt;UnsafeMutablePointer&lt;Int32&gt;&gt;?</a></code></p><p id="60bf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是一种奇怪的类型，如果你不使用“低级”的Cocoa框架，就不会经常看到。我们有一个指向不同通道的外部不可变指针，每个通道都有指向音频帧的可变指针。我们有几个音频频道？这取决于我们的音频格式。</p><p id="e66d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在是后退一步，打印出我们从或AVAudioFile获得的AVAudioFormat的最佳时机。</p><p id="0a6a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe os ot ou ov b">print(format)</code></p><p id="18d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe os ot ou ov b"><strong class="kt ir">&lt;AVAudioFormat 0x6000021201e0: 2 ch, 44100 Hz, Float32, non-inter&gt;</strong></code></p><p id="dba5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们有两个通道，音频采样频率为44100 Hz，音频帧的幅度由32位浮点表示。最后一个属性指定格式是非交错的。你可以在这里了解更多。</p><p id="503e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">音频通道是来自或去往单个点的声音的表示。例如，您可能听说过5.1环绕声家庭系统或耳机。只有当您的音频格式包含五个全宽通道和一个低频通道(用于低音炮)时，这些功能才有效。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/dc2f667c6ac1bfdcb541ebb2ba4fb0bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*V2se3crd7dCtYtXHqcO1dg.png"/></div></figure><p id="8337" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我离题了——就我们的意图而言，我们可以只使用其中一个通道(最简单的方法是只使用第一个通道，因为总会有至少一个通道)。但是出于兴趣，您可以使用不同的通道来制作更高级的音频可视化工具。想到的一个简单的方法是双通道音频可视化。</p><h2 id="c788" class="nk mo iq bd mp nl nm dn mt nn no dp mx la np nq mz le nr ns nb li nt nu nd nv bi translated"><strong class="ak">采样率、抽头的样本大小以及抽头的采样率</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/cd596eea281383330ad5dee791d99278.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/1*bhKdqgShwSJKO8iYll5Kgw.gif"/></div></figure><p id="2ad0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们建立了音频格式的<em class="or">采样率</em>。当我们从AVAudioFile中获取处理格式时，我们无意中做到了这一点。采样速率表示(以Hz为单位)从模拟信号中获取数字值的频率。这很重要，因为我们知道播放每个音频帧的速度，这样听起来就一样了。例如，大多数音频的采样率为22050或44100Hz；如果我们在回放时将采样率提高一倍，声音会快一倍，如果我们在回放时将采样率减半，回放会慢一倍。</p><p id="041a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们通过bufferSize参数指定抽头的<em class="or">样本大小。不幸的是，框架通常不关心我们告诉它的样本大小。使用<code class="fe os ot ou ov b">buffer.frameLength</code>可以找到真实的样本大小。这并不奇怪，因为它实际上是在<a class="ae ol" href="https://developer.apple.com/documentation/avfoundation/avaudionode/1387122-installtaponbus?language=swift" rel="noopener ugc nofollow" target="_blank"> installTap: </a>的文档中指定的</em></p><blockquote class="ph pi pj"><p id="5a52" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated"><strong class="kt ir">缓冲器尺寸</strong></p><p id="48a4" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated">请求的传入缓冲区大小。<strong class="kt ir">实施可以选择另一个尺寸。</strong></p></blockquote><p id="5b00" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在一个重要的问题是:抽头的<em class="or">采样率是多少？或者，我们多久得到一次样本量的回调？如果回调速率和采样大小不匹配，我们可能会丢失很多音频帧！经过一些实验测试后，该框架似乎每0.1秒触发一次回调，而不会丢失一个音频帧。这意味着如果音频格式的采样率是44100Hz，我们将每0.1秒得到4410个音频帧。(注意:自从我差不多一年前开始写这篇文章以来，这些数字似乎已经改变了。不要惊慌，这对本教程的目的来说没有什么区别)。</em></p><p id="dbb7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">总结第一部分，我们的ViewController应该如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="8f68" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们现在准备好下一部分:信号处理！</p><h2 id="0614" class="nk mo iq bd mp nl nm dn mt nn no dp mx la np nq mz le nr ns nb li nt nu nd nv bi translated">第2部分:信号处理</h2><p id="3f6d" class="pw-post-body-paragraph kr ks iq kt b ku nf jr kw kx ng ju kz la nh lc ld le ni lg lh li nj lk ll lm ij bi translated">首先，让我们回顾一下性能要求。因为我们想让这很快，我们需要两样东西。</p><ol class=""><li id="803d" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ok oc od oe bi translated">快点算吧。</li><li id="3e40" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ok oc od oe bi translated">不要在主(UI)线程上这样做。</li></ol><p id="4971" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们已经知道可以使用Accelerate框架。对于第二点，我们很幸运。从installTap文档中:</p><blockquote class="ph pi pj"><p id="f557" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated">可以在主线程之外的线程上调用<code class="fe os ot ou ov b">tapBlock</code>。</p></blockquote><p id="62d8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们<em class="or">最有可能</em>(这可能不是决定性的行为，为了生产目的相应地计划)不会在主线程中，所以我们不必担心使用GCD或NSThreads来运行这些计算。</p><p id="cb67" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在让我们言归正传。我们知道我们正在使用第一个通道，并且我们知道框架可能不太关心我们所请求的bufferSize，所以让我们获得这个信息。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在ViewController类内部</p></figure><p id="d74b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们现在有了一个浮点数组(channelData)和数组大小(frames)。帧数采用AVAudioFrameCount的形式，它只是UInt32的别名。</p><p id="b660" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">引入加速</strong></p><blockquote class="ph pi pj"><p id="658f" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated">通过利用其矢量处理能力，加速器在CPU上提供高性能、高能效的计算。以下加速库抽象了这种能力，以便为它们编写的代码在运行时执行处理器可用的适当指令:</p></blockquote><p id="1a01" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果我们看一下<a class="ae ol" href="https://developer.apple.com/documentation/accelerate" rel="noopener ugc nofollow" target="_blank">文档</a>，我们可以看到框架为我们提供了多个库。</p><p id="e5b1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们感兴趣的是<a class="ae ol" href="https://developer.apple.com/documentation/accelerate/vdsp" rel="noopener ugc nofollow" target="_blank"> vDSP </a>:</p><blockquote class="ph pi pj"><p id="46ed" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated">vDSP框架包含一组高度优化的函数，用于大型阵列上的数字信号处理和通用运算。</p></blockquote><p id="f7b5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是信号处理的核心。在这里，我们会找到我们所需要的一切。</p><p id="c4a3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第2.1节:信号响度测量</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/f21d21afb85c4a175e730dbd650ead7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/1*UVcTgzGTMjdssCJt-KNLHA.gif"/></div></figure><p id="c743" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是用来画圆的。让我们把注意力集中在前面看到的图表和来自缓冲区数据的音频帧样本的快照上(如果您要打印出这些值的话)。</p><div class="kg kh ki kj gt ab cb"><figure class="pq kk pr ps pt pu pv paragraph-image"><img src="../Images/96ff6fbd9cf90189163d9d589889a55e.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*E6feYj3ma26zW7RnGZ4zTA.jpeg"/></figure><figure class="pq kk pw ps pt pu pv paragraph-image"><img src="../Images/7b945c787628c62fae77887c9912eb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*JX8DgQpP8E_flrWPOJjUwA.png"/></figure></div><p id="cfaa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们注意到这些值可以是正的，也可以是负的；这是怎么回事？声音是一种压力波，相对于一些基线，压力可以更高或更低。更多信息<a class="ae ol" href="https://stackoverflow.com/questions/1380692/meaning-of-negative-values-in-audio-waveforms" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="f300" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们来看看矢量缩减&gt;矢量平均计算下的vDSP文档。因为毕竟，我们处理的是一个信息向量，我们试图找到当前音频缓冲区的某种平均响度来显示给用户。</p><p id="3785" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">那我们选哪一个？</p><p id="deae" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这有点复杂。我们在vDSP框架中的最佳选择是均方根计算。这是有意义的，因为均方根用于计算x轴上下的函数的平均值。事实证明，在实践中，这是一种非常好的、广泛使用的响度测量技术。</p><p id="5efa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了完整起见，我将提到有更高级的方法来进行响度测量，但现在我希望你能欣赏和理解为什么我们不过度关注细节。如果你正在寻找最精确的方法来测量这个，你可以看看A-Weighting，它会把重点放在我们的耳朵可以更好地听到的频率上。</p><p id="1096" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们做吧，看看我们会得到什么！</p><p id="d9e1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们现在要上信号处理课了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi px"><img src="../Images/1e3401718857dfa5f58cfe2383d0fea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FKZHSxNYmlyP2Veonje4Xg.png"/></div></div></figure><p id="7da5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们希望导入Accelerate来利用vDSP库。接下来，我们来看看RMS函数，<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450655-vdsp_rmsqv" rel="noopener ugc nofollow" target="_blank">vDSP_rmsqv</a></code>。</p><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="4a8a" class="nk mo iq ov b gy pc pd l pe pf"><strong class="ov ir">func</strong> vDSP_rmsqv(<strong class="ov ir">_</strong> __A: UnsafePointer&lt;Float&gt;,</span><span id="09fc" class="nk mo iq ov b gy pg pd l pe pf"><strong class="ov ir">                _</strong> __IA: vDSP_Stride,</span><span id="8d1e" class="nk mo iq ov b gy pg pd l pe pf"><strong class="ov ir">                _</strong> __C: UnsafeMutablePointer&lt;Float&gt;,</span><span id="02ff" class="nk mo iq ov b gy pg pd l pe pf"><strong class="ov ir">                _</strong> __N: vDSP_Length)</span></pre><p id="a62b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">答:(很有描述性，我知道)指向我们数据的指针，定义为单精度实输入向量。单精度意味着它是一个浮点数；真实输入意味着值是真实的并且不复杂。</p><p id="417d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">IA:我们的缓冲数据的跨度。跨距是内存(在某种容器中，如数组、向量等)中数据的离散值之间的距离，以某种单位度量。在我们的例子中，vDSP_Stride是一个单位步幅，这意味着它将在内存中移动x个字节，其中x表示容器中值类型的大小。vDSP_Stride只是Int的类型别名。</p><p id="e5f1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">c:指向一个浮点型的指针，我们想在这里写操作的结果。</p><p id="c0c7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">n:我们想要进行运算的数据的长度。这只是UInt的类型别名。</p><p id="2c80" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们可以在SignaProcessing类中创建一个函数，在给定一个浮点容器和我们想要计算的值的数量的情况下，返回RMS值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="ec46" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果我们回到ViewController的processAudioData函数，我们可以获得当前音频样本的有效响度。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi py"><img src="../Images/bcc404153ebeab803ba222f435e8b3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*BlbN0UozQhkVD_Esfq43fg.png"/></div></figure><p id="e544" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好了，我们有了样本的值——现在呢？这些值相当小。如果您还记得点在金属中的工作方式，X轴和Y轴的范围是从-1到1。我们首先需要建立一个基线，或者更确切地说，响度为0时的圆圈有多大，最大值是多少？如果我们从UI角度考虑这个问题，我们不希望圆圈填满整个MetalView需要为频率线留有空间。我们将采用最低0.3，最高0.6。</p><p id="e81a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们需要对这些值进行归一化，使其介于0.3和0.6之间。如果我们对我们的圆使用0.3半径的基线，那么一个简单的方法是0.3+rms value；但是正如我们所看到的，这些值太小了，不足以产生显著的差异，所以我们需要将它们放大。</p><p id="05d4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，让我们将结果转换成分贝(<code class="fe os ot ou ov b">10*log10f(val)</code>)，这是一个更容易使用和理解的单位。</p><p id="6604" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们现在将得到范围从-160dB(无声)到0dB(最大声)的值。要将其调整到+0.3范围而不是-160范围，需要一些简单的算法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="ccff" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但现在我们注意到另一个问题:我们的价值观似乎都在5.27-5.28左右徘徊。这似乎不太令人印象深刻。我们能做些什么来强调这些小变化呢？嗯，我们可以选择放大我们的响度似乎受到限制的某个范围。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="7fba" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">添加一个打印语句并查看输出！</p><p id="0dce" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下一个要解决的问题是采样率。我们每0.1秒得到一次回调。10fps的响度计看起来并不令人印象深刻，尤其是如果你考虑到我们只是渲染了十次不同大小的圆圈这一事实。它将看起来起伏不定，一点也不平稳。那么我们能做些什么来填补空白呢？好问题。我们可以在点之间做一些插值来平滑它！在这种情况下，线性插值非常好。</p><p id="1bdb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将放大它，然后粘贴代码。本质上，我们需要做的就是将previous值存储在控制器类中，并使用以前和当前的rms调用信号处理类中的插值函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在ViewController类内部。</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在SignalProcessing类内部。</p></figure><p id="a3b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，这些结果将不会被使用，因为它们在下一部分之前都不重要。</p><p id="5adc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第2.2节:信号的频率计量</strong></p><p id="e471" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们需要了解频率的含义，以及如何获得离散频率仓的幅度来表示我们的线的大小。频率仓的大小是多少？它是这个频率附近的能量总量。我们将很快讨论这个概念。首先，我们来看一下音频信号，然后是傅立叶变换的工作原理，最后是如何实现快速傅立叶变换(FFT)，从字面上看，这是一种从算法上快速计算傅立叶变换的方法。</p><p id="78d2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">声音以波的形式传播。增加波的振幅会通过增加波的能量来增加声音的响度，这就是为什么使用我们的音频样本的振幅来计算响度是可行的。下面的视频很好地总结了我们听到的频率(声音)以及它与振幅的关系。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pz ox l"/></div></figure><p id="2261" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们如何得到每个频率的能量？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qa"><img src="../Images/1fb48ed470686929932b60aab57626e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMWqnSRF06lxoYKptQ4d-A.png"/></div></div><p class="on oo gj gh gi op oq bd b be z dk translated">来源:<a class="ae ol" href="https://www.researchgate.net/post/how_to_convert_time_domain_data_into_frequency_domain_data" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/post/how _ to _ convert _ time _ domain _ data _ into _ frequency _ domain _ data</a></p></figure><p id="2dc0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们需要将缓冲数据(音频样本)从左侧(时域中)的表示形式转移到右侧(频域中)。通过分析信号在频域中的表现，我们发现我们处理的是相同类型的值。每个频率范围的线条高度决定了能量(以及我们将为音频可视化工具生成的线条长度)。</p><p id="70de" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在让我们得到这些值！</p><p id="e3fb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">回到vDSP框架，看看矢量和矩阵傅立叶变换，我们看到了一个选择<a class="ae ol" href="https://developer.apple.com/documentation/accelerate/fast_fourier_transforms" rel="noopener ugc nofollow" target="_blank"> FFT </a>！我们有很多选择。</p><p id="7583" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">FFT页面上函数的直接子部分分组如下:</p><ul class=""><li id="8bfd" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ob oc od oe bi translated">1D还是2D？</li><li id="eaf3" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ob oc od oe bi translated">原地还是原地？</li><li id="8e07" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ob oc od oe bi translated">真实的还是复杂的？</li></ul><p id="0c9b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">看一下我们的音频样本，应该很清楚我们是在一维上工作，也就是说，我们只关心y轴上的值(振幅)。在位还是不在位，指的是算法本身。第三个问题，真实的还是复杂的，比较有意思。当我们从时域转到频域时，我们会得到虚轴和实轴上的值，即一个复数。我们关心这个数的能量或大小。如果我们选择<em class="or">实数</em>，我们得到代表能级的值。如果我们选择<em class="or">虚</em>，我们需要自己计算复杂结果的大小(一个简单的函数调用)。是否忽略复杂部分的问题是一个精度问题。在我们的例子中，这无关紧要，但我们将继续使用复数。</p><p id="12d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们会在每个小节中看到更多选项。单精度还是双精度？出于我们的目的，双精度不会给我们带来额外的价值，只会让函数执行得更久，所以我们将使用单精度。有缓冲还是没有缓冲？提供一个缓冲区会给我们带来更好的性能，所以我们会使用它。多重信号？对我们来说不是。</p><p id="e42d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们最终缩小到我们想要的功能:</p><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="0168" class="nk mo iq ov b gy pc pd l pe pf">func vDSP_fft_zipt(_ __Setup: FFTSetup,</span><span id="fa85" class="nk mo iq ov b gy pg pd l pe pf">                   _ __C: UnsafePointer&lt;DSPSplitComplex&gt;,</span><span id="1a27" class="nk mo iq ov b gy pg pd l pe pf">                   _ __IC: vDSP_Stride,</span><span id="d6ae" class="nk mo iq ov b gy pg pd l pe pf">                   _ __Buffer: UnsafePointer&lt;DSPSplitComplex&gt;,</span><span id="17b2" class="nk mo iq ov b gy pg pd l pe pf">                   _ __Log2N: vDSP_Length,</span><span id="0fc2" class="nk mo iq ov b gy pg pd l pe pf">                   _ __Direction: FFTDirection)</span></pre><p id="3585" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是等等！文件告诉我们:</p><blockquote class="ph pi pj"><p id="ff38" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated">尽可能使用DFT程序代替这些程序。(例如，不是用<code class="fe os ot ou ov b">vDSP_create_fftsetup</code>创建的设置调用<code class="fe os ot ou ov b">vDSP_fft_zip</code>，而是用<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450061-vdsp_dft_zop_createsetup" rel="noopener ugc nofollow" target="_blank">vDSP_DFT_zop_CreateSetup(_:_:_:)</a></code>创建的设置调用<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450538-vdsp_dft_execute" rel="noopener ugc nofollow" target="_blank">vDSP_DFT_Execute(_:_:_:_:_:)</a></code>。)</p></blockquote><p id="4cd0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">实际上我过去忽略了这些，但是FFT执行函数使用起来要简单得多，所以我们将继续使用<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450538-vdsp_dft_execute" rel="noopener ugc nofollow" target="_blank"><em class="or">vDSP_DFT_Execute(_:_:_:_:_:)</em></a></code> <em class="or"> </em>而不是更冗长的函数。</p><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="5c48" class="nk mo iq ov b gy pc pd l pe pf">func vDSP_DFT_Execute(_ __Setup: OpaquePointer,</span><span id="2828" class="nk mo iq ov b gy pg pd l pe pf">                      _ __Ir: UnsafePointer&lt;Float&gt;,</span><span id="b4fc" class="nk mo iq ov b gy pg pd l pe pf">                      _ __Ii: UnsafePointer&lt;Float&gt;,    </span><span id="3c18" class="nk mo iq ov b gy pg pd l pe pf">                      _ __Or: UnsafeMutablePointer&lt;Float&gt;,</span><span id="bf18" class="nk mo iq ov b gy pg pd l pe pf">                      _ __Oi: UnsafeMutablePointer&lt;Float&gt;)</span></pre><p id="01be" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些输入需要一些解释。</p><p id="8fc9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们有<code class="fe os ot ou ov b">OpaquePointer</code>，也就是函数的设置对象<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450061-vdsp_dft_zop_createsetup" rel="noopener ugc nofollow" target="_blank">vDSP_DFT_zop_CreateSetup(_:_:_:)</a></code></p><blockquote class="ph pi pj"><p id="fcb5" class="kr ks or kt b ku kv jr kw kx ky ju kz pk lb lc ld pl lf lg lh pm lj lk ll lm ij bi translated">创建与<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450538-vdsp_dft_execute" rel="noopener ugc nofollow" target="_blank">vDSP_DFT_Execute(_:_:_:_:_:)</a></code>或<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450016-vdsp_dct_execute" rel="noopener ugc nofollow" target="_blank">vDSP_DCT_Execute(_:_:_:)</a></code>一起使用的数据结构，以执行复数到复数的离散傅立叶变换，正向或反向。</p></blockquote><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="6993" class="nk mo iq ov b gy pc pd l pe pf">func vDSP_DFT_zop_CreateSetup(_ __Previous: vDSP_DFT_Setup?,</span><span id="ef87" class="nk mo iq ov b gy pg pd l pe pf">                              _ __Length: vDSP_Length,</span><span id="83df" class="nk mo iq ov b gy pg pd l pe pf">                              _ __Direction: vDSP_DFT_Direction<br/>                              ) -&gt; vDSP_DFT_Setup?</span></pre><p id="2690" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于前一个，我们没有，所以它是零。</p><p id="a241" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe os ot ou ov b">vDSP_length</code>是unsigned long的类型别名，表示我们将要转换的元素的数量。我们可以使用2 (4096)个值，但这对于画线来说是太多的结果箱了，所以看起来不太好(会太拥挤)。用1024(2 ⁰)个元素进行变换给出了更合理的结果。现在，正如我们之前从我们收到的特定mp3的样本大小中看到的，这只是缓冲数据的四分之一！如果你想要更高的精确度(这对我们来说并不重要)，你可以增加更多的值。</p><p id="683b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在初始化setup对象之后，我们还应该在完成后销毁它。这是不需要的，因为我们在这个项目中没有真正的应用程序生命周期，所以它将被省略。</p><p id="b628" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们的视图控制器类中，我们将导入accelerate并初始化一个存储为类变量的fftSetup对象:</p><pre class="kg kh ki kj gt oy ov oz pa aw pb bi"><span id="164c" class="nk mo iq ov b gy pc pd l pe pf">import Accelerate</span><span id="3d58" class="nk mo iq ov b gy pg pd l pe pf">....</span><span id="6b8e" class="nk mo iq ov b gy pg pd l pe pf">//fft setup object for 1024 values going forward (time-&gt; frequency)</span><span id="aa40" class="nk mo iq ov b gy pg pd l pe pf">let fftSetup = vDSP_DFT_zop_CreateSetup(nil, 1024, vDSP_DFT_Direction.FORWARD)</span></pre><p id="7f43" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，FFT接受两个输入指针(不可变的)和两个输出指针(可变的),用于表示数字的实部和虚部的浮点向量。所以我们需要做的就是创建它，然后运行函数！这将在SignalProcessing类(在一个新函数中)中完成，并从ViewController类中调用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在SignalProcessing.swift中添加了函数</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">在ViewController.swift中添加了函数</p></figure><p id="83fc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好吧，我们停一下。我之前说过，FFT会在频率仓中吐出幅度，但有多少频率仓，我们没有具体说明。根据<a class="ae ol" href="https://en.wikipedia.org/wiki/Nyquist–Shannon_sampling_theorem" rel="noopener ugc nofollow" target="_blank">奈奎斯特-香农采样定理</a>，频率仓的数量实际上与数据点的数量(n/2)成线性关系。</p><p id="ea79" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">那么这些箱子里装的是什么频率呢？其工作方式是:如果我们使用1024个数据点，则采样时间约为0.025秒或1/40 ~ 40Hz，这意味着我们可以检测的最低频率是1*40Hz = 40Hz(第一个频段)，最高频率是(n/2)*40Hz = 512*40Hz = 20.48Khz(最后一个频段)。</p><p id="d7e0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们需要得到震级。记住，幅度将表示频率仓中的能量。在vDSP框架中有没有一种计算复数幅度的方法？当然有。我们有两个选项:compute sqrt(a + b)或compute (a +b)来节省一些计算时间。但是，对于我们的归一化方法，我们需要前一种方法。</p><p id="72a5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用的函数称为<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1449881-vdsp_zvabs" rel="noopener ugc nofollow" target="_blank">vDSP_zvabs</a></code>，可以在vDSP框架的绝对和求反函数下找到。(另一个选项叫做<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450557-vdsp_zvmags" rel="noopener ugc nofollow" target="_blank">vDSP_zvmags</a></code>)。从现在开始，我将省略加速函数的参数解释。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">内部信号处理</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/2f13dfe5a5363962ffcefa27fd858840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*M3ICqHrcsT06nYs2V_KlwA.png"/></div></figure><p id="1bf9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从价值观来看，我们看到的范围很广。就像我们之前处理信号幅度一样，我们需要将其归一化。这一次，我们不只是缩放一个值；我们正在缩放1024个值。因此，我们希望确保能够以最佳方式实现这一点，这也是矢量标量运算在DSP框架中发挥作用的地方。如何选择比例因子？对此，T4没有简单的答案。</p><p id="c136" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">网上常用的方法是除以样本数。在以一种我们可以使用的方式调整这些值之后，我们的缩放因子将是25.0/512。注意:我们不是要保证不出界，我们只是要保证好看(这当然是偏向我的口味。)</p><p id="55a0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">看看你是否能使用<code class="fe os ot ou ov b"><a class="ae ol" href="https://developer.apple.com/documentation/accelerate/1450020-vdsp_vsmul?language=occ" rel="noopener ugc nofollow" target="_blank">vDSP_vsmul</a></code>独立完成这一部分。</p><p id="5488" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，在返回我们的结果后，我们完成了第1部分:)</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">完整的信号处理类</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="on oo gj gh gi op oq bd b be z dk translated">已完成的ViewController类</p></figure></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="2098" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你真的理解了我这篇冗长的文章，那就休息一下吧！你应得的！</p><p id="24da" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">完整的第一部分代码在我的Github <a class="ae ol" href="https://github.com/barbulescualex/MetalAudioVisualizer" rel="noopener ugc nofollow" target="_blank">这里</a>:</p><p id="5641" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">别忘了第二部分！</p><div class="lo lp gp gr lq lr"><a href="https://medium.com/@barbulescualex/audio-visualization-in-swift-using-metal-accelerate-part-2-7ec8df4def91" rel="noopener follow" target="_blank"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">使用Metal &amp; Accelerate在Swift中实现音频可视化(第二部分)</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">我们都见过各种形式的音频可视化，但是我们如何在Cocoa应用程序中实现呢？</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">medium.com</p></div></div><div class="ma l"><div class="qc l mc md me ma mf kp lr"/></div></div></a></div><p id="3078" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你有任何问题或建议，请在下面的评论中留下。</p></div></div>    
</body>
</html>
# 一位资深 iOS 开发者对 WWDC 2020 的预测

> 原文：<https://betterprogramming.pub/a-senior-ios-developers-predictions-for-wwdc-2020-fb727a4b45e6>

## 我认为在不久的将来，苹果公司将会推出

![](img/4b2823bdd975c3ec31f783372315cf29.png)

[苹果图片](https://www.apple.com/newsroom/2020/06/apple-reveals-lineup-for-its-biggest-ever-worldwide-developers-conference/)

WWDC 2020 就要到了，鉴于目前的健康状况，这是苹果首次只在网上举办的开发者活动。我们肯定会错过现场观众的掌声，看看苹果如何在主题演讲和视频中重现这种体验会很有趣。

但更令人兴奋的是苹果今年将向开发者社区和世界展示的新的好东西和更新。

WWDC 2019 无疑是近年来最大的苹果事件，因为它揭示了开创性的变化:系统级黑暗模式；支持多窗口实现的新 iPadOS 13Project Catalyst，只需轻轻一点就可以将 iOS 应用移植到 macOS 上；或者 SwiftUI，苹果闪亮的新声明式 UI 框架。

这确保了“Dub Dub”2020 的门槛很高，在一般水平上，人们会期待开发者生态系统的增强和改进，而不是太多的新功能。

我很兴奋，并且有一个我希望在苹果发布会上看到的改进和功能的愿望清单。

CoreML、CreateML 和 Vision Framework 去年进行了巨大的更新，而 RealityKit、SwiftUI 和 Combine frameworks 首次亮相，抢尽了风头。我预计这六个框架也将是这次的主要参与者，其他框架将围绕它们展开。

# CoreML:对更多层的支持

CoreML 在 WWDC 19 中引入了设备上迁移学习，允许我们在 iOS 设备上重新培训模型。目前，它只支持 k-最近邻和 CNN 分类器。人们会期望苹果通过包括递归神经网络(RNN)层来扩展层集，例如 LSTM；提供更多的内置优化器(目前有 Adam 和 SGD)，并释放出一种创建自定义损失函数的方法。

训练 RNN 模型的能力应该有助于开发人员轻松构建有趣的移动机器学习应用程序，如股票价格预测(尽管只是出于教育/娱乐目的，不要将其用于投资建议)。

# CreateML:训练自定义图像分割模型等等

上次 CreateML 终于在 Playgrounds 之外有了自己的独立应用。现在，它允许非机器学习开发人员通过一个惊人的拖放界面快速训练模型，该界面拥有内置的图像分类器、对象检测和推荐系统等模型训练器。

通过包括图像分割和姿态估计来扩展训练的可能性是我最想要的。拥有一个内置的注释工具，可能是一个让你从视频中选择对象的工具，将使训练对象检测变得更加容易，并且可能完全在内部完成——今天你需要从外部添加你的`annotation.json`文件。

# 更强大的愿景框架

Vision 是苹果的深度学习框架，为复杂的计算机视觉算法提供开箱即用的实现。它也有助于驱动 CoreML 模型。WWDC 19 推出了新的宠物动物分类器，内置的图像分类工具，计算图像相似性，并支持具有捕捉质量要求的人脸技术。

今年，苹果可以通过以下方式将计算机视觉的极限推得更远:

*   将面部捕捉质量扩展到更一般的图像质量视觉要求
*   引入运动跟踪，并提供内置功能来确定物体与摄像机的距离，从而为更智能的应用创造可能性
*   引入图像配准和内置的图像分割请求将能够实现更好的数字图像处理，这对医疗用例可能是有用的

这些是我希望在今年的愿景框架更新中看到的一些内容。

# RealityKit 和 Reality Composer 的巨大更新

随着 3D 引擎 RealityKit 的推出，苹果重新启动了其增强现实(AR)战略，该战略早期使用 SceneKit。

但它苦于缺乏文献。苹果肯定会致力于此，以便将开发者带上增强现实的列车。iOS 14 的新 AR 应用可能会展示对象遮挡，这应该是一个好的开始。对手势跟踪的开箱即用支持将有助于打开令人兴奋的 AR 应用的大门。

Reality Composer 是一个 AR 场景编辑器，允许您创建、导入和自定义 3D 内容。更灵活地将形状与枢轴混合，以及将 GLTF 和其他模型文件类型导入 USDZ 应该会有所帮助。

鉴于苹果对 AR 眼镜的巨大抱负，RealityKit 将在未来几年发挥巨大作用。我们可以期待今年的巨大更新，这可能只是 ar 中 SceneKit 的帷幕。

# 更多联合出版商

苹果自己的声明式反应式编程框架 Combine 可能是去年首次亮相时最完美的框架。一些基金会类型可以通过它公开他们的发布者的功能。

今年，苹果可能会为 MapKit、PencilKit、CoreLocation 和 CoreML 引入更多内置发布程序，并提供新的合并操作符。

# 机器学习驱动的铅笔套件

PencilKit 框架也在去年首次亮相，但它受到的欢迎相当低调，因为其他人抢了风头。目前，它只允许您集成画布和墨迹工具。

苹果今年可以通过允许在`PKCanvas`中无缝集成图像和资产来推动它。通过机器学习来增强绘图框架，无论是通过内置的手写文本识别还是通过点检测，都可以引起轰动，并允许开发人员构建更令人兴奋的机器学习应用程序。

# SwiftUI 可能会再次成为焦点

SwiftUI 上次引发了一场风暴，今年可能也不会有什么不同。状态驱动的框架仍然有点粗糙，缺乏良好的文档加上缺少 UIKit 功能已经对 SwiftUI 2.0 设定了很高的期望。难怪它会成为 WWDC 2020 周期间和之后谈论最多的功能。

肩负重任，这里是我的 SwiftUI 愿望清单和我希望看到的改进。

## SwiftUI 中的集合视图

集合视图通过新的组合布局得到了有趣的更新，但它们在 SwiftUI 中完全丢失了。今年，组合布局的声明性质应该会在 SwiftUI 中带来某种集合视图。通过这样做，开发人员可以构建复杂的基于网格的用户界面。

## 带来缺失的 UI 视图

SwiftUI 的第一个版本没有活动指示器、搜索栏、多行文本视图和刷新控件。我们必须利用`UIViewRepresentable`协议和 UIKit 互操作性，或者使用`GeometryReader`和形状(对于进度条)来构建等价的 SwiftUI 包装器视图。

## 选项卡视图和导航视图的改进

虽然基本的选项卡视图和导航视图似乎可以工作，但存在一些严重的潜在问题。例如，SwiftUI 的选项卡视图一直是切换选项卡时的一个关注点。无论是滚动还是导航位置都不会被保留，你不得不返回到`UITabBarController`。

在导航方面，最大的问题是在`NavigationLinks`中目的地视图的处理——它们是在你点击导航链接之前创建的。我们期待目的地视图的一致延迟加载(苹果在 Xcode 11.4.1 中修复了它，但仍然不一致)。

我们希望苹果能解决这些问题，并可能为 SwiftUI 提供更好的导航方式。

## 滚动视图的当前位置

无法访问 SwiftUI 中的当前滚动视图位置。我们可以期待 Apple 为位置偏移量引入一个绑定属性。

## 更容易与其他框架集成

`WKWebView`、`MapKit`、`PencilKit`、`ARKit`视图和`ShareSheet`目前都需要`UIViewRepresentable`。与 SwiftUI 更好的互操作性将加速工作流程并减少样板代码。

## Rehaul CoreData

就像 SwiftUI 改变了我们构建用户界面的方式一样，现在是时候了，苹果推出了类似 SwiftData 的东西，只在 Swift 中构建，而不是 Objective-C。

## SwiftUI 故事板

虽然 SwiftUI 提供实时画布预览，但拥有一个显示不同 SwiftUI 视图如何连接的应用程序级视图(如故事板)将是一个很好的补充，并将帮助开发人员在生产中使用 SwiftUI。

# 结束语

虽然这是我的主要愿望清单，但考虑到我们上次介绍的游乐场，拥有一个适用于 iPad 的 Xcode 将是一个梦想。

macOS 和 Xcode visual `po`类似调试的试飞也不能排除。

人们可以预期`AVFoundation` API(考虑到我们现在有三个或更多的摄像头)和`Location`和`Bluetooth`API 也会有相当大的变化。

像上次一样，SwiftUI 和 RealityKit 将成为 WWDC 20 期间的领跑者，除非苹果再次给我们带来惊喜。

感谢阅读。我期待着 WWDC 2020 年以及更远的未来！
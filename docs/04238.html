<html>
<head>
<title>ODI Match Prediction With Elo Scores and sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用Elo分数和sklearn进行ODI匹配预测</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/odi-match-prediction-with-elo-scores-and-sklearn-b9dc60900ff5?source=collection_archive---------13-----------------------#2020-03-31">https://betterprogramming.pub/odi-match-prediction-with-elo-scores-and-sklearn-b9dc60900ff5?source=collection_archive---------13-----------------------#2020-03-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5b15" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用sklearn中的机器学习和超参数优化技术，将ODI Elo分数用于预测比赛结果</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e6156a4003f2641206531044a1aa8ec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RbMvMhwikABEUU4dcKJ1DA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">查理·索洛萨诺在<a class="ae ky" href="https://unsplash.com/s/photos/chess?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="b119" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="c6a7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Elo评分系统由匈牙利裔美国物理学教授Arpad Elo创建，最初用于计算零和游戏(如国际象棋)中玩家的相对技能。该排名系统已被用于各种体育环境，自从“金钱球”革命以来变得越来越受欢迎，主要是因为Elo排名已被证明具有预测能力。</p><p id="4110" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一个队的Elo分数由一个数字表示，该数字根据其他排名队之间的比赛结果而增加或减少。每场比赛后，赢的一方从输的一方那里拿分。胜负双方的评分之差决定了一场比赛后的总得分或总失分；失分和得分的数量根据球队的质量进行加权，这说明了意想不到的结果(也称为运动冷门)。虽然分配给一个团队的初始数字有些随意，但大多数以前的分析都使用1500作为起始数字。</p><p id="da06" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我之前尝试过使用印度超级联赛(IPL)的比赛数据和二元逻辑回归，使用<a class="ae ky" href="https://googlyanalytics.sport.blog/2019/06/10/ipl-current-elo-rankings-probabilities/" rel="noopener ugc nofollow" target="_blank"> Elo分数来预测比赛</a>结果。虽然这仍然有很好的效用，但是在IPL中球员被选中的方式和球队随赛季的变化意味着Elo分数在这种情况下使用时特别敏感。此外，IPL从2008年才开始运行，所以数据有限，这可能导致相对虚假的发现。该模型可以根据团队之间Elo分数的巨大差异来预测胜利，但当对手更加势均力敌时则不行。</p><p id="5274" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，我想对一天国际(ODI) Elo分数进行类似的分析，因为这种形式的游戏(1972年至2019年)有更多的数据。</p><p id="bba8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此外，我希望评估各种机器学习技术，包括超参数优化和交叉验证，以确定最佳模型来估计ODI匹配结果，并将Elo作为主要预测因素。使用来自Kaggle 的所有<strong class="lt iu"> </strong> <a class="ae ky" href="https://www.kaggle.com/jaykay12/odi-cricket-matches-19712017" rel="noopener ugc nofollow" target="_blank"> ODI匹配数据，我能够创建更多的特征变量来丰富模型并随后提高准确性。迭代方法将在下面讨论。</a></p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="7f45" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated"><strong class="ak">方法</strong></h1><p id="e693" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在执行任何实质性分析或机器学习之前，你将面临任何体育统计学家都非常熟悉的艰巨任务:电子表格维护。</p><p id="41cb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我以前使用过EPSNcricinfo API来遍历数据，但是(如前所述)所有ODI匹配数据都可以在Kaggle中获得，并且采用适合计算Elo分数的格式。你可以在<a class="ae ky" href="https://googlyanalytics.sport.blog/2019/06/07/ipl-elo-ranking-2008-2017/" rel="noopener ugc nofollow" target="_blank">谷歌分析</a>上找到我的工作，它分解了用于计算国际板球Elo排名的公式和方法。</p><p id="db57" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一旦你有了一个合适的系统，你就可以绘制一段时间内的Elo分数，这将让你感受到胜败是如何影响团队的整体表现的(图1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/fd99e1a2e1284b37d6e134a3eef65a53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JUedJtEntdfyEoC9BxHDmw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:杰出ODI团队的Elo得分(1972-2019)</p></figure><p id="3446" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，打开Jupyter Notebook或您选择的IDE，并安装必要的软件包:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="fda0" class="nk la it ng b gy nl nm l nn no">import pandas as pd<br/>import seaborn as sb<br/>import matplotlib.pyplot as plt<br/>import plotly.graph_objects as go<br/>import plotly.express as px<br/>import chart_studio<br/>import chart_studio.plotly as py<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn import metrics<br/>import numpy as np<br/>from sklearn.impute import SimpleImputer<br/>from pylab import rcParams<br/>from sklearn.neural_network import MLPRegressor, MLPClassifier<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor<br/>import joblib<br/>import pandas as pd<br/>from sklearn.metrics import accuracy_score, precision_score, recall_score<br/>from time import time<br/>from sklearn.tree import export_graphviz<br/>import pydot</span></pre><p id="3655" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">读入您的Excel文件，将其存储为Pandas对象，并可视化数据格式:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="4a11" class="nk la it ng b gy nl nm l nn no">local = ‘/.../.../.../Elo_pred.xlsx’<br/>elo = pd.read_excel(local)<br/>elo.head(100)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/528f84bd224d60acefcfdc585d69e320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*vnq9deGJJRrdaDGIHdojbw.png"/></div></figure><p id="c62b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如上面的<code class="fe nq nr ns ng b">DataFrame</code>所示，在导入Excel文件之前，我创建了一些变量。此<code class="fe nq nr ns ng b">DataFrame</code>中的每一行都代表了1972年至2019年间发生的一场对决:</p><ul class=""><li id="82e0" class="nt nu it lt b lu mn lx mo ma nv me nw mi nx mm ny nz oa ob bi translated"><code class="fe nq nr ns ng b">Home_Elo</code>:主场球队在比赛当天的Elo得分</li><li id="d377" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><code class="fe nq nr ns ng b">Away_Elo</code>:比赛当天客场球队的Elo得分</li><li id="2160" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><code class="fe nq nr ns ng b">Elo_Diff</code>:主客场球队Elo的差异</li><li id="a8ff" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><code class="fe nq nr ns ng b">Home_Advantage</code>:主队是否获胜(<code class="fe nq nr ns ng b">2</code> =是，<code class="fe nq nr ns ng b">1</code> =否)</li><li id="02b2" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><code class="fe nq nr ns ng b">Home_Team_Innings</code>:主队先击球还是先投球(<code class="fe nq nr ns ng b">2</code> =击球，<code class="fe nq nr ns ng b">1</code> =投球)</li><li id="1c6b" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><code class="fe nq nr ns ng b">Match_Outcome</code>:我们希望预测的变量；它代表了比赛的结果(<code class="fe nq nr ns ng b">1</code> =主队赢了，<code class="fe nq nr ns ng b">0</code> =主队输了)</li></ul><p id="198a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您可能希望可视化一些预测变量的分布:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="3041" class="nk la it ng b gy nl nm l nn no">elo_dist = sb.distplot(elo['Home_Elo'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7c3ce3ebf93bbfc341b84d69787b563a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*rtsknHjwMdCjS5PqiLPcTA.png"/></div></figure><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="4b23" class="nk la it ng b gy nl nm l nn no">elo_dist = sb.distplot(elo['Elo_Diff'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/729b73ffbd53c8713f9237e9d3802113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*V5-qWWM2TFnn2WwkaVyN-w.png"/></div></figure><p id="3add" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您现在需要将您的数据分成训练、测试和验证数据。训练数据将用于训练单个模型，而测试数据将用于评估我们训练的模型的准确性。</p><p id="c5af" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，我们将在最后使用一个验证数据集来评估模型性能，并与所有其他使用的模型进行比较。sklearn没有将数据分成三部分的选项；以下语法将数据拆分为60:40的标准训练测试拆分，并将训练数据集进一步划分为训练和验证成分(20:20):</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="017c" class="nk la it ng b gy nl nm l nn no">## Split features (x) and outcomes (y)</span><span id="3a1d" class="nk la it ng b gy oj nm l nn no">features = df[['Elo_Diff','Home_Elo', 'Away_Elo', 'Home_Advantage','Home_Team_Innings']].copy()<br/>labels = df['Match Outcome']</span><span id="4331" class="nk la it ng b gy oj nm l nn no">## Train - test</span><span id="61e1" class="nk la it ng b gy oj nm l nn no">X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)</span><span id="3f37" class="nk la it ng b gy oj nm l nn no">## Validation</span><span id="778f" class="nk la it ng b gy oj nm l nn no">X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)</span></pre><p id="9346" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要确保您的数据已正确分割:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="ae78" class="nk la it ng b gy nl nm l nn no">for dataset in [y_train, y_val, y_test]:<br/>    print(round(len(dataset) / len(labels), 2))</span><span id="c2dc" class="nk la it ng b gy oj nm l nn no">&gt; 0.6<br/>&gt; 0.2<br/>&gt; 0.2</span></pre></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="3839" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">逻辑回归</h1><p id="13df" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们要训练的第一个模型是逻辑回归。由于我们有一个二元的结果测量，这通常是一个很好的起点；模型更容易训练，逻辑回归适合二元问题。</p><p id="cac9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在拟合逻辑模型之前，重要的是要确保我们使用了将传递到sklearn模块中的最佳超参数。我们要优化的参数是<code class="fe nq nr ns ng b">C</code>，它控制模型将使用的正则化程度。</p><p id="a482" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">低<code class="fe nq nr ns ng b">C</code> <em class="ok"> </em>值等于高正则化程度和随后的较低复杂度，高<code class="fe nq nr ns ng b">C</code>值等于低正则化程度和较高复杂度。由于该值本质上代表了逻辑模型与训练数据的拟合程度，因此较高的<code class="fe nq nr ns ng b">C</code>值会导致过度拟合。</p><p id="ac9d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下函数打印出您传递的参数的最佳输入值:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="042f" class="nk la it ng b gy nl nm l nn no">def print_results(results):<br/>    print('BEST PARAMS: {}\n'.format(results.best_params_))</span><span id="8ec0" class="nk la it ng b gy oj nm l nn no">means = results.cv_results_['mean_test_score']<br/>    stds = results.cv_results_['std_test_score']<br/>    for mean, std, params in zip(means, stds, results.cv_results_['params']):<br/>        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))</span></pre><p id="ee8f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，您可以存储想要评估的输入值:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="271c" class="nk la it ng b gy nl nm l nn no">lr = LogisticRegression()<br/>parameters = {<br/>    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]<br/>}</span></pre><p id="b117" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">并在您的训练数据上使用<code class="fe nq nr ns ng b">GridSearchCV()</code>来查看您的输入参数的交叉验证:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d64c" class="nk la it ng b gy nl nm l nn no">log_cv = GridSearchCV(lr, parameters, cv=5)<br/>log_cv.fit(X_train, y_train.values.ravel())<br/>print_results(log_cv)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/85e2481c3931550504e7b25e18e4a656.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*fTpNgRGykaj4_cBpPkyR7g.png"/></div></figure><p id="4a83" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您可以看到<code class="fe nq nr ns ng b">C</code>的推荐最佳输入值是<code class="fe nq nr ns ng b">0.001</code>，这表明我们可以在相当高的规范化水平下实现约62%的准确度；这非直觉地意味着数据拟合不太复杂。</p><p id="a8e6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们应该存储这个最佳估计值，以便在我们对照所用的其他模型验证逻辑模型时使用:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d76b" class="nk la it ng b gy nl nm l nn no">joblib.dump(log_cv.best_estimator_, '/.../.../.../EloScores/LOG_model.pkl')</span></pre><p id="a445" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们可以使用推荐的超参数来拟合我们的逻辑模型:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="35ae" class="nk la it ng b gy nl nm l nn no">logreg = LogisticRegression(C = 0.001)<br/>model = logreg.fit(X_train,y_train)<br/>log_y_pred=logreg.predict(X_test)</span></pre><p id="bc44" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您可以打印模型的精确度:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="f9a3" class="nk la it ng b gy nl nm l nn no">print("Accuracy:",metrics.accuracy_score(y_test, log_y_pred))</span><span id="0792" class="nk la it ng b gy oj nm l nn no">&gt;&gt; Accuracy: 0.6254467476769121</span></pre><p id="488b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">并打印出模型预测的混淆矩阵:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="8d7c" class="nk la it ng b gy nl nm l nn no">%matplotlib inline<br/>rcParams['figure.figsize'] = 10, 7</span><span id="3e1b" class="nk la it ng b gy oj nm l nn no">class_names=[0,1] # name  of classes<br/>fig, ax = plt.subplots()<br/>tick_marks = np.arange(len(class_names))<br/>plt.xticks(tick_marks, class_names)<br/>plt.yticks(tick_marks, class_names)</span><span id="68d0" class="nk la it ng b gy oj nm l nn no"># Create heatmap<br/>sb.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')<br/>ax.xaxis.set_label_position("top")<br/>plt.tight_layout()<br/>plt.title('Confusion matrix', y=1.1)<br/>plt.ylabel('Actual label')<br/>plt.xlabel('Predicted label')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/62a243ecda0ae97a714112b6c8d4d097.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*OUYBvoF0i30gvFKrwLjPlQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数组([[455，250]，<br/>，[274，420]])</p></figure></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="84b4" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">随机森林模型</h1><p id="6c35" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如上所述，我们用一个基本的二元逻辑回归达到了大约62%的准确率，这是一个很好的起点，但是还有很多需要改进的地方。我们要训练的下一个模型是随机森林模型。</p><p id="bd11" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">顾名思义，随机森林由大量单独的决策树组成，这些决策树作为一个整体运行。每个独立的决策树提供一个分类结果，具有最高比例结果的类被选为该单独分类的预测(图2)。</p><p id="eebc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">随机森林模型的工作前提是，大量的模型/决策树——看似不相关——仍将优于任何促成随机森林的独立模型。</p><p id="40c3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与其他组成模型没有相关或线性关系的独立决策树可以得出比任何独立预测更准确和精确的集体预测，这表现为独立决策树保护其他起作用的模型免受其估计中的独立误差的影响。</p><p id="e608" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">出于这个原因，随机森林模型对于分类问题有很好的实用性，并将用于我们的二进制格式的匹配结果数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/c474e7c80b7a7411ea4e93f5c791b9a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*IZPkeNVMY25zdEtf7NrtxQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:带有三个独立决策树、多数投票和最终分类的随机森林模型的示意图</p></figure><p id="e6a2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在拟合我们的随机森林模型之前，我们将调整一些超参数，就像我们对逻辑模型所做的那样。</p><p id="dd31" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">之前使用的<code class="fe nq nr ns ng b">print_results()</code>函数将使用相同的训练数据为我们的随机森林打印最佳超参数。我们要优化的参数是<code class="fe nq nr ns ng b">n_estimators</code>、<em class="ok">、</em>，这是森林中决策树的数量，以及<code class="fe nq nr ns ng b">max_depth</code>，这是树的深度。<code class="fe nq nr ns ng b">max_depth</code>的缺省值是<code class="fe nq nr ns ng b">None</code>，这意味着节点被扩展，直到所有叶子都是纯的，或者直到所有叶子包含少于<code class="fe nq nr ns ng b">min_samples_split</code>个样本:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="ac18" class="nk la it ng b gy nl nm l nn no">rf = RandomForestClassifier()<br/>parameters = {<br/>    'n_estimators': [5, 50, 250,500],<br/>    'max_depth': [2, 4, 8, 16, 32, 64, None]<br/>}</span><span id="6744" class="nk la it ng b gy oj nm l nn no">rf_cv = GridSearchCV(rf, parameters, cv=6)<br/>rf_cv.fit(X_train, y_train.values.ravel())</span><span id="5bd9" class="nk la it ng b gy oj nm l nn no">print_results(rf_cv)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/7f7a66436c36d90c6c1ba98afe26c1df.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*jnstSeS30MUWS_MsXtpDYg.png"/></div></figure><p id="7210" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">同样，我们应该存储这个最佳估计值，以便在我们对照所用的其他模型验证随机森林模型时使用:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d27f" class="nk la it ng b gy nl nm l nn no">joblib.dump(rf_cv.best_estimator_, '/.../.../.../EloScores/RF_model.pkl')</span></pre><p id="8f70" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在可以使用前面提到的参数来拟合我们的随机森林模型(因为推荐的<code class="fe nq nr ns ng b">max_depth</code>是<code class="fe nq nr ns ng b">None</code>，这被设置为默认值):</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="3000" class="nk la it ng b gy nl nm l nn no">rf_model = RandomForestClassifier(n_estimators=500)<br/>rf_model.fit(X_train, y_train)<br/>rf_predicted_values = rf_model.predict(X_test)</span></pre><p id="e867" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在可以打印模型的精确度:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d408" class="nk la it ng b gy nl nm l nn no">print("Accuracy:",metrics.accuracy_score(y_test, log_y_pred))</span><span id="699a" class="nk la it ng b gy oj nm l nn no">&gt;&gt;&gt; 0.7055039313795568</span></pre><p id="c729" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要打印出随机森林模型中的各个决策树，您可以创建一个点文件并转换为PNG，该文件将保存到您的本地驱动器:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="a4c8" class="nk la it ng b gy nl nm l nn no"># Create an individual decision tree</span><span id="8b7a" class="nk la it ng b gy oj nm l nn no">tree = rf_model.estimators_[5]</span><span id="bedb" class="nk la it ng b gy oj nm l nn no"># Export tree to a dot file</span><span id="cc30" class="nk la it ng b gy oj nm l nn no">export_graphviz(tree,<br/>                feature_names=elo.columns,<br/>                filled=True,<br/>                rounded=True)</span><span id="0161" class="nk la it ng b gy oj nm l nn no"># Save to local as png</span><span id="c48a" class="nk la it ng b gy oj nm l nn no">os.system('dot -Tpng tree.dot -o tree.png')</span></pre><p id="9943" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">生成的文件如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/545877d4b119b5d0247750a3df6142bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjrWi5St8znTFa1ExfhKPQ.png"/></div></div></figure></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="e8d1" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">多层感知器</h1><p id="f3b5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如您所见，我们将基线逻辑回归的准确性提高到了约71%。</p><p id="62ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们要拟合的最后一个模型是多层感知器(MLP)，这是一类前馈神经网络，旨在模拟大脑处理和存储信息的神经生理过程。MLP通常用于监督学习问题，它们在一组输入-输出对上进行训练，并学习对它们之间的相关性进行建模。</p><p id="cbc9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">训练通常包括调整模型的参数或权重和偏差，以减少期望结果和计算结果之间的误差。这种方法通常被称为<em class="ok">反向传播，</em>，在输入参数的每次前后传递后，随机分配的权重和偏差被重新校准以减少误差。</p><p id="91fd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">多层感知器由一个输入层、一个输出层和任意数量的隐藏层(将根据您可用的数据进行调整)组成。在你的输出层和所有的隐藏层，执行一个激活函数，将数据传递给下一个隐藏层或个体分类的最终结果(这就是<em class="ok">前馈</em>所涉及的；图3)。</p><p id="2bc8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">MLP适用于分类和回归问题，但在较小的数据集上表现不佳。上面的描述被大量转述，我推荐阅读Nitin Kumar Kain ，他更深入地解释了MLP。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/95e4d611ad668aa29d3aaf18399a0e63.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*c4pJ7HqU7OlO7IHk1cnWbg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:具有二元结果的MLP模型的例子，比如本文中用于Elo预测的模型</p></figure><p id="eb97" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在拟合我们的MLP模型之前，我们将调整一些超参数，就像我们对逻辑和随机森林模型所做的那样。之前使用的<code class="fe nq nr ns ng b">print_results()</code>函数将使用相同的训练数据为我们的MLP打印最佳超参数。</p><p id="b85f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们要优化的参数是<code class="fe nq nr ns ng b">hidden_layer_sizes</code>，它是隐藏层中的节点数，以及<em class="ok">激活</em>，<em class="ok"> </em>，它是隐藏层的激活函数。对于激活功能，我们将确定逻辑激活和relu激活之间哪个功能更好:</p><ul class=""><li id="44db" class="nt nu it lt b lu mn lx mo ma nv me nw mi nx mm ny nz oa ob bi translated"><strong class="lt iu">逻辑</strong>:使用sigmoid函数(如逻辑回归)；返回<em class="ok"> f(x) = 1 / (1 + exp(-x)) </em></li><li id="8fde" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><strong class="lt iu"> Relu </strong>:整流后的线性单位函数，返回<em class="ok"> f(x) = max(0，x) </em>。如果值为正，该函数输出输入值；否则，它传递一个零。</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="f8f5" class="nk la it ng b gy nl nm l nn no">mlp = MLPClassifier()<br/>parameters = {<br/>    'hidden_layer_sizes': [(10,), (50,), (100,),(250)],<br/>    'activation': ['relu', 'logistic'],<br/>}</span><span id="75c1" class="nk la it ng b gy oj nm l nn no">mlp_cv = GridSearchCV(mlp, parameters, cv=5)<br/>mlp_cv.fit(X_train, y_train.values.ravel())<br/>print_results(mlp_cv)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/46d5e809a95118787be1ef4882a89332.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*WQXuEFfQEA2QyEcgQRTYpw.png"/></div></figure><p id="3183" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">同样，我们应该存储这个最佳估计值，以便在我们用其他模型验证MLP模型时使用:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="6c15" class="nk la it ng b gy nl nm l nn no">joblib.dump(rf_cv.best_estimator_, '/.../.../.../EloScores/MLP_model.pkl')</span></pre><p id="d4ad" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在可以使用上述参数来拟合我们的MLP模型:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="5f96" class="nk la it ng b gy nl nm l nn no">mlp_model = MLPClassifier(hidden_layer_sizes=(50,), activation='logistic')<br/>mlp_model.fit(X_train, y_train) <br/>mlp_predicted_values = mlp_model.predict(X_test)</span></pre><p id="b919" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在可以打印模型的精确度:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="6930" class="nk la it ng b gy nl nm l nn no">print("Accuracy:",metrics.accuracy_score(y_test, log_y_pred))</span><span id="0465" class="nk la it ng b gy oj nm l nn no">&gt;&gt;&gt; 0.6275911365260901</span></pre><p id="eff2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与所有这些模型一样，您可以微调任意数量的超参数，以便最适合您的数据。对于MLP，这总是以过度拟合数据为代价。</p><p id="f1bf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与成功调整MLP相关的其他超参数包括历元数、批量大小和反向传播方法，这些都超出了本文的范围，但在训练MLP模型时应该加以考虑。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="ba37" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">模型验证和总结</h1><p id="46a6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如上所述，我们对数据进行了分割，这样我们就有了一个验证集，可用于在评估的最后阶段对模型进行比较。该数据与验证阶段使用的任何模型都完全不同，因此它可以用作我们训练的模型的性能的有力衡量标准。此外，我们还存储了用于此目的的各种超参数的最佳估计量。</p><p id="d3d9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下代码将遍历您存储的最佳估计值:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="9220" class="nk la it ng b gy nl nm l nn no">models = {}</span><span id="b4cb" class="nk la it ng b gy oj nm l nn no">for mdl in ['LOG','MLP', 'RF']:<br/>    models[mdl] = joblib.load('/Users/hopkif05/Desktop/EloScores/{}_model.pkl'.format(mdl))</span><span id="0b4e" class="nk la it ng b gy oj nm l nn no">models</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/9d5aced28ac59394d3bcbc18a05992cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*t3gt11YTmCmlAwtQXCvxRQ.png"/></div></figure><p id="85da" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将使用三种方法来确定模型的性能:</p><ul class=""><li id="74c6" class="nt nu it lt b lu mn lx mo ma nv me nw mi nx mm ny nz oa ob bi translated"><strong class="lt iu">准确度:</strong>总体正确分类数(正确预测数/总样本数)</li><li id="e1fa" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><strong class="lt iu">精度:</strong>:正确预测的1数/预测的1总数</li><li id="e349" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated"><strong class="lt iu">回忆:</strong>:正确预测的1的数量/实际1的总数</li></ul><p id="7dab" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面的代码将创建一个函数来评估和比较所使用的模型。正如所见，<code class="fe nq nr ns ng b">model.predict()</code>函数存在于开始和结束时间函数之间，这意味着我们可以计算每个模型的延迟值，以评估它们计算预测需要多长时间:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d500" class="nk la it ng b gy nl nm l nn no">def evaluate_model(name, model, features, labels):<br/>    start = time()<br/>    pred = model.predict(features)<br/>    end = time()<br/>    accuracy = round(accuracy_score(labels, pred), 3)<br/>    precision = round(precision_score(labels, pred), 3)<br/>    recall = round(recall_score(labels, pred), 3)<br/>    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,<br/>                                                                                   accuracy,<br/>                                                                                   precision,<br/>                                                                                   recall,<br/>                                                                                   round((end - start)*1000, 1)))</span></pre><p id="6c32" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在可以在这个函数中遍历我们的模型:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="ffc8" class="nk la it ng b gy nl nm l nn no">for name, mdl in models.items():<br/>    evaluate_model(name, mdl, X_val, y_val)</span><span id="c1d3" class="nk la it ng b gy oj nm l nn no">&gt;&gt;&gt; LOG -- Accuracy: 0.693 / Precision: 0.686 / Recall: 0.779 / Latency: 44.1ms</span><span id="09b5" class="nk la it ng b gy oj nm l nn no">&gt;&gt;&gt; MLP -- Accuracy: 0.619 / Precision: 0.656 / Recall: 0.593 / Latency: 1.8ms</span><span id="f3da" class="nk la it ng b gy oj nm l nn no">&gt;&gt;&gt; RF -- Accuracy: 0.71 / Precision: 0.73 / Recall: 0.718 / Latency: 113.6ms</span></pre><p id="4382" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从上面可以看出，我们的随机森林模型在看不见的数据上表现最好，具有最好的准确度和精确度分数；然而，做出预测确实需要最长的时间。对于这个相对较小的数据集来说，这是可以的，但是如果数据集的大小增加，就可能出现问题。</p><p id="5b44" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">另一个要考虑的权衡是精确度和召回率，因为两者通常是负相关的。逻辑模型在召回和延迟方面得分更高，但是，考虑到前面提到的小数据集，我们考虑到这一点，以便利用额外的准确性和精确度。与所有的验证一样，这归结于您试图解决的问题和模型的适用性。</p><p id="816a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">可以看出，MLP模型在所有性能指标中表现最差，这可以归结为几个因素。首先，MLP在较小的数据集上表现不佳，可能不适合所用的Elo评分数据。其次，在当前评估中，MLP的超参数优化相当简洁，给出了优化MLP模型可以调整的参数数量。未来的MLP模型可以考虑优化世代数和/或批量大小或反向传播方法。</p><p id="76a9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，应该考虑输入变量的质量。如下面的关联图所示，与我们的比赛结果测量(<code class="fe nq nr ns ng b">Match_Outcome</code>)仅有的远程关联变量与Elo得分(<code class="fe nq nr ns ng b">Home_Elo</code>、<code class="fe nq nr ns ng b">Away_Elo</code>和<code class="fe nq nr ns ng b">Elo_Diff</code>)相关。</p><p id="8ce6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">鉴于使用了额外的指标来丰富Elo相关数据，额外的特征变量(<code class="fe nq nr ns ng b">Home_Advantage</code>和<code class="fe nq nr ns ng b">Home_Team_Innings</code>)可能无法提高所用模型的性能，应考虑其他变量。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="bff1" class="nk la it ng b gy nl nm l nn no">plt.figure(figsize=(12,10))<br/>cor = df.corr()<br/>sb.heatmap(cor, annot=True, cmap=plt.cm.Blues)<br/>plt.show</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/f6551011a251920ab615c204a9426ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*vx263yC4J5cOiGJ2iKIx7A.png"/></div></figure><p id="3786" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，可以确定的是，我们的随机森林模型能够使用Elo相关数据实现相对高水平的准确度(71%)、精确度(73%)和召回率(71%)，这在一定程度上验证了该给定上下文中的Elo排名系统。</p><p id="6183" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">用Elo计算中使用的k值<a class="ae ky" href="https://bnetcmsus-a.akamaihd.net/cms/content_entry_media/9c/9C72SY747QEM1534557019664.pdf" rel="noopener ugc nofollow" target="_blank">进行试验是值得的；这个系数反映了Elo分数对输赢的反应程度，应该根据体育环境进行调整。我使用了一个值<code class="fe nq nr ns ng b">22</code>，它与我在IPL模型中使用的值一致，但这在ODI cricket中可能太保守了，ODI cricket已经运行了更长一段时间，因此可以被认为是一种更可预测的游戏格式。</a></p></div></div>    
</body>
</html>
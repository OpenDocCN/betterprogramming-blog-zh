<html>
<head>
<title>How To Deploy Your TensorFlow Model in a Production Environment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在生产环境中部署TensorFlow模型</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-deploy-your-tensorflow-model-in-a-production-environment-23a9572e94d3?source=collection_archive---------6-----------------------#2021-03-05">https://betterprogramming.pub/how-to-deploy-your-tensorflow-model-in-a-production-environment-23a9572e94d3?source=collection_archive---------6-----------------------#2021-03-05</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="3a71" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">使用TensorFlow服务、Python、Traefik、FastAPI和Docker创建稳定的预测引擎</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/1b0facb9c35b1270c22f4c909553425a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rlo5OTNVG0Yfgamgg9gEpQ.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://www.pexels.com/photo/person-looking-at-phone-and-at-macbook-pro-1181244/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae kz" href="https://www.pexels.com/@divinetechygirl?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Christina Morillo </a>拍摄。</p></figure><p id="0062" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果你一直在关注的<a class="ae kz" href="https://towardsdatascience.com/increase-the-accuracy-of-your-cnn-by-following-these-5-tips-i-learned-from-the-kaggle-community-27227ad39554" rel="noopener" target="_blank">，你就会知道我一直在忙着建立一个深度学习模型。有了这个模型，木薯农民可以检测出作物上的疾病。农民给他们怀疑有问题的木薯拍了张照片。然后，应用程序显示疾病的类型，以便农民可以采取适当的措施。</a></p><p id="151f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了在农民的手机上获得应用程序，我们必须将这个<a class="ae kz" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>模型转换成实际的应用程序。我将把应用程序分成四个不同的服务。这些服务将在Docker容器中运行。选择Docker的原因应该很清楚:Docker容器是任何基于服务器的应用程序的标准部署单元。</p><p id="64cb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我将在本文中解释这四种服务背后的基本原理以及它们是如何交互的。下图显示了最终的架构:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj lw"><img src="../Images/03c97de3397c61abe95c0c1844aee4d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lunifzt-hrX_JSH0pkWNdw.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">解决方案的架构。作者照片。</p></figure><p id="ae3f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">每个服务的源代码和Dockerfile都可以在<a class="ae kz" href="https://github.com/PatrickKalkman/leave-deploy" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。在文章的最后，我将告诉您如何让服务在您的本地工作站上运行。</p><p id="a103" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">但是首先，我们将讨论服务的细节以及如何将它们转换成Docker容器。</p></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="ccba" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">模特服务</h1><p id="03f5" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">谷歌开发了一个特殊的模块，用于在生产环境中服务TensorFlow模型，称为<a class="ae kz" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank"> TensorFlow Serving </a>。因此，我们的模型服务将使用TensorFlow服务。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nb"><img src="../Images/5f5a67fcaf9d1289ee9ada6b864039c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dt9wfyGxd9vujYPAhXO_2g.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>。</p></figure><p id="b3d5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在训练期间，我们以h5格式保存我们的模型。这种格式将模型和权重包含在一个文件中。但是，我们不能使用带TensorFlow服务的h5。我们必须将其转换为SavedModel格式。</p><p id="f536" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">您可以使用以下Python脚本将h5文件转换为SavedModel格式:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">将TensorFlow H5格式文件转换为SavedModel格式</p></figure><p id="6428" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在第4行，我们为SavedModel构造了导出路径。有了路径中的<code class="fe ne nf ng nh b">1</code>,我们将这个模型版本化。</p><p id="8afe" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一旦我们有了SavedModel格式的模型，我们就可以开始使用TensorFlow服务了。</p><p id="8da5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们将使用TensorFlow团队为我们创建的<a class="ae kz" href="https://hub.docker.com/r/tensorflow/serving" rel="noopener ugc nofollow" target="_blank"> TensorFlow服务Docker </a>容器。注意，这个容器有多个版本(一个使用GPU，另一个用于CPU)。我们将使用最新版本的CPU。</p><p id="2ee0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们使用CPU而不是GPU版本，因为GPU版本需要一个特殊的Docker插件。这使得容器依赖于Docker安装，这是不希望的。</p><h2 id="1047" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">用于创建模型服务的docker文件</h2><p id="1f22" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我们没有直接使用TensorFlow服务Docker映像，而是创建了一个包含我们的模型的Docker映像。docker文件为模型服务创建图像。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">用于创建自定义TensorFlow服务图像的docker文件</p></figure><p id="904a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在使用TensorFlow服务图像时，我注意到它不能正确处理默认的信号处理程序。</p><p id="603d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这意味着当你试图用ctrl-c停止正在运行的容器时，它不会停止。发生的情况是Docker会等待十秒钟(默认超时)等待一个应用程序响应。如果你的应用在这段时间内没有响应，它会停止容器。</p><p id="b544" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">你可以做的是将<a class="ae kz" href="https://github.com/krallin/tini" rel="noopener ugc nofollow" target="_blank">天尼</a>添加到你的Docker图片中。我在Dockerfile的第3-6行就是这么做的。Tini然后确保它正确地处理默认的信号处理程序，比如SIGTERM，这样您就不必等待十秒钟。</p><h2 id="94a2" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">用于创建Docker图像的脚本</h2><p id="9835" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我总是使用一个小的助手脚本来构建Docker映像。该脚本创建并标记图像:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">使用BASH构建模型服务Docker映像</p></figure><p id="485d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我还创建了一个在Windows上运行的PowerShell脚本:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">使用PowerShell构建模型服务映像</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="b24b" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">API服务</h1><p id="871f" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我创建了API服务，因为我不希望web或移动应用程序直接与模型服务对话。这有两个原因:</p><ul class=""><li id="de3e" class="nu nv iu lc b ld le lg lh lj nw ln nx lr ny lv nz oa ob oc bi translated">模型服务的输入和输出特定于TensorFlow和模型。我不希望web或移动应用程序了解这些格式。</li><li id="1f34" class="nu nv iu lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated">TensorFlow Serving提供的REST接口并不支持所有TensorFlow数据结构。比如<code class="fe ne nf ng nh b"><a class="ae kz" href="https://github.com/tensorflow/serving/pull/1753" rel="noopener ugc nofollow" target="_blank">DT_HALF</a></code> <a class="ae kz" href="https://github.com/tensorflow/serving/pull/1753" rel="noopener ugc nofollow" target="_blank">不支持</a>。gRPC接口确实支持所有的数据结构，但是我确实想在web或移动应用程序中使用HTTP REST。</li></ul><p id="5f25" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">API服务公开了一个REST接口。这个REST接口有一个方法，它接受图像(jpg或png ),并通过gRPC将其发送给模型服务。然后，模型服务生成预测并将其返回给API服务。API服务将预测转换成JSON并返回给调用者。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oi"><img src="../Images/1d9f63a1d0109ab759d37530a55a8b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*du7p50wS_fIsaC_lR18qsg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank"> FastAPI </a>。</p></figure><p id="325a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我使用Python和<a class="ae kz" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank"> FastAPI </a>实现了预测服务。FastAPI是一个现代的高性能web框架，用于使用Python构建API。</p><p id="1d76" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">下面实现了<code class="fe ne nf ng nh b">predict</code>功能。当您在<code class="fe ne nf ng nh b">/predict/image</code>端点上执行HTTP POST时，它被FastAPI触发。您想要预测的图像应该包含在HTTP消息的正文中。</p><p id="811a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果我们看源代码，我们看到我们首先检查提供的图像是否正确。然后，在第10行，我们将图像转换为预测函数可以接受的格式。在第11行，我们通过gRPC将图像发送给模型服务。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">使用快速API处理POST请求</p></figure><p id="9cad" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe ne nf ng nh b">read_convert_image</code>读取图像并将其转换为一个1x150x150x3的四维数组。它还通过将每个像素值除以255来标准化图像。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div></figure><p id="1032" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe ne nf ng nh b">predict</code>功能使用gRPC连接到模型服务。</p><p id="c722" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">通过TensorFlow服务与TensorFlow模型通信需要gRPC和TensorFlow特定的protobuffs。PyPI上的<code class="fe ne nf ng nh b">tensorflow-serving-apis</code>包提供了这些接口，但是需要<code class="fe ne nf ng nh b">tensorflow</code>。TensorFlow Python包的大小约为700MB。</p><h2 id="549b" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">使用最小tfs客户端</h2><p id="a5b7" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我们使用来自<a class="ae kz" href="https://github.com/zendesk/min-tfs-client" rel="noopener ugc nofollow" target="_blank"> min-tfs-client </a>的<code class="fe ne nf ng nh b">TensorServingClient</code>，而不是使用TensorFlow来连接TensorFlow服务。这个包不包括TensorFlow作为依赖项，这将整个包的大小减少到1MB以下。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">预测功能的实现</p></figure><p id="9444" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">第7行中输入字典的名称和输出键是特定于模型的。我们选择具有最高预测的类别，并将其映射到适当的木薯叶疾病。然后通过REST API以JSON的形式返回。</p><h2 id="2e3b" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">用于创建API服务的docker文件</h2><p id="a2dd" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我们使用python:3.8-slim-buster作为API服务的基础映像。我尝试使用Alpine，但无法安装所有需要的软件包。</p><p id="5b13" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们在第5行创建一个非root用户，并在第17行安装所需的软件包。这产生了一个大约300MB的图像，我认为还是有点大。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">用于创建预测API的docker文件</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="af12" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">UI服务</h1><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oj"><img src="../Images/5b9ae126e806a06b95cbff4bbabe5568.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*YQa7h43uWps6fHUV6u-DVA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片来自<a class="ae kz" href="https://angular.io/" rel="noopener ugc nofollow" target="_blank">角度</a>。</p></figure><p id="ccf4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">UI服务由一个使用Angular创建的网页组成。该网页允许用户上传图像并获得预测的木薯叶疾病，如下图所示:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ok"><img src="../Images/e7bb98b71226543ba820e93e40baafb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fASRKi6ckMwqQo4aiqskdw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">上传图像并获得预测的小网页</p></figure><p id="0f0a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们创建了一个角度组件来定义上传组件。上传组件使用Angular服务，该服务使用<code class="fe ne nf ng nh b">HttpClient</code>来执行对我们的API服务的POST请求。你可以在下面的源代码中看到Angular <code class="fe ne nf ng nh b">upload-service</code>:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">Angular中的上传服务</p></figure><h2 id="baec" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">用于创建UI服务的docker文件</h2><p id="0e21" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我使用官方NGINX Docker图像来服务于Angular应用程序。下面的Docker文件用NGINX和Angular应用程序创建了一个Docker图像。</p><p id="9c7b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">它将本地的<code class="fe ne nf ng nh b">dist</code>文件夹复制到NGINX HTML文件夹中。通过使用<code class="fe ne nf ng nh b">ng build --prod</code>命令编译Angular应用程序来创建<code class="fe ne nf ng nh b">dist</code>文件夹。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">UI服务的Dockerfile</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="e580" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">反向代理Docker容器</h1><p id="2d94" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">最后一个Docker容器是提供反向代理的容器。反向代理由Traefik代理实现。<a class="ae kz" href="https://traefik.io/traefik/" rel="noopener ugc nofollow" target="_blank"> Traefik Proxy </a>是一个开源的反向代理和负载均衡器，可以轻松部署微服务。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/e2e8975d61bb8ba0403b84f817d65653.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*EEov-2FpWNpIujZbZGu6jw.jpeg"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片来自<a class="ae kz" href="https://traefik.io/traefik/" rel="noopener ugc nofollow" target="_blank"> Traefik代理</a>。</p></figure><p id="8a16" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Traefik的配置是动态的。启动Traefik后，它连接到Docker并监听容器事件。当容器启动或停止时，Traefik会自动重新配置自身。我们用的是Traefik 2.4。</p><p id="149a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我们的例子中，Traefik帮助我们服务之间的通信。我们可以不用IP地址和端口进行通信，而是使用域名和URL进行连接和通信。</p><p id="1f03" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">比如Angular应用中的<code class="fe ne nf ng nh b">upload-file.service</code>使用<a class="ae kz" href="http://api.service.localhost" rel="noopener ugc nofollow" target="_blank">http://api . service . localhost</a>而不是<a class="ae kz" href="http://127.0.0.1:8000" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:8000 </a>与API服务进行通信。Traefik将请求路由到API服务的Docker容器的端口8000。</p><p id="b375" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Traefik有很多其他有用的函数，我们不会在这个项目中使用。例如，您可以配置Traefik使用ACME provider(比如Let's Encrypt)来自动生成证书。</p></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="73cd" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">使用Docker Compose启动所有容器</h1><p id="ab5e" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我们将使用Docker Compose来配置和启动所有容器。我将讨论每个服务的配置。</p><p id="4993" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">先说Traefik吧。</p><h2 id="fcf2" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">特拉菲克</h2><p id="d175" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">我们用的是<code class="fe ne nf ng nh b">traefik:v2.4</code>，是写作时的最新版本。通过将<code class="fe ne nf ng nh b">api.insecure</code>设置为<code class="fe ne nf ng nh b">true</code>，我们可以在端口8080上访问Traefik API。第14行中的卷配置将Traefik连接到Docker。通过这种方式，Traefik接收所有Docker请求。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">docker-compose.yml中的Traefik配置</p></figure><h2 id="d298" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">模特服务</h2><p id="b0f9" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">TensorFlow服务在启动时需要模型的名称。这就是我们设置环境变量<code class="fe ne nf ng nh b">MODEL_NAME</code>的原因。模型服务连接到<code class="fe ne nf ng nh b">pred-network</code>。我们只能通过其他容器访问模型服务，因此缺少端口映射。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">模型服务的服务定义</p></figure><h2 id="b50d" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">API服务</h2><p id="f074" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">API服务是第一个为Traefik提供附加信息的服务。您可以使用标签来提供这些信息。首先，在第9行，我们启用Traefik。其次，在下一行，我们设置这个服务的主机名。</p><p id="e479" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这意味着Traefik将创建一个路由器，将<code class="fe ne nf ng nh b">api.service.localhost</code>的传入流量重定向到端口8000上该服务容器的IP地址。使用第7行中的<code class="fe ne nf ng nh b">expose</code>指定端口8000。</p><p id="0b71" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">API服务将通过gRPC与模型服务通信。这是可行的，因为我们将模型服务和API服务连接到同一个网络。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">API服务的服务定义</p></figure><h2 id="5adb" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">UI服务</h2><p id="3b28" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">UI服务使用Traefik的方式与API服务相同。Traefik将创建一个路由器，将<code class="fe ne nf ng nh b">ui.service.localhost</code>的传入流量重定向到端口80上该服务容器的IP地址。我们在第10行对此进行了配置。</p><p id="14d3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">UI服务将把Angular应用程序交付给浏览器。然后，Angular应用程序将使用URL <code class="fe ne nf ng nh b"><a class="ae kz" href="http://api.service.localhost" rel="noopener ugc nofollow" target="_blank">http://api.service.localhost</a></code>连接到API服务。Traefik会将请求路由到API服务容器的端口8000。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nc nd l"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">Docker-Compose.yml中的UI服务定义</p></figure><h2 id="4f85" class="ni mf iu bd mg nj nk dn mk nl nm dp mo lj nn no mq ln np nq ms lr nr ns mu nt bi translated">Traefik UI</h2><p id="0505" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">当所有的服务都在运行时，您可以使用Traefik仪表板来验证所有的配置是否正确。您可以了解所有路由器的概况，并深入了解每台路由器。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj om"><img src="../Images/17c5e0a49a4482a29ea968c4a2622e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e6k6sl0dwTaczKBVvXv6GA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">UI服务路由器的详细信息。作者照片。</p></figure></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="73ef" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">在本地运行</h1><p id="b77b" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">在运行Docker Compose之前，您必须为每个服务构建单独的Docker映像。我已经向每个服务文件夹添加了一个shell和PowerShell脚本，可以构建该服务的映像。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj on"><img src="../Images/fec1747585a6088a2743a536d514c42c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kd4vLmBqH_IL0JZiY_19lw.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">应用程序的文件夹结构。作者照片。</p></figure><p id="c5a1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在每个服务文件夹中，执行<code class="fe ne nf ng nh b">./docker-build.sh</code>或<code class="fe ne nf ng nh b">./docker-build.ps1</code>脚本来构建该服务的Docker映像。</p><p id="9b1e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一个例外是<code class="fe ne nf ng nh b">ui.service</code>。在为这个服务构建Docker映像之前，必须先构建应用程序。在构建应用程序之前，您必须安装所需的包。首先，通过执行<code class="fe ne nf ng nh b">npm install -g @angular/cli</code>安装Angular。</p><p id="813b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">然后通过调用<code class="fe ne nf ng nh b">npm install</code>安装项目的所有依赖项。<code class="fe ne nf ng nh b"> </code>最后，执行<code class="fe ne nf ng nh b">ng build — prod</code>来构建应用程序。然后您可以调用<code class="fe ne nf ng nh b">./docker-build.sh</code>来构建<code class="fe ne nf ng nh b">ui.service</code>的Docker映像。</p><p id="463f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一旦构建了所有三个Docker映像，就可以使用以下命令在前台启动应用程序:</p><pre class="kk kl km kn gu oo nh op oq aw or bi"><span id="e8cb" class="ni mf iu nh b gz os ot l ou ov">docker-compose up</span></pre><p id="b523" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果您想在后台运行它，您可以添加<code class="fe ne nf ng nh b">-d</code>标志:</p><pre class="kk kl km kn gu oo nh op oq aw or bi"><span id="a5e6" class="ni mf iu nh b gz os ot l ou ov">docker-compose up -d</span></pre><p id="39b5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这将启动所有容器，包括反向代理。如果你随后使用浏览器，进入<a class="ae kz" href="http://ui.service.localhost/" rel="noopener ugc nofollow" target="_blank">http://ui.service.localhost/</a>，你会看到用户界面，让你上传图像并获得预测。</p></div><div class="ab cl lx ly hy lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="in io ip iq ir"><h1 id="b53e" class="me mf iu bd mg mh mi mj mk ml mm mn mo ka mp kb mq kd mr ke ms kg mt kh mu mv bi translated">结论</h1><p id="2d5b" class="pw-post-body-paragraph la lb iu lc b ld mw jv lf lg mx jy li lj my ll lm ln mz lp lq lr na lt lu lv in bi translated">本文总结了一个由三部分组成的系列。它始于<a class="ae kz" href="https://towardsdatascience.com/helping-african-farmers-increase-their-yields-using-deep-learning-93a8d70dff36" rel="noopener" target="_blank">进入一场追逐赛</a>。比赛的目标是创建一个可以对木薯叶上的疾病进行分类的模型。在第一篇文章中，我们创建了一个准确率为88.9%的模型。</p><p id="eefc" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在第二篇文章中，目标是<a class="ae kz" href="https://towardsdatascience.com/increase-the-accuracy-of-your-cnn-by-following-these-5-tips-i-learned-from-the-kaggle-community-27227ad39554" rel="noopener" target="_blank">提高模型的准确性</a>。我们使用了来自Kaggle社区的五种不同的优化技术。通过结合使用这些技术，我们将准确率提高到了89.35%</p><p id="54e2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在最后一篇文章中，我们看到了如何在生产环境中使用该模型。我们使用TensorFlow服务于我们的模型，并通过gRPC访问它。我们创建了一个REST API来使用REST进行预测。为了便于创建预测，我们添加了一个使用这个REST API的Angular UI。</p><p id="8d82" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">所有的服务都在Docker容器中运行。我们选择Docker是因为它是任何基于服务器的应用程序的标准部署单元。我们使用Docker Compose部署了该应用程序。通过一些修改，Docker Compose的YAML配置可以用于真实的生产环境，如Docker Swarm或Kubernetes。</p><p id="00d3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">谢谢你的阅读，记住永远不要停止学习！</p></div></div>    
</body>
</html>
<html>
<head>
<title>The Art of Web Scraping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网络抓取的艺术</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/the-art-of-web-scraping-382e2ea43c18?source=collection_archive---------6-----------------------#2021-02-26">https://betterprogramming.pub/the-art-of-web-scraping-382e2ea43c18?source=collection_archive---------6-----------------------#2021-02-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1f34" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">掌握尽可能高效地从网站中提取数据的做法。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fb1f3ee2e4be50ae13bb52de3fe83e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uMC51jH8EyQvWJo6"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@zal3wa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">达米安·扎莱斯基</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="0459" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这几乎是自动化的复制/粘贴，事实证明它有一些非常有用的应用。网络上充满了有价值的信息和资源，但是人们需要花费时间和精力来发现和处理这些信息，这就是为什么网络抓取很流行的原因。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/451a462d89ea9b3738b380690aa8ca5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8OoBeKhvQqc7MbVnAa3Vw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">网络抓取在2020年6月最受欢迎，现在还没有结束</p></figure><p id="cc11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看一个例子。</p><p id="f2e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设你是一名消费者，想从易贝购买一款新的显卡。你<em class="lt">可以</em>查看每天搜索到的类似商品的价格，并在Excel中写下平均价格，这样你就知道最佳购买时间——但这需要耗费大量人力。而且费时。以及<em class="lt">镗孔</em>。</p><p id="79ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你<em class="lt">应该</em>做的是写一个程序替你做这件事。但是你会怎么做呢？</p><p id="7451" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，如果你还没有学过编程语言，你就必须学一门。出于本文的目的，我们称之为Python。你还必须知道网站是如何工作的，这意味着一些基本的HTML和CSS。</p><p id="2907" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，你需要决定如何使用这种语言从这个网站上提取信息。你需要检查网站，了解你会刮什么。您是否必须与页面交互来提取数据，或者您是否可以简单地下载页面数据并处理文本？</p><p id="ce0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们正在搜索GTX 1660显卡，现在让我们来看看易贝:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/1037439ca3923b95cdb859d16a71b8dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6drHnrk3GY_ojB7DhQOr5g.png"/></div></div></figure><p id="2a8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">马上你看到搜索把我们带到了网址:“https://www . ebay . co . uk/sch/I . html？_ nkw = gtx+1660”，结果好像瞬间加载。现在是检查页面源代码的好时机。右键单击产品，然后按“检查”结果如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/8863afc1cd6a5d656c6cfd19da7f837a.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*eKs5-yg_2P8Wfg4MVP3Utw.png"/></div></figure><p id="91b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在检查产品清单时，我们看到每个清单都是一个<a class="ae kv" href="https://www.w3schools.com/html/html_lists_unordered.asp" rel="noopener ugc nofollow" target="_blank">无序清单</a>中的一个项目。列表有一些独特的类，可以用来将这个HTML元素从页面的其余部分中分离出来:<code class="fe lw lx ly lz b">srp-results</code>和<code class="fe lw lx ly lz b">srp-list</code>，每个列表项都有一个类<code class="fe lw lx ly lz b">s-item</code>。</p><p id="8f47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个产品列表都有一个类别为<code class="fe lw lx ly lz b">s-item__price</code>的范围。这是HTML:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/d8166d0f0048a1f3472ca53c6728a52d.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*hWQHHAGl6aeTiHnakrH4qw.png"/></div></figure><p id="1f31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于这项任务的性质，我们可以使用<a class="ae kv" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank"> Beautiful Soup </a> <em class="lt">，</em>一个处理标记文档的Python库，以便于导航和提取数据。如果您必须与页面进行交互(例如，单击按钮、提供输入)，最好使用Selenium或Mechanize之类的库，它可以自动化整个浏览器，但是最好尽可能避免这样做，因为在许多情况下这不是最有效的方法。</p><p id="5926" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要安装漂亮的汤:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="b6f1" class="mf mg iq lz b gy mh mi l mj mk">pip3 install bs4</span></pre><p id="6b33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当使用内置的“requests”库获取URL的来源时，我得到了响应代码200。您可以在这里阅读不同的响应代码<a class="ae kv" href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes" rel="noopener ugc nofollow" target="_blank"/>，但是200意味着请求是正确的，我们可以继续。但是，有时候，你必须使用一个用户代理<a class="ae kv" href="https://en.wikipedia.org/wiki/User_agent" rel="noopener ugc nofollow" target="_blank">来让网站认为请求来自浏览器而不是抓取器。代码如下:</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/df3ff0a66c13f9563df1428e1a04a1c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pe48fHnr21Cm-jx16WM2Pw.png"/></div></div></figure><blockquote class="mm mn mo"><p id="62fc" class="kw kx lt ky b kz la jr lb lc ld ju le mp lg lh li mq lk ll lm mr lo lp lq lr ij bi translated">“用户代理字符串是使用<a class="ae kv" href="https://en.wikipedia.org/wiki/Robots_Exclusion_Standard" rel="noopener ugc nofollow" target="_blank"> Robots排除标准</a> ( <em class="iq"> robots.txt </em>文件)排除网络爬虫访问网站特定部分的标准之一。”—维基百科</p></blockquote><p id="9f99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总之，有时用户代理必须包含某个字符串才能接受请求，或者不能包含某个字符串，或者必须简单地包含某些内容而不是什么都没有。</p><p id="b7e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">HTTP请求返回页面的来源——这与您浏览网页时浏览器获取它呈现和显示的HTML的方式相同</p><p id="8d63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用Beautiful Soup来解析HTML，并通过使用我们之前确定的类来处理产品列表。代码如下:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="a8a1" class="mf mg iq lz b gy mh mi l mj mk">from bs4 import BeautifulSoup<br/>import requests </span><span id="4565" class="mf mg iq lz b gy ms mi l mj mk"># get source<br/>r = requests.get("<a class="ae kv" href="https://www.ebay.co.uk/sch/i.html?_nkw=gtx+1660" rel="noopener ugc nofollow" target="_blank">https://www.ebay.co.uk/sch/i.html?_nkw=gtx+1660</a>")</span><span id="1b35" class="mf mg iq lz b gy ms mi l mj mk"># parse source<br/>soup = BeautifulSoup(r.text, 'html.parser')</span><span id="3d7f" class="mf mg iq lz b gy ms mi l mj mk"># find all list items from search results<br/>results = soup.find("ul",{"class":"srp-results"}).find_all("li",{"class":"s-item"})</span></pre><p id="2c51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以对结果进行迭代，找到类为<code class="fe lw lx ly lz b">s-item__price</code>的span中的文本。下面是实现这一点的代码:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="384c" class="mf mg iq lz b gy mh mi l mj mk">for result in results:<br/>    priceSpan = result.find("span",{"class":"s-item__price"})<br/>    print(priceSpan.text)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/ac9a294a6ba8de6077ab62d2290fa404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f2U24nfTbAX2WaVz3INwAw.png"/></div></div></figure><p id="5c72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您将获得以下输出。要将其转换为整数，我们应该首先删除第一个字符，该字符始终为“，”然后您就可以对其余的字符使用Python <code class="fe lw lx ly lz b">float</code>方法——如果没有一些异常的话。</p><p id="0c9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有时，有多种价格:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/404e50388708c31ef9156ec353b87ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*mst5LH_QmGY9_lNn8E5RWQ.png"/></div></figure><p id="71d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其他时候，用逗号分隔千位:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/3274d35d7025ca4672fcded3f08e8a7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*Vbg8VtPi15J2CTw1sawV5w.png"/></div></figure><p id="aa59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，您可以忽略包含字符串“To”的列表，使用Python <code class="fe lw lx ly lz b">replace</code>方法删除任何逗号，然后转换为float。代码如下:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="ddb0" class="mf mg iq lz b gy mh mi l mj mk">for result in results:<br/>    priceText = result.find("span",{"class":"s-item__price"}).text<br/>    if "to" in priceText:<br/>        continue<br/>    price = float(priceText[1:].replace(",",""))</span></pre><p id="7cf4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个易贝产品列表还包含一个类别为<code class="fe lw lx ly lz b">s-item__shipping</code>的span。我们可以使用它来查找运费和项目的总成本，如下所示:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="08d9" class="mf mg iq lz b gy mh mi l mj mk">for result in results:<br/>    shippingSpan = result.find("span",{"class":"s-item__shipping"})<br/>    print(shippingSpan.text)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/925337d4ef5e03435855c9e09fdeaa9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AHNKoNp20FB8qooLhUOSdg.png"/></div></div></figure><p id="0653" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果运输是免费的，运输文本采用<code class="fe lw lx ly lz b">+ £(PRICE) postage</code>或<code class="fe lw lx ly lz b">Free postage</code>的形式。您可以使用Python的<code class="fe lw lx ly lz b">split()</code>函数处理第一个例子，选择第二个项目，做与上面相同的事情:将没有第一个字符的字符串解析为<code class="fe lw lx ly lz b">float</code>。对于第二个实例，您可以检查价格是否包含“免费”，如果包含，则将价格值设置为<code class="fe lw lx ly lz b">0</code>。</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="08d1" class="mf mg iq lz b gy mh mi l mj mk">prices = []</span><span id="59b0" class="mf mg iq lz b gy ms mi l mj mk">for result in results:<br/>    priceText = result.find("span",{"class":"s-item__price"}).text<br/>    if "to" in priceText:<br/>        continue<br/>    price = float(priceText[1:].replace(",",""))<br/>    <br/>    shippingText = result.find("span",{"class":"s-item__shipping"}).text<br/>    if "Free" in shippingText:<br/>        shipping = 0<br/>    else: # is not free<br/>        shipping = float(shippingText.split()[1][1:])</span><span id="171f" class="mf mg iq lz b gy ms mi l mj mk">prices.append(price+shipping)</span></pre><p id="4205" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面，我已经实现了这个描述的方法，并把商品和邮费加到一个列表中，这样以后就可以处理它了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/da17f3e1c860838ff94303d682ca2be4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HuQg2zx3UMzV9NugFxNPHA.png"/></div></div></figure><p id="d939" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一些异常的清单——可能是为了欺骗自动采购机器人在供应链短缺时购买价格过高的商品。</p><p id="78fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在计算平均值之前，您应该从数据中排除这些异常值。这可以通过标准差和正态分布来实现。如果这对你来说是新的，我推荐阅读<a class="ae kv" href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>，以及<a class="ae kv" href="https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html" rel="noopener ugc nofollow" target="_blank">这篇关于排除Python </a>中异常的文章。</p><blockquote class="mm mn mo"><p id="fa91" class="kw kx lt ky b kz la jr lb lc ld ju le mp lg lh li mq lk ll lm mr lo lp lq lr ij bi translated">“我们的方法是在绘制频率之前，通过消除任何高于(平均值+ 2*SD)和低于(平均值-2 * SD)的点来消除异常点。”—首席数据科学家Punit Jajodia</p></blockquote><p id="0591" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Numpy，可以实现上述内容。首先，确保您安装了Numpy。命令如下:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="e4fc" class="mf mg iq lz b gy mh mi l mj mk">pip3 install numpy</span></pre><p id="c41a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将此方法添加到代码中:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="c263" class="mf mg iq lz b gy mh mi l mj mk">import numpy as np</span><span id="c311" class="mf mg iq lz b gy ms mi l mj mk">def reject_outliers(data, m=2):<br/>    return data[abs(data - np.mean(data)) &lt; m * np.std(data)]</span></pre><p id="4462" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将从Numpy数组中移除离群值。现在，您可以将它与您的价格表一起使用，并取平均值，如下所示:</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="ae7e" class="mf mg iq lz b gy mh mi l mj mk">prices = reject_outliers(np.array(prices))<br/>avgPrice = np.mean(prices)</span></pre><p id="c578" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了能够在Excel中分析这些数据，平均值应被写入一个<a class="ae kv" href="https://www.howtogeek.com/348960/what-is-a-csv-file-and-how-do-i-open-it/" rel="noopener ugc nofollow" target="_blank"> CSV文件</a>。我使用日期作为第一列，价格作为第二列。</p><pre class="kg kh ki kj gt mb lz mc md aw me bi"><span id="5e04" class="mf mg iq lz b gy mh mi l mj mk">import csv</span><span id="1538" class="mf mg iq lz b gy ms mi l mj mk">fields=[date.today().strftime("%b-%d-%Y"),np.around(avgPrice,2)]<br/>with open('prices.csv', 'a', newline='') as f:<br/>    writer = csv.writer(f)<br/>    writer.writerow(fields)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/8dec89db43f64b4cab108bc237d06532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8uhW87tBww0TlmIcmTu9_g.png"/></div></div></figure><p id="fc07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在运行我的脚本几天后，我使用Excel绘制了数据的图表，给出了上面的结果。代码如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="16af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网络抓取是一个强大的工具，学习和练习它非常有趣。我推荐在Raspberry Pi或类似的设备上运行这样的程序，因为它可以24/7全天候运行，几乎不耗电。此外，您可以将脚本编程为每天运行，而不是自己每天运行程序。</p><p id="1481" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我强烈建议您更多地了解这个主题，这是一个非常吸引人的数据科学介绍。我希望这篇文章是有帮助的。</p></div></div>    
</body>
</html>
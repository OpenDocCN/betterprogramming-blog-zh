<html>
<head>
<title>How to Control Your React App With Your Voice</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用声音控制你的React应用</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-control-your-react-app-with-your-voice-510d58bea5d1?source=collection_archive---------7-----------------------#2020-11-25">https://betterprogramming.pub/how-to-control-your-react-app-with-your-voice-510d58bea5d1?source=collection_archive---------7-----------------------#2020-11-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="eafe" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Chrome语音识别API构建声控界面</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/601d0a2a88709d63a2144eadb06ce7ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P0Bi7SSfcKf-mxIlQj_SoQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@gift_habeshaw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Gift Habeshaw </a>在<a class="ae ky" href="https://unsplash.com/s/photos/microphone?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ec9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几个月前，我用TensorflowJS 写了一篇关于<a class="ae ky" href="https://towardsdatascience.com/speech-recognition-with-tensorflow-js-66608355376e" rel="noopener" target="_blank">网络语音识别的文章。尽管实现起来非常有趣，但对你们中的许多人来说，扩展起来非常麻烦。原因很简单:如果你想检测比我提供的模型更多的单词，这需要训练一个深度学习模型，这是非常基本的。</a></p><p id="d1d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于那些需要更实际的方法的人来说，那篇文章是不够的。根据您的要求，我今天写了一篇关于如何使用web Speech API为您的Web应用程序带来完整的语音识别的文章。</p><p id="8a0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是在我们讨论实际的实现之前，让我们先了解一下这个功能可能有用的一些场景:</p><ul class=""><li id="810e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">为无法使用键盘或触摸设备的情况构建应用程序。例如，在野外工作或戴着特殊手套的人可能会发现很难与输入设备进行交互。</li><li id="3206" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">来支持残疾人。</li><li id="a1df" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">因为太牛逼了！</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="67ca" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">用语音识别支持Web应用的秘密是什么？</h1><p id="cbc6" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">鼓…秘诀就是Chrome(或Chromium) <a class="ae ky" href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition" rel="noopener ugc nofollow" target="_blank"> Web Speech API </a>。这个与基于Chromium的浏览器一起工作的API非常棒，它为我们做了所有繁重的工作，让我们只关心使用语音构建更好的界面。</p><p id="552e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不管这个API有多不可思议，截止到2020年11月，它还没有得到广泛的支持，根据您的需求，这可能是一个问题。以下是当前的支持状态，承蒙<a class="ae ky" href="https://caniuse.com/speech-recognition" rel="noopener ugc nofollow" target="_blank">允许，我可以使用</a>吗？此外，它只在联机时工作，所以如果您脱机，您将需要一个不同的设置。</p><p id="4d2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自然，这个API可以通过JavaScript获得，并且它不是唯一的或者只限于React。尽管如此，有一个很棒的<a class="ae ky" href="https://github.com/JamesBrill/react-speech-recognition#readme" rel="noopener ugc nofollow" target="_blank"> React库</a>可以进一步简化API，这就是我们今天要使用的。</p><p id="1729" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想在普通JS或任何其他框架上实现，请随意阅读MDN文档上的语音识别API文档。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="a8a1" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">你好，世界，我正在抄写</h1><p id="39c3" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我们将从基础开始。我们将建立一个Hello World应用程序，它将实时转录用户所说的话。在做所有好的事情之前，我们需要一个良好的工作基础，所以让我们从建立我们的项目开始。为了简单起见，我们将使用create-react-app来设置我们的项目。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="46cb" class="ns mr it no b gy nt nu l nv nw">npx create-react-app voice-command</span></pre><p id="8af3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，安装<a class="ae ky" href="https://openbase.io/js/react-speech-recognition/documentation" rel="noopener ugc nofollow" target="_blank"> react-speech-recognition </a>库，包括:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="39d5" class="ns mr it no b gy nt nu l nv nw">npm i react-speech-recognition</span></pre><p id="0b98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将处理文件<code class="fe nx ny nz no b">App.js</code>。CRA为我们创造了一个很好的起点。开个玩笑，我们不需要它，所以从一个空白的<code class="fe nx ny nz no b">App.js</code>文件开始，和我一起编码。</p><p id="8fc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们做任何事情之前，我们需要<code class="fe nx ny nz no b">imports</code>:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="433f" class="ns mr it no b gy nt nu l nv nw">import { useEffect } from 'react';<br/>import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';</span></pre><p id="462a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将创建一个简单的功能组件，带有几个按钮来与语音引擎交互。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="c238" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很简单，对吧？让我们详细看看我们在做什么，从<code class="fe nx ny nz no b"><a class="ae ky" href="https://github.com/JamesBrill/react-speech-recognition/blob/master/docs/API.md#useSpeechRecognition" rel="noopener ugc nofollow" target="_blank">useSpeechRecognition</a></code>钩开始。</p><p id="26a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个钩子负责捕获语音识别过程的结果。这是我们获得预期结果的途径。最简单的形式是，我们可以提取麦克风启用时用户说话的<code class="fe nx ny nz no b">transcript</code>，如下所示:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="1579" class="ns mr it no b gy nt nu l nv nw">const { transcript } = useSpeechRecognition();</span></pre><p id="5714" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">即使我们激活了钩子，我们也不会立即开始听；为此，我们需要与开始时导入的对象<code class="fe nx ny nz no b"><a class="ae ky" href="https://github.com/JamesBrill/react-speech-recognition/blob/master/docs/API.md#SpeechRecognition" rel="noopener ugc nofollow" target="_blank">SpeechRecognition</a></code>进行交互。这个对象公开了一系列帮助我们控制语音识别API的方法，开始在麦克风上听，停止，改变语言的方法，等等。</p><p id="c4bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的界面只暴露了两个控制麦克风状态的按钮；如果您复制了所提供的代码，那么您的界面应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/89dfea0a1fd793629d9dcec2125efc1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FVG9FC-87Sna_ai1Bxi0dw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://livecodestream.dev/post/2020-11-22-how-to-control-your-react-app-with-your-voice/" rel="noopener ugc nofollow" target="_blank">现场代码流</a>尝试现场演示</p></figure><p id="977a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您尝试了演示应用程序，您可能会注意到，如果您在听完之后停顿了一下，您可能会遗漏一些单词。这是因为库默认设置了这个行为，但是您可以通过在<code class="fe nx ny nz no b">startListening</code>方法上设置参数<code class="fe nx ny nz no b">continuous</code>来改变它，就像这样:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="c6af" class="ns mr it no b gy nt nu l nv nw">SpeechRecognition.startListening({ continuous: true });</span></pre></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="3d92" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">兼容性检测</h1><p id="7649" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我们的app很好看！但是如果你的浏览器不被支持会怎么样呢？对于那些场景，我们能有一个回退行为吗？是的，我们可以。如果您需要根据是否支持语音识别API来改变应用程序的行为，react-speech-recognition有一种方法可以实现这一目的。这里有一个例子:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="e1f0" class="ns mr it no b gy nt nu l nv nw">useEffect(() =&gt; {<br/>    if (!SpeechRecognition.browserSupportsSpeechRecognition()) {<br/>      alert("Ups, your browser is not supported!");<br/>    }  <br/>  }, []);</span></pre></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="b1f1" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">检测命令</h1><p id="d445" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">到目前为止，我们介绍了如何将语音转换为文本，但现在我们将通过识别应用程序中预定义的命令来更进一步。构建这一功能将使我们有可能构建完全通过语音运行的应用程序。</p><p id="700a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们需要构建一个命令解析器，这可能需要大量的工作，但是谢天谢地，语音识别API已经有了一个内置的命令识别功能。</p><p id="639a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如<a class="ae ky" href="https://openbase.io/js/react-speech-recognition/documentation" rel="noopener ugc nofollow" target="_blank">反应语音识别文档</a>所述:</p><blockquote class="od oe of"><p id="0e7b" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">为了在用户说出一个特定短语时做出响应，你可以向<code class="fe nx ny nz no b">useSpeechRecognition</code>钩子传递一个命令列表。每个命令都是一个具有以下属性的对象:</p><p id="aef7" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated"><code class="fe nx ny nz no b">command</code>:这是一个字符串或<code class="fe nx ny nz no b">RegExp</code>，代表你想听的短语。</p><p id="07c2" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated"><code class="fe nx ny nz no b">callback</code>:说出命令时执行的功能。该函数接收的最后一个参数将始终是包含以下属性的对象:</p><p id="11b0" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated"><code class="fe nx ny nz no b">resetTranscript</code>:将抄本设置为空字符串的函数</p><p id="6cfb" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated"><code class="fe nx ny nz no b">matchInterim</code>:决定“临时”结果是否应与命令匹配的布尔值。这将使您的组件更快地响应命令，但也使误报更有可能-即，命令可能会在它没有说出时被检测到。这是默认的<code class="fe nx ny nz no b">false</code>,应该只为简单的命令设置。</p><p id="a6ee" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated"><code class="fe nx ny nz no b">isFuzzyMatch</code> : Boolean，确定speech和<code class="fe nx ny nz no b">command</code>之间的比较是否基于相似性而不是精确匹配。模糊匹配对于容易发音错误或被语音识别引擎误解的命令(例如，地名、运动队、餐馆菜单项)很有用。它适用于不带特殊字符的字符串命令。如果<code class="fe nx ny nz no b">command</code>是带特殊字符的字符串或者是<code class="fe nx ny nz no b">RegExp</code>，模糊匹配时会转换成不带特殊字符的字符串。匹配命令所需的相似性可通过<code class="fe nx ny nz no b">fuzzyMatchingThreshold</code>进行配置。<code class="fe nx ny nz no b">isFuzzyMatch</code>默认为<code class="fe nx ny nz no b">false</code>。</p><p id="9588" class="kz la og lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated"><code class="fe nx ny nz no b">fuzzyMatchingThreshold</code>:当<code class="fe nx ny nz no b">isFuzzyMatch</code>开启时，如果语音与<code class="fe nx ny nz no b">command</code>的相似度高于此值，将调用回调。只有当<code class="fe nx ny nz no b">isFuzzyMatch</code>是<code class="fe nx ny nz no b">true</code>时，你才应该设置这个。它取值在<code class="fe nx ny nz no b">0 </code>(将匹配任何内容)和<code class="fe nx ny nz no b">1</code>(需要精确匹配)之间。默认值为<code class="fe nx ny nz no b">0.8</code>。"</p></blockquote><p id="ae97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是如何为您的应用程序预定义命令的示例:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="45ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您也可以使用如下所示的动态命令:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="2f65" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论</h1><p id="38e9" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">多亏了Chrome的语音识别API，构建语音激活的应用程序再简单不过了，也更有趣了。希望在不久的将来，我们会看到这个API被更多的浏览器支持，并具有离线功能。那么它将成为一个非常强大的API，可能会改变我们构建web的方式。</p><p id="6b3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p></div></div>    
</body>
</html>
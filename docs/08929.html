<html>
<head>
<title>How To Easily Scrape Multiple Pages of a Website Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python轻松抓取网站的多个页面</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-easily-scrape-multiple-pages-of-a-website-using-python-73e85bd06f8c?source=collection_archive---------0-----------------------#2021-06-28">https://betterprogramming.pub/how-to-easily-scrape-multiple-pages-of-a-website-using-python-73e85bd06f8c?source=collection_archive---------0-----------------------#2021-06-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f701" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python从网站提取数据的简单指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9d91a7720753ce1b9c6b2066fdda76d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mdhUXDq81GLCB6eE47Bsyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供。</p></figure><p id="c5d6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据无处不在。您访问的每个网站都包含一些以可读格式显示的数据，您可以在项目中使用这些数据。虽然您可以轻松地复制和粘贴这些数据，但对于大量数据，web抓取是最佳解决方案。</p><p id="4d24" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">学习网络抓取在开始时可能很有挑战性，但是如果你从正确的网络抓取库开始，事情会变得容易得多。这就是为什么在这个分步指南中，我将向您展示如何使用Python最简单的web抓取库<a class="ae lu" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> Beautiful Soup </a>来抓取一个网站的多个页面。</p><p id="1dc9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本指南将分为两个部分。在第一部分中，我将向您展示如何抓取单个页面，而第二部分将基于第一部分中使用的代码重点抓取多个页面。</p><p id="cc54" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面，您将找到本指南涵盖的主题:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="99dc" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu">Table of Contents<br/></strong>1. <a class="ae lu" href="#3441" rel="noopener ugc nofollow">What Do You Need To Scrape the Web?</a><br/>2. <a class="ae lu" href="#571e" rel="noopener ugc nofollow">Setting Up Beautiful Soup</a><br/>3. <a class="ae lu" href="#ef80" rel="noopener ugc nofollow">Section 1: Scraping a Single Page</a><br/> - <a class="ae lu" href="#9e17" rel="noopener ugc nofollow">Importing Libraries</a><br/> - <a class="ae lu" href="#8b1b" rel="noopener ugc nofollow">Get the HTML of the website</a><br/> - <a class="ae lu" href="#d3ec" rel="noopener ugc nofollow">Analyzing the website and HTML code</a><br/> - <a class="ae lu" href="#f337" rel="noopener ugc nofollow">Locating an element with Beautiful Soup</a><br/> - <a class="ae lu" href="#6fb2" rel="noopener ugc nofollow">Exporting data in a txt file</a><br/>4. <a class="ae lu" href="#7dcc" rel="noopener ugc nofollow">Section 2: Scraping Multiple Transcripts and Pages</a><br/> - <a class="ae lu" href="#3b90" rel="noopener ugc nofollow">Getting the href attribute</a><br/> - <a class="ae lu" href="#bb9d" rel="noopener ugc nofollow">Locating multiple elements with Beautiful Soup</a><br/> - <a class="ae lu" href="#7c40" rel="noopener ugc nofollow">Looping through each link</a></span></pre></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="3441" class="mn mb it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">刮网需要什么？</h1><ol class=""><li id="3a32" class="ne nf it la b lb ng le nh lh ni ll nj lp nk lt nl nm nn no bi translated">美汤:是一个Python包，用于抓取不运行JavaScript的网站。美丽的汤帮助我们解析HTML和XML文档。它为解析过的页面创建一个解析树，可以用来从HTML中提取数据。不需要之前的美汤知识。你将从零开始学习这里的一切！</li><li id="9a4c" class="ne nf it la b lb np le nq lh nr ll ns lp nt lt nl nm nn no bi translated"><a class="ae lu" href="https://pypi.org/project/requests/" rel="noopener ugc nofollow" target="_blank">请求</a>库:请求库是用Python发出HTTP请求的标准。我们将使用它和美丽的汤一起得到一个网站的HTML。</li><li id="5f89" class="ne nf it la b lb np le nq lh nr ll ns lp nt lt nl nm nn no bi translated">Python:要学习本教程，你不需要成为Python专家。然而，你至少需要知道<code class="fe nu nv nw lw b">for</code>循环和列表在Python中是如何工作的。</li></ol><p id="b359" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们开始之前，请确保您的计算机上安装了Python 3.x。如果有，那就从教程开始用Python设置美汤吧！</p><p id="fe6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nx">注:我之前提到过，美汤会帮我们刮不运行JavaScript的网站，所以如果你打算刮JavaScript驱动的页面，可以查看我做的这个另外的</em> <a class="ae lu" href="https://medium.com/swlh/web-scraping-basics-scraping-a-betting-site-in-10-minutes-8e0529509848" rel="noopener"> <em class="nx">指南</em> </a> <em class="nx">。</em></p><p id="9e92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们会看到很多在美汤里经常用到的函数和方法。要记住所有这些，查看我创建的<strong class="la iu">网页抓取备忘单</strong>。</p><div class="ny nz gp gr oa ob"><a href="https://medium.com/geekculture/web-scraping-cheat-sheet-2021-python-for-web-scraping-cad1540ce21c" rel="noopener follow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">网络抓取备忘单(2021)，用于网络抓取的Python</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">网页抓取完全指南:美丽的汤，硒，刺痒，XPath，等等！</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">medium.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="571e" class="mn mb it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">设置漂亮的汤</h1><ul class=""><li id="124f" class="ne nf it la b lb ng le nh lh ni ll nj lp nk lt oq nm nn no bi translated">安装Beautiful Soup:在命令提示符或终端中运行以下命令:</li></ul><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9fc2" class="ma mb it lw b gy mc md l me mf">pip install bs4</span></pre><ul class=""><li id="1e80" class="ne nf it la b lb lc le lf lh or ll os lp ot lt oq nm nn no bi translated">安装解析器:我们需要一个解析器从HTML文档中提取数据。在本指南中，我们将使用<code class="fe nu nv nw lw b">lxml</code>解析器。要安装此解析器，请运行以下命令:</li></ul><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="a94e" class="ma mb it lw b gy mc md l me mf">pip install lxml</span></pre><ul class=""><li id="5bb3" class="ne nf it la b lb lc le lf lh or ll os lp ot lt oq nm nn no bi translated">安装请求库:在命令提示符或终端中运行以下命令:</li></ul><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="d6bf" class="ma mb it lw b gy mc md l me mf">pip install requests</span></pre><p id="75cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该编码了！</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="ef80" class="mn mb it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">第1部分:抓取单个页面</h1><p id="3955" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">我将指导您完成我们构建第一个scraper所需的每一行代码。您可以在本文末尾找到完整的代码。我们开始吧！</p><h2 id="9e17" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">导入库</h2><p id="d43d" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">以下是美汤刮痧需要的库:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="a21f" class="ma mb it lw b gy mc md l me mf">from bs4 import BeautifulSoup<br/>import requests</span></pre><h2 id="8b1b" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">获取网站的HTML</h2><p id="ea24" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">我们要刮一个网站，里面有几百页的电影抄本。我们将从抓取一页开始，然后我将向您展示如何抓取多页。</p><p id="cea9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们定义链接。在这种情况下，我选择电影<em class="nx">泰坦尼克号</em>的抄本，但你可以选择任何你想要的电影。然后，我们向网站发送一个请求，并获得一个响应，我们将该响应保存在<code class="fe nu nv nw lw b">result</code>变量中。在这之后，我们使用<code class="fe nu nv nw lw b">.text</code>的方法来获取网站的内容。最后，我们使用<code class="fe nu nv nw lw b">lxml</code>解析器获得<code class="fe nu nv nw lw b">soup</code>，它是包含嵌套结构中所有数据的对象，我们稍后将重用这些数据。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="f8d5" class="ma mb it lw b gy mc md l me mf">website = 'https://subslikescript.com/movie/Titanic-120338'<br/>result = requests.get(website)<br/>content = result.text<br/>soup = BeautifulSoup(content, 'lxml')<br/>print(soup.prettify())</span></pre><p id="6995" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦我们有了<code class="fe nu nv nw lw b">soup</code>对象，使用<code class="fe nu nv nw lw b">.prettify()</code>就可以很容易地获得可读格式的HTML。虽然我们可以使用文本编辑器中打印的HTML来定位元素，但是直接找到我们想要的特定元素的HTML代码要好得多。我们将在下一步中这样做。</p><h2 id="d3ec" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">分析网站和HTML代码</h2><p id="8f6a" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">在我们继续编写代码之前，重要的一步是分析我们想要抓取的网站和获得的HTML代码，以便找到抓取网站的最佳方法。下面，你可以找到一张成绩单的截图。要抓取的元素是电影片名和剧本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/a5255059ca6b953d8ab84f9e94709a30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dgbvVKqGPhq1b-_GSZshUw.png"/></div></div></figure><p id="1d71" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要获取特定元素的HTML代码，请按照下列步骤操作:</p><ol class=""><li id="241b" class="ne nf it la b lb lc le lf lh or ll os lp ot lt nl nm nn no bi translated">去你想要的成绩单的网站。</li><li id="cc35" class="ne nf it la b lb np le nq lh nr ll ns lp nt lt nl nm nn no bi translated">将鼠标悬停在电影标题或脚本上，然后右键单击。将显示一个列表。选择“Inspect”打开页面的源代码。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/fa6daf8f057fadd88d5e3ab6b8d72c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2an3EhHiQNwkxPZYUTgdXQ.png"/></div></div></figure><p id="f78c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面，您可以找到单击inspect后获得的HTML代码的较小版本。在下一步中，我们将使用这个HTML代码作为定位元素的参考。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pl l"/></div></figure><h2 id="f337" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">用美丽的汤定位元素</h2><p id="3b0c" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">在美丽的汤里找到一个元素很简单。你只需要将<code class="fe nu nv nw lw b">.find()</code>方法应用到之前创建的汤里。</p><p id="0cc8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，让我们定位包含电影标题、描述和脚本的盒子。它在一个<code class="fe nu nv nw lw b">article</code>标签中，有一个名为<code class="fe nu nv nw lw b">“main-article”</code>的类。我们用以下代码找到了这个盒子:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8a2e" class="ma mb it lw b gy mc md l me mf">box = soup.find('article', class_='main-article')</span></pre><p id="e6e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们来定位电影片名和剧本。电影标题在一个<code class="fe nu nv nw lw b">h1</code>标签中，没有类名。定位后，我们使用<code class="fe nu nv nw lw b">.get_text() </code>方法获取节点内的文本:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5dfc" class="ma mb it lw b gy mc md l me mf">title = box.find('h1').get_text()</span></pre><p id="d349" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个脚本在一个<code class="fe nu nv nw lw b">div</code>标签中，有一个名为<code class="fe nu nv nw lw b">”full-script”</code>的类。为了获得本例中的文本，我们将修改<code class="fe nu nv nw lw b">.get_text()</code>方法中的默认参数。首先，我们设置<code class="fe nu nv nw lw b">strip=True</code>来删除前导和尾随空格。然后我们在分隔符<code class="fe nu nv nw lw b">separator=’ ‘ </code>上添加一个空格，这样单词在每一个新行之后都有一个空格(<code class="fe nu nv nw lw b">\n</code>)。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="0467" class="ma mb it lw b gy mc md l me mf">transcript = box.find('div', class_='full-script')<br/>transcript = transcript.get_text(strip=True, separator=' ')</span></pre><p id="5aa9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到目前为止，我们已经成功地收集了数据。打印<code class="fe nu nv nw lw b">title</code>和<code class="fe nu nv nw lw b">transcript</code>变量，确保到目前为止一切正常。</p><h2 id="6fb2" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">在txt文件中导出数据</h2><p id="b2ed" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">如果需要，您可以导出抓取的数据，以便以后重复使用。您可以用CSV、JSON和更多格式存储数据。对于这个例子，我将把提取的数据存储在一个<code class="fe nu nv nw lw b">.txt</code>文件中。</p><p id="5d6f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们需要使用<code class="fe nu nv nw lw b">with</code>关键字，如下面的代码所示:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b8ff" class="ma mb it lw b gy mc md l me mf">with open(f'{title}.txt', 'w') as file:<br/>    file.write(transcript)</span></pre><p id="42e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，我正在使用<code class="fe nu nv nw lw b">f</code> -string将文件名设置为电影标题。运行代码后，一个<code class="fe nu nv nw lw b">.txt</code>文件应该位于您的工作目录中。</p><p id="a12c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">既然我们已经成功地从一页中抓取了数据，我们就可以从多页中抓取文本了！</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="7dcc" class="mn mb it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">第2部分:抓取多个抄本和页面</h1><p id="e2ab" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">下面，你可以找到有电影抄本的网站首页截图。该网站有1234页，每页大约有30个电影脚本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/1b4caff79a62b79f3ce027e4a428f07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sBc1UbmI7FbKDI4i0EAY7A.png"/></div></div></figure><p id="f45f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在第二部分中，我将向您展示如何通过获取每个链接的<code class="fe nu nv nw lw b">href</code>属性来抓取多个链接。首先我们要修改网站来刮。上面显示的网站链接是<a class="ae lu" href="https://subslikescript.com/movies" rel="noopener ugc nofollow" target="_blank">subslikescript.com/movies</a></p><p id="6252" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们新的网站变量如下:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9c98" class="ma mb it lw b gy mc md l me mf">root = 'https://subslikescript.com'<br/>website = f'{root}/movies'</span></pre><p id="f1be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我还定义了一个<code class="fe nu nv nw lw b">root</code>变量，它将帮助我们稍后抓取多个页面。</p><h2 id="3b90" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">获取href属性</h2><p id="e403" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">让我们首先获得一页上列出的30部电影的<code class="fe nu nv nw lw b">href</code>属性。为此，检查上面截图中“电影抄本列表”框内的任何电影标题。</p><p id="d6cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这之后，你应该得到HTML代码。一个<code class="fe nu nv nw lw b">a</code>标签应该以蓝色突出显示。每个<code class="fe nu nv nw lw b">a</code>标签属于一个电影标题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/1e3ede7ba86565fe9ea74dce6151d4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgF_fbjldf_wO2ecRGVNYw.png"/></div></div></figure><p id="f4c2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，<code class="fe nu nv nw lw b">href </code>中的链接不包含根<code class="fe nu nv nw lw b">subslikescript.com</code>。这就是为什么我在之前定义了一个<code class="fe nu nv nw lw b">root</code>变量，以便以后连接它。</p><p id="0d04" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们定位页面上的所有<code class="fe nu nv nw lw b">a</code>元素。</p><h2 id="bb9d" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">用美丽的汤定位多种元素</h2><p id="ef51" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">为了在美丽的汤里找到多种元素，我们必须使用<code class="fe nu nv nw lw b">.find_all()</code>方法。我们需要添加参数<code class="fe nu nv nw lw b">href=True</code>来提取对应于每个电影脚本的链接。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="912e" class="ma mb it lw b gy mc md l me mf">box.find_all('a', href=True)</span></pre><p id="ecea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了从<code class="fe nu nv nw lw b">href</code>中提取链接，我们必须将<code class="fe nu nv nw lw b">['href']</code>添加到上面的表达式中。然而，<code class="fe nu nv nw lw b">.find_all()</code>方法将返回一个列表，所以我们必须循环遍历它，并在循环中逐个获取<code class="fe nu nv nw lw b">hrefs</code>。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="be63" class="ma mb it lw b gy mc md l me mf">for link in box.find_all('a', href=True):<br/>    link['href']</span></pre><p id="cf22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了存储链接，我们可以使用列表理解，如下所示:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="515e" class="ma mb it lw b gy mc md l me mf">links = [link['href'] for link in box.find_all('a', href=True)]<br/>print(links)</span></pre><p id="32f3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你打印链接列表，你会看到我们想要刮的链接。下一步我们将刮去每一页。</p><h2 id="7c40" class="ma mb it bd mo ox oy dn ms oz pa dp mw lh pb pc my ll pd pe na lp pf pg nc ph bi translated">在每个链接中循环</h2><p id="8c1f" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">为了抓取每个链接的副本，我们将遵循之前对一个副本所做的相同步骤。这一次，我们将在下面的<code class="fe nu nv nw lw b">for</code>循环中包含这些步骤。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8692" class="ma mb it lw b gy mc md l me mf">for link in links:<br/>    result = requests.get(f'{root}/{link}')<br/>    content = result.text<br/>    soup = BeautifulSoup(content, 'lxml')</span></pre><p id="b4a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可能还记得，我们之前存储的链接不包含根<code class="fe nu nv nw lw b">subslikescript.com</code>，所以我们必须用表达式<code class="fe nu nv nw lw b">f’{root}/{link}’</code>将它连接起来。</p><p id="efab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">代码的其余部分与我们为本指南的第一部分编写的代码相同。该项目的完整代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pl l"/></div></figure><p id="11ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您想浏览网上列出的页面，您有两种选择:</p><ul class=""><li id="150e" class="ne nf it la b lb lc le lf lh or ll os lp ot lt oq nm nn no bi translated">选项1:检查网站上显示的任何页面(例如1、2、3…1234)。您应该获得一个包含每个页面链接的<code class="fe nu nv nw lw b">href</code>属性的<code class="fe nu nv nw lw b">a</code>标签。一旦有了链接，将它们与根连接起来，并遵循第2节中所示的步骤。</li><li id="8e53" class="ne nf it la b lb np le nq lh nr ll ns lp nt lt oq nm nn no bi translated">选项2:转到第2页，复制获得的链接。应该是这样的:<a class="ae lu" href="https://subslikescript.com/movies?page=2" rel="noopener ugc nofollow" target="_blank">subslikescript.com/movies?page=2</a>。如你所见，网站的每个页面都遵循一种模式:<code class="fe nu nv nw lw b">f’{website}?page={i}’</code>。如果你想浏览前十页，你可以重复使用网站变量，在数字<code class="fe nu nv nw lw b">1</code>和<code class="fe nu nv nw lw b">10</code>之间循环。</li></ul></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="4880" class="mn mb it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">观看视频教程</h1><p id="b818" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ou lj lk ll ov ln lo lp ow lr ls lt im bi translated">就是这样！您刚刚学习了如何使用Python抓取网站的多个页面。如果有什么不清楚的，查看下面的视频教程。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="po pl l"/></div></figure><p id="6cb0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://frankandrade.ck.page/bd063ff2d3" rel="noopener ugc nofollow" target="_blank"> <em class="nx">与3k+人一起加入我的电子邮件列表</em> </a> <em class="nx">以获得我在所有教程中使用的Web抓取小抄(免费PDF)。</em></p></div></div>    
</body>
</html>
<html>
<head>
<title>Building a General Classification System for Image Quality Defects</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立图像质量缺陷的通用分类系统</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/building-a-general-classification-system-for-image-quality-defects-beadbe026a19?source=collection_archive---------8-----------------------#2022-06-10">https://betterprogramming.pub/building-a-general-classification-system-for-image-quality-defects-beadbe026a19?source=collection_archive---------8-----------------------#2022-06-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3a91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">常见质量缺陷、当前识别方法和面临的挑战</h2></div><p id="20c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由<a class="ae lb" href="https://www.linkedin.com/in/prakritipritmani/" rel="noopener ugc nofollow" target="_blank">普拉克里蒂·普里马尼</a>、<a class="ae lb" href="https://www.linkedin.com/in/sachitpandey/" rel="noopener ugc nofollow" target="_blank">萨吉特·潘迪</a>、<a class="ae lb" href="https://www.linkedin.com/in/shresthrana/" rel="noopener ugc nofollow" target="_blank">什雷思·拉纳</a>、<a class="ae lb" href="https://www.linkedin.com/in/sridhar-jonnala-12157116/" rel="noopener ugc nofollow" target="_blank">斯里达尔·琼娜拉</a>和<a class="ae lb" href="https://www.linkedin.com/in/traptikalra/" rel="noopener ugc nofollow" target="_blank">特拉皮·卡拉</a></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/ee4a7f2721c79a18a1ef3562f74aa1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wLEhohRlZz6xeibG"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Joshua Sortino 在<a class="ae lb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="c308" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几年来，针对各种不同的使用案例，开发了许多基于图像的智能解决方案。它们都有一个共同点，即用于构建和测试解决方案的原始图像数据集中存在一系列图像质量问题。</p><blockquote class="ls lt lu"><p id="863e" class="kf kg lv kh b ki kj jr kk kl km ju kn lw kp kq kr lx kt ku kv ly kx ky kz la ij bi translated">根据<strong class="kh ir"> </strong> <a class="ae lb" href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=fdf9b9a6f637" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">《福布斯》</strong> </a> <strong class="kh ir"> (2016) </strong>，“数据科学家80%的时间都花在寻找、清理和试图组织数据上”。在清理图像数据集的过程中会进一步观察到这种趋势，其中也普遍存在人为错误。“一个坏的数据集将导致一个坏的模型”——如果图像质量缺陷是由于捕捉时的错误或不代表自然生活的条件，那么训练的模型肯定会失败。</p></blockquote><p id="7150" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当一幅图像被人类捕获时，它很容易被当场判断并被纠正或重拍。如今的智能手机内置了专有的校正软件，可以照亮黑暗的图像，或者在人像模式下检测人脸，以确保对焦准确。</p><p id="0c27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在工业自动化工作流程等特定场景中，我们看到过这样的使用案例:机器人被编程执行任务，以捕捉室外/工厂环境中可能不安全的资产/设备的图像，供人类检查。这种图像将通过下游工作流程步骤自动发送处理。</p><p id="602b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模拟基于人的实时审查和纠正步骤——实施“通用”图像质量缺陷检测系统可以为解决方案设计和工作流程结果增加巨大的价值。一种图像质量检测框架，能够在边缘和移动设备上实时有效地工作。</p><p id="c370" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种情况下出现了一个重要的问题:我们是否考虑主观(人)的意见，即即使鲁棒的模型可能能够正确地对图像进行分类，图像的质量也是差的，或者如果模型不能正确地检测到对象/分类，图像的质量是差的吗？</p><p id="1fbb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个问题导致围绕可能存在什么缺陷以及如何识别质量差的图像要考虑许多因素。在本文中，我们将讨论一些最常见的缺陷、当前的识别方法——基于传统图像处理和深度学习，以及我们在尝试实施/运行复杂的自治系统时可能面临的挑战。</p><h1 id="0176" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">常见的图像质量缺陷</h1><h2 id="1f66" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">模糊:</h2><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nd"><img src="../Images/92ed4b5bc9c641c52bab398e74f66be0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_tqqyoLOBspoJZN0.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来自VizWiz数据集的包含散焦模糊的图像示例</p></figure><p id="2980" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有两种类型的模糊，即运动模糊，在这种情况下，图像是在对象运动或相机不稳定时拍摄的；第二种类型是散焦模糊，在这种情况下，拍摄图像时感兴趣的对象不在焦点上，因此它在图像中是模糊的。</p><h2 id="f391" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">眩光:</h2><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/b589471aecfa5d3240f46d50dad84acc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7bUNTt13X5Oxfhcb.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">包含来自VizWiz数据集的反射眩光的图像示例</p></figure><p id="8f3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当图像上捕捉到非常强的发光物体时，会出现眩光。当你试图捕捉夜晚的太阳、鞭炮或街灯时，你一定注意到了这一点；以及它们如何在其位置上发出明亮的斑点，特别是如果相机设置没有相应校准的话。</p><h2 id="45e8" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">黑暗:</h2><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/2e4ef6b98cf188feb9dbe3e8bd740b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/0*RPcvKF0W7TV3L4Xo.jpeg"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">前暗数据集的暗图像示例</p></figure><p id="df8a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">顾名思义，这发生在黑暗/弱光环境(例如，夜间)中捕获图像时。当一个物体出现在发光源前面时，也会发生这种情况，使该物体看起来像一个黑暗的轮廓(有没有视频呼叫某人，当他们站在灯光前时，你看不到他们的脸？)</p><h2 id="90cc" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">图像质量检测</h2><p id="bbc0" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">图像质量检测是指由计算设备实现的识别图像中质量问题种类的能力。传统上，使用各种计算度量，已经开发了试探法来处理缺陷检测，这虽然对定义良好的情况有效，但是缺乏跨各种用例的通用性。这些方法本质上主要是分析性的，并且在启发式的上下文中应用人类的理解。后来，随着多模态人工智能的兴起，已经开发了图像质量检测通用机制，这些机制能够识别图像中的这种“关键特征”，这有助于图像缺陷识别。</p><p id="e866" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种功能可用于随时过滤现有数据集的质量问题，而不依赖于人工干预来为机器学习管道挑选数据集。这有助于减少数据专业人员清理影像数据集的时间。类似地，这也可以在数据收集的源处使用，其中在点击图像时，可以通知操作者任何缺陷的存在，或者在生产工作流程中作为用于部署的机器学习模型的图像过滤机制。</p><p id="4607" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，这有助于节省时间和资源。这是因为效率的提高是自动化视觉检测任务的结果，而这些任务以前是手动完成的。底层自动化是通过使用图像质量检测功能生成的洞察来实现的。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/7f6c4578b76f3476c32f51315ea87f06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*Vg9tcV9It8AyqIpB.jpeg"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">手动检查一个巨大的数据集的缺陷可能有点…乏味。<a class="ae lb" href="https://www.picturemosaics.com/photo-mosaic-tool/share/id/M6439325/p/p0" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="4edd" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">传统缺陷检测技术</h1><h2 id="7a31" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">模糊检测</h2><p id="9e9e" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated"><strong class="kh ir">拉普拉斯算子</strong>:该方法用于发现图片中的边缘。它突出显示图像中包含快速亮度变化的区域。它用于测量图像的二阶导数。如果图像包含高方差，则存在广泛的响应分布，包括边缘状和非边缘状，代表正常的聚焦图像。但是，如果方差非常低，那么响应的分布很小，表明图像中的边缘非常少。众所周知，图像越模糊，边缘就越少。该方法将输入图像与拉普拉斯算子进行卷积，并计算方差。在设置方差阈值之后，方差低于该阈值的图像被分类为“模糊的”。主要的挑战是设置一个给出最佳精度的正确阈值。阈值可以随着来自不同场景的图像而变化；因此，推广是困难的。要了解这种方法的内部运作，请参考<a class="ae lb" href="https://medium.com/@sagardhungel/laplacian-and-its-use-in-blur-detection-fbac689f0f88" rel="noopener">这篇博客</a>。</p><p id="c983" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">快速傅立叶变换</strong>:这是一种数学算法，用于将图像从空间域转换到傅立叶/频率域。在频域中，每个点代表包含在相应空间域中的特定频率。当基于设定的频率水平存在低数量的频率时，则它声明图像是模糊的，否则，如果计算的频率高，则图像是清晰的。在这种情况下，根据用例，阈值取决于程序员。如需帮助实施，请参考<a class="ae lb" href="https://pyimagesearch.com/2020/06/15/opencv-fast-fourier-transform-fft-for-blur-detection-in-images-and-video-streams/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><p id="a55e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有关不同模糊检测技术之间的比较的更多信息，请参见<a class="ae lb" href="https://www.semanticscholar.org/paper/iBlurDetect%3A-Image-Blur-Detection-Techniques-and-Pagaduan-Aragon/955bc0d1b9ebbc3b3263adad2e7360ad757e1f11" rel="noopener ugc nofollow" target="_blank">本</a>。</p><h2 id="639f" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">眩光检测</h2><p id="bba3" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">图像特征，其在计算时返回具有原始尺寸的图像以及包含图像眩光的位置的概率。</p><p id="be8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择的第一个图像图是强度图。所选择的第二图像图是饱和度图，其中色彩饱和度非常低的区域是眩光区域的良好候选。因此，输入图像的HSV颜色空间表示用于导出每个像素的颜色饱和度。所选择的第三图像图是局部对比度图，其中低亮度区域预期是图像眩光的良好候选。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nm"><img src="../Images/26ffd233e25147b4941b98482f212ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9L37K3uA0jn9CT9_.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">根据原始图像计算的光度贴图[使用JET色彩贴图]。<a class="ae lb" href="https://library.imaging.org/ei/articles/29/19/art00013" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="027c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以理解的是，这三张光度贴图都使用了数学公式来识别眩光区域。通过对图像的仔细观察，我们了解到具有较高色度值的区域(以红色突出显示)是眩光的识别候选区域。作者还提供了更多关于如何整合其他功能以提高性能的细节，但是分析方法的基础仍然是相同的。有关该方法的更多信息，请参考此处的<a class="ae lb" href="https://library.imaging.org/ei/articles/29/19/art00013" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/3c6c56d0fd4d0ee7f5e0d22449475ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xg9CXsH0_rvmpbU3.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">红色区域是图像中眩光的候选区域。<a class="ae lb" href="https://library.imaging.org/ei/articles/29/19/art00013" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="de53" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，面临的关键挑战是关于使用这种方法实现分类系统。由于镜面高光可能是很强的假阳性，因此重要的是，在最终图像中仅仅存在高值不能被归类为眩光。因此，相对于用户定义的阈值，高值与总值的比率可以帮助我们识别眩光区域的百分比，该百分比可以与自定义阈值进行比较，并帮助识别图像是否有眩光。这里，我们需要指定几个关键参数，如图像值的阈值和百分比眩光区域的阈值。这进一步意味着，对于每个用例，这些值必须根据经验确定(在训练集上)，而不是对所有用例都具有普遍性。</p><h2 id="2e18" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">黑暗检测</h2><p id="bebf" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">已经使用了各种分析方法来确定图像是否是暗的。通常，使用固定大小的核来平滑图像的灰度近似值，以获得更高级别的近似值并降低图像尺寸。此后，计算图像矩阵中存在的所有值的平均值，并最终与阈值进行比较。像素值的灰度范围是(0–255)，127位于中间。该阈值可以根据经验确定，或者使用127的理论近似值。如果该值小于阈值(127)，则图像被分类为暗的。然而，这被证明是非常粗略的近似，并且在实践中产生不太理想的结果。</p><p id="ede9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，上述技术有几个缺点，因此，对ML技术的鲁棒性和可推广性进行了研究。</p><h1 id="06ac" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">ML技术和数据集</h1><h2 id="ae79" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated"><strong class="ak">模糊CNN </strong></h2><p id="70f1" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">对于模糊检测，我们把它框架为二元分类问题，其中输入图像将被分类为“模糊”或“不模糊”。起初，迁移学习用于像ResNet50和VGG-16这样的预训练模型(在ImageNet上进行了预训练)。虽然与传统方法相比，这些方法在精度上有了显著提高，但这些模型的尺寸相当大，不适合边缘设备。因此，我们试图最大限度地提高我们的模型精度，并减少模型大小。我们从头开始训练了一个定制的CNN架构，它比迁移学习提供了更好的准确性，可能的原因是从ImageNet数据集学习(预训练)的低级特征对学习模糊特征没有帮助。</p><p id="ad3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考代码实现<a class="ae lb" href="https://github.com/Nem3sisX/pretrained-image-quality-cnn" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/dfd94667215ef13ac13719eba729c686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Nm6_HfzCBN7BacFP.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">左边的图像(取自VizWiz数据集)被归类为“不模糊”，右边的(<a class="ae lb" href="https://fineartamerica.com/featured/blurred-traffic-jam-victor-bezrukov.html" rel="noopener ugc nofollow" target="_blank">源</a>)被归类为“模糊”</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/16e22349a8bcd237acfcb69be0dc46f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ICfxCpe566Zm02mh.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">用于模糊检测的模型之间的精度比较</p></figure><h2 id="e88d" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated"><strong class="ak">眩光CNN </strong></h2><p id="ded4" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">为了检测每幅图像中的眩光，我们研究了学术文献中的方法。然而，代替快速推理时间的限制和对最小化模型大小的关注，定制CNN模型比预训练模型更受欢迎。</p><p id="911e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是因为预训练模型关注于提高的准确性，但是具有较慢的推理时间和较大的模型尺寸，因此不适合边缘设备。随着模型训练的进一步改进，我们能够限制模型大小，同时强调眩光的分类性能。</p><p id="539c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于该模型，检查点用于确定在验证集上表现最佳的模型。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nn"><img src="../Images/9d2c935c0dcf2485e3257a48ad91d2d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TVDt95pLWtS_B2XI.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">左边的图像(取自VizWiz数据集)被分类为“非眩光”，右边的图像(取自VizWiz数据集的<a class="ae lb" href="https://fineartamerica.com/featured/blurred-traffic-jam-victor-bezrukov.html" rel="noopener ugc nofollow" target="_blank"> t </a> aken)被分类为“眩光”</p></figure><p id="8400" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于人工智能解释能力，流入最终卷积层的目标概念[ <strong class="kh ir">眩光</strong> ]的梯度用于产生定位图，该定位图突出显示图像中用于预测概念的区域。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi no"><img src="../Images/8eaa62d2534aba784680a2da854e2270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rdZSLSJZppLXuUzx.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">[左-右] GradCAM热图，原始输入图像(缩小到64x64)，热图叠加+输入图像</p></figure><p id="d624" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们可以清楚地划分局部区域。类别激活图显示眩光区域与类别激活图重叠。因此，通过视觉验证，我们可以观察我们的网络在“看”哪里，并评估它是否确实在看图像中表示眩光的正确图案。正如所观察到的，最终的卷积层在表示图像中存在眩光的图案周围被激活。</p><p id="c300" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考代码实现<a class="ae lb" href="https://github.com/Nem3sisX/pretrained-image-quality-cnn" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h2 id="b300" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated"><strong class="ak">黑暗检测</strong></h2><p id="8ddd" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">为了检测给定图像的暗度，计算像素值[范围从0到255]的直方图表示，其中桶的大小以15为间隔固定。</p><p id="dd63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是对所有训练图像进行的。这些图像表示此后被存储在对应于每个图像的文件中。</p><p id="f7fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此后，整个文件作为一个数据帧读取，并在其上训练一个随机森林模型。最后，将性能与验证分割进行比较，以准确确定模型的性能。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/d52723a678338de79096f6b21f7d7a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*atZDf8-oiA0TvUYt.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">左边的图像(取自VizWiz数据集)归类为“不暗”，右边的图像(<a class="ae lb" href="https://fineartamerica.com/featured/blurred-traffic-jam-victor-bezrukov.html" rel="noopener ugc nofollow" target="_blank"> t </a>取自前暗数据集)归类为“暗”</p></figure><p id="9092" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于模型构建，使用的基线数据集是Ex-Dark数据集的子集。这里，训练图像和验证分割也指这里所指的来自Ex-Dark的图像子集。</p><p id="17c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> ExDARK数据集:</strong>exclusive Dark(ex Dark)数据集是从极弱光环境到黄昏(即10种不同条件)的7，363幅弱光图像的集合，具有12个对象类(类似于PASCAL VOC)，在图像类级别和局部对象边界框上都有注释。对于我们的使用，我们用它来评估我们的黑暗模型的性能。</p><p id="43f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> VizWiz图像质量问题数据集</strong>:viz wiz大挑战的一部分，这是计算机视觉社区设计这种技术来帮助盲人克服日常视觉挑战的自然大挑战。该数据集是围绕23，431幅训练图像建立的，这些图像是由盲人拍摄的，他们真正试图了解他们使用VizWiz移动电话应用程序拍摄的图像。图像注释在一个JSON文件中给出，在那里它们被标记在一个基于投票的度量标准中，每张图像的质量缺陷和不可识别性，在0到5的范围内。标签如下:</p><p id="ad78" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">a.【无】:无瑕疵</p><p id="bf51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">b.[BLR]:模糊</p><p id="d903" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">c.[BRT]:高亮度/眩光</p><p id="c723" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">d.[DRK]:暗/曝光不足的图像</p><p id="2d8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">e.[ROT]:旋转的图像</p><p id="3e8d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f.[OBS]:模糊/遮挡</p><p id="dc09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">g.[FRM]:对象超出了框架</p><p id="9a92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">h.无法识别:由于严重的质量问题，图像内容无法识别</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/7fbb17191a59111450aade77bed3ef35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OtRp-UaTSu7E0xGt.jpg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">VizWiz中不同类型的类:图像质量问题数据集。<a class="ae lb" href="https://vizwiz.org/wp-content/uploads/2020/03/VizWiz-QualityIssues-1-1536x435.jpg" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h2 id="3a7e" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">挑战</h2><p id="6913" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">由于以下原因，不管给定的场景/数据如何，将图像质量检测方法推广到具有类似性能的工作可能是一项复杂的任务:</p><p id="1b17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> </strong>在模糊检测中，重要的是确定图像的模糊程度可以被归类为“模糊”。还存在图像具有部分模糊的情况，这通常在摄影中看到，其中失焦部分被有意模糊，以将整个焦点给予感兴趣的对象和/或为了美学效果(例如，散景效果)。</p><p id="0944" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> </strong>通用图像质量检测系统应适应存在缺陷但不影响感兴趣对象(OOI)/感兴趣区域的异常情况。例如，无论图像中是否有眩光点，或者图像是否有上述散景效果，OOI都不会受到它的影响，您可以清楚地看到它。在这些情况下，定位您感兴趣的区域变得非常重要。</p><p id="a20b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> </strong>我们试图用VizWiz数据集实现遮挡检测(使用[OBS]类)，但发现该模型在测试数据集上不能很好地推广。我们通常将遮挡与一些暗斑或“污点”联系起来，这些暗斑或“污点”使我们看不到感兴趣的物体。情况并非总是如此。有些情况下，适当的对象可能是遮挡对象。例如，自行车是一个对象，并且是对象检测数据集中的一个常见类，但是如果将其放在汽车前面并遮挡了汽车的一部分，它可能会成为遮挡对象。因此，需要基于上下文的遮挡检测来使图像质量检测系统通用化。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/7f2d65926e53bd9cdc55ccbf76a82222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fOXMfdDNNsEdFQkw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">左图中的自行车是一个遮挡的物体(<a class="ae lb" href="https://images.unsplash.com/photo-1584126997295-f9327e5ee374?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=1031&amp;q=80" rel="noopener ugc nofollow" target="_blank">来源</a>，右图中的OOI(<a class="ae lb" href="https://images.unsplash.com/photo-1505705694340-019e1e335916?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=1032&amp;q=80" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="f1e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> </strong>通用的图像质量检测系统还应该考虑具有深色和/或亮色物体的图像，并且不应该分别将其与黑暗或眩光混淆。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/119fcc23082bcc8266bacaf0cb1d08e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mcKr6WmJ9_lkIido.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">黑暗物体。<a class="ae lb" href="https://images.unsplash.com/photo-1532298229144-0ec0c57515c7?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=822&amp;q=80" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="5f44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考代码实现<a class="ae lb" href="https://github.com/Nem3sisX/pretrained-image-quality-cnn" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><h2 id="367f" class="mr ma iq bd mb ms mt dn mf mu mv dp mj ko mw mx ml ks my mz mn kw na nb mp nc bi translated">参考</h2><p id="dbbe" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">[1] Mehran Andalibi，Damon M. Chandler，“通过光度、几何和全球定位信息进行自动眩光检测”，Proc .IS&amp;T国际公司。症状。电子成像:自动驾驶车辆和机器，2017年，第77-82页</p><p id="cc3a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://vizwiz.org/tasks-and-datasets/image-quality-issues/" rel="noopener ugc nofollow" target="_blank">图像质量问题— VizWiz </a></p><p id="c097" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://github.com/cs-chan/Exclusively-Dark-Image-Dataset" rel="noopener ugc nofollow" target="_blank">https://github.com/cs-chan/Exclusively-Dark-Image-Dataset</a></p><p id="b365" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://pyimagesearch.com/2020/06/15/opencv-fast-fourier-transform-fft-for-blur-detection-in-images-and-video-streams/" rel="noopener ugc nofollow" target="_blank"> OpenCV快速傅立叶变换(FFT)用于图像和视频流中的模糊检测— PyImageSearch </a></p><p id="ddc9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://www.semanticscholar.org/paper/iBlurDetect%3A-Image-Blur-Detection-Techniques-and-Pagaduan-Aragon/955bc0d1b9ebbc3b3263adad2e7360ad757e1f11" rel="noopener ugc nofollow" target="_blank"> [PDF] iBlurDetect:图像模糊检测技术评估与评价研究|语义学者</a></p><p id="91ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://medium.com/@sagardhungel/laplacian-and-its-use-in-blur-detection-fbac689f0f88" rel="noopener">拉普拉斯算子及其在模糊检测中的应用| Sagar | Medium</a></p></div></div>    
</body>
</html>
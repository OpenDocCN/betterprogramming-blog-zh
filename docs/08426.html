<html>
<head>
<title>Bagging Tutorial — Classify Higgs Boson Particles With AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">装袋教程——用人工智能分类希格斯玻色子粒子</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/bagging-tutorial-classify-higgs-boson-particles-with-ai-941801559231?source=collection_archive---------10-----------------------#2021-04-28">https://betterprogramming.pub/bagging-tutorial-classify-higgs-boson-particles-with-ai-941801559231?source=collection_archive---------10-----------------------#2021-04-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="87bf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python代码集成学习实用指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/18e337054c0d10ae1a974013e5efcfe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*xzgnKrklFHKQjzJBfYmSNw.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">哈尔·盖特伍德在<a class="ae ku" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><p id="41db" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lr"> Bagging </em>是来自<em class="lr">集成学习</em>范例的元算法，其中多个模型(通常称为“弱学习者”)被训练来解决同一个问题，并组合起来以获得更好的结果。</p><p id="d7fd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">通过bagging，我们根据数据在多个引导上构建相同的模型，并结合每个模型的预测来获得总体分类。</p><p id="b4e0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本文中，我将带您浏览一个物理学中的实际例子，并解释bagging如何对希格斯玻色子(有争议地称为“上帝粒子”)进行分类。</p><p id="c63e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我使用了UCI机器学习库中希格斯数据集的一个小子集。<a class="ae ku" href="https://www.nature.com/articles/ncomms5308" rel="noopener ugc nofollow" target="_blank">这份2014年的论文</a>包含了关于数据的更多细节。</p><p id="eff9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">每一行代表高能质子束碰撞的实验。类别栏区分产生希格斯玻色子的碰撞(值1)和只产生背景噪音的碰撞(值0)。我们对使用bagging技术预测类别感兴趣。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/c2bd87e6690edf8d946e18c727faccd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZyBHzZYZoEUCntoOiKIJA.png"/></div></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="2dbe" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">决策树分类</h1><p id="2d66" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">让我们从一个完整的分类树开始，它将分割训练数据，直到每一片叶子都包含一个观察值。该树将实现训练观察的完美分类，并且偏差将是<code class="fe nb nc nd ne b">0</code>(训练的误分类误差)。</p><p id="843e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">换句话说，完整的树会过度拟合训练数据。这样的树将是非常敏感的，因为对训练观察的微小改变将导致预测的类显著改变。这意味着模型方差会非常高。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="7d17" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">通过交叉验证提高性能</h1><p id="0eee" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">理想情况下，我们希望降低树的深度，以实现更好的模型泛化。然而，这增加了偏差。偏差-方差权衡通过采用交叉验证来寻求偏差和方差之间的折衷。</p><p id="651d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">交叉验证会对数据进行多次重新采样，将其分为训练和验证折叠，在训练折叠上拟合不同大小的树，并在验证折叠上查看分类准确性。</p><div class="nh ni gp gr nj nk"><a href="https://towardsdatascience.com/how-to-find-decision-tree-depth-via-cross-validation-2bf143f0f3d6" rel="noopener follow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">如何通过交叉验证找到决策树深度</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">消化偏差-方差权衡、过拟合、欠拟合、K倍交叉验证背后的直觉。</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ko nk"/></div></div></a></div><p id="9659" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这允许我们找到给出最佳偏差-方差权衡的树深度。这样的决策树不能完美地预测训练集(可接受的偏差)，但是如果我们稍微改变训练集(可接受的方差)，它的性能将大致相同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/e1bd42ed2bf2a851f72b31fdc99a70ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*_c5PYwOpfBwGWZNf9XApGA.png"/></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="d370" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">装袋的工作原理</h1><p id="a68e" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">我们能改善交叉验证的结果吗？</p><p id="cd4b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">Bagging代表“自举聚合”，由Leo Breiman于1996年提出。该技术主要集中于获得方差小于其分量的集合模型:</p><ul class=""><li id="0a70" class="oa ob it kx b ky kz lb lc le oc li od lm oe lq of og oh oi bi translated">Bootstrap:我们通过bootstrap生成训练数据的多个样本。我们在每个数据样本上训练一个更深的决策树。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oj"><img src="../Images/24df787f17c53b677213aa9ad07ff8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uquLTQ2fE9v8Vzgf.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">助推器插图。作者照片。</p></figure><ul class=""><li id="b6f3" class="oa ob it kx b ky kz lb lc le oc li od lm oe lq of og oh oi bi translated">聚合:对于给定的输入，我们输出该输入的所有决策树的平均输出。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ok"><img src="../Images/0fcccb4fb7aa39c05b837eb34d37f30d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s_F4Q1hpEnNlFbRv.png"/></div></div></figure><p id="a706" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下面，我们创建了原始训练数据的45个引导复制，并为每个复制建立了一个大型决策树:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="14fd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">查看下面的结果准确性，通过在训练集的45个引导上拟合深度为20的树，并通过多数投票对它们的分类进行平均，与使用通过交叉验证获得的单个深度为7的树相比，我们在测试数据集上实现了更好的分类准确性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ol"><img src="../Images/8f2359e30cbfa78a47d8db58c81864f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UiAFTxPsaoSB5sZJ0d-n_w.png"/></div></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="242f" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">为装袋寻找引导尺寸</h1><p id="dd15" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">我们想知道鞋带的数量如何影响我们的装袋组合的性能。下面的代码创建了一个作为引导大小函数的训练集和测试集精度图:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi om"><img src="../Images/69e6b9baeeadb6d29b2dc8b114e603e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tql9zHjmtzpe5rWqr8QQhg.png"/></div></div></figure><ul class=""><li id="9282" class="oa ob it kx b ky kz lb lc le oc li od lm oe lq of og oh oi bi translated">限制树的深度:深度为20的大树有大量的参数和过度拟合的训练数据——特别是因为我们最终得到的树的每一片叶子都在对一个训练样本进行分类(100%准确)。为了避免过度拟合和减少方差，当叶子是纯的时，当叶子具有特定大小时，或者当添加节点的增益小于给定阈值时，我们可以停止构建树。最终，我们通过交叉验证找到了最佳的5层树。</li><li id="b476" class="oa ob it kx b ky on lb oo le op li oq lm or lq of og oh oi bi translated">Bagging:通过替换采样，bagging创建了几个适合自举训练数据的大的低偏差深度20树。假设这些树是独立的，我们对它们的预测进行平均，以减少方差并解决过度拟合问题。较大的树大小捕获了训练数据集中的大多数信息，从而导致较低的偏差。与单棵深度为5的树(64.8%)相比，用20棵或更多的树装袋提高了测试精度(68.22%)。</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="63a1" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">Bagging与其他集成技术</h1><p id="5273" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">bagging的一大优势是它可以并行化。</p><p id="991f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">即使使用bagging，我们仍然可以过度拟合数据——特别是当树是相关的时候。在这种情况下，总方差不仅仅是单个方差的平均值。还考虑了一大堆协方差项。这是因为bagging很可能在树的第一次分裂开始时选择相同的预测值。<em class="lr">随机森林</em>开始解决这个问题。</p><p id="4f5b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">装袋也会使食物不足。当树深度太低时就是这种情况。此外，由于我们不使用所有数据通过bootstrap进行训练，我们最终可能会欠拟合整个训练数据集。然而，袋外样本可用于验证树。</p><p id="963e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lr"> Boosting </em>以一种非常适应的方式依次训练弱学习者。与装袋不同，助推利用团队合作。每个运行的模型决定了下一个模型将关注的特性。</p><p id="8184" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lr">堆叠</em>不同于boosting和bagging<strong class="kx iu">T5】通过并行训练异类弱学习器，并通过训练元模型而不是仅仅聚集预测来组合它们。</strong></p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="b7ef" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="cb44" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">在这篇文章中，我用简单的英语解释了合奏技术是如何工作的。亲手操作的Python代码演示了打包的实际实现。用真实世界的数据检验了物理学中的一个分类问题。</p><div class="nh ni gp gr nj nk"><a href="https://towardsdatascience.com/2020-how-a-i-could-help-astronomers-sorting-big-data-811571705707" rel="noopener follow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">用卷积神经网络对引力波进行分类</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">使用Python和Keras的天文学信号处理实用指南。</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="os l nv nw nx nt ny ko nk"/></div></div></a></div><p id="8bf1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">感谢阅读。</p></div></div>    
</body>
</html>
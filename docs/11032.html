<html>
<head>
<title>5 Open-Source Tools That Can Help You Build ML Pipelines With Ease</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5个开源工具，可以帮助您轻松构建ML管道</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/5-open-source-tools-that-can-help-you-build-ml-pipelines-with-ease-46eb5d4c3488?source=collection_archive---------7-----------------------#2022-02-11">https://betterprogramming.pub/5-open-source-tools-that-can-help-you-build-ml-pipelines-with-ease-46eb5d4c3488?source=collection_archive---------7-----------------------#2022-02-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="804d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">所有生产友好型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/38d13f4c26d36ddcf165527226ffee5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PC4RAUksq0HQxCLkNDh16g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5500" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ML不仅仅是在Jupyter笔记本上训练虹膜数据的K-means分类器。你可能希望<em class="lr">在<em class="lr">高端基础设施</em>存在的情况下，使用<em class="lr">复杂的ML模型</em>训练成吨的数据</em>。现在，这不能用单一的工具来完成。我们需要收集它们！</p><p id="0588" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随着对构建生产就绪的端到端ML管道的兴趣激增，使用可更快扩展的正确工具集的需求不断增长，并且正在积极开发中。</p><p id="ffa9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我将讨论我遇到并使用过的5个开源工具，它们可以在构建ML管道的多个阶段为您提供帮助。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="074d" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated"><a class="ae ms" href="https://flyte.org/" rel="noopener ugc nofollow" target="_blank">弗莱特</a></h2><p id="ba5e" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated"><a class="ae ms" href="https://github.com/flyteorg/flyte" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。<a class="ae ms" href="https://docs.flyte.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">单据</a>。<a class="ae ms" href="https://slack.flyte.org/" rel="noopener ugc nofollow" target="_blank">社区</a></p><p id="8cdd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">当前部署:Spotify、Lyft、Freenome、GoJek等。</em></p><p id="5101" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了部署具有高开发速度的生产级ML <em class="lr">和没有基础设施</em>麻烦的<em class="lr">，我们需要一个平台来帮助解决<em class="lr"> ML </em>的<em class="lr">操作</em>方面。确切地说，我们需要一个平台来促进团队之间的协作，在不耗尽资源的情况下处理代码的重复运行，支持不喜欢干预基础架构方面的数据科学家，可扩展且值得信赖，这样的例子还可以继续。</em></p><div class="my mz gp gr na nb"><a href="https://flyte.org" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd ir gy z fp ng fr fs nh fu fw ip bi translated">争吵</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">Flyte使得为机器学习和数据创建并发的、可扩展的和可维护的工作流变得容易…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">flyte.org</p></div></div><div class="nk l"><div class="nl l nm nn no nk np kp nb"/></div></div></a></div><p id="cefc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Flyte是一个工作流自动化平台，有助于自动化关键的ML和数据管道。它使分布式培训变得容易，没有单点故障，提供了数据沿袭，并简化了引导基础设施的过程。有了Flyte，你再也不用担心处理<em class="lr"> ML </em>的<em class="lr"> Ops </em>了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/6f41188f6de4c0395e8ca550a4304704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hY6JAC5sXF7M6wY794I8pg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自blog.flyte.org<a class="ae ms" href="https://blog.flyte.org/from-incubation-to-graduation-and-beyond#heading-enter-the-world-of-ml-aware-orchestration" rel="noopener ugc nofollow" target="_blank">的FlyteConsole屏幕截图</a></p></figure><p id="1024" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">开始使用Flyte非常简单；安装Docker、Python、Git，运行几个命令，就可以开始了！</p><p id="4497" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">如何部署？</strong>所有部署指南和最佳实践都汇编在文档的<a class="ae ms" href="https://docs.flyte.org/en/latest/deployment/index.html" rel="noopener ugc nofollow" target="_blank">部署部分。一些部署可能需要Kubernetes及其相关工具方面的专业知识。</a></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="e03a" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated"><a class="ae ms" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank">远大前程</a></h2><p id="00d8" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated"><a class="ae ms" href="https://github.com/great-expectations/great_expectations" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。<a class="ae ms" href="https://docs.greatexpectations.io/docs/" rel="noopener ugc nofollow" target="_blank">单据</a>。<a class="ae ms" href="https://greatexpectations.io/slack" rel="noopener ugc nofollow" target="_blank">社区</a></p><p id="397a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">当前部署:GitHub、Calm、Agero、Civis等。</em></p><p id="13ab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据并不总是我们期望的那样。数据验证始终是至关重要的，以确保数据看起来像我们想要的那样。高期望值有助于实现完全相同的目标—在实际流程开始之前确保数据质量，无论是建模还是分析。</p><p id="c492" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae ms" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank">远大期望</a>通过“<em class="lr">期望</em>”来实现，是对数据的断言。在这些套件中，我们必须描述我们对数据的预期。或者，可以使用“<em class="lr">数据分析器</em>”生成预期。我还没有彻底测试过这个特性，但是它看起来很有前途！</p><p id="2d9b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在定义了所需的配置和期望之后，Great Expectations会进行数据验证并给出结果。为了美化数据验证结果，远大前程提供了“<em class="lr">数据文档</em>”——一个用户友好的用户界面来查看哪里出了问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/3e389b0c162077089e0566f94f74e87c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GRqo_8t_QCMPmErv.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据文件截屏来自<a class="ae ms" href="https://docs.greatexpectations.io/docs/tutorials/getting_started/tutorial_validate_data" rel="noopener ugc nofollow" target="_blank">docs . great expectations . io</a></p></figure><p id="ae5b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">如何部署？</strong> <a class="ae ms" href="https://docs.greatexpectations.io/docs/deployment_patterns/how_to_instantiate_a_data_context_hosted_environments#" rel="noopener ugc nofollow" target="_blank">部署指南</a>包含在文档中。它有一些集成已经启动并运行；然而，独立部署应该不会太难。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="5129" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated"><a class="ae ms" href="https://feast.dev/" rel="noopener ugc nofollow" target="_blank">盛宴</a></h2><p id="29f5" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated"><a class="ae ms" href="https://github.com/feast-dev/feast" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。<a class="ae ms" href="https://docs.feast.dev/" rel="noopener ugc nofollow" target="_blank">单据</a>。<a class="ae ms" href="https://slack.feast.dev/" rel="noopener ugc nofollow" target="_blank">社区</a></p><p id="f002" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">当前部署:GoJek、Shopify、Salesforce、IBM等。</em></p><p id="190a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae ms" href="https://feast.dev/" rel="noopener ugc nofollow" target="_blank">宴</a>是一种<em class="lr"> fea </em>真<em class="lr"> st </em>矿石。在ML中，如果数据集很大，可能会有很多要素。功能存储有助于管理和生产功能，实现培训和服务数据之间的一致性，以及跟踪功能版本和沿袭。Feast发表了一篇名为<a class="ae ms" href="https://feast.dev/blog/what-is-a-feature-store/" rel="noopener ugc nofollow" target="_blank">什么是特色店的综合文章？如果你想深入了解特色商店的概念。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/e2c43cba0bc92185fed897b6bc05b6db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*19yeR8GFV0-owKtF"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">盛宴建筑(<a class="ae ms" href="https://docs.feast.dev/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="66ab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人们主要在训练和推理期间与特征库进行交互。首先，需要定义和注册特征定义，可以使用特征存储生成训练数据，需要将特征从离线存储具体化到在线存储，最后，可以使用在线存储的最新特征进行推理。</p><p id="22d7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">如何部署？</strong>有<strong class="kx ir"> </strong>有<strong class="kx ir"> </strong> <a class="ae ms" href="https://docs.feast.dev/how-to-guides/running-feast-in-production" rel="noopener ugc nofollow" target="_blank">详细指导</a>部署盛宴生产。部署需要自动化，以简化后续的使用。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="aca9" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated"><a class="ae ms" href="https://horovod.ai/" rel="noopener ugc nofollow" target="_blank"> Horovod </a></h2><p id="bfac" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">GitHub 。<a class="ae ms" href="https://horovod.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">文档</a></p><p id="43f8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果深度学习(DL)模型在使用单个GPU进行训练的过程中表现不佳，我们可能需要许多模型来分配工作负载，以加快过程。Horovod是一个用于TensorFlow、Keras、PyTorch和Apache MXNet的分布式培训框架。即使代码是单GPU兼容的(当然，代码必须使用Horovod APIs)，也很容易扩展到数千个GPU。</p><p id="6a26" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Horovod的主要优势是它可以与多个DL库一起工作——选择DL框架，调用正确的API，瞧！结果应该在更短的时间内产生。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/0eafaf8ca8a84cffa4d4c18c8cb34b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xbw8qond13P4smLK.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Horovod基准(<a class="ae ms" href="https://horovod.readthedocs.io/en/stable/summary_include.html" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="7a65" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">如何部署？</strong><a class="ae ms" href="https://horovod.readthedocs.io/en/stable/summary_include.html#id7" rel="noopener ugc nofollow" target="_blank">安装指南</a>应该有助于设置环境。如果有docker文件，仔细插入所有安装说明，无论是MPI、NCCL还是相关的环境变量。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="703d" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated"><a class="ae ms" href="https://developer.nvidia.com/nvidia-triton-inference-server" rel="noopener ugc nofollow" target="_blank"> Triton推理服务器</a></h2><p id="fa36" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated"><a class="ae ms" href="https://github.com/triton-inference-server/server" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。<a class="ae ms" href="https://github.com/triton-inference-server/server/tree/r22.01#documentation" rel="noopener ugc nofollow" target="_blank">文档</a></p><p id="7217" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">推理是ML的一个重要方面。因为它是面向用户的，所以我们不能只考虑速度，它必须又快又准。当你打开网飞时，你会得到即时的电影推荐。想象一下生成预测的速度，以及可能同时访问网飞的用户数量！这可能是一个相当大的数字，不是吗？</p><p id="2eab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">NVIDIA的<a class="ae ms" href="https://developer.nvidia.com/nvidia-triton-inference-server" rel="noopener ugc nofollow" target="_blank"> Triton </a>“推理”服务器可以简化属于各种框架的各种型号的部署，并轻松扩展。它可以在多个GPU上并发运行，并提供许多功能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5b6b04b3e6b141faf9c31dffdc67ddcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/0*vbozLjL9bJ7KQoQA.jpg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">海卫一是什么做的？(<a class="ae ms" href="https://developer.nvidia.com/nvidia-triton-inference-server" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="5a67" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要运行Triton，提取一个预先存在的Docker映像，并启动容器，然后启动服务器。</p><p id="6fb9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">如何部署？</strong>使用Kubernetes和Helm部署Triton，有<a class="ae ms" href="https://github.com/triton-inference-server/server/blob/main/deploy/gcp/README.md" rel="noopener ugc nofollow" target="_blank"> GCP </a>、<a class="ae ms" href="https://github.com/triton-inference-server/server/blob/main/deploy/aws/README.md" rel="noopener ugc nofollow" target="_blank"> AWS </a>和<a class="ae ms" href="https://github.com/triton-inference-server/server/blob/main/deploy/fleetcommand/README.md" rel="noopener ugc nofollow" target="_blank"> NVIDIA FleetCommand </a>指南。一个名为<a class="ae ms" href="https://els-rd.github.io/transformer-deploy/" rel="noopener ugc nofollow" target="_blank"> transformer-deploy </a>的开源项目提供了一个现成的基于NVIDIA Triton的CPU/GPU推理服务器，用于拥抱Face transformer模型，以简化部署过程。</p><div class="my mz gp gr na nb"><a href="https://els-rd.github.io/transformer-deploy/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd ir gy z fp ng fr fs nh fu fw ip bi translated">变压器-由Lefebvre Dalloz部署</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">高效、可扩展的企业级CPU/ GPU推理服务器，适用于Lefebvre的人脸变形模型</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">els-rd.github.io</p></div></div></div></a></div></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="018a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">感谢阅读！让我知道你用来建立ML管道的工具。</p></div></div>    
</body>
</html>
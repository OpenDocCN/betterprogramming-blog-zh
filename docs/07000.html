<html>
<head>
<title>How to Create a Simple Neural Network in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用Python创建一个简单的神经网络</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-create-a-simple-neural-network-in-python-dbf17f729fe6?source=collection_archive---------1-----------------------#2020-11-25">https://betterprogramming.pub/how-to-create-a-simple-neural-network-in-python-dbf17f729fe6?source=collection_archive---------1-----------------------#2020-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e35f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">学习如何创建一个神经网络，并教它分类向量</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/efcafee13722b3a282a633267f1e9587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tY4xVpA7JtcEejrt"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@dulgier?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">纳斯蒂亚·杜尔希尔</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="f454" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在过去的几十年里，机器学习对世界产生了巨大的影响，并且它的受欢迎程度似乎越来越高。最近，越来越多的人熟悉了机器学习子领域，如神经网络，这是由人脑启发的网络。在本文中，将介绍一个简单神经网络的Python代码，该网络以10作为第一个元素对1×3向量进行分类。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="bf51" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤1:导入NumPy、Scikit-learn和Matplotlib</h1><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="a7bf" class="mw ma iq ms b gy mx my l mz na">import numpy as np<br/>from sklearn.preprocessing import MinMaxScaler<br/>import matplotlib.pyplot as plt</span></pre><p id="5573" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将为这个项目使用三个包。NumPy将用于创建向量和矩阵，以及数学运算。Scikit-learn将用于缩放数据，Matplotlib将用于绘制神经网络训练期间的误差发展。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="01fd" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤2:创建训练和测试数据集</h1><p id="3781" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">神经网络非常擅长学习大数据集和小数据集的趋势。然而，数据科学家必须意识到过度拟合的危险，这在使用小数据集的项目中更加明显。过度拟合是指对算法进行训练和建模，使其过于拟合一组数据点，从而不能很好地推广到新的数据点。</p><p id="ec2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通常，过度拟合的机器学习模型在它们被训练的数据集上具有非常高的准确性，但作为数据科学家，目标通常是尽可能精确地预测新的数据点。为了确保根据预测新数据点的效果来评估模型，而不是根据当前数据点的建模效果来评估模型，通常将数据集分成一个定型集和一个测试集(有时还有一个验证集)。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="fdae" class="mw ma iq ms b gy mx my l mz na">input_train = np.array([[0, 1, 0], [0, 1, 1], [0, 0, 0], <br/>                        [10, 0, 0], [10, 1, 1], [10, 0, 1]])<br/>output_train = np.array([[0], [0], [0], [1], [1], [1]])<br/>input_pred = np.array([1, 1, 0])<br/><br/>input_test = np.array([[1, 1, 1], [10, 0, 1], [0, 1, 10], <br/>                       [10, 1, 10], [0, 0, 0], [0, 1, 1]])<br/>output_test = np.array([[0], [1], [0], [1], [0], [0]])</span></pre><p id="feec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个简单的神经网络中，我们将以10作为第一个元素对1×3向量进行分类。输入输出训练和测试集是使用NumPy的<code class="fe ng nh ni ms b">array</code>函数创建的，而<code class="fe ng nh ni ms b">input_pred</code>是为了测试稍后将定义的<code class="fe ng nh ni ms b">prediction</code>函数而创建的。训练和测试数据都由六个样本组成，每个样本有三个特征，由于输出是给定的，我们知道这是监督学习的一个例子。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="ea34" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤3:缩放数据</h1><p id="2517" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">许多机器学习模型不能够理解例如单位之间的差异，并且自然地将更多权重应用于高量值的特征。这可能会破坏算法预测新数据点的能力。此外，训练具有大量特征的机器学习模型将比必要的要慢，至少如果使用梯度下降的话。这是因为当输入值在大致相同的范围内时，梯度下降收敛得更快。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="3068" class="mw ma iq ms b gy mx my l mz na">scaler = MinMaxScaler()<br/>input_train_scaled = scaler.fit_transform(input_train)<br/>output_train_scaled = scaler.fit_transform(output_train)<br/>input_test_scaled = scaler.fit_transform(input_test)<br/>output_test_scaled = scaler.fit_transform(output_test)</span></pre><p id="2b06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的训练和测试数据集中，这些值在一个相对较小的范围内，因此可能没有必要进行特征缩放。然而，它被包含在这里，这样人们可以使用他们自己的数字，而不需要改变太多的代码。由于Scikit-learn包和它的MinMaxScaler类，在Python中进行特征缩放非常容易。只需创建一个MinMaxScaler对象，使用<code class="fe ng nh ni ms b">fit_transform</code>函数将未缩放的数据作为输入，该函数将返回缩放后的相同数据。Scikit-learn包中还有其他缩放函数，我鼓励您尝试一下。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="c77a" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4:创建神经网络类</h1><p id="712b" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">熟悉神经网络所有元素的最简单方法之一是创建一个神经网络类。这样的类应该包括神经网络正常工作所需的所有变量和函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="9463" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4.1:创建一个初始化函数</h1><p id="440b" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">当我们在Python中创建一个类时，会调用<code class="fe ng nh ni ms b">__init__</code>函数，以便正确初始化变量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/c88a0371fde5414bd798c4fba3d8619e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brr-qO9oOw16DXkhS40ZLA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供。</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/c88a0371fde5414bd798c4fba3d8619e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brr-qO9oOw16DXkhS40ZLA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者分列的数字</p></figure><p id="e442" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本例中，我选择了一个具有三个输入节点、三个隐藏层节点和一个输出节点的神经网络。上面的<code class="fe ng nh ni ms b">__init__</code>函数初始化描述神经网络大小的变量。<code class="fe ng nh ni ms b">inputSize</code>是输入节点数，应该等于我们输入数据中的特征数。<code class="fe ng nh ni ms b">outputSize</code>等于输出节点数，<code class="fe ng nh ni ms b">hiddenSize</code>描述隐藏层的节点数。此外，我们的网络中不同节点之间的权重将在训练期间进行调整。</p><p id="4c1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了描述神经网络大小及其权重的变量之外，我还创建了几个变量，这些变量在创建用于评估目的的<code class="fe ng nh ni ms b">NeuralNetwork</code>对象时被初始化。<code class="fe ng nh ni ms b">error_list</code>将包含每个历元的平均绝对误差(MAE ),并且极限将描述何时向量应该被分类为以元素10作为第一元素的向量以及不作为第一元素的向量的边界。然后，有一些变量将用于存储真阳性、假阳性、真阴性和假阴性的数量。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="fe92" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4.2:创建正向传播函数</h1><p id="752a" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">正向传递函数的目的是通过神经网络的不同层向前迭代，以预测特定时期的输出。然后，查看预测输出和实际输出之间的差异，权重将在反向传播期间更新。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="41e3" class="mw ma iq ms b gy mx my l mz na">def forward(self, X):<br/>        self.z = np.matmul(X, self.W1)<br/>        self.z2 = self.sigmoid(self.z)<br/>        self.z3 = np.matmul(self.z2, self.W2)<br/>        o = self.sigmoid(self.z3)<br/>        return o</span></pre><p id="f584" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了计算每层中每个节点处的值，在应用非线性<a class="ae kv" href="https://medium.com/writers-blokke/what-is-an-activation-function-in-a-neural-network-ae0eb2bd2f82" rel="noopener">激活函数</a>来拓宽最终输出函数的可能性之前，前一层中节点处的值将与适用的权重进行矩阵相乘。在这个例子中，我们选择了Sigmoid作为激活函数，但是也有许多其他的选择。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f874" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4.3:创建反向传播函数</h1><p id="719b" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">反向传播是更新神经网络中不同节点的权重并因此决定它们的重要性的过程。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="9844" class="mw ma iq ms b gy mx my l mz na">def backward(self, X, y, o):<br/>        self.o_error = y - o<br/>        self.o_delta = self.o_error * self.sigmoidPrime(o)<br/>        self.z2_error = np.matmul(self.o_delta,<br/>                                  np.matrix.transpose(self.W2))<br/>        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)<br/>        self.W1 += np.matmul(np.matrix.transpose(X), self.z2_delta)<br/>        self.W2 += np.matmul(np.matrix.transpose(self.z2),<br/>                             self.o_delta)</span></pre><p id="c987" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码片段中，输出层的输出错误被计算为转发传播的预测输出与实际输出之间的差异。然后，将该误差乘以Sigmoid质数，以运行梯度下降，然后重复整个过程，直到到达输入层。最后，更新不同层之间的权重。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="60c1" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4.4:创建一个培训函数</h1><p id="751c" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">在训练期间，该算法将向前和向后运行，从而在有历元时更新权重。为了获得最精确的重量，这是必要的。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="1751" class="mw ma iq ms b gy mx my l mz na">def train(self, X, y, epochs):<br/>        for epoch in range(epochs):<br/>            o = self.forward(X)<br/>            self.backward(X, y, o)<br/>            self.error_list.append(np.abs(self.o_error).mean())</span></pre><p id="f192" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了运行向前和向后传递之外，我们还将平均绝对误差(MAE)保存到一个误差列表中，以便我们稍后可以观察平均绝对误差在训练过程中是如何发展的。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="7541" class="mw ma iq bd mb nm nn dn mf no np dp mj lf nq nr ml lj ns nt mn ln nu nv mp nw bi translated">步骤4.5:创建预测函数</h2><p id="babc" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">在训练期间对权重进行微调之后，算法就可以预测新数据点的输出了。这是通过转发过程的单次迭代来完成的。预测的输出将是一个非常接近实际输出的数字。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="9a7e" class="mw ma iq ms b gy mx my l mz na">def predict(self, x_predicted):<br/>        return self.forward(x_predicted).item()</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="6b95" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4.6:绘制平均绝对误差发展曲线</h1><p id="6542" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">有许多方法可以评估机器学习算法的质量。常用的度量之一是平均绝对误差，它应该随着历元数的增加而减小。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="3c70" class="mw ma iq ms b gy mx my l mz na">def view_error_development(self):<br/>        plt.plot(range(len(self.error_list)), self.error_list)<br/>        plt.title(<strong class="ms ir">'Mean Sum Squared Loss'</strong>)<br/>        plt.xlabel(<strong class="ms ir">'Epoch'</strong>)<br/>        plt.ylabel(<strong class="ms ir">'Loss'</strong>)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/8f3ec721c7044613a341f23fcf8fc119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5xbdmbcvx6CEHS9iF7eIig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:训练期间平均绝对误差的发展</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f80a" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤4.7:计算精确度及其组成部分</h1><p id="a905" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">真阳性、假阳性、真阴性和假阴性的数量描述了机器学习分类算法的质量。在训练神经网络之后，应该更新权重，以便算法能够准确地预测新的数据点。在二元分类任务中，这些新数据点只能是1或0。根据预测值是高于还是低于定义的限制，算法会将新条目分类为1或0。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="792b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当运行test_evaluation函数时，我们得到以下结果:</p><p id="e824" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">真阳性:2 <br/>真阴性:4 <br/>假阳性:0 <br/>假阴性:0</p><p id="7825" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">精度由以下公式给出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/843ff241eb6f1184c034748341f68a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*DkjxuwlqzCT1EvfNsIh0cQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">等式1:精确度</p></figure><p id="b1a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由此我们可以推断，我们的精度是1。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a62f" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">步骤5:运行训练和评估神经网络模型的脚本</h1><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="3bd2" class="mw ma iq ms b gy mx my l mz na">NN = NeuralNetwork()<br/>NN.train(input_train_scaled, output_train_scaled, 200)<br/>NN.predict(input_pred)<br/>NN.view_error_development()<br/>NN.test_evaluation(input_test_scaled, output_test_scaled)</span></pre><p id="8a9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了测试我们刚刚构建的神经网络类，我们将从初始化一个类型为<code class="fe ng nh ni ms b">NeuralNetwork</code>的对象开始。然后，在测试向量上测试新训练的模型之前，根据训练数据训练神经网络，以在200个时期内微调算法的权重。然后，在使用测试数据集评估模型之前，绘制误差发展图。</p><p id="0d3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://github.com/cverdence/simplennet" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上看到整个项目和代码。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d559" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">第六步:改进剧本，并发挥它</h1><p id="ee16" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">提出的代码可以很容易地修改，以处理其他类似的情况。我们鼓励读者尝试一下，改变变量，使用他们自己的数据等等。改进或改变的潜在想法包括:</p><ol class=""><li id="c56d" class="nz oa iq ky b kz la lc ld lf ob lj oc ln od lr oe of og oh bi translated">将代码一般化，使其适用于任何输入和输出大小的数据</li><li id="791e" class="nz oa iq ky b kz oi lc oj lf ok lj ol ln om lr oe of og oh bi translated">使用除平均绝对误差之外的另一种度量来监控误差发展</li><li id="e91c" class="nz oa iq ky b kz oi lc oj lf ok lj ol ln om lr oe of og oh bi translated">使用另一个缩放函数</li></ol></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="d91a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">艾丹·威尔逊。<strong class="ky ir"><em class="op"/></strong><a class="ae kv" href="https://towardsdatascience.com/inroduction-to-neural-networks-in-python-7e0b422e6c24" rel="noopener" target="_blank"><em class="op">Python中的简单神经网络(2019年10月)</em> </a> <em class="op">。</em></p></div></div>    
</body>
</html>
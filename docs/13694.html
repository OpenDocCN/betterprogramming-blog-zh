<html>
<head>
<title>Memory Bandwidth Optimized Parallel Radix Sort in Metal for Apple M1 and Beyond</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">内存带宽优化的并行基数排序在金属苹果M1和超越</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/memory-bandwidth-optimized-parallel-radix-sort-in-metal-for-apple-m1-and-beyond-4f4590cfd5d3?source=collection_archive---------8-----------------------#2022-09-17">https://betterprogramming.pub/memory-bandwidth-optimized-parallel-radix-sort-in-metal-for-apple-m1-and-beyond-4f4590cfd5d3?source=collection_archive---------8-----------------------#2022-09-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9c05" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Metal中用于原始数据类型的排序着色器</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/152792426e5f57efd349c062d47b36fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VUcUbvjBdg8RU2c3Qq9o4w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">M1形象。版权所有2022苹果公司。保留所有权利。参见<a class="ae kv" href="https://www.apple.com/newsroom/2020/11/apple-unleashes-m1/" rel="noopener ugc nofollow" target="_blank">许可证</a>了解使用限制。</p></figure><p id="f393" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并行排序是一种在大规模并行架构上广泛使用但仍然难以实现的原语。这些挑战包括不规则的内存访问模式、数据的多次传递、中间存储要求以及导致线程分歧的分支。在这个故事中，我们将在Metal中开发一个用于原始数据类型的排序着色器。</p><p id="4a48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对这些数据进行排序的自然算法选择是基数排序，因为它的总时间复杂度是<code class="fe ls lt lu lv b">O(k•n)</code>而不是基于比较的排序中的<code class="fe ls lt lu lv b">O(n•log(n))</code>，其中<code class="fe ls lt lu lv b">n</code>是值的数量，<code class="fe ls lt lu lv b">k</code>是表示最大值所需的位。基数排序是计数排序的一种形式，因此，这项工作建立在我们高效的<a class="ae kv" href="https://kieber-emmons.medium.com/efficient-parallel-prefix-sum-in-metal-for-apple-m1-9e60b974d62" rel="noopener">扫描</a>和<a class="ae kv" href="https://kieber-emmons.medium.com/optimizing-parallel-reduction-in-metal-for-apple-m1-8e8677b49b01" rel="noopener">归约</a>原语之上，以分割和分散值。</p><h1 id="fc57" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">简要背景</h1><p id="e2ef" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">文献中已经讨论了并发系统基数排序的许多变体。这些变化中的共性是计数步骤，由此确定数值序列中特定位置的数字的频率，接着是分割步骤，其中基于该数字将数值分成桶。对值中的每个位置重复这些步骤。例如，基数为2的基数排序产生数字0和1。</p><p id="8fc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对0的数量进行计数，以便可以将1移动到0之后的位置。对数字中的每个后续位置重复该过程。对于32位值，这意味着数据要经过32次传递，每次传递都由计数步骤和移动步骤组成。敏锐的读者当然会认识到，按位划分可能发生在一位上的<code class="fe ls lt lu lv b">k</code>遍或<code class="fe ls lt lu lv b">k</code>位上的一遍。在后一种情况下，计数将不再是一个值，而是每个数字的频率直方图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/016a0c9bda3a50660c5b827e7f72313c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4m5yG3f5v4typ-TwU86L3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">为了执行基数排序，对值的位值进行k次遍历(其中k是位数)。版权2022马修·基伯-埃蒙斯。保留所有权利。</p></figure><p id="afd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单说说基本词汇——位置记数法用按位值顺序排列的数字来表示数字。该数字与其位值的乘积之和等于该数。给定数字的索引是该数字在数字中的位置。数字的基数是每个位置可能的唯一位数。例如，16进制(十六进制)数可以跨越数字<code class="fe ls lt lu lv b">{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F}</code>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/994513551ec50a2afc7dd04845ed3956.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*rvuVDjEFnMcqBf7F7OFLZw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">以16为基数的数字42的表示。版权2022马修·基伯-埃蒙斯。保留所有权利。</p></figure><p id="782b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回到基数排序——在这一点上，总体算法是什么样子，以及基数排序为什么如此好地映射到并行架构，应该是相当明显的。对数字中的第一个位置执行计数排序，然后对数字中的每个位置重复执行，直到值排序完毕。I)计数以生成直方图，ii)计数的前缀扫描，以及iii)值重新排序这三个基本步骤都是去耦操作，因此很容易并行化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/eced9570fc7c8203c2c16c076853fd53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YVu9zUHDsd4wxpVqt_nS_Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">广义基数排序的实现步骤。版权2022马修·基伯-埃蒙斯。保留所有权利。</p></figure><h2 id="b845" class="mw lx iq bd ly mx my dn mc mz na dp mg lf nb nc mi lj nd ne mk ln nf ng mm nh bi translated">算法细节</h2><p id="53f7" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">据报道，基数排序的实现细节变化很大，很大程度上针对给定的架构或问题进行了优化。尽管有这些变化，基数排序只有两种基本类型:I)更常见的算法，从最低有效位(LSD)开始，向最高有效位前进；ii)不太常见的方法，从最高有效位(MSD)开始，向最低有效位前进。一如既往，细节决定成败，选择MSD或迷幻药的意义深远。</p><p id="50d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">最低有效位</strong>。给定一个数组值<code class="fe ls lt lu lv b">{a0, a1, …, an}</code>，其中<code class="fe ls lt lu lv b">n</code>是值的数量，LSD排序遍历每个位，从最低位开始，逐位划分，直到我们用完所有的位。为了在给定的通道中高效地并行划分，我们需要创建一个直方图，其中包含给定数字的频率。该直方图在输出数组中生成偏移量，用于对值进行重新排序。</p><p id="9443" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第一遍中，移动步长的相对顺序并不重要，但是在后续的遍中，重新排序必须是稳定的，这意味着必须保留先前遍中低位的相对顺序。因此，每个<code class="fe ls lt lu lv b">threadgroup</code>在计数步骤中创建自己的局部直方图。为了确定给定<code class="fe ls lt lu lv b">threadgroup</code>中给定数字的全局位置，我们在整个直方图集合上使用唯一前缀和来生成偏移量。</p><p id="f0e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://doi.org/10.1145/125826.126164" rel="noopener ugc nofollow" target="_blank">技巧</a>是将局部直方图以条状而非分块配置(即，列主顺序)存储到全局直方图阵列，以避免前缀和计算所需的转置。与局部偏移量一起，我们可以计算一个全局索引来确定在哪里放置一个给定值。对要排序的值中的每个位置重复此过程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/3a46c80578f8e4b9c1d46ed1b63e0109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X8huL9SWsuQFK19aMPLaJg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">如果线程组(本地)直方图以条带化(列主)顺序存储，简单的并行排他前缀扫描会产生全局偏移量。版权2022马修·基伯-埃蒙斯。保留所有权利。</p></figure><p id="9ae3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过整个数据的次数取决于值的大小和基数。一个32位整数在256进制中需要四次传递，在16进制中需要八次传递。这里值得一提的最后一点是，第一遍完全分散了数据，只有在最后一遍中才会出现顺序。这不同于基于比较的排序(如合并排序)，在基于比较的排序中，人们可以从接近排序的数据集早期短路。因此，从时间角度来看，基数排序更具确定性，但在某些情况下会输给合并排序。</p><p id="7eee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">最高有效位(MSD)。</strong>给定一个值数组{a0，a1，…，an}，其中n是值的个数，MSD排序也遍历每一位并逐位划分，直到我们用完所有的位。但与迷幻药不同，MSD从最高位开始。差异是深远的，因为I)每次分区都会产生更多排序的数据，因为每次循环都会将值移动到更小的桶中，以及ii)从给定桶移出的移动不需要相对于彼此稳定。</p><p id="335c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，在对32位值的基数为256的MSD排序中，值的前8位被屏蔽并计数，以生成256个桶的单个全局直方图。为了完成传递，值被移动到它们各自的桶中。下一步通过执行相同的步骤对每个单独的桶进行排序，以此类推，直到所有子桶都被递归排序。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/43998b634430e9e37b188da897224822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_tb3PoWhhyYt3uaAjmvbmg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在MSD排序中，概念与LSD排序相同，但是移动不需要在给定桶内保持顺序。版权2022马修·基伯-埃蒙斯。保留所有权利。</p></figure><p id="5b75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为直方图是每个桶而不是每个<code class="fe ls lt lu lv b">threadgroup</code>的，所以原子计数器通常用于计算桶中的值。这些操作是高度并行的，但这也意味着对越来越小的存储桶进行排序，并维护一个存储桶大小的树。此外，尽管Apple Silicon上的原子操作效率很高，但这些操作仍然会有争用。最后，每个子桶中值的数量是可变的，这给GPU上的编码带来了挑战。可以采用各种策略来克服这一挑战。例如，<a class="ae kv" href="https://doi.org/10.1145/3035918.3064043" rel="noopener ugc nofollow" target="_blank">斯蒂赫勒和雅各布森</a>使用了一种混合方法，其中小桶被合并并直接在单个<code class="fe ls lt lu lv b">threadgroup</code>中排序，而大桶被递归排序。</p><h2 id="c4fc" class="mw lx iq bd ly mx my dn mc mz na dp mg lf nb nc mi lj nd ne mk ln nf ng mm nh bi translated">内存注意事项</h2><p id="0cfb" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">不考虑LSD或MSD，Metal中一个设计合理的基数排序最低限度要求每次从全局内存移动<code class="fe ls lt lu lv b">3n</code>数据的下限。这使得基数排序内存带宽密集。虽然这种内存带宽密度意味着每次使用更大的基数来排序更多的位，但这也有其自身的问题。在LSD排序中，直方图存储按照<code class="fe ls lt lu lv b">2^r</code>的因子增加，其中<code class="fe ls lt lu lv b">r</code>是基数。</p><p id="ffc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，线程组本身必须在创建期间维护自己的本地直方图，这意味着共享内存也会限制r的大小并影响占用率。在MSD排序中，较小的基数意味着更深的直方图树，而较大的基数意味着更宽的树。虽然有机会合并存储桶并在MSD本地完成小型存储桶，但这些因素也限制了占用率，因为任务要么通过提交许多运行小型数据的内核来完成，要么通过内核内的分支来完成。</p><p id="c2d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更好地权衡利弊，我们将深入分析LSD排序的存储和带宽要求，作为<code class="fe ls lt lu lv b">radix</code>、<code class="fe ls lt lu lv b">threadgroup</code>和问题大小的函数。</p><p id="82ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">全局存储。</strong> LSD排序是一种本质上不合适的算法，需要一个长度为<code class="fe ls lt lu lv b">n</code>的辅助数组。第二辅助阵列用于存储直方图。我们算法中的每个<code class="fe ls lt lu lv b">threadgroup</code>都创建了自己的直方图。因此，直方图存储需要一个长度为</p><p id="7976" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">(n + p − 1) / (p × 2^k)</code></p><p id="0ad9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<code class="fe ls lt lu lv b">n</code> =元素数量，<code class="fe ls lt lu lv b">p</code> =处理器数量(每个<code class="fe ls lt lu lv b">threadgroup</code>的线程数)，而<code class="fe ls lt lu lv b">k</code> =位数。注意这里的<code class="fe ls lt lu lv b">k</code>不是一个元素的总位数，而是表示给定基数所需的位数，即<code class="fe ls lt lu lv b">log2(radix) = k</code>，所以base-256要求每个元素8位。这</p><p id="952f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">(n + p − 1) / p</code></p><p id="4787" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">term简单地表示了<code class="fe ls lt lu lv b">threadgroup</code>的数量，因此存储与数据的大小成比例增加，与基数的<code class="fe ls lt lu lv b">log2</code>成指数增加。请注意，增加<code class="fe ls lt lu lv b">threadgroup</code>中每个线程的工作(即，用<code class="fe ls lt lu lv b">v × p</code>替换<code class="fe ls lt lu lv b">p</code>，其中<code class="fe ls lt lu lv b">v</code>是每个处理器的值的数量)会按比例减少直方图数组的大小。</p><p id="2580" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">全局内存访问。如前所述，每次分拣都包括三个步骤。首先是计数步骤，从全局存储器(<code class="fe ls lt lu lv b">n</code>)中读取每个值，并将数字计数的直方图写成</strong></p><p id="7679" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">(n + p − 1) /( p × 2^k)</code></p><p id="35ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，确定计数的并行前缀和。我们的<a class="ae kv" href="https://kieber-emmons.medium.com/efficient-parallel-prefix-sum-in-metal-for-apple-m1-9e60b974d62" rel="noopener">有效前缀总和</a>总体上是<code class="fe ls lt lu lv b">~3n</code>，因此这里的扫描步骤贡献了大约</p><p id="9753" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">3 × (n + p − 1) / (p × 2^k)</code></p><p id="99b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，重新排序步骤读取每个值和扫描的直方图，并将这些值分散到全局内存so中</p><p id="a689" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">2n + (n + p − 1) / (p × 2^k)</code></p><p id="4397" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，全局访问的数量大约为</p><p id="a326" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">3n + 5(n + p − 1) / (p × 2^k)</code></p><p id="06ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每张通行证。遍数是每个元素的k位除以每遍的<code class="fe ls lt lu lv b">k</code>位，因此总存储器访问数是<code class="fe ls lt lu lv b">k(element)/k(pass)</code>与每遍访问数的乘积。</p><p id="d2be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来比较一下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/1f28187ff6c414508ce15b24783e2ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JMdeSFsG0q8Jcg5WX-nGdQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">32位值基数排序访问全局内存的理论次数，作为基数和每个线程组总值的函数(即每个线程组的线程数×每个线程的值)。Base-256是最佳的，因为它平衡了2^k.图像Matthew Kieber-Emmons的直方图存储的通过次数(4 ),版权所有。</p></figure><p id="b2ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">很明显，对于32位值，最适合的基数是256。超过该值后，随着直方图数组在全局存储中占据主导地位，指数<code class="fe ls lt lu lv b">O(2^k)</code>项会爆炸式增长。增加每个<code class="fe ls lt lu lv b">threadgroup</code>的工作会产生超过某个点的递减回报:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/779cb7ba0206bc7175e3619c43dda2fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rcUoXocyM6Af_lpUOaUpwQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">每个线程对32位值作为函数值进行基数为256的基数排序时访问全局内存的理论次数。随着每个线程的值的增加，全局内存访问次数趋向于12n的下限(4遍×每遍3n次访问)。图片Matthew Kieber-Emmons，版权所有。</p></figure><p id="0326" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这表明我们调优的起点将是基数为256，每个线程有四个值。它还强调了内存带宽在基数排序计算中的主导地位。这强烈表明，像第一步由<code class="fe ls lt lu lv b">threadgroup</code>排序和存储的<a class="ae kv" href="https://hal.archives-ouvertes.fr/hal-00596730" rel="noopener ugc nofollow" target="_blank"> Helluy </a>这样的方法是不受欢迎的。</p><p id="b071" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相比之下，如果可以在Metal中实现去耦后视扫描内核，那么耦合直方图和解耦后视的方法(<a class="ae kv" href="https://arxiv.org/pdf/2206.01784.pdf" rel="noopener ugc nofollow" target="_blank">one sweep by Adinets and Merrill</a>)会更快，不幸的是，目前还不能做到这一点。</p><h2 id="ab5b" class="mw lx iq bd ly mx my dn mc mz na dp mg lf nb nc mi lj nd ne mk ln nf ng mm nh bi translated">优化目标</h2><p id="2f29" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">这个故事将集中在实现一个有效的最低有效位(LSD)基数排序。MSD基数排序仍然是读者的一个练习。我们的问题域将是更大的数据集(&gt; 100M 32位值)，以确保我们对计算核心和内存带宽都有压力。这里值得再次注意的是，最有效的基数排序算法取决于上下文；我们的LSD排序不是为小数组或8位数据类型构建的最快的排序，因为它是为更大的数据类型或数组设计的。这个故事在很大程度上建立在先前关于<a class="ae kv" href="https://kieber-emmons.medium.com/optimizing-parallel-reduction-in-metal-for-apple-m1-8e8677b49b01" rel="noopener"> reduce </a>和<a class="ae kv" href="https://kieber-emmons.medium.com/efficient-parallel-prefix-sum-in-metal-for-apple-m1-9e60b974d62" rel="noopener"> scan </a>并行原语的故事中的概念和代码之上，鼓励读者首先理解这些概念。</p><p id="a1e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">全局算法。</strong>如上所述，我们的算法将对32位值进行32/k次遍历，每次遍历都对<code class="fe ls lt lu lv b">k</code>位进行排序。每一遍将由直方图-扫描-重新排序步骤组成，在最好的情况下，每一遍从全局内存产生<code class="fe ls lt lu lv b">~3n</code>数据移动。但是正如所讨论的，这确实是过于乐观的近似情况。</p><p id="c4e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个基数为256的基数排序，每个线程有256个线程，每个线程有4个值，从全局移动大约4.25n次。仅考虑数据移动，例如给定M1 58gb/秒的内存带宽，我们理论上的最大排序速率将是大约每秒8.5亿个32位值(58gb/秒÷ 17次全局内存访问= 3.4 GB/秒；每个值4字节产生0.85 G值/秒)。与reduce或scan原语不同，我们可以想象编写以架构的全带宽运行的原语，但我们不会达到这个速率，我认为这个速率的1/3或大约250–300M值/秒是一个完全可以接受的目标。</p><p id="7b69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">原因是I)排序具有非平凡的算术强度，因此需要强大的计算来使如此大的总线饱和；ii)流水线状态切换很快但不为零，因为每一遍都需要直方图内核、前缀扫描步骤中的归约和扫描内核以及重新排序内核。此外，这些可能需要依赖于n的大小的边界检查变量，因此更多的流水线状态改变。虽然这些状态都将被预编译，但仍然需要一些GPU/CPU往返时间来编码这项工作和状态切换以执行这项工作。</p><h2 id="8658" class="mw lx iq bd ly mx my dn mc mz na dp mg lf nb nc mi lj nd ne mk ln nf ng mm nh bi translated">内核实现</h2><p id="2f0e" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated"><strong class="ky ir">直方图。</strong>直方图内核琐碎。我们将数据从全局内存加载到寄存器中，迭代这些值，并自动更新<code class="fe ls lt lu lv b">threadgroup</code>(共享)内存中的局部直方图数组，然后将该数组以条带格式存储到全局内存中。</p><pre class="kg kh ki kj gt nl lv nm bn nn no bi"><span id="74d8" class="np lx iq lv b be nq nr l ns nt">template&lt;ushort BLOCK_SIZE,<br/>         ushort GRAIN_SIZE,<br/>         ushort RADIX, <br/>         typename T&gt; kernel void<br/>MakeHistogramOfPlaceValuesKernel(device uint* output_data,<br/>                                 device const T* input_data,<br/>                                 constant uint&amp; n,<br/>                                 constant uint&amp; current_digit,<br/>                                 uint group_id  <br/>                              [[threadgroup_position_in_grid]],<br/>                                 uint grid_size <br/>                                    [[threadgroups_per_grid]],<br/>                                 ushort local_id <br/>                               [[thread_position_in_threadgroup]]) {<br/>  // catch template parameter errors at compile time<br/>  static_assert(BLOCK_SIZE &gt;= RADIX, <br/>    "ERROR - BLOCK_SIZE must be greater than or equal to RADIX");<br/>  uint base_id = group_id * BLOCK_SIZE * GRAIN_SIZE;<br/>  // load data into registers<br/>  T values[GRAIN_SIZE];<br/>  LoadBlockedLocalFromGlobal(values, <br/>                             &amp;input_data[base_id], <br/>                             local_id);<br/>  // zero out the shared memory<br/>  threadgroup uint histogram[RADIX];<br/>  if (local_id &lt; RADIX) histogram[local_id] = 0;<br/>  threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  // iterate over values to update the histogram using an atomics<br/>  volatile threadgroup atomic_uint* atomic_histogram =   <br/>    reinterpret_cast&lt;volatile threadgroup atomic_uint*&gt;(histogram);<br/>  for (ushort i = 0; i &lt; GRAIN_SIZE; i++){<br/>    uchar key = ValueToKeyAtDigit&lt;RADIX&gt;(values[i], current_digit);<br/>    atomic_fetch_add_explicit(&amp;atomic_histogram[key], <br/>                              1, <br/>                              memory_order_relaxed);<br/>  }<br/>  threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  // store histogram to global in column major format (striped)<br/>  if (local_id &lt; RADIX){<br/>    output_data[grid_size * local_id + group_id] = <br/>      histogram[local_id];<br/>  }<br/>}</span></pre><p id="06c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上所述，对每个<code class="fe ls lt lu lv b">threadgroup</code>直方图使用条纹输出格式允许通过在整个全局数组上使用简单的排他前缀和来确定全局偏移。为了简单起见，我删除了边界检查代码，这意味着这个内核只能在数组上运行，其中<code class="fe ls lt lu lv b">n</code>是每个<code class="fe ls lt lu lv b">threadgroup</code>的线程数的倍数。<code class="fe ls lt lu lv b">LoadBlockedLocalFromGlobal</code>请参见此处的<a class="ae kv" href="https://kieber-emmons.medium.com/efficient-parallel-prefix-sum-in-metal-for-apple-m1-9e60b974d62" rel="noopener"/>。为了更简单，我将<code class="fe ls lt lu lv b">BLOCK_SIZE</code>限制为大于或等于<code class="fe ls lt lu lv b">RADIX</code>，并用<code class="fe ls lt lu lv b">static assert</code>强制执行。这极大地简化了reorder内核，但是如果希望用如下的循环替换<code class="fe ls lt lu lv b">local_id &lt; RADIX</code>测试，这里接受任何大小的<code class="fe ls lt lu lv b">BLOCK_SIZE</code>都是微不足道的:</p><pre class="kg kh ki kj gt nl lv nu nv aw nw bi"><span id="cbfb" class="mw lx iq lv b gy nx ny l nz nt">for (ushort i = 0; i &lt; (RADIX+BLOCK_SIZE-1)/BLOCK_SIZE; i++) {<br/>  if (local_id + i * BLOCK_SIZE &lt; RADIX) {<br/>    histogram[local_id + i * BLOCK_SIZE] = 0;<br/>  }<br/>}</span></pre><p id="da0b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为<code class="fe ls lt lu lv b">BLOCK_SIZE</code>和<code class="fe ls lt lu lv b">RADIX</code>在编译时是已知的，所以这个固定循环将展开。等效回路也将取代输出测试线。您可能感兴趣的一个函数是屏蔽函数<code class="fe ls lt lu lv b">ValueToKeyAtDigit</code>，它接受一个值、一个数字和一个基数(radix)作为模板参数，并返回用于索引直方图的屏蔽(key)。简化代码如下:</p><pre class="kg kh ki kj gt nl lv nm bn nn no bi"><span id="405c" class="np lx iq lv b be nq nr l ns nt">template &lt;ushort RADIX, typename T&gt; static inline ushort<br/>ValueToKeyAtBit(T value, ushort current_bit){<br/>  return (value &gt;&gt; current_bit) &amp; (RADIX - 1);<br/>}<br/>template &lt;ushort RADIX&gt; static inline ushort<br/>ValueToKeyAtBit(int32_t value, ushort current_bit){<br/>  return ( (as_type&lt;uint32_t&gt;(value) ^ (1U &lt;&lt; 31)) &gt;&gt; current_bit) &amp; (RADIX - 1);<br/>}<br/>template &lt;ushort RADIX, typename T&gt; static inline ushort<br/>ValueToKeyAtDigit(T value, ushort current_digit){<br/>  ushort bits_to_shift = RadixToBits(RADIX) * current_digit;<br/>  return ValueToKeyAtBit&lt;RADIX&gt;(value, bits_to_shift); <br/>}</span></pre><p id="c915" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为除了无符号整数之外，我们还想处理32位有符号整数，所以我们必须处理这些情况，因为在缺少符号位之后，符号位会被排序。在有符号整数的情况下，我们使用逐位<code class="fe ls lt lu lv b">XOR</code>(异或<code class="fe ls lt lu lv b"> OR</code>，即<code class="fe ls lt lu lv b">^</code>)在移位前翻转符号位。该掩码用于索引到本地直方图数组中，并且该桶中的计数自动递增。</p><p id="a363" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">直方图内核很快，但达不到内存速度。在base-256中，内核高度依赖于每个线程的值参数，最大化接近每秒10 G的值，这意味着大约40–45 GB/秒的内存带宽。在base-16中，这种对每个线程的值的强烈依赖消失了，每个线程4–16个值总是产生大于10G的值/秒。我查看了<code class="fe ls lt lu lv b">BLOCK_SIZE</code>参数(数据未显示)，256是最好的，这是相当典型的，因此我们不会进一步优化这个参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/78d8d07d5a9e2be3e737f973e5c37162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fYMM_WIXSRjwA4hUKT1IBg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">M1上32位无符号整数的内核吞吐量和有效带宽的直方图，作为每个线程值的函数(<code class="fe ls lt lu lv b">BLOCK_SIZE</code> = 256)。基准测试是在配有8 GB内存和256 GB固态硬盘的M1 Mac Mini上进行的。在操作系统优化级别编译的代码，代表25次试验的平均值。图片Matthew Kieber-Emmons，版权所有。</p></figure><p id="3f1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一种替代方法可以生成值的直方图，这种方法在对值进行排序后会更快。给定一个排序的数组，可以生成一个头标志数组(片段是相同掩码的游程)。分段扫描或包含“最大”扫描可用于将段头线程id传播到段尾线程。</p><p id="cfde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尾线程索引和头线程索引之间的差异是特定掩码的计数。这个过程很快，但是，当然，需要排序的值，这在全局数组排序之前是很慢的。总之，对本地<code class="fe ls lt lu lv b">threadgroup</code>值进行排序，然后使用这种替代算法来确定直方图，比只对未排序的数据使用原子计数器慢大约4倍。尽管如此，这种替代算法在下面的重新排序内核中是有用的，在这里我们首先进行局部排序，然后进行全局分散。</p><p id="8e01" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">前缀求和。</strong>因为我之前的<a class="ae kv" href="https://kieber-emmons.medium.com/efficient-parallel-prefix-sum-in-metal-for-apple-m1-9e60b974d62" rel="noopener">故事</a>讨论了Apple Silicon上的金属扫描原语的细节，读者可以在那里了解更多细节。我们的前缀和代码具有较低的算术强度，对全局内存进行<code class="fe ls lt lu lv b">~3n</code>访问，并显示在M1的内存带宽限制下进行。换句话说，它很快，你不会再从中挤出更多的时间。关于LSD基数排序过程中的前缀求和步骤，唯一需要考虑的是<a class="ae kv" href="https://dl.acm.org/doi/10.1145/321812.321815" rel="noopener ugc nofollow" target="_blank">布伦特定理</a>与基于整体全局内存访问选择的基数的关系。</p><p id="84fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，如果在base-256中执行排序，每个线程有256个线程，每个线程有一个值，那么直方图数组的大小等于或大于要排序的原始数组的大小！随着每个线程的值的数量增加，直方图数组按比例减少，因为每个<code class="fe ls lt lu lv b">threadgroup</code>只维护一个直方图。因此，很明显，利用每个线程更多的工作将会大大减少这一步的工作量。</p><p id="4069" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">重新排序。</strong>直方图数组的前缀和由<code class="fe ls lt lu lv b">threadgroup</code>表示，是存储每个唯一值的全局偏移量。移动必须是稳定的，这意味着产生相同掩码的值的移动尊重相对于彼此的顺序。这一点很重要，否则在对高位进行排序时，低位的排序将无法保留。这是我们的算法:</p><pre class="kg kh ki kj gt nl lv nm bn nn no bi"><span id="85e7" class="np lx iq lv b be nq nr l ns nt">template&lt;ushort BLOCK_SIZE, ushort GRAIN_SIZE, ushort RADIX, <br/>         typename T&gt; <br/>kernel void<br/>ReorderByPlaceValuesKernel(device T* output_data,<br/>                           device const T* input_data,<br/>                           constant uint&amp; n,<br/>                           device const uint* offsets_data,<br/>                           constant uint&amp; current_digit,<br/>                           uint group_id<br/>                             [[threadgroup_position_in_grid]],<br/>                           uint grid_size<br/>                             [[threadgroups_per_grid]],<br/>                           ushort local_id<br/>                             [[thread_position_in_threadgroup]]) {<br/>  uint base_id = group_id * BLOCK_SIZE * GRAIN_SIZE;<br/>  // 1) load data into registers<br/>  T values[GRAIN_SIZE];<br/>  LoadStripedLocalFromGlobal(values, <br/>                             &amp;input_data[base_id], <br/>                             local_id,  <br/>                             BLOCK_SIZE);<br/>  // 2) sort striped values by threadgroup<br/>  threadgroup uint shared_data[BLOCK_SIZE];<br/>  for (ushort i = 0; i &lt; GRAIN_SIZE; i++){<br/>    values[i] = PartialRadixSort&lt;BLOCK_SIZE, T, RADIX&gt;(values[i], <br/>                                                      shared_data, <br/>                                                       local_id,<br/>                                                   current_digit);<br/>  }<br/>  threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  // 3) load the global histogram into shared memory by digit<br/>  threadgroup uint global_offset[RADIX];<br/>  if (local_id &lt; RADIX){<br/>    global_offset[local_id] = <br/>      offsets_data[grid_size * local_id + group_id];<br/>  }<br/>  threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  // 4) create local histogram to make global indexes<br/>  uint indexes[GRAIN_SIZE];<br/>  for (ushort i = 0; i &lt; GRAIN_SIZE; i++){<br/>    // local offset by scan of head flags of the range of digits<br/>    uchar key = ValueToKeyAtDigit&lt;RADIX&gt;(values[i],  <br/>                                         current_digit);<br/>    uchar flag = FlagHeadDiscontinuity&lt;BLOCK_SIZE&gt;(key,<br/>                reinterpret_cast&lt;threadgroup uchar*&gt;(shared_data), <br/>                                                   local_id);<br/>    ushort local_offset = local_id - <br/>ThreadgroupPrefixScanRaking&lt;BLOCK_SIZE, SCAN_TYPE_INCLUSIVE&gt;(<br/>                                flag ? (ushort)local_id (ushort)0,<br/>               reinterpret_cast&lt;threadgroup ushort*&gt;(shared_data),<br/>                                                         local_id,<br/>                                                      MaxOp&lt;T&gt;());<br/>    indexes[i] = local_offset + global_offset[key];<br/>    threadgroup_barrier(mem_flags::mem_threadgroup);<br/>    flag = FlagTailDiscontinuity&lt;BLOCK_SIZE&gt;(key,<br/>                reinterpret_cast&lt;threadgroup uchar*&gt;(shared_data), <br/>                                             local_id);<br/>    if (flag){<br/>      global_offset[key] += local_offset + 1;<br/>    }<br/>    threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  }<br/>  // 5) scatter to global<br/>  for (ushort i = 0; i &lt; GRAIN_SIZE; i++){<br/>    output_data[indexes[i]] = values[i];<br/>  }<br/>}</span></pre><p id="63b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了保持值的相对顺序以使重新排序稳定，我们以条带格式而不是块格式将值加载到寄存器中。该代码是对阻塞负载的一个小修改:</p><pre class="kg kh ki kj gt nl lv nu nv aw nw bi"><span id="4f4a" class="mw lx iq lv b gy nx ny l nz nt">// non-bounds checking version of striped load into registers<br/>template&lt;ushort LENGTH, typename T&gt; static void<br/>LoadStripedLocalFromGlobal(thread T (&amp;value)[LENGTH],<br/>                           const device T* input_data,<br/>                           const ushort local_id,<br/>                           const ushort local_size) {<br/>  for (ushort i = 0; i &lt; LENGTH; i++){<br/>    value[i] = input_data[local_id + i * local_size];<br/>  }<br/>}</span></pre><p id="fba8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们对当前数字执行部分基数排序，如下所示:</p><pre class="kg kh ki kj gt nl lv nm bn nn no bi"><span id="05c0" class="np lx iq lv b be nq nr l ns nt">template &lt;ushort BLOCK_SIZE, typename T, ushort RADIX&gt; static T<br/>PartialRadixSort(const T value, <br/>                 threadgroup uint* shared, <br/>                 const ushort local_id,<br/>                 const ushort current_digit) {<br/>  T result = value;<br/>  ushort current_bit = current_digit * RadixToBits(RADIX);<br/>  const ushort last_bit = min(current_bit + RadixToBits(RADIX), <br/>                              (ushort)sizeof(T) * 8);<br/>  while (current_bit &lt; last_bit) {<br/>    if (last_bit - current_bit &gt; 1) {<br/>      result = SortByTwoBits&lt;BLOCK_SIZE&gt;(result, <br/>                                         shared, <br/>                                         local_id, <br/>                                         current_bit);<br/>      current_bit += 2;<br/>    } else {<br/>      result = SortByBit&lt;BLOCK_SIZE&gt;(result,  <br/>                                     shared, <br/>                                     local_id, <br/>                                     current_bit);<br/>      current_bit += 1;<br/>    }<br/>  }<br/>  return result;<br/>}</span></pre><p id="b3ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于Apple已经提供了四分量向量类型，我们可以利用这一点来执行四路排序，这减少了本地传递的数量，并在需要时进行最后一次传递来排序剩余的位。这一策略源于Ha、Krüger和Silva的工作，但在算法的细节上有所不同。我们的四路功能<code class="fe ls lt lu lv b">SortByTwoBits</code>如下:</p><pre class="kg kh ki kj gt nl lv nm bn nn no bi"><span id="f06b" class="np lx iq lv b be nq nr l ns nt">template &lt;ushort BLOCK_SIZE, typename T&gt; static T<br/>SortByTwoBits(const T value, <br/>              threadgroup uint* shared, <br/>              const ushort local_id, <br/>              const uchar current_bit) {<br/>  <br/>  uchar mask = ValueToKeyAtBit&lt;4&gt;(value, current_bit);<br/>  // 4-way scan<br/>  uchar4 partial_sum;<br/>  uchar4 scan = {0};<br/>  scan[mask] = 1;<br/>  scan = ThreadgroupPrefixScan&lt;BLOCK_SIZE, SCAN_TYPE_EXCLUSIVE&gt;<br/>                     (scan,<br/>                      &amp;partial_sum,<br/>                      reinterpret_cast&lt;threadgroup uchar4*&gt;(shared),<br/>                      local_id,<br/>                      SumOp&lt;T&gt;());<br/>  // make offsets from unrolled prefix sum of the partial sums<br/>  ushort4 offset;<br/>  offset[0] = 0;<br/>  offset[1] = offset[0] + partial_sum[0];<br/>  offset[2] = offset[1] + partial_sum[1];<br/>  offset[3] = offset[2] + partial_sum[2];  <br/>  shared[scan[mask] + offset[mask]] = value;<br/>  threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  // read new value from shared<br/>  T result = shared[local_id];<br/>  threadgroup_barrier(mem_flags::mem_threadgroup);<br/>  return result;<br/>}</span></pre><p id="10bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该算法将当前位的值屏蔽为基数为4的值，构建一个标志数组来表示给定值的存在，并计算标志的排他前缀和以生成索引，其中<code class="fe ls lt lu lv b">index = scan[mask] + offset[max]</code>。这些索引将值按排序顺序放在共享内存中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/9bc390b39076d785c24f6b5ead129de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*74yeZzQ9PzQ5vq0uC2bgCA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的四路排序算法的图形描述。图片Matthew Kieber-Emmons，版权所有。</p></figure><p id="5ff0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">迭代一个数中给定位置的所有位，对该位置进行排序。用<code class="fe ls lt lu lv b">n &gt; 4</code>执行这种<code class="fe ls lt lu lv b">n</code>方式很难，原因有几个，其中最大的原因是Metal只支持最多4个分量的向量。但是，即使Metal支持更大的向量，比如像我们在OpenCL 1.2中那样通过8路或16路向量来一次按3位和4位排序，它也可能没有什么帮助，因为SIMD组中的各个线程可能本来就是标量的。此外，很可能在执行单元中存在某种专有的SIMT魔法，因此不清楚向量操作是否以及如何被矢量化以利用执行单元。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/8b44caa4eb25d0bc83a41a69848ea780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O010vD8eJ5E_ep4i1Wv9MA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">根据每个线程的值对32位无符号整数的内核吞吐量和M1上的有效带宽进行重新排序(<code class="fe ls lt lu lv b">BLOCK_SIZE</code> = 256)。基准测试是在配有8 GB内存和256 GB固态硬盘的M1 Mac Mini上进行的。在操作系统优化级别编译的代码，代表25次试验的平均值。图片Matthew Kieber-Emmons，版权所有。</p></figure><p id="db40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个核比直方图核慢得多。在base-256中，性能峰值为每线程4个值，每秒约1.3千兆样本，相当于约5gb/秒的带宽。我注意到在每个线程四个值的情况下，内核占用率只有60%,值越大越低，情况越糟。没有达到最大理论占用率本身并不一定是个问题，但是值得深入研究一下，看看是什么原因导致内核这样调度，特别是因为这是一个非常耗时的内核。</p><p id="f1b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于来自CUDA的人来说，Xcode(截至撰写本文时)并不像NSight那样显示SIMD组(warp)占用信息，因此很难考虑线程组内的不平衡工作负载、尾部效应和部分最后一波。但是，Metal API也简单得多，所以这种权衡是值得的，因为在内核调度期间更容易做正确的事情。</p><p id="9884" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在运行缓慢的内核中，首先要寻找的是寄存器压力和共享内存的使用，这是限制占用率的因素。M1有一个特别大的寄存器文件(根据<a class="ae kv" href="https://rosenzweig.io/blog/asahi-gpu-part-3.html" rel="noopener ugc nofollow" target="_blank">该</a>分析为4.875 MiB)，它转化为每个<code class="fe ls lt lu lv b">threadgroup</code>256个线程可用的&gt; 256个寄存器。我们的内核编译到28个寄存器，所以我们远远低于限制。<code class="fe ls lt lu lv b">Threadgroup</code>(共享)内存使用可通过<code class="fe ls lt lu lv b">MTLComputeCommandEncoder</code>对象上的<code class="fe ls lt lu lv b">setThreadgroupMemoryLength:atIndex:</code>在命令编码时设置。</p><p id="c24b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相反，我们选择在内核中使用共享数组的静态实例化，因为对我来说，这样更容易，所以我们通过<code class="fe ls lt lu lv b">MTLComputePipelineState</code>对象的<code class="fe ls lt lu lv b">staticThreadgroupMemoryLength</code>属性进行查询。在每个线程组有256个线程的base-256中，我们的内核使用2 KB的<code class="fe ls lt lu lv b">threadgroup</code>内存。在这种情况下，我们可以只添加它，但我可以想象编译器有时可能会优化一些东西，所以最好不要猜测，只使用API来检查。</p><p id="bf33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给定在<a class="ae kv" href="https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf" rel="noopener ugc nofollow" target="_blank"> Apple8/Mac2系列设备</a>上的32 KB <code class="fe ls lt lu lv b">threadgroup</code>内存限制，这意味着我们可以同时运行16个<code class="fe ls lt lu lv b">threadgroup</code>，在M1上最多可以运行24个<code class="fe ls lt lu lv b">threadgroup</code>(苹果引用的1024个线程× 24组= 24，576个线程<a class="ae kv" href="https://web.archive.org/web/20201110184757/https://www.apple.com/mac/m1/" rel="noopener ugc nofollow" target="_blank">，因此这反映了占用率问题(66%)。但是，将基数降低到基数32，将对<code class="fe ls lt lu lv b">threadgroup</code>内存的需求降低到1152 B，并不会增加占用率，因此我们需要查看指令本身，因为<code class="fe ls lt lu lv b">threadgroup</code>内存不是真正的问题。</a></p><p id="1411" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用XCode捕获工具来查看着色器统计数据，重新排序算术指令支配着内核。考虑数字中所有位的循环，每次循环对数字进行前缀求和以划分数据。内核执行时间一半以上是ALU指令，大致四分之一是同步。因此，我们的内核是计算受限的，这就是为什么它需要一些时间，因为我们几乎达到了ALU限制器的70%。如果我们想要一个更快的重新排序步骤，我们需要重新思考并开发一个替代算法。</p><p id="8a89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">基数排序程序。</strong>我们终于拥有了组装高性能带宽优化LSD基数排序的所有部件。这是结果。我们表现如何？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/4344fe1dc62bea4c61cf6e1a03a8b78f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SPfFvsWdODXgXouVJKHh8Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">均匀随机32位无符号整数的基数排序吞吐量。基准测试是在配有8 GB内存和256 GB固态硬盘的M1 Mac Mini上进行的。在操作系统优化级别编译的代码，代表25次试验的平均值。图片Matthew Kieber-Emmons，版权所有。</p></figure><p id="1213" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们做得很好！对于32位无符号整数，我们每秒处理大约3.64亿个键。这算出带宽为1.42 GB/秒，是理论值的43%。使用8位无符号整数，这些内核可以实现每秒13.2亿个密钥。虽然这可能是一个不公平的比较，但这比<code class="fe ls lt lu lv b">std::sort</code>的introsort算法快得多，它达到了43 MSamp/sec，并且本身比Accelerate库的<code class="fe ls lt lu lv b">vDSP_sort</code>函数甚至C stdlib <code class="fe ls lt lu lv b">qsort</code>都快。我考虑过为M1编写一个手动调整的多线程基数排序，但决定它不会与GPU竞争，所以真的没有意义。</p><h1 id="7e6c" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">结论</h1><p id="ddef" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">我们对全局内存访问的理论分析和一些早期测试表明，LSD基数排序的32位整数在M1上的最佳位置是base-256，每个线程组有256个线程。因此，每个线程的值的数量实际上是唯一可调整的参数。最大占用率和最大排序率是通过每个线程四个值来实现的。很难看出哪里还能获得额外的性能；我会对你的想法感兴趣。</p><p id="c451" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">源代码在<a class="ae kv" href="https://gist.github.com/kieber-emmons/7c30e2ba3e02da30bbb44baee6bada39#file-parallelradixsort-metal" rel="noopener ugc nofollow" target="_blank">我的要诀</a>中。感谢阅读！</p></div></div>    
</body>
</html>
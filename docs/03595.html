<html>
<head>
<title>Scanning Credit Cards with Computer Vision on iOS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在iOS上用计算机视觉扫描信用卡</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/scanning-credit-cards-with-computer-vision-on-ios-c3f4d8912de4?source=collection_archive---------3-----------------------#2020-02-20">https://betterprogramming.pub/scanning-credit-cards-with-computer-vision-on-ios-c3f4d8912de4?source=collection_archive---------3-----------------------#2020-02-20</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><h2 id="d243" class="ip iq ir bd b dl is it iu iv iw ix dk iy translated" aria-label="kicker paragraph">计算机视觉</h2><div class=""/><div class=""><h2 id="1e6d" class="pw-subtitle-paragraph jx ja ir bd b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dk translated">利用Vision的矩形检测和文本识别器来检测实时摄像头馈送中的信用卡和其他名片</h2></div><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj kp"><img src="../Images/aca862514a2e3f89a81f711beac1aff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-983-gQIRVLRCdML"/></div></div><p class="lb lc gk gi gj ld le bd b be z dk translated">由<a class="ae lf" href="https://unsplash.com/@alesnesetril?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Ales Nesetril </a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="e86a" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">自iPhone问世以来，摄影一直是苹果的核心关注点。多年来，他们已经发布了令人惊叹的新功能，让这个世界成为一个没有iPhone就很难生活的地方。由于苹果公司稳步增加的最先进的图像智能功能，用户能够捕捉越来越好的照片。</p><p id="699c" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">具体来说，苹果一直在计算机视觉领域进行大量投资，通过其2017年发布的视觉框架每年推出重大更新。</p><p id="13f2" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">凭借人脸检测、物体跟踪、<a class="ae lf" href="https://medium.com/r?url=https%3A%2F%2Fheartbeat.fritz.ai%2Fcomputer-vision-in-ios-determine-the-best-facial-expression-in-live-photos-452a2eaf6512" rel="noopener">捕捉质量</a>和<a class="ae lf" href="https://heartbeat.comet.ml/compute-image-similarity-using-computer-vision-in-ios-75b4dcdd095f" rel="noopener ugc nofollow" target="_blank">图像相似度</a>功能，苹果一直在让移动开发者能够集成复杂的计算机视觉算法，以构建基于人工智能的照片应用。</p><p id="5741" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">在WWDC 2019新发布的产品中，Vision的<a class="ae lf" href="https://venturebeat.com/2020/01/23/kneron-raises-40-million-to-grow-edge-ai-chip-design-operations/" rel="noopener ugc nofollow" target="_blank">文本识别</a>和<a class="ae lf" href="https://medium.com/better-programming/cropping-areas-of-interest-using-vision-in-ios-e83b5e53440b" rel="noopener">显著性</a>功能脱颖而出。</p><p id="2554" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">但是这不是我们在这篇文章中的目的。</p><h1 id="8ea2" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">我们的目标</h1><ul class=""><li id="5e7d" class="mu mv ir li b lj mw lm mx lp my lt mz lx na mb nb nc nd ne bi translated">这件作品的想法是深入挖掘视觉的<strong class="li jb">矩形检测</strong>要求。</li><li id="53cd" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated">我们将探索<code class="fe nk nl nm nn b">VNDetectRectanglesRequest</code>的各种可能配置。</li><li id="2624" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated">在本文的整个过程中，我们将开发一个应用程序，该应用程序可以扫描信用卡或其他类似尺寸的名片，并从应用程序的实时摄像头获取图像。</li><li id="2f93" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated">最后，我们将使用Vision的文本识别请求从卡片中只解析所需的值。用户通过手势选择的值。</li></ul><h2 id="b9b8" class="no md ir bd me np nq dn mi nr ns dp mm lp nt nu mo lt nv nw mq lx nx ny ms ix bi translated">需要矩形检测</h2><p id="a3c6" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">如果你有机会使用iOS 13的文档摄像头扫描文档——它内置在笔记和文件应用程序中，你会注意到它要求你手动设置文档的边角。</p><p id="0bf8" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">通过利用视觉的矩形检测，我们可以自动检测通常为矩形的文档的角。</p><h1 id="4de2" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">VNDetectRectanglesRequest</h1><p id="adeb" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">视觉的矩形检测请求是基于图像的请求，在图像中寻找矩形区域。除了指定可信度阈值，我们还可以使用以下属性定制此请求:</p><ul class=""><li id="55d2" class="mu mv ir li b lj lk lm ln lp oc lt od lx oe mb nb nc nd ne bi translated"><strong class="li jb">vnaspectation</strong>—通过指定视觉请求的最小和最大纵横比，我们可以限制我们想要检测的矩形类型。将<code class="fe nk nl nm nn b">minimumAspectRatio</code>和<code class="fe nk nl nm nn b">maximumAspectRatio</code>设置为1会将请求设置为仅检测正方形。</li><li id="f168" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated"><strong class="li jb">最小尺寸</strong> —我们可以指定想要检测的矩形的最小尺寸。它需要指定在0和1.0之间，默认值为0.2。</li><li id="2807" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated"><strong class="li jb">最大观察值</strong> —一个整数属性，指定视觉请求可以返回的矩形的最大数量。</li><li id="3583" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated"><strong class="li jb">边与边之间的角度</strong> —通过使用属性<code class="fe nk nl nm nn b">quadratureTolerance</code>，我们可以指定矩形边缘偏离90度的程度。</li></ul><p id="6bb0" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">在接下来的几节中，我们将创建一个iOS应用程序，该应用程序使用带有AVFoundation的Vision框架来扫描来自自定义相机的文档。</p><p id="d56a" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我们将在裁剪检测到的区域并将其保存为图像之前进行透视校正。我们开始吧！</p><h1 id="073b" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">入门指南</h1><p id="5cbe" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">启动Xcode并创建一个新的单视图应用程序。确保通过在您的<code class="fe nk nl nm nn b">info.plist</code>文件中添加关键字<code class="fe nk nl nm nn b">NSCameraUsageDescription</code>来添加摄像机隐私政策的描述。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj of"><img src="../Images/c4fdaaf58610bd6809ac9aca3d531731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4H3WORrZ0DFKFbpXElNjaA.png"/></div></div></figure></div><div class="ab cl og oh hv oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ik il im in io"><h1 id="a134" class="mc md ir bd me mf on mh mi mj oo ml mm kg op kh mo kj oq kk mq km or kn ms mt bi translated">设置摄像头输入</h1><p id="01ac" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">在下面的代码中，我们设置了我们的后置摄像头，媒体类型为video，并将其添加到<code class="fe nk nl nm nn b">AVCaptureSession</code>:</p><pre class="kq kr ks kt gu os nn ot ou aw ov bi"><span id="54cc" class="no md ir nn b gz ow ox l oy oz">private let captureSession = AVCaptureSession()</span><span id="81e7" class="no md ir nn b gz pa ox l oy oz">private func <strong class="nn jb">setCameraInput</strong>() {</span><span id="bd57" class="no md ir nn b gz pa ox l oy oz">guard let device = AVCaptureDevice.DiscoverySession(</span><span id="0820" class="no md ir nn b gz pa ox l oy oz">deviceTypes: [.builtInWideAngleCamera, .builtInDualCamera, .builtInTrueDepthCamera],mediaType: .video, position: .back).devices.first else {<br/>fatalError("No back camera device found.")<br/>}</span><span id="524f" class="no md ir nn b gz pa ox l oy oz">let cameraInput = try! AVCaptureDeviceInput(device: device)</span><span id="e1a4" class="no md ir nn b gz pa ox l oy oz">self.captureSession.addInput(cameraInput)</span><span id="8f4a" class="no md ir nn b gz pa ox l oy oz">}</span></pre><p id="56d0" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">接下来，我们需要将摄像机镜头添加到我们的<code class="fe nk nl nm nn b">ViewController</code>视图中。</p><h1 id="fbbc" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">显示相机预览并设置输出</h1><p id="d91a" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">下面的代码包含显示实时摄像机输入和设置输出的函数。输出视频帧最终将被馈送到视觉请求:</p><pre class="kq kr ks kt gu os nn ot ou aw ov bi"><span id="7581" class="no md ir nn b gz ow ox l oy oz">private lazy var previewLayer = AVCaptureVideoPreviewLayer(session: self.captureSession)</span><span id="3d5b" class="no md ir nn b gz pa ox l oy oz">private let videoDataOutput = AVCaptureVideoDataOutput()</span><span id="5530" class="no md ir nn b gz pa ox l oy oz">private func <strong class="nn jb">showCameraFeed</strong>() {<br/>        self.previewLayer.videoGravity = .resizeAspectFill<br/>        self.view.layer.addSublayer(self.previewLayer)<br/>        self.previewLayer.frame = self.view.frame<br/>    }<br/>    </span><span id="1ec6" class="no md ir nn b gz pa ox l oy oz">private func <strong class="nn jb">setCameraOutput</strong>() {<br/>    self.videoDataOutput.videoSettings = [(kCVPixelBufferPixelFormatTypeKey as NSString) : NSNumber(value: kCVPixelFormatType_32BGRA)] as [String : Any]</span><span id="4609" class="no md ir nn b gz pa ox l oy oz">self.videoDataOutput.alwaysDiscardsLateVideoFrames = true<br/>    <strong class="nn jb">self.videoDataOutput.setSampleBufferDelegate(self</strong>, queue: DispatchQueue(label: "camera_frame_processing_queue"))</span><span id="1313" class="no md ir nn b gz pa ox l oy oz">self.captureSession.addOutput(self.videoDataOutput)<br/>    guard let connection = self.videoDataOutput.connection(with: AVMediaType.video),<br/>        connection.isVideoOrientationSupported else { return }</span><span id="be1e" class="no md ir nn b gz pa ox l oy oz">connection.videoOrientation = .portrait<br/>}</span></pre><p id="c2be" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">为了接收摄像机帧，我们需要遵守<code class="fe nk nl nm nn b">AVCaptureVideoDataOutputSampleBufferDelegate</code>协议并实现<code class="fe nk nl nm nn b">captureOutput</code>功能。</p><p id="4fcf" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我们的相机准备好了！将这三个函数添加到<code class="fe nk nl nm nn b">ViewController</code>的<code class="fe nk nl nm nn b">viewDidLoad</code>方法中，并简单地调用<code class="fe nk nl nm nn b">AVCaptureSession</code>实例上的<code class="fe nk nl nm nn b">startRunning</code>函数。</p><pre class="kq kr ks kt gu os nn ot ou aw ov bi"><span id="7c01" class="no md ir nn b gz ow ox l oy oz">override func viewDidLoad() {</span><span id="33b1" class="no md ir nn b gz pa ox l oy oz">super.viewDidLoad()</span><span id="a3c4" class="no md ir nn b gz pa ox l oy oz">self.setCameraInput()<br/>self.showCameraFeed()<br/>self.setCameraOutput()<br/><strong class="nn jb">self.captureSession.startRunning()</strong></span><span id="e626" class="no md ir nn b gz pa ox l oy oz">}</span></pre><h1 id="9009" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">设置我们的愿景请求</h1><p id="6815" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">现在是时候设置我们的视觉矩形检测请求了。在下面的函数<code class="fe nk nl nm nn b">detectRectangles</code>中，我们设置了我们的<code class="fe nk nl nm nn b">VNDetectRectanglesRequest</code>并将其传递给图像请求处理器以开始处理:</p><figure class="kq kr ks kt gu ku"><div class="bz fq l di"><div class="pb pc l"/></div></figure><p id="715b" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">在上面的代码中需要注意一些事情:</p><ul class=""><li id="bae5" class="mu mv ir li b lj lk lm ln lp oc lt od lx oe mb nb nc nd ne bi translated">我们已经将<code class="fe nk nl nm nn b">minimumAspectRatio</code>和<code class="fe nk nl nm nn b">maximumAspectRatios</code>设置为1.3和1.7。因为大多数信用卡和商务卡都在这个范围内。</li><li id="a9fa" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated">上述函数在以下函数中调用:</li></ul><pre class="kq kr ks kt gu os nn ot ou aw ov bi"><span id="6d42" class="no md ir nn b gz ow ox l oy oz">func captureOutput(<br/>        _ output: AVCaptureOutput,<br/>        didOutput sampleBuffer: CMSampleBuffer,<br/>        from connection: AVCaptureConnection) {<br/>        <br/>        guard let frame = CMSampleBufferGetImageBuffer(sampleBuffer) else {<br/>            debugPrint("unable to get image from sample buffer")<br/>            return<br/>        }<br/>        <br/>        self.detectRectangle(in: frame)<br/>}</span></pre><ul class=""><li id="b341" class="mu mv ir li b lj lk lm ln lp oc lt od lx oe mb nb nc nd ne bi translated">完成处理程序中的视觉请求返回的结果是类型<code class="fe nk nl nm nn b">VNRectangleObservation</code>，由<code class="fe nk nl nm nn b">boundingBox</code>和<code class="fe nk nl nm nn b">confidence</code>值组成。</li><li id="83c9" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated">使用边界框属性，我们将在检测到矩形的摄像机顶部绘制一个层。</li><li id="fa08" class="mu mv ir li b lj nf lm ng lp nh lt ni lx nj mb nb nc nd ne bi translated"><code class="fe nk nl nm nn b">doPerspectiveCorrection</code>功能用于在图像失真的情况下修复图像。我们将很快对此进行更深入的研究。当用户点击“扫描”按钮以从相机馈送中提取完全裁剪的卡时，调用该功能。</li></ul><h1 id="d644" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">在相机视图上绘制边界框</h1><p id="c70d" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">Vision的边界框坐标属于归一化坐标系，其原点为屏幕的左下角。</p><p id="339b" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">因此，我们需要将视觉的边界框<code class="fe nk nl nm nn b">CGRect</code>转换到图像坐标系中，如下面的代码所示:</p><pre class="kq kr ks kt gu os nn ot ou aw ov bi"><span id="9ae2" class="no md ir nn b gz ow ox l oy oz">func drawBoundingBox(rect : VNRectangleObservation) {<br/>    <br/>    <br/>let transform = CGAffineTransform(scaleX: 1, y: -1).translatedBy(x: 0, y: -self.previewLayer.frame.height)<br/>    <br/>let scale = CGAffineTransform.identity.scaledBy(x: self.previewLayer.frame.width, y: self.previewLayer.frame.height)<br/>    <br/>let bounds = rect.boundingBox.applying(scale).applying(transform)</span><span id="50d3" class="no md ir nn b gz pa ox l oy oz">createLayer(in: bounds)</span><span id="ab3f" class="no md ir nn b gz pa ox l oy oz">}</span><span id="0e71" class="no md ir nn b gz pa ox l oy oz">private func createLayer(in rect: CGRect) {</span><span id="9f9c" class="no md ir nn b gz pa ox l oy oz">        maskLayer = CAShapeLayer()<br/>        maskLayer.frame = rect<br/>        maskLayer.cornerRadius = 10<br/>        maskLayer.opacity = 0.75<br/>        maskLayer.borderColor = UIColor.red.cgColor<br/>        maskLayer.borderWidth = 5.0<br/>        <br/>        previewLayer.insertSublayer(maskLayer, at: 1)</span><span id="4498" class="no md ir nn b gz pa ox l oy oz">}</span></pre><p id="3b05" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我们可以使用Vision framework提供的以下内置方法，而不是使用<code class="fe nk nl nm nn b">CGAffineTransform</code>将边界框转换到图像的坐标空间:</p><pre class="kq kr ks kt gu os nn ot ou aw ov bi"><span id="df2d" class="no md ir nn b gz ow ox l oy oz">func VNNormalizedRectForImageRect(_ imageRect: CGRect, <br/>                                _ imageWidth: Int, <br/>                                _ imageHeight: Int) -&gt; CGRect</span></pre><p id="cec8" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">当<code class="fe nk nl nm nn b">maskLayer</code>被设置在相机馈送中检测到的矩形上时，您将得到如下结果:</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div class="gi gj pd"><img src="../Images/41777b6c17f10572982e3b5a5bfc5961.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*ECe-ta5NhKVomCOn-xDW1w.jpeg"/></div></figure><p id="c059" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">这项工作只完成了一半！我们的下一步包括提取边界框内的图像。让我们看看如何做到这一点。</p><h1 id="ce7a" class="mc md ir bd me mf mg mh mi mj mk ml mm kg mn kh mo kj mp kk mq km mr kn ms mt bi translated">从包围盒中提取图像</h1><p id="9dff" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">函数<code class="fe nk nl nm nn b">doPerspectiveCorrection</code>从缓冲区中取出核心图像，将它的角点从归一化转换到图像空间，并对它们应用透视校正过滤器以给出图像。代码如下所示:</p><figure class="kq kr ks kt gu ku"><div class="bz fq l di"><div class="pb pc l"/></div></figure><p id="7a07" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated"><code class="fe nk nl nm nn b">UIImageWriteToSavedPhotosAlbum</code>功能用于将图像保存在用户设备的照片库中。</p><p id="9f80" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">如果你直接将<code class="fe nk nl nm nn b">CIImage</code>传递到<code class="fe nk nl nm nn b">UIImage</code>初始化器中，图片不会显示在你的相册中。因此，首先将<code class="fe nk nl nm nn b">CIImage</code>转换成<code class="fe nk nl nm nn b">CGImage</code>，然后将它发送给<code class="fe nk nl nm nn b">UIImage</code>是至关重要的。</p><p id="062e" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">让我们看看应用了透视校正的提取图像:</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div class="gi gj pd"><img src="../Images/54092bd56457f410b65d4c39d5a15202.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/1*jeppH_Kbkie8wlJA7zfmqg.gif"/></div></figure><p id="0a47" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">从上面的图示中可以明显看出，在核心图像上应用透视校正滤波器固定了所述图像的方向。</p><p id="74c4" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">接下来，让我们来看看如何从扫描图像中提取所需的文本。</p></div><div class="ab cl og oh hv oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ik il im in io"><h1 id="8094" class="mc md ir bd me mf on mh mi mj oo ml mm kg op kh mo kj oq kk mq km or kn ms mt bi translated">优化的视觉文本识别</h1><p id="b727" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">iOS 13的愿景是在<code class="fe nk nl nm nn b">VNRecognizeTextRequest</code>中加入文本标识符，这在以前只能告诉我们文本是否存在。我们必须使用核心ML模型来解析所述文本的值。</p><p id="3305" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">具体来说，我们不得不使用正则表达式，它不仅效率低，而且不能通用。使用正则表达式模式需要支持许多边缘情况来过滤不同类型的信用卡(例如，不是所有的卡都是16位的。美国运通有15个)。</p><p id="b320" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">相反，我们将允许用户使用手势在图像上创建一个可移动的矩形。随后，我们将从用户选择的区域解析文本。这不仅提高了效率，还让用户可以控制他们共享的数据。</p><p id="0671" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">为了创建一个可移动的矩形，我们将跟踪用户在扫描图像上的触摸，并重新绘制选定的区域，如下所示:</p><figure class="kq kr ks kt gu ku"><div class="bz fq l di"><div class="pb pc l"/></div></figure><p id="b93d" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">一旦用户选择了一个矩形区域，并按下“提取”按钮，我们将从矩形中裁剪图像，并将其传递给视觉请求。</p><p id="f44e" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我没有粘贴<code class="fe nk nl nm nn b">TextExtractorVC.swift</code>的完整源代码，只是分享了下面的相关片段:</p><figure class="kq kr ks kt gu ku"><div class="bz fq l di"><div class="pb pc l"/></div></figure><p id="e767" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">下面是最终应用程序的输出结果:</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div class="gi gj pd"><img src="../Images/107a3f4aa9c7b9b9805871f7f06f4b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/1*yMI1VcwJ-UfrQJt0Iz1EnA.gif"/></div></figure><p id="c9a8" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">上图并没有提取并给出我的信用卡号码，而是在卡的正面提取。</p></div><div class="ab cl og oh hv oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ik il im in io"><h1 id="1dc1" class="mc md ir bd me mf on mh mi mj oo ml mm kg op kh mo kj oq kk mq km or kn ms mt bi translated">当与PencilKit一起使用时，准确性…不是最好的</h1><p id="10c5" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">Vision的矩形检测在手绘形状上效果不佳。下面是我在使用上述视觉请求时在PencilKit框架上运行的一个实验的一瞥:</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj pe"><img src="../Images/f523954e288c8ad9fadac7182a81ad59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YCU3Ga4L48Rnum3FQsEaGQ.png"/></div></div></figure></div><div class="ab cl og oh hv oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ik il im in io"><h1 id="3c6d" class="mc md ir bd me mf on mh mi mj oo ml mm kg op kh mo kj oq kk mq km or kn ms mt bi translated">结论</h1><p id="398f" class="pw-post-body-paragraph lg lh ir li b lj mw kb ll lm mx ke lo lp nz lr ls lt oa lv lw lx ob lz ma mb ik bi translated">在这篇文章中，我们完成了计算机视觉的另一个经典应用，在这个应用中，我们使用了一个实时摄像头馈送中的矩形检测请求来检测信用卡并将其裁剪出来，同时考虑到它的方向和变形。</p><p id="aea4" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">接下来，我们在刚刚扫描的图像上实现了文本识别器，以提取信用卡的数字。通过让用户选择要解析的感兴趣的区域，我们不仅给了他们对自己信息的控制权，还去掉了不需要的信息。</p><p id="ee89" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">在已识别的文本上设置一个边界框，并对它们进行点击测试，这可能是从卡片中提取所需信息的另一种方式！</p><p id="6d65" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">这个项目的完整源代码可以在这个<a class="ae lf" href="https://github.com/anupamchugh/iowncode/tree/master/VisionCreditScan" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><p id="ee8e" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">这一次到此为止。感谢阅读。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Introduction to Naive Bayes Classifiers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯分类器简介</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/introduction-to-naive-bayes-classifiers-70b2aa073377?source=collection_archive---------5-----------------------#2021-02-19">https://betterprogramming.pub/introduction-to-naive-bayes-classifiers-70b2aa073377?source=collection_archive---------5-----------------------#2021-02-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b6d3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们了解一种流行的ML算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ece48312381b1977fd84e5e2c865e872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_obY9-biPgY7x_k8sA-c7g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com/s/photos/variation?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@pritesh557?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Pritesh Sudra </a>拍摄的照片。</p></figure><p id="7f02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当你开始学习人工智能时，你首先遇到的是朴素贝叶斯。为什么朴素贝叶斯分类器对AI和ML如此重要？让我们找出答案。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="cdd7" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">机器学习中的不确定性和概率</h1><p id="b70a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">人工智能必须处理数据，在许多情况下，这些数据很大但不完整。就像人类一样，计算机必须承担风险，思考不确定的未来。</p><p id="36c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不确定性是人类难以承受的。但是在机器学习中，有某些算法可以帮助你找到绕过这个限制的方法。朴素贝叶斯机器学习算法是借助概率方法处理不确定性的工具之一。</p><p id="a316" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概率是一个数学领域，它使我们能够对不确定性进行推理，并评估某些结果或事件的可能性。当你使用预测最大似然建模时，你必须预测一个不确定的未来。例如，你可能试图根据过去的成绩预测一个奥运冠军在下一届奥运会上的表现。即使他们以前赢过，也不意味着他们这次会赢。不可预测的因素，如与伴侣的争吵或没有时间吃早餐，可能会影响他们的结果。</p><p id="344d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，不确定性对于机器学习建模是不可或缺的，因为生活是复杂的，没有什么是完美的。机器学习中不确定性的三个<a class="ae ky" href="https://machinelearningmastery.com/uncertainty-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">主要来源</a>是嘈杂的数据、问题的不完全覆盖和不完美的模型。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="fa09" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">计算概率</h1><p id="185a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在机器学习中，我们对条件概率感兴趣。我们感兴趣的不是某件事发生的总概率，而是在其他事情发生的情况下它发生的可能性。例如，通过使用条件概率，我们可以根据运动员过去十年的成绩来确定他们赢得比赛的概率。</p><p id="f8eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">条件概率是这样定义的:给定<em class="mz"> b </em>的情况下<em class="mz"> a </em>的概率=发生<em class="mz"> a </em>和<em class="mz"> b </em>的联合概率除以<em class="mz"> b </em>的概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/abbe3aed21fa712deb7602430e9bd607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_mzVZbcHxuqv6u9g.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片。</p></figure><p id="a853" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">稍微摆弄一下条件概率方程，你就可以得到另一个方程，也就是众所周知的贝叶斯定理。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/b128436a5a0472e3a2feb8875cbf9ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wcxOvixmyyoQ9A_bNQskgg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片。</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="08c1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">贝叶斯概率</h1><p id="5dd3" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">贝叶斯定理允许我们计算条件概率。它非常方便，因为它使我们能够使用一些我们已经拥有的知识(称为先验知识)来计算相关事件的概率。它用于开发分类模型和预测建模问题，如朴素贝叶斯。</p><p id="602e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">贝叶斯规则通常用于概率论中计算条件概率。</p><p id="5931" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，假设我们正在咨询一名运动员的赛前饮食，他们提供了以下数据:</p><ul class=""><li id="e22f" class="nb nc it lb b lc ld lf lg li nd lm ne lq nf lu ng nh ni nj bi translated">80%的情况下，如果他们赢了比赛，他们会吃一顿丰盛的早餐。这是<em class="mz"> P(早餐|赢)</em>。</li><li id="dcc5" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">60%的时候，他们会吃一顿丰盛的早餐。<em class="mz"> P(早餐)</em>。这是我们的<em class="mz"> b </em>。</li><li id="baed" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">20%的情况下，他们会赢得比赛。<em class="mz"> P(赢)</em>。这是我们的<em class="mz">一</em>。</li></ul><p id="d235" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过应用贝叶斯法则，我们可以计算出<em class="mz"> P(win|breakfast) </em>为0.2乘以0.8除以0.6 = 0.26。换句话说，给他们一顿丰盛的早餐，他们赢得比赛的概率是26%。显然，额外的碳水化合物让他们在比赛中保持耐力。</p><p id="d031" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重要的是，我们不仅可以发现证据如何影响一个事件的概率，还可以发现影响的程度。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9302" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">朴素贝叶斯</h1><p id="ed8f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">朴素贝叶斯是一种简单的监督机器学习算法，它使用贝叶斯定理，在特征之间进行强独立性假设来获得结果。这意味着算法只是假设每个输入变量是独立的。</p><p id="4ae4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对真实世界的数据做出这样的假设实在是太天真了。</p><p id="5929" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果您使用朴素贝叶斯进行情感分析，给定句子“我喜欢哈利波特”，算法将查看单个单词，而不是整个句子。在一个句子中，相邻而立的单词影响着彼此的意思，单词在句子中的位置也很重要。然而，对于算法来说，类似“我喜欢哈利波特”、“哈利波特喜欢我”、“波特我喜欢哈利”这样的短语是相同的。</p><p id="48f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实证明，该算法能够有效地解决许多复杂问题。例如，使用朴素贝叶斯构建文本分类器要比使用诸如神经网络等更受欢迎的算法容易得多。即使在数据不足或错误标注的情况下，该模型也能很好地工作，因此您不必“喂”它成千上万的例子，然后才能从中获得合理的东西。即使朴素贝叶斯最多能走50行，也是很有效的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="eee9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">朴素贝叶斯的缺点</h1><p id="ae65" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">至于朴素贝叶斯的弱点，它用分类比用数值表现得更好。它自动假定钟形曲线分布，但这并不总是正确的。此外，如果分类变量在测试数据集中有一个不包括在训练数据集中的类别，那么模型将为其分配一个<em class="mz"> 0 </em>概率，并且将无法进行预测。这就是所谓的<a class="ae ky" href="https://towardsdatascience.com/continuous-data-and-zero-frequency-problem-in-naive-bayes-classifier-7784f4066b51" rel="noopener" target="_blank">零频率问题</a>。</p><p id="31c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解决这个问题，我们将不得不使用平滑技术。当然，它的主要缺点是在现实生活中很少有事件是完全独立的。你必须应用其他算法来追踪因果依赖。</p><p id="a892" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想开始编写你的第一个朴素分类器，我推荐这个<a class="ae ky" href="https://www.kaggle.com/springboardroger/naive-bayes-name-gender-classifier" rel="noopener ugc nofollow" target="_blank">名字性别分类器</a>。笔记本会逐步引导您完成该过程，并为您提供训练和测试模型所需的数据。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="6293" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">朴素贝叶斯分类器的类型</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/5d48aa295b4e943ee2e3990aaff58378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XlcmgNvdyKuOuOrj.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片。</p></figure><p id="f9b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几种类型的朴素贝叶斯分类器。</p><h2 id="8ce3" class="np md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">最优朴素贝叶斯</h2><p id="c69f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">该分类器选择具有最大后验发生概率的类别(所谓的最大后验估计或<a class="ae ky" href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" rel="noopener ugc nofollow" target="_blank">图</a>)。顾名思义，它确实是最佳的，但是遍历所有可能的选项是相当缓慢和耗时的。</p><h2 id="2bf4" class="np md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">高斯朴素贝叶斯</h2><p id="b976" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">高斯贝叶斯基于高斯(或<a class="ae ky" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank">正态</a>)分布。它显著地加快了搜索速度，并且在一些非严格条件下，误差仅比最优Bayes高两倍。那就好！</p><h2 id="9c40" class="np md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">多项式朴素贝叶斯</h2><p id="8f6c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">这通常适用于文档分类问题。它的决策基于离散的特征(整数)，例如，文档中出现的单词的频率。</p><h2 id="eeaa" class="np md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">伯努利朴素贝叶斯</h2><p id="6a4c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">伯努利类似于前一种类型，但预测器是布尔变量。因此，用于预测类变量的参数只能有yes或no值(例如，单词是否出现在文本中)。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="193f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">可以使用朴素贝叶斯算法的地方</h1><p id="eaa0" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">下面是朴素贝叶斯在现实生活任务中的一些常见应用:</p><ul class=""><li id="9ff4" class="nb nc it lb b lc ld lf lg li nd lm ne lq nf lu ng nh ni nj bi translated">文档分类—该算法可以帮助您确定给定文档属于哪个类别。它可以用于将文本分类为不同的语言、流派或主题(通过关键词的存在)。</li><li id="03f7" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">垃圾邮件过滤——朴素贝叶斯使用关键字轻松筛选出垃圾邮件。例如，在垃圾邮件中，你可以比在普通邮件中更频繁地看到“伟哥”这个词。必须训练该算法来识别这种概率，然后它可以有效地将它们应用于垃圾邮件过滤。</li><li id="cd74" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">情感分析——基于文本中的单词所表达的情感，朴素贝叶斯可以计算出它是积极的还是消极的概率。例如，在顾客评论中，“好”或“不贵”通常意味着顾客满意。然而，朴素贝叶斯对讽刺并不敏感。</li><li id="25c5" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">图像分类-出于个人和研究目的，很容易建立一个朴素贝叶斯分类器。它可以被训练识别手写数字，或者通过监督机器学习将图像分类。</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="e0b6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">贝叶斯中毒</h1><p id="b525" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">贝叶斯中毒是垃圾邮件发送者使用的一种技术，旨在降低使用贝叶斯规则的垃圾邮件过滤器的效率。他们希望通过将贝叶斯数据库中以前无害的单词变成垃圾单词来增加垃圾邮件过滤器的误报率。添加更有可能出现在非垃圾邮件中的单词可以有效抵御朴素贝叶斯过滤器，并允许垃圾邮件漏网。</p><p id="70a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，重新训练过滤器可以有效地防止所有类型的攻击。这就是为什么朴素贝叶斯仍然与某些启发式方法(如黑名单)一起用于垃圾邮件检测。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="7f63" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="b905" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">朴素贝叶斯可用于许多使用分类器的领域，如垃圾邮件检测、图像分类等。现在您已经知道了算法的优点和缺点，您可以在自己的项目中尝试它了。祝你好运！</p><p id="4631" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mz">原载于</em><a class="ae ky" href="https://serokell.io/blog/naive-bayes-classifiers" rel="noopener ugc nofollow" target="_blank"><em class="mz"/></a><em class="mz">。</em></p></div></div>    
</body>
</html>
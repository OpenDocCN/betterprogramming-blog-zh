<html>
<head>
<title>Classify Marvel Characters by Fine-tuning a Vision Transformer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过微调视觉转换器对漫威人物进行分类</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/marvel-character-classification-by-fine-tuning-vision-transformer-45c14a7d8719?source=collection_archive---------4-----------------------#2022-07-10">https://betterprogramming.pub/marvel-character-classification-by-fine-tuning-vision-transformer-45c14a7d8719?source=collection_archive---------4-----------------------#2022-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7465" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">微调视觉转换器(ViT)来分类漫威电影角色。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/653614008539b16b657bdfb6332ae7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_dNPR3PERmcKyIzm"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/es/@mullyadii?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">穆利亚迪</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="06c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你只是想先试用一下模型，你可以在这里做<a class="ae kv" href="https://huggingface.co/dingusagar/vit-base-avengers-v1" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a031" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算机视觉领域很长一段时间是由卷积神经网络(CNN)主导的。另一方面，变形金刚成为任何NLP任务的首选深度学习架构。但在2021年，随着<a class="ae kv" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">视觉变形金刚论文</a>的出现，变形金刚也开始参与计算机视觉任务的竞赛。</p><p id="a587" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们对视觉转换器模型进行了微调，以检测漫威电影角色。</p><h1 id="4141" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">稍微了解一下视觉转换器</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/21645eff7c5ebc96d0a9aa01c5d0a42f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoE_mecs9_prJ2mIc9TDqQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2010.11929.pdf</a></p></figure><p id="7c19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">视觉转换器(ViT)基本上是一个应用于图像而不是文本的普通转换器网络。如果你想了解变形金刚是如何工作的，<a class="ae kv" href="https://youtu.be/4Bdc55j80l8" rel="noopener ugc nofollow" target="_blank">这个</a>是一个很棒的视频。</p><p id="7e59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如图所示，输入图像被分割成单独的小块。这些单独的补丁就像NLP任务中的令牌，通常使用转换器。这些单独的图像片段被展平成线性向量。然后添加位置向量以嵌入这些小块的位置信息。这些然后被传递到变换器编码器块。一个特殊的令牌CLS也被传递给变换器块，我们可以用它来预测图像的类别。来自变换器块的CLS嵌入的输出被馈送到具有softmax分类器的前馈网络中，以预测类别。</p><h1 id="dda2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">微调视觉转换器</strong></h1><p id="7e88" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">根据我们的图像微调ViT非常容易。感谢来自<a class="ae kv" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> Huggingface的棒极了的库🤗</a>。</p><p id="0e1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们建立一个识别漫威电影角色的分类器。首先，我们需要一些不同漫威角色的图像。</p><h2 id="676a" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">从谷歌图片准备数据集</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="0c80" class="mq lt iq nd b gy nh ni l nj nk"><em class="nl">git clone </em><a class="ae kv" href="https://github.com/Joeclinton1/google-images-download.git" rel="noopener ugc nofollow" target="_blank"><em class="nl">https://github.com/Joeclinton1/google-images-download.git</em></a><em class="nl"> &amp;&amp; cd google-images-download &amp;&amp; pip install -e . &amp;&amp; cd ..</em></span></pre><p id="eb7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的命令安装了一个工具，您可以使用它从Google Images下载图像。安装后，执行下面的命令开始下载图像。<code class="fe nm nn no nd b">keywords</code>选项应该是一串不同的搜索词，每个词代表一个类别。<code class="fe nm nn no nd b">limit</code>是每节课需要多少张图片。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="4ec4" class="mq lt iq nd b gy nh ni l nj nk">googleimagesdownload  --keywords "Iron Man,Captain America,Thor,Spider Man,Docter Strage,Black Panther,Ant Man,Captain Marvel,Hulk,Black Widow,Hawkeye Avengers,Scarlet Witch,Vision Avengers,Bucky Barnes,Falcon Avengers,Loki" --limit 100</span></pre><p id="19a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下载的文件将类似于这种格式。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="9f54" class="mq lt iq nd b gy nh ni l nj nk">downloads/Iron Man/ironman.jpg<br/>downloads/Iron Man/iron_man2.jpg<br/>.<br/>.<br/>downloads/Loki/loki.jpg</span></pre><p id="40d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们希望将文件分为模型的训练集和验证集。我们可以使用另一个工具<a class="ae kv" href="https://pypi.org/project/split-folders/" rel="noopener ugc nofollow" target="_blank">分割文件夹</a>来实现。通过以下方式安装:</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="9f75" class="mq lt iq nd b gy nh ni l nj nk">pip install split-folders</span></pre><p id="0c8c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，要将文件夹分割成80–20%分割的train和val集合，请执行。在<code class="fe nm nn no nd b">--</code>后指定文件夹的名称</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="729b" class="mq lt iq nd b gy nh ni l nj nk">splitfolders --ratio .8 .2  -- downloads</span></pre><p id="5d9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您应该会看到类似于此结构的文件夹。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="75cc" class="mq lt iq nd b gy nh ni l nj nk">output/train/Iron Man/ironman.jpg<br/>output/train/Iron Man/iron_man2.jpg<br/>.<br/>.<br/>output/train/Loki/loki.jpg</span><span id="e362" class="mq lt iq nd b gy np ni l nj nk">output/val/Iron Man/ironman3.jpg<br/>output/val/Iron Man/iron_man22.jpg<br/>.<br/>output/val/Loki/loki_.jpg</span></pre><h1 id="1609" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">微调代码</strong></h1><p id="03c6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">安装所需的库</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="aca4" class="mq lt iq nd b gy nh ni l nj nk">pip install -U transformers datasets</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="7fd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导入必要的包后，我们在第6，7行指定数据集的位置。修改它以匹配您系统中的位置。</p><p id="8d4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第12–20行将一个变换函数附加到数据集上，该变换函数用于将数据集库读取的原始PIL图像转换为适合输入模型的张量格式。我们还在转换函数中将标签信息添加到批处理中。</p><p id="7f8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第21–30行定义了计算精确度的度量。第34–41行定义了来自<code class="fe nm nn no nd b">model_name_or_path</code>指定的检查点的模型和特征提取器。特征提取器的工作是对图像应用任何规范化、标准化和调整大小操作，以使其准备好被输入到模型中。</p><p id="90f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第23行定义了一个数据整理器函数，它将作为<code class="fe nm nn no nd b">dicts</code>列表传入的批处理转换成批处理张量的字典。</p><p id="1016" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从第44行开始，用训练参数定义了教练对象。请参考文档以更深入地了解每个参数。<code class="fe nm nn no nd b">trainer.train()</code>应该开始训练了。之后，我们保存模型并记录指标。将创建一个包含模型权重和配置的文件夹。该文件夹的路径由TrainingArguments类中的<code class="fe nm nn no nd b">output_dir</code>指定。</p><p id="537a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每类100张图片和当前设置的情况下，我得到了0.8683的测试精度。看起来有通过增加数据集大小或调整训练参数中的一些参数来改进的空间。</p><h1 id="22e3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">测试我们的复仇者分类器</strong></h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="7ff3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的代码使用训练好的模型来预测复仇者角色。第6–8行从训练模型的路径加载模型。第11–13行将图像下载到PIL图像对象中。第16–17行执行特征提取和预测。第19–21行提取最终图层预测(也称为logit)并找到与最大logit值对应的类索引。</p><h1 id="8792" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">最后一步:享受与模型玩耍的乐趣。</strong></h1><p id="8ad0" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">输入图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/7f7840f1a8791b28a2dfbb4563fd53b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oweYZfAgqBVcSgiqK6yKfg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://static1.srcdn.com/wordpress/wp-content/uploads/2022/06/Iron-Man-Change-After-The-Avengers-Is-Deeper-Than-You-Thought.jpg" rel="noopener ugc nofollow" target="_blank">https://static 1 . srcdn . com/WordPress/WP-content/uploads/2022/06/Iron-Man-Change-After-The-Avengers-Is-deep-Than-You-think . jpg</a></p></figure><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="aee9" class="mq lt iq nd b gy nh ni l nj nk">Predicted class: Iron Man</span></pre><p id="cb22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输入图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/a6546c9c68d2a332013791814d06585f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ptdPzhuT4Th_JlHlKUu2iQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://br.glbnews.com/-/52781023297688/" rel="noopener ugc nofollow" target="_blank">https://br.glbnews.com/-/52781023297688/</a></p></figure><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="99a7" class="mq lt iq nd b gy nh ni l nj nk">Predicted class: Black Widow</span></pre><h2 id="c26c" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">可选步骤:推轮毂炫耀</strong></h2><p id="d721" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">如果你想把模型推到拥抱脸模型中枢，这很容易。只需在训练参数中将<code class="fe nm nn no nd b">push_to_hub</code>设为True，你的模型就会被推送到你的拥抱脸账户。您还必须通过执行以下命令登录到hugging face。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="b9de" class="mq lt iq nd b gy nh ni l nj nk">pip install huggingface_hub<br/>huggingface-cli login</span></pre><h1 id="edcd" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">链接和引用</strong></h1><div class="nu nv gp gr nw nx"><a href="https://huggingface.co/dingusagar/vit-base-avengers-v1" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">丁格萨加/维特-基地-复仇者联盟-v1拥抱脸</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">编辑模型卡这个模型是imagefolder数据集上Google/vit-base-patch 16-224-in21k的微调版本。</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">huggingface.co</p></div></div><div class="og l"><div class="oh l oi oj ok og ol kp nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a href="https://huggingface.co/blog/fine-tune-vit" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">微调用于图像分类的ViT🤗变形金刚(电影名)</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">就像基于变形金刚的模型彻底改变了自然语言处理一样，我们现在看到大量的论文将它们应用于所有…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">huggingface.co</p></div></div><div class="og l"><div class="om l oi oj ok og ol kp nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a href="https://arxiv.org/abs/2010.11929" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">一幅图像相当于16x16个字:大规模图像识别的变形金刚</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">虽然Transformer体系结构已经成为自然语言处理任务的事实上的标准，但它…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">arxiv.org</p></div></div><div class="og l"><div class="on l oi oj ok og ol kp nx"/></div></div></a></div></div></div>    
</body>
</html>
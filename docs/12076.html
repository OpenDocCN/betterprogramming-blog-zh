<html>
<head>
<title>Apache Airflow on Docker With AWS S3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有AWS S3的Docker上的Apache气流</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/apache-airflow-on-docker-with-aws-s3-3abaf6874a49?source=collection_archive---------3-----------------------#2022-05-10">https://betterprogramming.pub/apache-airflow-on-docker-with-aws-s3-3abaf6874a49?source=collection_archive---------3-----------------------#2022-05-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="094c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">写你的第一个DAG</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6eb0983c71f99e145f0665942d7c7357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vGVMv7m-1trJ7wnQ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@emin008?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Emin Sefiyarov </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="1201" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个博客是为那些想快速入门Apache Airflow的人准备的。这篇博客假设您对Apache Airflow、Docker和AWS有基本的了解。</p><p id="a69f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博客的结尾，你将会有你的第一个DAG在气流中编写和编排。</p><p id="19e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主要关注如何使用Docker上的扩展映像启动气流，使用PythonOperator为中心的任务构建DAG，利用XComs(一种允许任务相互通信的技术)，使用Python模块，以及最终从AWS S3桶发布和检索数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/064b3febbda30cf66f3105a2b6da1b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aiN1CSc2Hht4lE_SZNZfKQ.jpeg"/></div></div></figure><p id="332d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更好地理解这一点，我们将执行一个包含以下任务的小项目:</p><p id="522d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">a)使用Python脚本创建一个网络日志文件<br/> b)将该文件上传到上一步中创建的AWS S3存储桶<br/> c)使用AWS CLI连接到AWS S3进行对象验证</p><p id="9cab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将按照下面的步骤完成我们的气流设置并启动docker，之后我们将能够在气流中运行我们的管道并检索数据。</p><ol class=""><li id="067e" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">气流对接配置</li><li id="1468" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">气流扩展图像的Docker配置</li><li id="b7d8" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">AWS的Docker配置</li><li id="6c39" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">执行docker映像以创建容器</li><li id="68ea" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">DAG和气流中的任务创建</li><li id="301a" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">从Airflow UI执行DAG</li><li id="4706" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">使用AWS CLI访问S3存储桶/对象</li></ol></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h2 id="6255" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated"><strong class="ak"> 1。气流的停靠配置</strong></h2><p id="88f6" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">我们将在macOS上使用docker来运行气流设置的容器。我们将使用Airflow文档中的<code class="fe nm nn no np b">docker-compose.yaml</code>文件作为基础，并在其上添加所需的配置。下面是<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#running-airflow" rel="noopener ugc nofollow" target="_blank">链接</a>和气流官网的一些信息。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="50e3" class="mo mp iq np b gy nu nv l nw nx">curl -LfO ‘<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/2.2.5/docker-compose.yaml'" rel="noopener ugc nofollow" target="_blank">https://airflow.apache.org/docs/apache-airflow/2.2.5/docker-compose.yaml'</a></span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/30385fdee58a0e97d8cf3aa44e556c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ySXnWtcdTDhCOuxE.png"/></div></div></figure><ul class=""><li id="92ab" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr nz lz ma mb bi translated"><code class="fe nm nn no np b">airflow-scheduler</code>-<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/scheduler.html" rel="noopener ugc nofollow" target="_blank">调度器</a>监控所有的任务和Dag，然后一旦它们的依赖完成就触发任务实例。</li><li id="fa4b" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nz lz ma mb bi translated"><code class="fe nm nn no np b">airflow-webserver</code> —网络服务器在<code class="fe nm nn no np b"><a class="ae kv" href="http://localhost:8080." rel="noopener ugc nofollow" target="_blank">http://localhost:8080</a></code>可用</li><li id="9bb6" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nz lz ma mb bi translated"><code class="fe nm nn no np b">airflow-worker</code> —执行调度程序给定任务的工人。</li><li id="f269" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nz lz ma mb bi translated"><code class="fe nm nn no np b">airflow-init</code> —初始化服务。</li><li id="5921" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nz lz ma mb bi translated"><code class="fe nm nn no np b">flower</code> — <a class="ae kv" href="https://flower.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">用于监测环境的花卉app </a>。在<code class="fe nm nn no np b"><a class="ae kv" href="http://localhost:5555." rel="noopener ugc nofollow" target="_blank">http://localhost:5555</a></code> <a class="ae kv" href="http://localhost:5555." rel="noopener ugc nofollow" target="_blank">有。</a></li><li id="4e0b" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nz lz ma mb bi translated"><code class="fe nm nn no np b">postgres</code> —数据库。</li><li id="8c25" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nz lz ma mb bi translated"><code class="fe nm nn no np b">redis</code>—<a class="ae kv" href="https://redis.io/" rel="noopener ugc nofollow" target="_blank">redis</a>—将消息从调度器转发到工作器的代理。</li></ul><h2 id="d03d" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">2.<strong class="ak">气流扩展图像的Docker配置</strong></h2><p id="b1ef" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">下一步是创建一个docker文件，它将允许我们扩展我们的Airflow基础映像，以包含原始映像中没有包含的Python包(apache/airflow:2.2.5)。</p><p id="c4d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在docker-compose.yaml文件所在的目录下创建一个名为“Dockerfile”的文件，并将下面几行粘贴到其中。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="5eb3" class="mo mp iq np b gy nu nv l nw nx">FROM apache/airflow:2.2.5<br/>RUN pip3 install Faker numpy boto3 botocore</span></pre><p id="65be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们使用Airflow的基本映像，然后使用附加的库、包、模块等来扩展它。这是我们的用例所需要的。您可以根据您的数据处理要求添加/删除包。</p><p id="705b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有几种方法可以执行Dockerfile</p><ol class=""><li id="b36b" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">注释基础图像并取消注释<code class="fe nm nn no np b">docker-compose.yaml</code>文件中的构建行</li><li id="9d2e" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">在此阶段不要对<code class="fe nm nn no np b">docker-compose.yaml</code>文件做任何更改，在运行docker时强制执行(在第4节中解释)。</li></ol><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="aa43" class="mo mp iq np b gy nu nv l nw nx"># image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.2.5}<br/>build: .</span></pre><h2 id="c75a" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">3.<strong class="ak">AWS的Docker配置</strong></h2><p id="727a" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">下一步是将AWS凭证作为ENV变量添加到<code class="fe nm nn no np b">docker-compose.yaml</code>文件中。</p><p id="03f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在environment部分下添加以下变量，并放置来自您的AWS帐户的凭证。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="acad" class="mo mp iq np b gy nu nv l nw nx">AWS_ACCESS_KEY_ID: &lt;&gt;<br/>AWS_SECRET_ACCESS_KEY: &lt;&gt;<br/>AWS_DEFAULT_REGION: &lt;&gt;</span></pre><p id="f88b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在<code class="fe nm nn no np b">docker-compose.yaml</code>文件中包含AWS CLI映像，它可用于访问AWS S3对象，以验证所需数据是否已存储在S3上。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="78ac" class="mo mp iq np b gy nu nv l nw nx">awscli:<br/>  image: amazon/aws-cli<br/>  entrypoint: tail -f /dev/null<br/>  environment:      <br/>    &lt;&lt;: *airflow-common-env</span></pre><p id="9933" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b"><strong class="ky ir">entrypoint</strong></code> <strong class="ky ir"> → </strong>这将保持cli容器运行</p><p id="cdce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b"><strong class="ky ir">environment</strong></code> <strong class="ky ir"> → </strong>将气流环境传递给AWS CLI以使用AWS凭证</p><h2 id="b80a" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">4.<strong class="ak">执行docker镜像创建容器</strong></h2><p id="414c" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">现在运行以下命令来初始化环境，验证气流图像是否太旧且不受支持，UID是否已配置，以及必要的RAM、磁盘空间和资源是否可用。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="bb31" class="mo mp iq np b gy nu nv l nw nx">docker-compose up airflow-init</span></pre><p id="fdc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们运行docker-compose.yaml文件，这将产生文件中指定的所有图像(包括Dockerfile ),然后使用这些图像运行容器。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="3d85" class="mo mp iq np b gy nu nv l nw nx">docker-compose up -d</span></pre><p id="b49f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">-d →在后台运行容器(分离模式)</p><p id="8b9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者</p><p id="c65c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您没有在docker-compose.yaml文件中注释图像行和取消注释构建行，请运行以下命令。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="b384" class="mo mp iq np b gy nu nv l nw nx">docker-compose up --build -d</span></pre><p id="4bd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">-构建→运行Dockerfile</p><p id="2cef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">成功完成后，您可以使用下面的命令或者通过点击Docker UI中新形成的容器/应用程序来验证图像的状态。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="585d" class="mo mp iq np b gy nu nv l nw nx">docker ps</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/b06720be7f91c57f70b7825808c21211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rlwkvPF68AAE1vK3__YhgQ.png"/></div></div></figure><p id="5988" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用以下命令，通过CLI登录到这些容器中的任何一个。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="8c56" class="mo mp iq np b gy nu nv l nw nx">docker exec -ti &lt;Container ID&gt; /bin/bash</span></pre><p id="8c7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.<strong class="ky ir"> DAG和气流中的任务创建:</strong></p><p id="6dfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将weblog_gen.py(来自Github链接-<a class="ae kv" href="https://github.com/narotam333/de-project-1" rel="noopener ugc nofollow" target="_blank">https://github.com/narotam333/de-project-1</a>)放在<code class="fe nm nn no np b">dags</code>文件夹下。该脚本用于生成weblog数据，并作为模块导入到我们的DAG中。</p><p id="f9ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们导入第一个dag所需的库、包或模块。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="c71d" class="mo mp iq np b gy nu nv l nw nx"># The DAG object; we'll need this to instantiate a DAG<br/>from airflow import DAG</span><span id="583a" class="mo mp iq np b gy ob nv l nw nx"># Pendulum is a Python package to ease datetimes manipulation<br/>import pendulum</span><span id="698a" class="mo mp iq np b gy ob nv l nw nx"># Operators; we need this to operate!<br/>from airflow.operators.python import PythonOperator</span><span id="6bce" class="mo mp iq np b gy ob nv l nw nx"># Python module for data weblog generation <br/>from weblog_gen import generate_log</span><span id="0a86" class="mo mp iq np b gy ob nv l nw nx"># Other packages for AWS connection and data processing<br/>import os<br/>import boto3<br/>from botocore.exceptions import ClientError<br/>import logging</span></pre><p id="dc12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> DAG: </strong> A <em class="oc"> DAG </em>(有向无环图)是气流的核心概念，将任务收集在一起，用依赖和关系组织起来，说它们应该如何运行。</p><p id="5049" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开始写我们的第一个DAG…</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="893d" class="mo mp iq np b gy nu nv l nw nx"># [START instantiate_dag]</span><span id="0d27" class="mo mp iq np b gy ob nv l nw nx">with DAG(<br/>    ‘my_first_dag’,<br/>    default_args={‘retries’: 2},<br/>    description=’ETL DAG tutorial’,<br/>    schedule_interval=None,<br/>    start_date=pendulum.datetime(2022, 1, 1, tz=”UTC”),<br/>    catchup=False,<br/>    tags=[‘example’],<br/>) as dag:</span><span id="1bb4" class="mo mp iq np b gy ob nv l nw nx"># [END instantiate_dag]</span></pre><p id="3b21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">my_first_dag</code> →这是DAG ID，必须全部由字母数字字符、破折号、点号和下划线组成(全部为ASCII码)。所有不同的DAG必须有唯一的id。</p><p id="3661" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">default_args</code> →初始化运算符时用作构造函数关键字参数的默认参数字典(可选)</p><p id="bdc6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">description</code>→DAG的描述，例如显示在网络服务器上(可选)</p><p id="83ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">schedule_interval</code> →定义DAG运行的频率，这个timedelta对象被添加到您最新的任务实例的execution_date中，以确定下一个计划。</p><p id="c5e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">start_date</code> →调度程序将尝试回填的时间戳(可选)</p><p id="4420" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">catchup</code> →执行调度程序追赶(或仅运行最新的)？默认为真</p><p id="5b3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">tags</code> →帮助在UI中过滤Dag的标签列表(可选)</p><p id="4437" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们将使用PythonOperator编写我们的第一个任务。</p><p id="695f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">任务:</strong>任务是气流中执行的基本单位。任务被安排到<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html" rel="noopener ugc nofollow" target="_blank">Dag</a>中，然后在它们之间设置上游和下游依赖关系，以表示它们应该运行的顺序。</p><p id="b1f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">操作符:操作符在概念上是一个预定义任务的模板，你可以在你的DAG中声明性地定义它。</p><p id="9cf1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个任务中，我们将调用名为f_generate_log的函数，并将所需的参数传递给它。当运行我们的callable时，Airflow将传递一组可以在我们的函数中使用的参数/关键字参数。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="4306" class="mo mp iq np b gy nu nv l nw nx"># [START weblog_function]</span><span id="e6a1" class="mo mp iq np b gy ob nv l nw nx">def f_generate_log(*op_args, **kwargs):<br/>    ti = kwargs[‘ti’]<br/>    lines = op_args[0]<br/>    logFile = generate_log(lines)<br/>    ti.xcom_push(key=’logFileName’, value=logFile)</span><span id="3f2a" class="mo mp iq np b gy ob nv l nw nx"># [END weblog_function]</span><span id="f971" class="mo mp iq np b gy ob nv l nw nx"># [Start weblog task]</span><span id="158d" class="mo mp iq np b gy ob nv l nw nx"><strong class="np ir">create_weblog_task</strong> = PythonOperator(<br/>    task_id=’weblog’,<br/>    python_callable=f_generate_log,<br/>    op_args = [30],<br/>)</span><span id="98f4" class="mo mp iq np b gy ob nv l nw nx"># [End weblog task]</span></pre><p id="5527" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">task_id</code> →对于DAG中的所有任务，这应该是唯一的</p><p id="2bf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">python_callable</code> →对可调用对象的引用</p><p id="dc5b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">op_args</code> →调用callable时将被解压缩的位置参数列表</p><p id="af72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">op_kwargs</code> →将在函数中解包的关键字参数字典</p><p id="c597" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">generate_log</code> →这是生成网络日志数据文件的模块。请浏览weblog_gen.py脚本，看看它是如何工作的，但它基本上是在一个文件中生成weblog数据，行数将等于作为参数传递的数量。一旦创建了日志文件，它将返回日志文件的名称。</p><p id="e1e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">ti.xcom_push()</code> →使用<code class="fe nm nn no np b">taskInstance</code> (ti)关键字参数作为键值对，将键<code class="fe nm nn no np b">logFileName</code>的值推入XCom</p><p id="282d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">key=’logFileName’</code> →这保存了键名</p><p id="d4ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">value = logFile</code> →保存来自<code class="fe nm nn no np b">generate_log</code>模块的返回值(日志文件的名称)</p><p id="5783" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们继续我们DAG中的第二个任务。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="4506" class="mo mp iq np b gy nu nv l nw nx"># [START s3_upload_file function]</span><span id="3eb6" class="mo mp iq np b gy ob nv l nw nx">def s3_upload_file(**kwargs):<br/>    ti = kwargs[‘ti’]<br/>    bucketName = kwargs[‘bucketName’]</span><span id="c7e4" class="mo mp iq np b gy ob nv l nw nx">    fileName = ti.xcom_pull(task_ids='weblog', key='logFileName')<br/>    objectName = os.path.basename(fileName)    <br/>    s3_client = boto3.client(‘s3’)</span><span id="8917" class="mo mp iq np b gy ob nv l nw nx">    try:<br/>        response = s3_client.upload_file(fileName, bucketName, objectName)<br/>    except ClientError as e:<br/>        return False<br/>    return True</span><span id="a59f" class="mo mp iq np b gy ob nv l nw nx"># [END s3_upload_file function]</span><span id="2e60" class="mo mp iq np b gy ob nv l nw nx"># [Start s3 upload task]</span><span id="613e" class="mo mp iq np b gy ob nv l nw nx"><strong class="np ir">s3_upload_log_file_task</strong> = PythonOperator(<br/>    task_id = ‘s3_upload_log_file’,<br/>    python_callable=s3_upload_file,<br/>    op_kwargs = {‘bucketName’: &lt;&gt;},<br/>)</span><span id="c944" class="mo mp iq np b gy ob nv l nw nx"># [End s3 upload task]</span></pre><p id="7b01" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在这个任务中使用关键字参数，因为我们需要传递AWS S3存储桶名称。请提供您创建的或您的AWS帐户中可用的存储桶的名称。</p><p id="4645" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在这个任务中调用s3_upload_file函数，并传递所需的关键字参数。</p><p id="e3a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">ti.xcom_pull()</code> →使用XCom <code class="fe nm nn no np b">taskInstance</code> (ti)关键字参数，检索关键字<code class="fe nm nn no np b">logFileName</code>的值</p><p id="944c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">task_ids = ‘weblog’</code> →传递上一个任务的任务id名称</p><p id="6431" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nm nn no np b">key=’logFileName’</code> →传递保存生成的网络日志文件名的密钥</p><p id="9ba5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是建立新创建任务的流程。</p><pre class="kg kh ki kj gt nq np nr ns aw nt bi"><span id="d464" class="mo mp iq np b gy nu nv l nw nx">create_weblog_task &gt;&gt; s3_upload_log_file_task</span></pre><p id="550d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就完成了我们用例的DAG文件的开发，它包括DAG对象、任务和操作符，以及最后陈述的任务的编排。</p><h2 id="d7cd" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">6.<strong class="ak">从气流UI执行DAG</strong></h2><p id="5278" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">首先，使用下面列出的凭证登录到Airflow UI。</p><p id="b3de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">链接→<a class="ae kv" href="http://localhost:8080/home" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/</a><br/>用户名/密码→气流</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/7e945d3445f3c1af2824b3f1a35baccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pIr55RZLzd3Jk3O4x-Si-g.png"/></div></div></figure><p id="3b8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您应该能够在DAG的菜单下看到我们创建的DAG。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/3a63845bf63046006b7a44a7e8f27016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zMxZ0lV3m1DwKqVDJUAivQ.png"/></div></div></figure><p id="7e55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们通过点击右侧“Actions”下的“play”按钮来运行DAG。如果你点击DAG，你将能够看到DAG和任务的进度使用彩色编码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/4f9450cd536323873e4f32e17f1f33de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MTgNfisrXPbytKBL4ObkXQ.png"/></div></div></figure><p id="d86e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您也可以随时通过选择任务，然后选择日志来查看日志。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/17d19122f679045d320f4983eb51dab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeHtcxxMAiRjMEIR-z_uvQ.png"/></div></div></figure><p id="1309" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">打开日志后，单击XCom查看我们从一个任务传输到下一个任务的关键变量的值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/5c8ae192b2790dd792d4b1d7412c4df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BCDY4jMe-aUpENVhjptDRw.png"/></div></div></figure><p id="556a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就结束了我们的DAG在气流中的成功执行。</p><h2 id="56f8" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">7.<strong class="ak">使用AWS CLI访问S3存储桶/对象</strong></h2><p id="7fdd" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">让我们快速浏览一下AWS S3存储桶，看看是否生成了合适的文件或对象。为此，使用下面的命令登录到AWS CLI容器，并执行s3命令来显示所有对象。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/2c9d8ce9593acd027f8ac369eb8d02e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0H4P7dFMso0dz-hC2LNzg.png"/></div></div></figure><p id="a991" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里！该文件已成功上传到S3存储桶。这标志着我们首次在气流中运行DAG的完成，以及它的成功验证。</p><blockquote class="oj ok ol"><p id="91f8" class="kw kx oc ky b kz la jr lb lc ld ju le om lg lh li on lk ll lm oo lo lp lq lr ij bi translated">【GitHub链接】完整代码:【https://github.com/narotam333/de-project-1】<a class="ae kv" href="https://github.com/narotam333/de-project-1" rel="noopener ugc nofollow" target="_blank"/></p></blockquote></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="11e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这个博客能够帮助那些正在寻找Apache Airflow快速实践文章的人，并帮助他们开始使用这个令人敬畏的开源工具的旅程。</p><p id="3039" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读。</p></div></div>    
</body>
</html>
<html>
<head>
<title>Scaling Machine Learning Models With Docker Swarm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Docker Swarm扩展机器学习模型</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/scaling-machine-learning-models-with-docker-swarm-39a1a875a692?source=collection_archive---------6-----------------------#2019-09-23">https://betterprogramming.pub/scaling-machine-learning-models-with-docker-swarm-39a1a875a692?source=collection_archive---------6-----------------------#2019-09-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ee5c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">本教程展示了我们如何使用Docker Swarm在多台主机上轻松扩展机器学习服务</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/9dccfa2066804a8a2e9e578f2d6dfce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*4p2q9pGNiULh0c4wzWLcWw.png"/></div></figure><p id="c85f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这篇教程是我之前的文章的后续，关于用FastAPI、Redis和Docker对Keras模型进行dockerizing和部署。在这里，我们将看到如何使用相同的代码和相同的<code class="fe lk ll lm ln b">docker-compose.yml</code>通过Docker Swarm轻松地将我们的部署扩展到多个主机上。</p><p id="b7e6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们还将使用Locust来进行负载测试，并展示我们的响应时间是如何随着我们向集群中添加的每个工人而提高的。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="89e5" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">概述</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/82a094e093f1e3f5f6f51543bf10cd18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/0*t8hNgPDX-VujpIrS.png"/></div></figure><p id="54d8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在之前的帖子中，我们看到了我们如何在<a class="ae lj" href="https://www.pyimagesearch.com/2018/02/05/deep-learning-production-keras-redis-flask-apache/" rel="noopener ugc nofollow" target="_blank"> Adrian Rosebrock的教程</a>中对服务进行分类，并使整个服务变得非常容易。</p><p id="3426" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">然而，我们也从负载测试中看到，服务的性能可能不足以满足生产使用。在本教程中，我们将使用Docker Swarm来复制我们的模型服务器，以提供更好的性能。</p><p id="fd73" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">和以前一样，本教程中的所有代码都可以在以下位置找到:</p><div class="mo mp gp gr mq mr"><a href="https://github.com/shanesoh/deploy-ml-fastapi-redis-docker" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd ir gy z fp mw fr fs mx fu fw ip bi translated">Shane soh/deploy-ml-fastapi-redis-docker</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">使用FastAPI、Redis和…服务于生产就绪和可扩展的基于Keras的深度学习模型图像分类</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">github.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf kl mr"/></div></div></a></div></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="6078" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">什么是Docker Swarm？</h1><p id="4172" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">Docker Swarm是Docker的本地集群。Docker的现代版本带有内置的群模式，用于管理Docker引擎集群，有效地将一个Docker主机池转变为一个虚拟主机。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="202a" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">为什么Docker蜂拥而至？</h1><p id="9ee7" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">对于容器编排，有Docker Swarm的替代品，即Kubernetes，这也可以说是更受欢迎的选择。还有基于云的部署机器学习模型的解决方案(如AWS SageMaker)。</p><p id="6f54" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">然而，有时我们可能希望推出自己的解决方案，无论是为了学习还是为了自托管整个管道(即，不依赖于云)。后者在政府或监管行业中非常普遍。</p><p id="2742" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我的工作中，数据科学家和工程师经常需要部署在各种敏感的“基础设施受限”的无线网络中(例如，人们不能指望本地Kubernetes集群随时可用)，我们必须在各种受限环境中独立部署和扩展ML模型。</p><p id="ef4e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在这些公认的小众场景中，Docker Swarm是我的首选。Docker Swarm与Docker完全集成，使用相同的CLI，并且可以使用与Docker Compose相同的配置文件进行配置。与Kubernetes相比，它也更容易建立和大规模运行。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="9f64" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">决定在哪里托管你的Docker群</h1><p id="a23c" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">出于开发和测试目的，您可以选择使用虚拟机来设置Docker Swarm集群。Docker官方网站有一个<a class="ae lj" href="https://docs.docker.com/get-started/part4/" rel="noopener ugc nofollow" target="_blank">很好的教程</a>，可以在你的本地机器上初始化一大群虚拟机。但是，通过这样做，我们将看不到跨多台机器横向扩展模型服务器的性能优势(因为虚拟机仍然在资源有限的同一物理主机上运行)。</p><p id="ee83" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">托管蜂群的最简单方式是在云上(例如，在谷歌云平台上；GCP)。您可以使用Docker Machine在GCP实例上轻松启动和安装Docker。<a class="ae lj" href="https://engineering.galleon.ph/posts/docker-swarm-gcp/" rel="noopener ugc nofollow" target="_blank">本教程</a>将其分解为几个命令。</p><p id="4ea4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果你在一个离线环境中工作，或者如果你选择自托管，那么建立一个swarm可能就是在一些物理机器上安装Docker Engine，并用几个简单的Docker命令将它们连接起来。在这篇文章中，我选择在我的家庭服务器上运行它们(一台在壁橱里嗡嗡作响的白色盒子超微至强-D服务器)。</p><p id="18cc" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">不管你选择在哪里托管你的swarm，除了一些小的不同，你都应该能够遵循下面的步骤。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="a583" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">创造一个码头工人群体</h1><p id="d3a2" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">假设我们没有在可以使用Docker Machine 供应的<a class="ae lj" href="https://docs.docker.com/machine/drivers/" rel="noopener ugc nofollow" target="_blank">环境中托管我们的swarm，那么我们将不得不在我们所有的主机上手动安装Docker Engine和Docker Compose。</a></p><p id="2f53" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在本练习中，我们将设置一个管理者节点和三个工作者节点。</p><p id="0d3e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">一旦你完成了这些，在你想用作管理器的节点上运行<code class="fe lk ll lm ln b">docker swarm init</code>。您将看到join命令以及向节点添加新工人所需的令牌:</p><pre class="kg kh ki kj gt nl ln nm nn aw no bi"><span id="564c" class="np lw iq ln b gy nq nr l ns nt">Swarm initialized: current node (12mfhmaqslwd2x2jqs8c6k36m) is now a manager.</span><span id="d3f2" class="np lw iq ln b gy nu nr l ns nt">To add a worker to this swarm, run the following command:</span><span id="a922" class="np lw iq ln b gy nu nr l ns nt">docker swarm join --token xxxxxxx 10.145.1.20:2377</span><span id="1de4" class="np lw iq ln b gy nu nr l ns nt">To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.</span></pre><p id="5a67" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe lk ll lm ln b">10.145.1.20</code>是我的经理节点。我们将在我们的三个工作节点上运行上面的命令<code class="fe lk ll lm ln b">docker swarm join --token xxxxxxx 10.145.1.20:2377</code>,将它们添加到集群中。</p><p id="3d4b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在运行<code class="fe lk ll lm ln b">docker node ls</code>，您应该会看到您的集群中的所有节点:</p><pre class="kg kh ki kj gt nl ln nm nn aw no bi"><span id="e2fb" class="np lw iq ln b gy nq nr l ns nt">$ docker node ls                                                                                                                                          <br/>ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION<br/>niairu4mt6az6y8263qk3yl4y *   swarm-manager-1     Ready               Active              Leader              19.03.2<br/>n2gzk977b02byajotketwlhb3     swarm-worker-1      Ready               Active                                  19.03.2<br/>aupx477hzv4m8t0f4n1hqlmt2     swarm-worker-2      Ready               Active                                  19.03.2<br/>711gwle1dpzr9cjen6rqbqwdr     swarm-worker-3      Ready               Active                                  19.03.2</span></pre><p id="f541" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">就是这样！</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="f02b" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">在Docker Swarm上部署</h1><p id="162c" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">现在我们已经创建了我们的swarm，在其上部署我们的机器学习服务也很容易。</p><p id="ac08" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在manager节点上，下载包含环境变量的<code class="fe lk ll lm ln b">docker-compose.yml</code>和<code class="fe lk ll lm ln b">app.env</code>，然后部署一个名为<code class="fe lk ll lm ln b">mldeploy</code>的堆栈，如下所示:</p><pre class="kg kh ki kj gt nl ln nm nn aw no bi"><span id="a39d" class="np lw iq ln b gy nq nr l ns nt">$ wget <a class="ae lj" href="https://gist.githubusercontent.com/shanesoh/225b99902410a43fecb42b5f26ea5673/raw/e622e263911fc5bd285038f83e3c2d9e7cc0ce97/docker-compose.yml" rel="noopener ugc nofollow" target="_blank">https://gist.githubusercontent.com/shanesoh/225b99902410a43fecb42b5f26ea5673/raw/e622e263911fc5bd285038f83e3c2d9e7cc0ce97/docker-compose.yml</a></span><span id="908e" class="np lw iq ln b gy nu nr l ns nt">$ wget <a class="ae lj" href="https://raw.githubusercontent.com/shanesoh/deploy-ml-fastapi-redis-docker/master/app.env" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/shanesoh/deploy-ml-fastapi-redis-docker/master/app.env</a></span><span id="0db2" class="np lw iq ln b gy nu nr l ns nt">$ docker stack deploy -c docker-compose.yml mldeploy</span></pre><p id="5779" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">运行<code class="fe lk ll lm ln b">docker stack ps mldeploy</code>,您应该会看到三个服务已经启动:</p><pre class="kg kh ki kj gt nl ln nm nn aw no bi"><span id="b67a" class="np lw iq ln b gy nq nr l ns nt">ID                  NAME                     IMAGE                         NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS<br/>hffngo1qrnch        mldeploy_webserver.1     shanesoh/webserver:latest     swarm-manager-1     Running             Running 2 minutes ago                       <br/>otctku7gvpaf        mldeploy_modelserver.1   shanesoh/modelserver:latest   swarm-worker-2      Running             Running 2 minutes ago                       <br/>hwvr9mm50rhe        mldeploy_redis.1         redis:latest                  swarm-manager-1     Running             Running 2 minutes ago</span></pre><p id="f8b6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">管理器节点上的web服务器、工作器节点上的一个模型服务器实例，以及管理器或工作器节点上的Redis节点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">docker-compose.yml</p></figure><p id="f72d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这是因为我们在合成文件中约束了<code class="fe lk ll lm ln b">modelserver</code>和<code class="fe lk ll lm ln b">webserver</code>的<code class="fe lk ll lm ln b">node.role</code>。另外，请注意，我们已经默认设置了<code class="fe lk ll lm ln b">replicas: 1</code>。</p><p id="dbd5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这个机器学习服务的可伸缩性的主要来源是由<code class="fe lk ll lm ln b">replicas:</code>参数提供的<code class="fe lk ll lm ln b">modelserver</code>的复制。在下一节中，我们将使用负载测试和<code class="fe lk ll lm ln b">modelserver</code>的动态缩放来说明这一点。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="4a3c" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">用Locust扩展模型服务器和负载测试</h1><p id="16b9" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">在我之前的文章中，我们看到了如何使用<a class="ae lj" href="https://locust.io" rel="noopener ugc nofollow" target="_blank"> Locust </a>对像我们这样的HTTP端点进行负载测试。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi ob"><img src="../Images/4c02e0a7e604a067217f48996f840ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7GlYBwG75_CAdmKc.png"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">绿色表示平均响应时间；黄色代表p95</p></figure><p id="bd57" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们还发现我们的性能在50个模拟用户的情况下并不好。如图所示，p95的响应时间约为5000毫秒。</p><p id="605c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将使用从带有<code class="fe lk ll lm ln b">locust — host=http://localhost</code>的回购中提供的<code class="fe lk ll lm ln b">locustfile</code>再次启动Locust。现在将您的浏览器指向<code class="fe lk ll lm ln b">http://localhost:8089</code>以访问web UI，并开始50个用户的测试。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi og"><img src="../Images/d3d6c47f3c6b63c705cc0b14398c6d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0XfikGREdg0pmtwgg2f9Uw.png"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">从一个工人扩展到两个工人，然后是三个工人。</p></figure><p id="ac36" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">注意，现在响应时间更长了(大约12000 ms ),因为我选择了从互联网访问端点(模拟某人通过web访问该服务)。</p><p id="c5a9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在使用命令将<code class="fe lk ll lm ln b">modelserver</code>扩展到两个工人之前，我运行了一两分钟的蝗虫测试来稳定响应时间:</p><pre class="kg kh ki kj gt nl ln nm nn aw no bi"><span id="7145" class="np lw iq ln b gy nq nr l ns nt">docker service scale mldeploy_modelserver=2</span></pre><p id="d885" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">给它几秒钟让第二个工人开始工作，你应该看到响应时间下降。在我的例子中，响应时间从12000 ms下降到了大约5000 ms:仅仅通过扩展模型服务器就有超过100%的改进。</p><p id="874a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在发生的是，两个模型服务器都在轮询Redis消息队列，并并行处理请求。</p><p id="bdf6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">通过使用<code class="fe lk ll lm ln b">docker service scale mldeploy_modelserver=3</code>将<code class="fe lk ll lm ln b">modelserver</code>扩展到三个工人，可以进一步提高性能。响应时间进一步下降到大约3000毫秒。这是一个较小的改进，因为我们逐渐接近开销(来自网络、处理、代码效率低下等)的响应时间。)我们不能通过简单地横向扩展模型服务器来解决这个问题。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="18e9" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">结论</h1><p id="80a8" class="pw-post-body-paragraph kn ko iq kp b kq ng jr ks kt nh ju kv kw ni ky kz la nj lc ld le nk lg lh li ij bi translated">在这篇文章中，我们看到了如何快速构建我们自己的Docker-native集群(即Docker Swarm)并在其上部署可扩展的机器学习服务。我们还做了一个负载测试，观察复制模型服务器如何提高性能。</p></div></div>    
</body>
</html>
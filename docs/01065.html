<html>
<head>
<title>Kubernetes Tips: HA Cluster With Kubespray</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes提示:使用Kubespray的HA集群</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/kubernetes-tips-ha-cluster-with-kubespray-69e5bb2fa444?source=collection_archive---------4-----------------------#2019-08-12">https://betterprogramming.pub/kubernetes-tips-ha-cluster-with-kubespray-69e5bb2fa444?source=collection_archive---------4-----------------------#2019-08-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9f13" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Kubespray创建高可用性集群并了解控制平面组件的行为方式</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/f20cc09a46726449f66456d62a9eec1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*a8875PtMZPHP6ugX2VmuoQ.png"/></div></figure><p id="368f" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">有几种工具可以用来建立Kubernetes集群。这些选项包括但不限于:</p><ul class=""><li id="b9a6" class="lm ln it ks b kt ku kw kx kz lo ld lp lh lq ll lr ls lt lu bi translated">kubeadm:可用于部署一个<a class="ae lv" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/" rel="noopener ugc nofollow" target="_blank">单主机</a>或一个<a class="ae lv" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/" rel="noopener ugc nofollow" target="_blank">高可用性集群</a></li><li id="bea1" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><a class="ae lv" href="https://github.com/kubernetes-sigs/kubespray" rel="noopener ugc nofollow" target="_blank"> Kubespray </a>:基于Ansible playbook，在幕后使用kubeadm部署单主或多主集群</li><li id="5a80" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">eksctl:致力于在AWS基础设施上部署集群</li><li id="4681" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><a class="ae lv" href="https://rancher.com/products/rancher/" rel="noopener ugc nofollow" target="_blank"> Rancher </a>:提供了一个很棒的web UI来从一个位置管理几个集群</li><li id="5576" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">…这样的例子不胜枚举</li></ul><p id="81b9" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在本文中，我们将看到如何使用Kubespray建立一个HA集群。</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="6aee" class="mi mj it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">设置依赖关系</h1><p id="bb15" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">我们从克隆Kubespray存储库开始。它包含设置集群所需的所有可翻译的行动手册。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="8cae" class="nk mj it ng b gy nl nm l nn no">$ git clone <a class="ae lv" href="mailto:git@github.com" rel="noopener ugc nofollow" target="_blank">git@github.com</a>:kubernetes-sigs/kubespray.git</span></pre><p id="c1f3" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然后我们用Python的<code class="fe np nq nr ng b">pip</code>安装依赖项:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="f633" class="nk mj it ng b gy nl nm l nn no">$ cd kubespray</span><span id="1607" class="nk mj it ng b gy ns nm l nn no">$ pip3 install -r requirements.txt</span></pre><p id="0dd0" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在此过程中，将安装以下部件:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="5e7a" class="nk mj it ng b gy nl nm l nn no">$ cat requirements.txt<br/>ansible==2.7.12<br/>jinja2==2.10.1<br/>netaddr==0.7.19<br/>pbr==5.2.0<br/>hvac==0.8.2<br/>jmespath==0.9.4<br/>ruamel.yaml==0.15.96</span></pre></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="54c6" class="mi mj it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">供应基础设施</h1><p id="4f4e" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">在本例中，我们使用在DigitalOcean上创建的三个节点。每个节点都具有以下属性:</p><ul class=""><li id="fd32" class="lm ln it ks b kt ku kw kx kz lo ld lp lh lq ll lr ls lt lu bi translated">标准型(开发/测试环境的理想选择)</li><li id="06a5" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">Ubuntu Server 18.04</li><li id="51b1" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">4 GB / 2个CPU</li><li id="8692" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">位于伦敦数据中心</li><li id="d5d3" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">配置了预定义的ssh密钥(稍后用于从Ansible行动手册中自动建立ssh连接)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi nt"><img src="../Images/5da2a8492a1dbabf511994542719e4b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZIZYXO5ZAXsg-VcboEjV-g.png"/></div></div></figure></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="db18" class="mi mj it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">集群配置</h1><p id="7675" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">使用Kubespray时，首先建议从<code class="fe np nq nr ng b">inventory/sample</code>复制默认样本配置:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="7c6e" class="nk mj it ng b gy nl nm l nn no">$ cp -rfp inventory/sample inventory/mycluster</span></pre><p id="2331" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然后，我们可以在以下文件中自定义Ansible变量:</p><ul class=""><li id="3031" class="lm ln it ks b kt ku kw kx kz lo ld lp lh lq ll lr ls lt lu bi translated"><code class="fe np nq nr ng b">inventory/mycluster/group_vars/all/all.yml</code></li><li id="a98f" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><code class="fe np nq nr ng b">inventory/mycluster/group_vars/k8s-cluster/k8s-cluster.yml</code></li></ul><p id="ab88" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在当前示例中，使用默认值完全没问题。</p><h2 id="eda0" class="nk mj it bd mk ny nz dn mo oa ob dp ms kz oc od mu ld oe of mw lh og oh my oi bi translated">存货文件</h2><p id="85c3" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">Kubespray有一个助手脚本，用于根据IP地址列表创建清单。以下命令设置我们三个节点的IP，并在yaml中创建一个清单:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="2386" class="nk mj it ng b gy nl nm l nn no">$ declare -a IPS=(<!-- -->165.22.119.207<!-- --> <!-- -->68.183.36.52<!-- --> <!-- -->104.248.164.246<!-- -->)</span><span id="f6b3" class="nk mj it ng b gy ns nm l nn no">$ CONFIG_FILE=inventory/mycluster/hosts.yml python3 contrib/inventory_builder/inventory.py ${IPS[@]}</span></pre><p id="5283" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">生成的清单文件如下:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="ea6c" class="nk mj it ng b gy nl nm l nn no">all:<br/>  hosts:<br/>    node1:<br/>      ansible_host: 165.22.119.207<br/>      ip: 165.22.119.207<br/>      access_ip: 165.22.119.207<br/>    node2:<br/>      ansible_host: 68.183.36.52<br/>      ip: 68.183.36.52<br/>      access_ip: 68.183.36.52<br/>    node3:<br/>      ansible_host: 104.248.164.246<br/>      ip: 104.248.164.246<br/>      access_ip: 104.248.164.246<br/>  children:<br/>    kube-master:<br/>      hosts:<br/>        node1:<br/>        node2:<br/>    kube-node:<br/>      hosts:<br/>        node1:<br/>        node2:<br/>        node3:<br/>    etcd:<br/>      hosts:<br/>        node1:<br/>        node2:<br/>        node3:<br/>    k8s-cluster:<br/>      children:<br/>        kube-master:<br/>        kube-node:<br/>    calico-rr:<br/>      hosts: {}</span></pre><p id="d8fb" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果你喜欢玩类似INI格式的库存文件(像我一样)，你可以很容易地将内容重新格式化并保存为一个<code class="fe np nq nr ng b">hosts.ini</code>文件:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d8e8" class="nk mj it ng b gy nl nm l nn no">[all]<br/>node1 ansible_host=165.22.119.207<br/>node2 ansible_host=68.183.36.52<br/>node3 ansible_host=104.248.164.246</span><span id="896a" class="nk mj it ng b gy ns nm l nn no">[kube-master]<br/>node1<br/>node2</span><span id="2d0b" class="nk mj it ng b gy ns nm l nn no">[etcd]<br/>node1<br/>node2<br/>node3</span><span id="25bd" class="nk mj it ng b gy ns nm l nn no">[kube-node]<br/>node2<br/>node3</span><span id="15b5" class="nk mj it ng b gy ns nm l nn no">[k8s-cluster:children]<br/>kube-master<br/>kube-node</span></pre><p id="ea02" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这里需要注意几件重要的事情:</p><ul class=""><li id="16ba" class="lm ln it ks b kt ku kw kx kz lo ld lp lh lq ll lr ls lt lu bi translated">三个节点在<code class="fe np nq nr ng b">[all]</code>部分定义</li><li id="6a80" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><code class="fe np nq nr ng b">[master]</code>部分包含<code class="fe np nq nr ng b">node1</code>和<code class="fe np nq nr ng b">node2</code>,确保管理进程(API服务器、调度器、控制器管理器)在每个主机上运行</li><li id="8ce4" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><code class="fe np nq nr ng b">[etcd]</code>部分包含三个节点，这意味着etcd的一个实例将在其中的每一个节点上运行(至少需要一个HA etcd集群)</li><li id="6dab" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated"><code class="fe np nq nr ng b">[kube-node]</code>部分包含节点2和节点3，因此可以在这些节点上调度用户的工作负载。在每个主节点上默认设置的<code class="fe np nq nr ng b">NoExecute</code>污点不会在<code class="fe np nq nr ng b">node2</code>上设置。这个污点用于防止用户工作负载被调度到一个节点上</li><li id="e63a" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">yaml清单中的<code class="fe np nq nr ng b">calico-rr</code>键下没有定义主机，所以我们在这里不指定任何部分</li></ul><p id="10de" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">该清单定义了一个具有堆栈etcd拓扑的集群。这意味着etcd实例在主节点上运行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi oj"><img src="../Images/5c0d23fcd5a9fb2d126c08f4d35011f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MzsG-mE789PiISM9gncY7Q.png"/></div></div><p class="ok ol gj gh gi om on bd b be z dk translated">部署在主节点上的etcd集群(来源:Kubernetes文档)</p></figure><p id="ba22" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">注意:我们可以供应更多的虚拟机，并指定其中的3个运行etcd集群，这样它就在Kubernetes的外部。这将确保群集具有更高的安全性/弹性，但代价是增加了硬件。</p><h2 id="63fc" class="nk mj it bd mk ny nz dn mo oa ob dp ms kz oc od mu ld oe of mw lh og oh my oi bi translated">构建集群</h2><p id="2253" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">一旦一切就绪，我们就可以运行Ansible剧本来构建集群了。以下命令执行<code class="fe np nq nr ng b">cluster.yml</code>文件中指定的动作:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="0bbc" class="nk mj it ng b gy nl nm l nn no">$ ansible-playbook -i hosts.ini -u root -b --key-file=~/.ssh/do-key.pem cluster.yml</span></pre><p id="692b" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">群集只需要几分钟就可以准备就绪。一旦它启动并运行，我们就可以从主服务器上的<code class="fe np nq nr ng b">/etc/kubernetes/admin.conf</code>位置获得一个kube配置文件。我们可以通过<code class="fe np nq nr ng b">KUBECONFIG</code>环境变量配置<code class="fe np nq nr ng b">kubectl</code>客户端来使用它:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="cd0d" class="nk mj it ng b gy nl nm l nn no">$ scp root@MASTER_X_IP:/etc/kubernetes/admin.conf kubespray-do.conf</span><span id="289d" class="nk mj it ng b gy ns nm l nn no">$ export KUBECONFIG=$PWD/kubespray-do.conf</span></pre><p id="01b8" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然后我们可以得到节点列表:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="7f31" class="nk mj it ng b gy nl nm l nn no">$ kubectl get nodes<br/>NAME    STATUS   ROLES    AGE   VERSION<br/>node1   Ready    master   29m   v1.15.2<br/>node2   Ready    master   28m   v1.15.2<br/>node3   Ready    &lt;none&gt;   27m   v1.15.2</span></pre><h2 id="b538" class="nk mj it bd mk ny nz dn mo oa ob dp ms kz oc od mu ld oe of mw lh og oh my oi bi translated">近距离观察控制平面</h2><p id="341e" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">让我们列出集群上运行的所有pod。因为我们没有运行任何工作负载，所以所有的pod都属于<code class="fe np nq nr ng b">kube-system</code>名称空间，它们专用于管理任务。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="de89" class="nk mj it ng b gy nl nm l nn no"><strong class="ng iu">$ kubectl get pods -n kube-system</strong><br/>NAME                                  READY STATUS    RESTARTS   AGE<br/>calico-kube-controllers-64c..-dtnzv   1/1   Running   0          27m<br/>calico-node-j62dh                     1/1   Running   1          28m<br/>calico-node-jtfml                     1/1   Running   1          28m<br/>calico-node-qh8rw                     1/1   Running   1          28m<br/>coredns-74c9d4d795-cp274              1/1   Running   0          27m<br/>coredns-74c9d4d795-hrnqd              1/1   Running   0          27m<br/>dns-autoscaler-7d95989447-t54wv       1/1   Running   0          27m<br/>kube-apiserver-node1                  1/1   Running   0          29m<br/>kube-apiserver-node2                  1/1   Running   0          28m<br/>kube-controller-manager-node1         1/1   Running   0          29m<br/>kube-controller-manager-node2         1/1   Running   0          28m<br/>kube-proxy-6v5tf                      1/1   Running   0          28m<br/>kube-proxy-dbhvs                      1/1   Running   0          28m<br/>kube-proxy-tv4kg                      1/1   Running   0          28m<br/>kube-scheduler-node1                  1/1   Running   0          29m<br/>kube-scheduler-node2                  1/1   Running   0          28m<br/>kubernetes-dashboard-7c547b4c64-q2gds 1/1   Running   0          27m<br/>nginx-proxy-node3                     1/1   Running   0          28m<br/>nodelocaldns-52rwd                    1/1   Running   0          27m<br/>nodelocaldns-dgzk2                    1/1   Running   0          27m<br/>nodelocaldns-grfsq                    1/1   Running   0          27m</span></pre><p id="c6e5" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">列出集群的其他资源，我们可以很容易地看到:</p><ul class=""><li id="c32b" class="lm ln it ks b kt ku kw kx kz lo ld lp lh lq ll lr ls lt lu bi translated">pod<code class="fe np nq nr ng b">calico-kube-controllers</code>、<code class="fe np nq nr ng b">coredns</code>、<code class="fe np nq nr ng b">dns-autoscaler</code>和<code class="fe np nq nr ng b">kubernetes-dashboard</code>均由部署资源管理</li><li id="69d3" class="lm ln it ks b kt lw kw lx kz ly ld lz lh ma ll lr ls lt lu bi translated">pod<code class="fe np nq nr ng b">calico-node</code>、<code class="fe np nq nr ng b">kube-proxy</code>、<code class="fe np nq nr ng b">nodelocaldns</code>分别由一个DaemonSet资源管理</li></ul><p id="f10e" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">当谈到在控制平面内使用的吊舱时，事情有点不同:<code class="fe np nq nr ng b">kube-apiserver</code>、<code class="fe np nq nr ng b">kube-controller-manager</code>和<code class="fe np nq nr ng b">kube-scheduler</code>。这些pod不受任何更高资源(部署、DaemonSet等)的管理，并且在其名称中包含它们所运行的主节点。</p><p id="7267" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">由于这些进程对集群至关重要，我们可以想象每个进程的两个实例不能同时运行。接下来让我们看看这些流程是如何处理的。</p><p id="b28c" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><strong class="ks iu"> API服务器</strong></p><p id="b2ab" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">为了连接到API服务器，工作节点通过一个负载平衡器。在<code class="fe np nq nr ng b">node3</code>，吊舱<code class="fe np nq nr ng b">nginx-proxy-node3</code>正在运行。如果我们检查它的配置，我们可以看到它将每个请求代理到API服务器的一个实例(在下面的输出中以粗体显示)。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="9996" class="nk mj it ng b gy nl nm l nn no">$ kubectl exec -ti pod/nginx-proxy-node3 -n kube-system -- sh<br/># cat /etc/nginx/nginx.conf<br/>error_log stderr notice;</span><span id="88e3" class="nk mj it ng b gy ns nm l nn no">worker_processes 2;<br/>worker_rlimit_nofile 130048;<br/>worker_shutdown_timeout 10s;</span><span id="8f52" class="nk mj it ng b gy ns nm l nn no">events {<br/>  multi_accept on;<br/>  use epoll;<br/>  worker_connections 16384;<br/>}</span><span id="93a8" class="nk mj it ng b gy ns nm l nn no">stream {<br/>  upstream kube_apiserver {<br/>    least_conn;<br/>    <strong class="ng iu">server 165.22.119.207:6443;<br/>    server 68.183.36.52:6443;</strong><br/>    }</span><span id="465f" class="nk mj it ng b gy ns nm l nn no">server {<br/>    listen        127.0.0.1:6443;<br/>    proxy_pass    kube_apiserver;<br/>    proxy_timeout 10m;<br/>    proxy_connect_timeout 1s;<br/>  }<br/>}</span><span id="188d" class="nk mj it ng b gy ns nm l nn no">http {<br/>  aio threads;<br/>  aio_write on;<br/>  tcp_nopush on;<br/>  tcp_nodelay on;</span><span id="1d17" class="nk mj it ng b gy ns nm l nn no">  keepalive_timeout 75s;<br/>  keepalive_requests 100;<br/>  reset_timedout_connection on;<br/>  server_tokens off;<br/>  autoindex off;</span><span id="829a" class="nk mj it ng b gy ns nm l nn no">}</span></pre><p id="d537" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">因此，如果一个API服务器不健康(通过keepalive指令检测)，另一个将用于处理请求。</p><p id="80d8" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><strong class="ks iu">控制器管理器&amp;调度器</strong></p><p id="a91e" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">正如Kubernetes文档中所定义的，这些组件使用租用机制来确保集群中每个组件只有一个实例是活动的。考虑到调度程序，让我们仔细看看。</p><p id="396f" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">首先，我们需要获得端点列表，它定义了访问其他资源的方式(服务资源使用端点来对后端Pods的请求进行负载平衡):</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="e05e" class="nk mj it ng b gy nl nm l nn no"><strong class="ng iu">$ kubectl get endpoints -n kube-system<br/></strong>NAME                    ENDPOINTS                              AGE<br/>coredns                 10.233.90.2:53,10.233.96.1:53 + 3 more 109m<br/>kube-controller-manager &lt;none&gt;                                 112m<br/>kube-scheduler          &lt;none&gt;                                 112m<br/>kubernetes-dashboard    10.233.92.1:8443                       109m</span></pre><p id="4fd0" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们可以检查一下<code class="fe np nq nr ng b">kube-scheduler</code>里面有什么:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="e24a" class="nk mj it ng b gy nl nm l nn no"><strong class="ng iu">$ kubectl get endpoints kube-scheduler -n kube-system -o yaml</strong><br/>apiVersion: v1<br/>kind: Endpoints<br/>metadata:<br/>  annotations:<br/><strong class="ng iu">    control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"node1_e7f79dcf-ed72-43c0-902a-6fc62aac2a69","leaseDurationSeconds":15,"acquireTime":"2019-08-11T11:30:08Z","renewTime":"2019-08-11T13:24:55Z","leaderTransitions":0}'</strong><br/>  creationTimestamp: "2019-08-11T11:30:08Z"<br/>  name: kube-scheduler<br/>  namespace: kube-system<br/>  resourceVersion: "13193"<br/>  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler<br/>  uid: 5437cbe6-7e5d-4dd2-a491-e345dc09a73b</span></pre><p id="8fa2" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">然后关注<code class="fe np nq nr ng b">control-plane.alpha.kubernetes.io/leader</code>标注:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="0f0d" class="nk mj it ng b gy nl nm l nn no">{<br/>  "holderIdentity":"<strong class="ng iu">node1</strong>_e7f79dcf-ed72-43c0-902a-6fc62aac2a69",<br/>  "leaseDurationSeconds":15,<br/>  "acquireTime":"2019-08-11T11:30:08Z",<br/>  "renewTime":"2019-08-11T13:24:55Z",<br/>  "leaderTransitions":0<br/>}</span></pre><p id="9ffb" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这个定义了哪个调度器是领导者，在这个例子中，是运行在<code class="fe np nq nr ng b">node1</code>上的调度器。当前领导者有一个租约，必须更新以确保它仍然有效。如果它不能续约，那么将会进行新的领导人选举。</p><p id="78a7" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">从数字海洋界面，我们可以模拟断电并摧毁<code class="fe np nq nr ng b">node1</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nu nv di nw bf nx"><div class="gh gi nt"><img src="../Images/164fe5cc764cbf54d963e593d710caef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OgUVGguESydzLlPO67-qWg.png"/></div></div></figure><p id="1ee2" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果我们在<code class="fe np nq nr ng b">kube-scheduler</code>端点的注释中检查<code class="fe np nq nr ng b">control-plane.alpha.kubernetes.io/leader</code>键的内容，我们可以看到leader不再是运行在<code class="fe np nq nr ng b">node1</code>上的调度程序。新的领导者现在是在<code class="fe np nq nr ng b">node2</code>上运行的调度程序。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="4058" class="nk mj it ng b gy nl nm l nn no">{<br/>  "holderIdentity":"<strong class="ng iu">node2</strong>_a13c0374-44ea-419e-ac07-f868faddab3e",<br/>  "leaseDurationSeconds":15,<br/>  "acquireTime":"2019-08-11T14:19:51Z",<br/>  "renewTime":"2019-08-11T14:26:31Z",<br/>  "leaderTransitions":1<br/>}</span></pre><p id="8514" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">由于以前的计划程序无法更新租约，因此进行了新的领导者选举。</p><p id="cc5e" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">同样的过程也适用于控制器管理器，因此每次只使用一个实例。</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="aaf3" class="mi mj it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">摘要</h1><p id="b3f6" class="pw-post-body-paragraph kq kr it ks b kt na ju kv kw nb jx ky kz nc lb lc ld nd lf lg lh ne lj lk ll im bi translated">在本文中，我们使用Kubespray创建了一个HA集群，并看到了控制平面的组件在该集群中的行为。在使用HA集群时，理解用于访问API服务器的负载平衡器和租用机制非常重要。</p><p id="a1b2" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">为了获得更高的弹性和安全性，应该考虑外部etcd集群，这样etcd实例就不依赖于Kubernetes集群的节点。</p></div></div>    
</body>
</html>
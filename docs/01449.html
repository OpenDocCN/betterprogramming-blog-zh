<html>
<head>
<title>Machine Learning for Everyone: Pose Estimation in a Browser With Your Webcam</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向所有人的机器学习:通过网络摄像头在浏览器中进行姿态估计</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/machine-learning-for-everyone-pose-estimation-in-a-browser-with-your-webcam-65bb2648c16a?source=collection_archive---------4-----------------------#2019-09-11">https://betterprogramming.pub/machine-learning-for-everyone-pose-estimation-in-a-browser-with-your-webcam-65bb2648c16a?source=collection_archive---------4-----------------------#2019-09-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="68f3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">无需任何安装就能在浏览器中使用ML的代码友好指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/23bd2c1f2f7ea3a9209dad56120d9085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*D0jL3yO6HYqaCymgHEkBOg.gif"/></div></div></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h1 id="4486" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">目录</h1><ul class=""><li id="6731" class="lt lu it lv b lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated"><a class="ae ml" href="#d1f4" rel="noopener ugc nofollow">简介</a></li><li id="1581" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><a class="ae ml" href="#ac60" rel="noopener ugc nofollow">pose net模型简介</a></li><li id="7f63" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><a class="ae ml" href="#75ef" rel="noopener ugc nofollow">深度代码演练</a></li></ul></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h1 id="d1f4" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">2k19中的ML</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/c683d2b3a4a129d5c20560bb7daf9dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uIIN0l6GyxF80uKqsL_Kxg.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/76dc51bea84552a2464219ce4a10750b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89hR8Gmc37nlFHT_ZcfkHg.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/4028a97e7ccbab0eff2c6c225eb5cc91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gRv1DuiNOZR-Vku9iE9X4g.jpeg"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">AlphaGo、OpenAI和Deep fake在行动。</p></figure><p id="0ef9" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">20世纪是机器学习领域呈指数增长的时代。科学家们预测的有着3000年历史的古老围棋<a class="ae ml" href="https://www.wired.com/2014/05/the-world-of-computer-go/" rel="noopener ugc nofollow" target="_blank">将再花</a>十年时间来破解，这是由<a class="ae ml" href="https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html" rel="noopener ugc nofollow" target="_blank">谷歌大脑团队</a> AlphaGo AI、<a class="ae ml" href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol#targetText=AlphaGo%20versus%20Lee%20Sedol&amp;targetText=AlphaGo%20won%20all%20but%20the,slated%20to%20win%20%241%20million." rel="noopener ugc nofollow" target="_blank">击败</a>多次世界冠军Lee Sudol而实现的。</p><p id="516b" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">顺便说一下，这个中国游戏的组合比宇宙中预测的原子还要多，或者简而言之，这个游戏不能像IBM Blue在1997年那样，通过所有可能的移动来赢得比赛。</p><p id="3066" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">然后，<a class="ae ml" href="https://openai.com/blog/dota-2/" rel="noopener ugc nofollow" target="_blank"> OpenAI的bot </a>在DOTA2和其他有趣(潜在有害)的东西如<a class="ae ml" href="https://en.wikipedia.org/wiki/Deepfake#targetText=Deepfake%20(a%20portmanteau%20of%20&quot;deep,known%20as%20generative%20adversarial%20network." rel="noopener ugc nofollow" target="_blank"> Deepfake </a>中的崛起。研究社区在ML中蓬勃发展，从10年前每年提交100篇论文，到2019年仅在arXiv上每天就有100篇论文。</p><p id="2d89" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">但是，抛开一切不谈，重点是ML是高度数学密集型的。</p><p id="2a00" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">虽然像<a class="ae ml" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae ml" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>这样的库在让所有开发人员都可以使用ML方面做出了重大贡献，但我们仍然有一个陡峭的学习曲线，需要知道如何创建模型、训练模型并保存它以供以后在我们的任务中使用。</p><p id="4a87" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">这就是<a class="ae ml" href="https://ml5js.org/" rel="noopener ugc nofollow" target="_blank"> ml5.js </a>的用武之地，这是一个基于TensorFlow.js的库，它于去年3月推出，将愿景推进了更远。</p><h1 id="c351" class="lb lc it bd ld le nn lg lh li no lk ll jz np ka ln kc nq kd lp kf nr kg lr ls bi translated">为什么选择ml5.js</h1><blockquote class="ns"><p id="5b64" class="nt nu it bd nv nw nx ny nz oa ob mg dk translated">“ml5.js旨在让艺术家、创意程序员和学生等广大受众能够接触到机器学习。该库提供了在浏览器中访问机器学习算法和模型的途径。”—官方开发者</p></blockquote><p id="ee60" class="pw-post-body-paragraph my mz it lv b lw oc ju nb ly od jx nd ma oe nf ng mc of ni nj me og nl nm mg im bi translated">在浏览器中。是啊！<em class="oh">不需要</em>安装<strong class="lv iu">，</strong>它让你远离安装多个数据科学库的痛苦，并确保一切都与你已安装的版本协调工作，相信我，这有时并不容易。</p></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h1 id="4243" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">你需要什么</h1><ol class=""><li id="3d54" class="lt lu it lv b lw lx ly lz ma mb mc md me mf mg oi mi mj mk bi translated">从这个<a class="ae ml" href="https://github.com/kartik-nighania/Real-Time-Human-Pose-detection-in-browser" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>下载代码。它有两个文件夹，一个用于使用网络摄像头作为输入来检测姿势，另一个通过视频文件作为输入。</li><li id="3ee1" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg oi mi mj mk bi translated"><a class="ae ml" href="https://code.visualstudio.com/" rel="noopener ugc nofollow" target="_blank"> VS代码</a>(可选)读取代码。</li></ol></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h1 id="ac60" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">人体姿态估计简介</h1><p id="6ad1" class="pw-post-body-paragraph my mz it lv b lw lx ju nb ly lz jx nd ma oj nf ng mc ok ni nj me ol nl nm mg im bi translated">我们举个小例子。我们希望使用机器学习在一个文件夹中找到带有人脸的图片，该文件夹包含您最近一次度假旅行期间拍摄的所有图片。</p><p id="2a95" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">所以，我们拿一个神经网络，它是一个机器学习模型(牛逼的<a class="ae ml" href="https://www.youtube.com/watch?v=aircAruvnKk" rel="noopener ugc nofollow" target="_blank">初学者视频</a>了解它是什么)，用大量数据训练它，里面有随机的人脸，然后用同样的模型检测我们文件夹里的人脸。</p><p id="ffbf" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">如今，神经网络的味道比巴斯金和罗宾斯在冰淇淋中的味道要丰富得多。(如果你想知道，<a class="ae ml" href="https://simple.wikipedia.org/wiki/Baskin-Robbins#Original_31_Flavors" rel="noopener ugc nofollow" target="_blank">是31 </a>。)有的擅长处理图像，有的擅长处理文本数据，有的擅长处理声音之类的时间序列，等等。</p><p id="4f43" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">在我们的例子中，我们使用卷积神经网络，也就是CNN，来处理图像。</p><p id="9299" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">ml5.js是TensorFlow.js的包装器，它还提供了<a class="ae ml" href="https://github.com/tensorflow/tfjs-models/tree/master/posenet" rel="noopener ugc nofollow" target="_blank"> PoseNet </a>模型。一个现成的模型，内部有预先训练好的CNN，以一个图像作为输入，输出一个<code class="fe om on oo op b">keypoint heatmap</code>和<code class="fe om on oo op b">offset vectors</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/5156470553ac55194b43092192ac3c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L0UCQeynNlzH8kwdDtM9LQ.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">使用移动网络CNN并给出输出的PostNet模型。<a class="ae ml" href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5" rel="noopener">图像演职员表</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/3e812304d5cc732c001e55e5fddf9318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YVjUpFHXlBQetBk46F0KxA.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">PoseNet检测到17个关键点。发布在<a class="ae ml" href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5" rel="noopener"> Tensorflow博客</a></p></figure><p id="f3ed" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">通过使用这些表示和一点点数学魔法，我们最终找到了17个<code class="fe om on oo op b">keypoints</code>，如图所示，来检测一个完整的人体姿势。</p><p id="63b3" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">该模型还通过给每个<code class="fe om on oo op b">17 points</code>一个0-1分的<code class="fe om on oo op b">keypoint confidence score</code>来返回它有多自信(其中1表示100%自信，0.56表示56%)。</p><p id="e3de" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">它还返回在图像中检测人类姿态的总体<code class="fe om on oo op b">pose confidence score</code>，也是在0-1的范围内。</p></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h1 id="75ef" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">编码时间</h1><p id="5971" class="pw-post-body-paragraph my mz it lv b lw lx ju nb ly lz jx nd ma oj nf ng mc ok ni nj me ol nl nm mg im bi translated">我们将使用一个摄像头作为姿势估计模型的视频输入，并在我们的主页<code class="fe om on oo op b">index.html</code>上显示输出。</p><p id="2560" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们在这里使用两个库:</p><ul class=""><li id="1ec0" class="lt lu it lv b lw na ly nc ma os mc ot me ou mg mh mi mj mk bi translated"><code class="fe om on oo op b">ml5.js</code>用于创建和运行我们的ML模型。</li><li id="dc1d" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b"><a class="ae ml" href="https://p5js.org/" rel="noopener ugc nofollow" target="_blank">p5.js</a></code>用于获取网络摄像头视频并在浏览器中显示输出。</li></ul><p id="63dd" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我在代码中添加了大量的文档，解释了每一行。在这里，我们将讨论主要的症结所在，也就是大部分代码。</p><p id="03d0" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们的代码由两个文件组成:</p><ul class=""><li id="5761" class="lt lu it lv b lw na ly nc ma os mc ot me ou mg mh mi mj mk bi translated"><code class="fe om on oo op b">poseNet_webcam.js</code>，我们的JavaScript代码。</li><li id="8e18" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">index.html</code>，主页面显示输出。</li></ul><h2 id="5ecf" class="ov lc it bd ld ow ox dn lh oy oz dp ll ma pa pb ln mc pc pd lp me pe pf lr pg bi translated">PoseNet_webcam.js</h2><p id="a639" class="pw-post-body-paragraph my mz it lv b lw lx ju nb ly lz jx nd ma oj nf ng mc ok ni nj me ol nl nm mg im bi translated"><code class="fe om on oo op b">p5.js</code>运行两个功能:</p><ul class=""><li id="6d9b" class="lt lu it lv b lw na ly nc ma os mc ot me ou mg mh mi mj mk bi translated"><code class="fe om on oo op b">function setup()</code>。只执行和运行一次的第一个函数。我们将在其中进行初始设置。</li><li id="5f63" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">function draw()</code>。这个函数永远重复调用(除非你打算关闭浏览器或按下电源按钮)。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/07e880a7a61425583a1fc1e849f6e2e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*7XPisaXgva97r2beNrfrpg.png"/></div></figure><p id="8a96" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated"><code class="fe om on oo op b">createCanvas(width, height)</code>是由p5提供的在浏览器中创建一个框来显示我们的输出。这里画布有<code class="fe om on oo op b">width: 640px</code>和<code class="fe om on oo op b">height: 480px</code>。</p><p id="3ac9" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated"><code class="fe om on oo op b">createCapture(VIDEO)</code>用于捕获一个网络摄像头馈送并返回一个p5元素对象，我们将其命名为<code class="fe om on oo op b">webcam_output</code>。我们将网络摄像头视频设置为与画布相同的高度和宽度。</p><p id="963c" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated"><code class="fe om on oo op b">ml5.poseNet()</code>创建一个新的PoseNet模型，将以下内容作为输入:</p><ul class=""><li id="4994" class="lt lu it lv b lw na ly nc ma os mc ot me ou mg mh mi mj mk bi translated">我们现在的网络摄像头输出。</li><li id="2d95" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated">一个<a class="ae ml" href="https://www.dashingd3js.com/lessons/javascript-callback-functions#targetText=Passing%20JavaScript%20Functions%20as%20Variables%20Revisited&amp;targetText=functionName(argument1%2C%20argument2)%3B,used%20inside%20of%20the%20function.&amp;targetText=The%20variables%20and%20arguments%20must%20be%20in%20expected%20order." rel="noopener ugc nofollow" target="_blank">回调函数</a>，当模型成功加载时调用。在我们的<code class="fe om on oo op b">index.html</code>文件中，我们创建了一个带有ID <code class="fe om on oo op b">status</code>的HTML段落，向用户显示当前的状态文本。为了让用户知道，我们将文本改为<em class="oh">模型加载</em>，因为模型加载<em class="oh">需要一点时间。</em></li></ul><p id="de84" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated"><code class="fe om on oo op b">poseNet.on()</code>是一个触发器或事件监听器。每当网络摄像头给出一个新的图像，它就被提供给PoseNet模型。</p><p id="e6ab" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">检测到姿态并准备输出的时刻。它调用<code class="fe om on oo op b">function(results)</code>，其中<code class="fe om on oo op b">results</code>是<code class="fe om on oo op b">keypoints</code>的最终输出和模型给出的分数。</p><p id="25fe" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们将它存储在我们的<code class="fe om on oo op b">poses</code>数组中，这个数组是全局定义的，可以在我们代码的任何地方使用。<code class="fe om on oo op b">webcam_output.hide()</code>暂时隐藏网络摄像头输出，因为我们稍后将修改图像并显示检测到的点和线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/90b8e7073db6d6e0cabe7c1d5429d2d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*aepbsCeUatjTvS2zSaA06Q.png"/></div></figure><p id="856c" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们剩下要做的就是在浏览器中显示保存在<code class="fe om on oo op b">poses</code>中的所有检测结果的图像。</p><p id="55d1" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们知道，<code class="fe om on oo op b">draw()</code>函数永远循环运行。在这里，我们调用<code class="fe om on oo op b">image()</code>函数在画布中显示我们的图像(因为我们有我们的视频图像)。</p><p id="c8a9" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">它需要五个参数:</p><ul class=""><li id="0318" class="lt lu it lv b lw na ly nc ma os mc ot me ou mg mh mi mj mk bi translated"><code class="fe om on oo op b">input image</code>。我们想要显示的图像。</li><li id="e652" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">x position</code>。图像左上角相对于画布的x坐标。</li><li id="1e50" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">y position</code>。图像左上角相对于画布的y坐标。</li><li id="4658" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">width</code>。绘制图像的宽度。</li><li id="4fdd" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">height</code>。绘制图像的高度。</li></ul><p id="caa4" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">然后我们调用<code class="fe om on oo op b">drawKeyPoints()</code>和<code class="fe om on oo op b">drawSkeleton()</code>在当前图像上绘制<em class="oh">点和线</em>。<code class="fe om on oo op b">draw()</code>在无限循环中这样做，因此向用户显示连续的输出，这使它看起来像视频。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/b121253009e4464655fe7a9d277c9f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dClYxLdf-7b-TK4QigPdBg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">PoseNet的典型JS对象输出</p></figure><p id="d2fe" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">正如您在上面看到的，PoseNet返回一个JavaScript对象作为输出，由许多键值对组成。这是为图像中的每个人提供的<code class="fe om on oo op b">pose</code>和<code class="fe om on oo op b">skeleton</code>值中的<code class="fe om on oo op b">pose</code>键值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/7b02ed00f23e2af8de8f9ea7878de1fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*dMS9-tknztdcSumiP59zGQ.png"/></div></figure><p id="f07f" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们有一个在图像上绘制检测点的功能。记住，我们将PoseNet输出的所有结果保存在<code class="fe om on oo op b">poses</code>数组中。在这里，我们循环遍历图像中的每个<code class="fe om on oo op b">pose</code>或人物，并获得其<code class="fe om on oo op b">keypoints</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/7b324153b7406723fc55af40bc32a775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*4_Hv2UqmXKE9sNZME0TSlg.png"/></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">关键点数组中的一个点内</p></figure><p id="1cea" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们循环遍历<code class="fe om on oo op b">keypoints</code>数组中的每一个主体部分<code class="fe om on oo op b">point</code>，该数组还包含:</p><ul class=""><li id="b74e" class="lt lu it lv b lw na ly nc ma os mc ot me ou mg mh mi mj mk bi translated"><code class="fe om on oo op b">part</code>。检测到的零件的名称。</li><li id="3978" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">position</code>。图像中点的x和y值。</li><li id="33e4" class="lt lu it lv b lw mm ly mn ma mo mc mp me mq mg mh mi mj mk bi translated"><code class="fe om on oo op b">score</code>。检测的准确性。</li></ul><p id="5726" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们只在检测精度大于<code class="fe om on oo op b">0.2</code>的情况下画一个<code class="fe om on oo op b">point</code>。我们调用<code class="fe om on oo op b">fill(red, green, blue)</code>，取<code class="fe om on oo op b">0 to 255</code>范围内的RGB强度值决定一个点的颜色，<code class="fe om on oo op b">noStroke()</code>禁用绘制p5默认绘制的轮廓。</p><p id="71c2" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">然后，我们调用<code class="fe om on oo op b">ellipse(x_value, y_value, width, height)</code>在期望的位置画一个椭圆，但是我们保持宽度和高度非常小，这使得它们看起来像一个点(正是我们想要的)。</p><p id="9877" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">类似地，由于我们的变量<code class="fe om on oo op b">poses</code>中有多个<code class="fe om on oo op b">pose</code>，它也有多个<code class="fe om on oo op b">skeleton</code>值，它们有自己类型的键值对，这是通过<code class="fe om on oo op b">drawSkeleton()</code>画线而不是画点来处理的。</p><h2 id="d5e8" class="ov lc it bd ld ow ox dn lh oy oz dp ll ma pa pb ln mc pc pd lp me pe pf lr pg bi translated">index.html</h2><p id="2f0e" class="pw-post-body-paragraph my mz it lv b lw lx ju nb ly lz jx nd ma oj nf ng mc ok ni nj me ol nl nm mg im bi translated">这是我们显示输出的主页。我们使用脚本标签添加所有的库。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/4444259eade72b3f2eed17c9b35bb250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zO7VSOAv82soG2gYu0l5Qw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">ml5.js和p5.js库</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/60db8e970823603f878d7e237e01bdde.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*mMQwuHWBCmqKm2bbh_vlhQ.png"/></div></figure><p id="7cd2" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">我们向用户展示了一个可爱的欢迎介绍。由于模型加载需要时间，我们显示'<em class="oh">加载模型…' </em>消息。如果你还记得的话，一旦我们的模型使用一个ID上的引用被加载，我们就把它改成'<em class="oh"> Model Loaded' </em>'，这个ID叫做<code class="fe om on oo op b">status</code>。</p><p id="4c4e" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">最后，我们将自己的JS代码放入主体中。运行<code class="fe om on oo op b">index.html</code>文件查看输出。确保在出现提示时允许网络摄像机访问。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/5790afc9e2b11145d050072c31a7c8bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*pVPUKC-SPT2Vg4vLWdN6iA.gif"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/f42af949c4b004b014268e60c11830e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*RPBw9EuFTWPtVWcGdHYG-Q.gif"/></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">PoseNet在行动。图片来自<a class="ae ml" href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5" rel="noopener">官方Tensorflow medium博客</a>。</p></figure><p id="be59" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">就是这样！你可以随时去<a class="ae ml" href="https://ml5js.org/reference/" rel="noopener ugc nofollow" target="_blank"> ml5.js参考页面</a>，那里有更多现成的模式和代码片段，可以用于各种很酷的ml项目，处理各种各样的东西，比如文本、图像和声音。</p><p id="84dd" class="pw-post-body-paragraph my mz it lv b lw na ju nb ly nc jx nd ma ne nf ng mc nh ni nj me nk nl nm mg im bi translated">感谢阅读！</p></div></div>    
</body>
</html>
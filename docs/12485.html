<html>
<head>
<title>How To Rotate Proxies in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Python中旋转代理</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-rotate-proxies-in-python-650bcea20db5?source=collection_archive---------11-----------------------#2022-06-08">https://betterprogramming.pub/how-to-rotate-proxies-in-python-650bcea20db5?source=collection_archive---------11-----------------------#2022-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2827" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Python构建一个自定义代理旋转器，以避免在web抓取时被阻塞。从自动运行状况检查的IP池中随机选择。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/904c8606f760f31c3f3daa14c05c7c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5kgF8lhsxmTLGkDp22w3w.png"/></div></div></figure><p id="9519" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">代理可以隐藏你的IP地址，但是当它被禁止的时候会发生什么呢？你需要一个新的IP。或者您可以维护它们的列表，并为每个请求轮换代理。最后一个选择是使用<a class="ae ln" href="https://www.zenrows.com/?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=rotate_proxies" rel="noopener ugc nofollow" target="_blank">智能旋转代理</a>，稍后会详细介绍。</p><p id="b12d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们将专注于构建我们的定制代理旋转器。我们将从常规代理列表开始，检查它们以标记工作的代理，并提供简单的监控以从工作列表中删除失败的代理。提供的例子使用Python，但是这个想法在任何语言中都适用。</p><p id="b33a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们开始吧！</p><h1 id="8fb9" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">先决条件</h1><p id="f4f1" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">为了让代码工作，你需要安装<a class="ae ln" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank"> python3和</a>。有些系统已经预装了它。之后，通过运行<code class="fe ml mm mn mo b">pip install</code>安装所有必要的库。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="ad0e" class="mt lp iq mo b gy mu mv l mw mx">pip install aiohttp</span></pre><h1 id="98df" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">代理列表</h1><p id="ee3e" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">您可能没有包含域+端口列表的代理提供程序。别担心，我们会找到的。</p><p id="5f67" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">网上有几个免费代理人的名单。对于这个演示，抓取其中一个并将它的内容(只是URL)保存在一个文本文件(<code class="fe ml mm mn mo b">rotating_proxies_list.txt</code>)中。或者用下面的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/8ccf6177c1d09c40c93f59d491cbfe80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*zVa0OvFtQhySBBzo5j4X-Q.gif"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">从站点导出和复制代理</p></figure><p id="2b04" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">免费代理是不可靠的，下面的那些可能对你不起作用。它们通常是短命的。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="4d5a" class="mt lp iq mo b gy mu mv l mw mx">167.71.230.124:8080<br/>192.155.107.211:1080<br/>77.238.79.111:8080<br/>167.71.5.83:3128<br/>195.189.123.213:3128<br/>8.210.83.33:80<br/>80.48.119.28:8080<br/>152.0.209.175:8080<br/>187.217.54.84:80<br/>169.57.1.85:8123</span></pre><p id="f250" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，我们将读取该文件并创建一个包含所有代理的数组。读取文件，去掉空白，并拆分每一行。保存文件时要小心，因为我们不会对有效的<code class="fe ml mm mn mo b">IP:port</code>字符串进行任何健全性检查。我们会保持简单。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="0d07" class="mt lp iq mo b gy mu mv l mw mx">proxies_list = open("rotating_proxies_list.txt",<br/>                    "r").read().strip().split("\n")</span></pre><h1 id="c0de" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">检查代理</h1><p id="a547" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">让我们假设我们想要大规模运行铲运机。演示是简化的，但其思想是将代理和它们的“健康状态”存储在一个可靠的介质中，如数据库。我们将使用在每次运行后消失的内存中的数据结构，但是你得到了想法。</p><p id="0100" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，让我们编写一个简单的函数来<strong class="kt ir">检查代理是否工作</strong>。为此，调用<a class="ae ln" href="http://ident.me/" rel="noopener ugc nofollow" target="_blank"> ident.me </a>，它将返回IP。这是一个适合我们用例的简单页面。我们将使用<code class="fe ml mm mn mo b"><a class="ae ln" href="https://docs.python.org/3/library/asyncio.html" rel="noopener ugc nofollow" target="_blank">asyncio</a></code>和<code class="fe ml mm mn mo b"><a class="ae ln" href="https://docs.aiohttp.org/en/stable/" rel="noopener ugc nofollow" target="_blank">aiohttp</a></code>，一个类似于著名的<code class="fe ml mm mn mo b">requests</code>的“异步HTTP客户端/服务器”。它更适合我们，因为它的目的是异步工作，当同时检查几个代理时，它会帮助我们。</p><p id="80c7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">目前，它从代理列表中获取一个项目，并调用提供的URL。大部分代码都是样板文件，很快就会被证明是有用的。有两种可能的结果:</p><ul class=""><li id="dffc" class="ne nf iq kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">如果一切正常，它打印响应的内容和状态代码(即200)，这可能是代理的IP。</li><li id="45cc" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">由于超时或其他原因，打印出一个错误。这通常意味着代理不可用或无法处理请求。当使用免费代理时，许多这样的问题都会出现。</li></ul><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="3539" class="mt lp iq mo b gy mu mv l mw mx">import aiohttp<br/>import asyncio</span><span id="02ee" class="mt lp iq mo b gy ns mv l mw mx">proxies_list = open("rotating_proxies_list.txt", "r").read().strip().split("\n")<br/>timeout = aiohttp.ClientTimeout(total=30)</span><span id="9334" class="mt lp iq mo b gy ns mv l mw mx">async def get(url, session, proxy):<br/>    try:<br/>        async with session.get(url, proxy=f"http://{proxy}", timeout=timeout) as response:<br/>            print(response.status, await response.text())<br/>    except Exception as e:<br/>        print(e)</span><span id="d1b6" class="mt lp iq mo b gy ns mv l mw mx">async def check_proxies():<br/>    proxy = proxies_list.pop()<br/>    async with aiohttp.ClientSession() as session:<br/>        await get("http://ident.me/", session, proxy=proxy)</span><span id="1645" class="mt lp iq mo b gy ns mv l mw mx">asyncio.run(check_proxies())</span></pre><p id="14c7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们有意使用HTTP而不是HTTPS，因为许多免费代理不支持SSL。</p><h1 id="2abd" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">添加更多检查以验证结果</h1><p id="fdcd" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">异常意味着请求失败，但是我们应该检查其他选项，比如状态代码。我们将认为<strong class="kt ir">只对特定的代码</strong>有效，其余的标记为错误。这个列表并不详尽，可以根据你的需要进行调整。例如，您可能认为404“未找到”是无效的，应该再次测试。</p><p id="7a66" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们还可以添加其他检查，比如验证响应是否包含IP地址。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="227e" class="mt lp iq mo b gy mu mv l mw mx">VALID_STATUSES = [200, 301, 302, 307, 404]</span><span id="ac0a" class="mt lp iq mo b gy ns mv l mw mx">async def get(url, session, proxy):<br/>    try:<br/>        async with session.get(url, proxy=f"http://{proxy}", timeout=timeout) as response:<br/>            if response.status in VALID_STATUSES: # valid proxy<br/>                print(response.status, await response.text())<br/>            else:<br/>                print(response.status)<br/>    except Exception as e:<br/>        print('Exception: ', type(e))</span></pre><h1 id="d58f" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">迭代所有代理</h1><p id="9bda" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">太好了！我们现在需要为数组中的每个代理运行检查。我们将像以前一样遍历调用<code class="fe ml mm mn mo b">get</code>的代理列表。但是我们将使用<code class="fe ml mm mn mo b">asyncio.gather</code>来启动所有的请求并等待它们完成，而不是按顺序执行。Async使得代码更加复杂，但是它加快了网页抓取的速度。</p><p id="6c0e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了安全起见，该列表被硬编码为最多10项，以避免数百个非自愿请求。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="25ac" class="mt lp iq mo b gy mu mv l mw mx">async def check_proxies():<br/>    proxies = proxies_list[0:10] # limited to 10 to avoid too many requests<br/>    async with aiohttp.ClientSession() as session:<br/>        tasks = [<br/>            get("http://ident.me/", session, proxy=proxy)<br/>            for proxy in proxies<br/>        ]<br/>        await asyncio.gather(*tasks, return_exceptions=True)</span></pre><p id="3626" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们还应该<strong class="kt ir">限制并发请求的数量</strong>。我们将使用<a class="ae ln" href="https://docs.python.org/3/library/asyncio-sync.html#asyncio.Semaphore" rel="noopener ugc nofollow" target="_blank">信号量</a>来实现，信号量是一个获取和释放锁的对象。它将维护一个内部计数器，只允许这么多的调用(在本例中是10个)，从而创建一个最大的并发性。</p><p id="3318" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们也需要改变如何称呼<code class="fe ml mm mn mo b">check_proxies</code>。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="9b42" class="mt lp iq mo b gy mu mv l mw mx">sem = asyncio.Semaphore(10)<br/># ...<br/>async def get(url, session, proxy):<br/>    async with sem:<br/>        try:<br/>            # ...</span><span id="096e" class="mt lp iq mo b gy ns mv l mw mx">loop = asyncio.get_event_loop()<br/>loop.run_until_complete(check_proxies())</span></pre><h1 id="ce42" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">将工作的代理与失败的代理分开</h1><p id="c916" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">检查输出日志并不理想，不是吗？我们应该为代理列表保留一个内部状态。我们将他们分成三组:</p><ul class=""><li id="2888" class="ne nf iq kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">未选中:未知状态，待选中。</li><li id="10ef" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">工作中:使用此代理的最后一次调用成功。</li><li id="ad0f" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">不起作用:最后一个请求失败。</li></ul><p id="c029" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从<code class="fe ml mm mn mo b">set</code>中添加或删除条目比从数组中添加或删除条目更容易，并且它们具有避免重复的优点。我们可以在列表之间移动代理，而不用担心同一个列表会出现两次。如果有，就是不加。这将简化我们的代码:从一个集合中删除一个项目，并将其添加到另一个集合中。为了实现这一点，我们需要稍微修改一下代理存储。</p><p id="48c8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将存在三个集合，上面看到的每个组一个。第一个，<code class="fe ml mm mn mo b">unchecked</code>，将包含文件中的代理。一个集合可以从一个数组中初始化，这使得我们很容易创建它。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="1fc8" class="mt lp iq mo b gy mu mv l mw mx">proxies_list = open("rotating_proxies_list.txt", "r").read().strip().split("\n")<br/>unchecked = set(proxies_list[0:10]) # limited to 10 to avoid too many requests<br/># unchecked = set(proxies_list)<br/>working = set()<br/>not_working = set()</span><span id="253a" class="mt lp iq mo b gy ns mv l mw mx"># ...<br/>async def check_proxies():<br/>    async with aiohttp.ClientSession() as session:<br/>        tasks = [<br/>            get("http://ident.me/", session, proxy=proxy)<br/>            for proxy in unchecked # use the new set for the loop<br/>        ]<br/>        await asyncio.gather(*tasks, return_exceptions=True)<br/>#...</span></pre><p id="7bc5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，编写助手函数在状态之间移动代理。每个州一个助手。他们会将代理添加到一个集合中，并从其他两个集合中删除它(如果存在)。这就是集合派上用场的地方，因为我们不需要担心检查代理是否存在或循环数组。如果存在或被忽略，则调用" discard "来移除，但不会引发任何异常。</p><p id="e65c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如，当一个请求成功时，我们将调用<code class="fe ml mm mn mo b">set_working</code>。并且该函数将从未检查的或不工作的集合中移除代理，同时将其添加到工作集合中。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="c32c" class="mt lp iq mo b gy mu mv l mw mx">def reset_proxy(proxy):<br/>    unchecked.add(proxy)<br/>    working.discard(proxy)<br/>    not_working.discard(proxy)</span><span id="ac77" class="mt lp iq mo b gy ns mv l mw mx">def set_working(proxy):<br/>    unchecked.discard(proxy)<br/>    working.add(proxy)<br/>    not_working.discard(proxy)</span><span id="3870" class="mt lp iq mo b gy ns mv l mw mx">def set_not_working(proxy):<br/>    unchecked.discard(proxy)<br/>    working.discard(proxy)<br/>    not_working.add(proxy)</span></pre><p id="89d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们错过了关键的部分！我们需要编辑<code class="fe ml mm mn mo b">get</code>来在每次请求后调用这些函数。<code class="fe ml mm mn mo b">set_working</code>表示成功的，其余的用<code class="fe ml mm mn mo b">set_not_working</code>表示。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="4726" class="mt lp iq mo b gy mu mv l mw mx">async def get(url, session, proxy):<br/>    async with sem:<br/>        try:<br/>            async with session.get(url, proxy=f"http://{proxy}", timeout=timeout) as response:<br/>                if response.status in VALID_STATUSES: # valid proxy<br/>                    set_working(proxy)<br/>                else:<br/>                    set_not_working(proxy)<br/>        except Exception as e:<br/>            set_not_working(proxy)</span></pre><p id="9388" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">目前，在脚本的末尾添加一些跟踪，看看它是否运行良好。因为我们运行了所有的项目，所以集合<code class="fe ml mm mn mo b">unchecked</code>应该是空的。这些项目将填充其他两个集合。希望<code class="fe ml mm mn mo b">working</code>不是空的😅-这可能会发生在免费代理上。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="8bef" class="mt lp iq mo b gy mu mv l mw mx">#...<br/>loop = asyncio.get_event_loop()<br/>loop.run_until_complete(check_proxies())</span><span id="29e4" class="mt lp iq mo b gy ns mv l mw mx">print('unchecked -&gt;', unchecked)<br/># unchecked -&gt; set()<br/>print('working -&gt;', working)<br/># working -&gt; {'152.0.209.175:8080', ...}<br/>print('not_working -&gt;', not_working)<br/># not_working -&gt; {'167.71.5.83:3128', ...}</span></pre><h1 id="f872" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">使用工作代理</h1><p id="f9f4" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">这是一种检查代理的简单方法，但还不是真正有用的。我们现在需要一种方法来<strong class="kt ir">获得工作代理</strong>并为真正的原因使用它们:web抓取实际内容。我们将创建一个选择随机代理的函数。</p><p id="eaef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们在示例中包括了工作代理和未检查代理，如果符合您的需要，请随意只使用工作代理。我们将在后面看到为什么未检查的也会出现。</p><p id="9043" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe ml mm mn mo b">random</code>不适用于集合，所以我们将使用<code class="fe ml mm mn mo b">tuple</code>来转换它们。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="afd4" class="mt lp iq mo b gy mu mv l mw mx">import random</span><span id="93f6" class="mt lp iq mo b gy ns mv l mw mx">def get_random_proxy():<br/>    # create a tuple from unchecked and working sets<br/>    available_proxies = tuple(unchecked.union(working))<br/>    if not available_proxies:<br/>        raise Exception("no proxies available")<br/>    return random.choice(available_proxies)</span></pre><p id="b5ac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，如果没有代理，我们可以编辑<code class="fe ml mm mn mo b">get</code>函数来使用随机代理。<code class="fe ml mm mn mo b">proxy</code>参数现在是可选的。我们将使用该参数来检查初始代理，就像我们之前所做的那样。但在那之后，我们可以忘记代理名单，没有它也可以打电话给<code class="fe ml mm mn mo b">get</code>。<strong class="kt ir">如果失败，将随机使用一个</strong>并添加到<code class="fe ml mm mn mo b">not_working</code>集合中。</p><p id="2318" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因为我们现在想要获取实际内容，所以我们需要返回响应或引发异常。与<code class="fe ml mm mn mo b">requests</code>不同，使用<code class="fe ml mm mn mo b">aiohttp</code>，响应的内容必须是<code class="fe ml mm mn mo b">await</code>。这是最终版本。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="4cd6" class="mt lp iq mo b gy mu mv l mw mx">async def get(url, session, proxy=None):<br/>    if not proxy:<br/>        proxy = get_random_proxy()</span><span id="11d6" class="mt lp iq mo b gy ns mv l mw mx">async with sem:<br/>        try:<br/>            async with session.get(url, proxy=f"http://{proxy}", timeout=timeout) as response:<br/>                if response.status in VALID_STATUSES:<br/>                    set_working(proxy)<br/>                else:<br/>                    set_not_working(proxy)</span><span id="79ee" class="mt lp iq mo b gy ns mv l mw mx">await response.text() # content needs to be "awaited"<br/>                return response # return response<br/>        except Exception as e:<br/>            set_not_working(proxy)<br/>            raise e # raise exception</span></pre><p id="a31d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在脚本下面包含您想要抓取的内容。我们将再次调用相同的测试URL进行演示。</p><p id="a4be" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">想法是从这里开始，基于这个主干构建一个真实世界的刮刀。并且为了对其进行缩放，将项目存储在诸如数据库(即Redis)的永久存储器中。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="4b3a" class="mt lp iq mo b gy mu mv l mw mx">#....<br/>loop = asyncio.get_event_loop()<br/>loop.run_until_complete(check_proxies())</span><span id="bd95" class="mt lp iq mo b gy ns mv l mw mx"># real scraping part comes here<br/>async def main():<br/>    async with aiohttp.ClientSession() as session:<br/>        result = await get("http://ident.me/", session)<br/>        print(result.ok) # True<br/>        print(result.status) # 200<br/>        print(await result.text()) # 152.0.209.175</span><span id="d000" class="mt lp iq mo b gy ns mv l mw mx">asyncio.run(main())</span></pre><p id="46d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">假阴性或一次性错误会怎样？一旦我们向<code class="fe ml mm mn mo b">not_working</code>集合发送了一个代理，它将永远留在那里。已经无路可退了。</p><h1 id="6412" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">重新检查不工作的代理</h1><p id="04e0" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们应该<strong class="kt ir">不时地重新检查失败的代理</strong>。有许多原因:失败是由于网络问题、错误或代理提供者修复了它。</p><p id="cc0f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在任何情况下，Python都允许我们设置<code class="fe ml mm mn mo b"><a class="ae ln" href="https://docs.python.org/3/library/threading.html#timer-objects" rel="noopener ugc nofollow" target="_blank">Timers</a></code>，“一个应该只在经过一定时间后才运行的动作”。有不同的方法可以达到相同的目的，这非常简单，只需使用三行代码就可以运行它。</p><p id="0502" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还记得<code class="fe ml mm mn mo b">reset_proxy</code>功能吗？直到现在我们才开始使用它。我们将设置一个<code class="fe ml mm mn mo b">Timer</code>来为每个被标记为不工作的代理运行该功能。20秒对于真实世界来说是个小数字，但是对于我们的测试来说已经足够了。我们排除一个失败的代理，并在一段时间后将其移回未检查状态。</p><p id="310e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这就是在<code class="fe ml mm mn mo b">get_random_proxy</code>中同时使用工作集和未检查集的原因。修改该函数，只使用有效的代理，以获得更健壮的用例。然后，您可以定期运行<code class="fe ml mm mn mo b">check_proxies</code>,它将遍历未检查的元素——在本例中，失败的代理在sin bin中保留了一段时间。</p><pre class="kg kh ki kj gt mp mo mq mr aw ms bi"><span id="ee94" class="mt lp iq mo b gy mu mv l mw mx">from threading import Timer</span><span id="7bf2" class="mt lp iq mo b gy ns mv l mw mx">def set_not_working(proxy):<br/>    unchecked.discard(proxy)<br/>    working.discard(proxy)<br/>    not_working.add(proxy)</span><span id="20e2" class="mt lp iq mo b gy ns mv l mw mx"># move to unchecked after a certain time (20s in the example)<br/>    Timer(20.0, reset_proxy, [proxy]).start()</span></pre><p id="2886" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于更健壮的系统，还有最后一个选项，但是我们将把实现留给您。<strong class="kt ir">存储每个代理</strong>的分析和使用情况，例如，失败的次数以及最后一次失败是什么时候。使用这些信息，调整重新检查的时间——失败几次的代理需要更长的时间。或者甚至在工作代理的数量低于阈值时设置一些警报。</p><h1 id="cfa6" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">结论</h1><p id="dffb" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">构建一个简单的代理旋转器对于小型的抓取脚本来说似乎是可行的，但是它可能会变得很痛苦。但是，嘿，你做到了！！</p><p id="6231" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些是我们遵循的步骤:</p><ol class=""><li id="056a" class="ne nf iq kt b ku kv kx ky la ng le nh li ni lm nt nk nl nm bi translated">以纯文本形式存储代理列表</li><li id="01e8" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nt nk nl nm bi translated">作为数组从文件导入</li><li id="9474" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nt nk nl nm bi translated">检查每一个</li><li id="51d2" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nt nk nl nm bi translated">把工作的分开</li><li id="a3d6" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nt nk nl nm bi translated">清理时检查故障，并将其从工作列表中删除</li><li id="eff1" class="ne nf iq kt b ku nn kx no la np le nq li nr lm nt nk nl nm bi translated">不时地重新检查不工作的代理</li></ol><p id="d623" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意，在抓取登录或任何其他类型的会话/cookie时，不要轮换IP。</p><p id="a6fa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你不想担心手动旋转代理，你可以随时使用我们的<a class="ae ln" href="https://www.zenrows.com/?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=rotate_proxies" rel="noopener ugc nofollow" target="_blank"> ZenRows </a>，一个包含智能旋转代理的Web抓取API。它像一个普通的代理一样工作——只有一个URL——但是为每个请求提供不同的IP。</p><p id="fe7b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢阅读。</p></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><p id="5a5c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nd">原载于</em><a class="ae ln" href="https://www.zenrows.com/blog/how-to-rotate-proxies-in-python?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=rotate_proxies" rel="noopener ugc nofollow" target="_blank"><em class="nd">https://www.zenrows.com</em></a></p></div></div>    
</body>
</html>
<html>
<head>
<title>Neural Network From Scratch: Hidden Layers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的神经网络:隐藏层</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/neural-network-from-scratch-hidden-layers-bb7a9e252e44?source=collection_archive---------10-----------------------#2020-12-22">https://betterprogramming.pub/neural-network-from-scratch-hidden-layers-bb7a9e252e44?source=collection_archive---------10-----------------------#2020-12-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5023" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当我们试图将感知器升级到多层神经网络时，看看隐藏层</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9b609e6a739f30ead53db57295deddb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCrLegDP0_i-SVcCCpEJPg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://pixabay.com/illustrations/neural-network-3637503/" rel="noopener ugc nofollow" target="_blank">图片</a>由<a class="ae ky" href="https://pixabay.com/users/ahmedgad-9403351/" rel="noopener ugc nofollow" target="_blank">艾哈迈德·加德</a>在Pixabay上拍摄</p></figure><p id="7829" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我关于神经网络的<a class="ae ky" href="https://medium.com/better-programming/build-your-first-neural-network-from-scratch-c5d5490a3f76" rel="noopener">第一篇</a>和<a class="ae ky" href="https://medium.com/better-programming/building-a-neural-network-from-scratch-71533fc6e8bb" rel="noopener">第二篇</a>文章中，我正在研究感知器，一种单层神经网络。即使我们的人工智能能够识别简单的模式，也不可能用它来识别图像上的物体。这就是为什么今天我们将讨论隐藏层，并尝试将感知器升级到多层神经网络。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d839" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">隐藏图层</strong></h1><p id="e6ec" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为什么我们需要隐藏层？感知器识别简单的模式，也许如果我们增加更多的学习迭代，它们可能会学习如何识别更复杂的模式？实际上，没有。隐藏层允许输入值的额外转换，这允许解决更复杂的问题。</p><p id="0007" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个隐藏层都有输入和输出。输入和输出有自己的权重，通过激活函数和自己的导数计算。</p><p id="035b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是具有隐藏层的神经网络的可视化表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/dfb8cc5ff397d878fdb1f1ecd2639fa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qf1kNW7q1uAu-SpKUaKsYw.jpeg"/></div></div></figure><p id="f02d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从数学的角度来看，隐藏层中没有任何新的变化。您可以检查<a class="ae ky" href="https://medium.com/better-programming/building-a-neural-network-from-scratch-71533fc6e8bb" rel="noopener">上一篇文章</a>中的所有公式。我们使用激活函数和成本函数的相同计算，然后更新权重。隐藏层的特征隐藏在反向传播部分中。</p><p id="ea12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将计算预测的输出层成本，然后我们将使用此成本来计算隐藏层的成本。让我们用代码实现它。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="0e11" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">实施</strong></h1><p id="4771" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">神经网络有两个主要部分:前馈和反向传播。让我们从前馈开始:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2da93468bfe2111cbd88010f3a89a643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*LSC5Eyw4d3ggiBiG-FmdBQ.png"/></div></figure><p id="054a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所见，对于隐藏层，我们将训练数据集的矩阵和突触权重相乘。然后我们使用隐藏层的输出矩阵作为输出层的输入。对于输出层，我们重复与隐藏层相同的操作。</p><p id="d5c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用反向传播，我们从输出级开始操作，然后将误差传播到隐藏层。首先，我们将计算输出图层的误差成本和导数。然后我们将使用输出层的误差成本来计算隐藏层的误差成本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/a7ea736985ff83881a6e66fb01f8acbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*XKUV-Gb4zyYFsn0iugA_7A.png"/></div></figure><p id="83a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将通过乘以每个层的学习速率和反向传播结果来更新输出层和隐藏层的权重。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="3831" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">数据和可视化</strong></h1><p id="c1a4" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在来说说训练数据。我将使用<code class="fe nc nd ne nf b"><a class="ae ky" href="https://sklearn.org/" rel="noopener ugc nofollow" target="_blank">sklearn</a></code>库为输入和标签数据生成一些数据。这里的函数用使用<code class="fe nc nd ne nf b">sklearn</code>来生成数据集:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/9a52fc17f289c5e1af0865e352e1dc13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*f0XvXNBhagjeLfQsDIt9Fw.png"/></div></figure><p id="13f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，我们正在生成一个包含100个元素的数据集，并将其保存到JSON文件中，这样就不需要在每次运行代码时都生成数据。</p><p id="be2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我将使用数据可视化库<code class="fe nc nd ne nf b"><a class="ae ky" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank">matplotlib</a></code>来创建漂亮的图形。这是我们的数据集的样子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/67fc0792cbe04d5099c5bbd65ca7b298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*px0wjaDzBwgAUvpfojgFsw.png"/></div></figure><p id="38cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">而这个就是打开带有训练数据集的JSON文件并将数据传递给Matplotlib库，告诉它显示图片的函数。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="1bec" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">测试</strong></h1><p id="6413" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">你可以看到数据点在2D空间的分布并不完全随机。圆点的分布是有规律的。这种模式反映在我们的<code class="fe nc nd ne nf b">labels</code>数据集中。如果一个数据点被标记为<code class="fe nc nd ne nf b">1</code>，那么它被涂上绿色，如果是<code class="fe nc nd ne nf b">0</code>，那么它是蓝色。你可以看到有一个空间所有的点都是蓝色的，还有一个空间所有的点都是绿色的。</p><p id="5326" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的神经网络在训练后将做的是获取一个带有点坐标的新输入，并尝试确定它是位于所有蓝色点的空间还是所有绿色点的空间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/9f85dff3b942287d700fd68c7322bdef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vV3mkOQcGKNiwwbqg3b4mw.png"/></div></div></figure><p id="1859" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我正在为3000次迭代或时期训练模型。现在它已经准备好让我们玩了！</p><p id="5032" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们的第一个测试案例:</p><pre class="kj kk kl km gt nj nf nk nl aw nm bi"><span id="0a40" class="nn md it nf b gy no np l nq nr"><em class="ns">np.array([0.0, -0.5])</em></span></pre><p id="1149" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们模型的一个输出是<code class="fe nc nd ne nf b">[0.99104346]</code>，这意味着神经网络认为它可能在绿点的空间中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/8e39279a585560ce8104632f6a01e961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UA4EvJWpxho3Fa210KwXVg.png"/></div></div></figure><p id="34d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二个测试案例:</p><pre class="kj kk kl km gt nj nf nk nl aw nm bi"><span id="9224" class="nn md it nf b gy no np l nq nr"><em class="ns">np.array([1.0, 1.0])</em></span></pre><p id="c51c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们可以看到输出是<code class="fe nc nd ne nf b">[0.0067755]</code>，这意味着神经网络认为它可能位于蓝点的空间中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/fb1eed226fddd03f71eb3fd3f72857cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5WmF1XOjnKyBtzSLOdyBRw.png"/></div></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="ac09" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">完整代码</strong></h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="e824" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">结论</strong></h1><p id="3a5a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们成功地在网络中添加了一个隐藏层，并学会了如何处理更复杂的情况。在下一篇文章中，我们将致力于提高我们网络的准确性和通用性。敬请期待！</p><p id="8ec4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不断学习，不断成长！</p></div></div>    
</body>
</html>
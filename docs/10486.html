<html>
<head>
<title>Experiment Variants of Graph Neural Network in Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流中图形神经网络的实验变体</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/experiment-variants-of-graph-neural-network-in-tensorflow-1f0e010011e0?source=collection_archive---------15-----------------------#2022-01-10">https://betterprogramming.pub/experiment-variants-of-graph-neural-network-in-tensorflow-1f0e010011e0?source=collection_archive---------15-----------------------#2022-01-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="526f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解这些模型背后的思想及其在Tensorflow中的实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f2868412066a9678bfccdfb6bcd029b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3q2B8D1CW6B6EKGD"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@pritesh557?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Pritesh Sudra </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="48e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在之前的<a class="ae ky" href="https://levelup.gitconnected.com/graph-convolutional-network-node-classification-with-tensorflow-49d3e091ea15#ab41-5cda1f0a557e" rel="noopener ugc nofollow" target="_blank">博客文章</a>中，我们已经详细研究了图卷积网络(GCN)。它允许我们不仅利用节点特征，而且利用节点连接来训练机器学习模型，这明显优于纯粹基于节点特征训练的模型。</p><p id="4562" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇博客文章中，我们将介绍其他一些类似于GCN的图形神经网络架构。</p><p id="bd23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一如既往，我们将解释新模型架构背后的核心思想，并使用Tensorflow演示端到端培训工作流。</p><p id="ba83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">强烈建议您在尝试这篇博文之前先通读一下之前的博文。</p><h1 id="bb7f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">训练目标</strong></h1><p id="9900" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先，让我们布置我们的训练目标，并在这篇博文中把它作为所有模型的运行实验。</p><p id="6b65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将上一篇博文中介绍的<a class="ae ky" href="https://graphsandnetworks.com/the-cora-dataset/" rel="noopener ugc nofollow" target="_blank"> Cora </a>数据集重新用于节点分类任务。数据集是以每篇论文为节点，每篇引文为边的论文引文图。</p><p id="e964" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该纸张分为7类(标签)。任务是在已标记的纸张上训练一个模型来预测未见过的纸张的标签。请注意，Cora数据集通常用于直推式学习环境中，在这种环境中，模型会看到所有示例(已标记或未标记)。</p><p id="d256" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标是预测未标记的标签。转导学习的思想是，即使你不知道一些例子的标签。这些例子仍然告诉你一些关于问题空间的有用信息。</p><p id="14ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只是为了好玩，我们将把实验框架设计为归纳学习，在这种学习中，模型将只看到标记的例子。我们留出一部分节点用于验证目的。</p><p id="661f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练期间，这些节点及其对应的边会从图形中移除。</p><p id="c870" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在验证过程中，移除的节点和边会重新加入。准确性度量仅根据验证节点上预测的正确性来衡量。</p><p id="e63b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这在现实世界中更适用，在现实世界中，新的看不见的节点不断被添加到图形中。有关详细信息，请参见以下培训和评估代码片段。</p><p id="d70d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，训练函数接受模型类定义。我们将在这篇博文中定义各种模型类，但是所有实验都共享这些训练和评估代码。</p><p id="c164" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，请注意，我们不会费心创建测试集，因为我们的主要目标是这篇博文中的培训演示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">培训和评估代码。</p></figure><h1 id="5e5f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">图卷积网络</strong></h1><p id="b8da" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先，我们用一个两层的GCN运行这个任务。关于GCN建筑的细节，请参考之前的<a class="ae ky" href="https://levelup.gitconnected.com/graph-convolutional-network-node-classification-with-tensorflow-49d3e091ea15#ab41-5cda1f0a557e" rel="noopener ugc nofollow" target="_blank">博文</a>。</p><p id="4ef8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将下面的模型类定义提供给上面的训练和评估代码，以获得结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图形卷积网络类别定义</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/2efcb09f6578169ae0cc28ff4de898f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*0xE_CnYiT2y6vuEzAdR7AA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图形卷积网络的精度。最终验证准确率:69%</p></figure><h1 id="c214" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">图表用法</strong></h1><p id="34fe" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将介绍的第一个新模型是<a class="ae ky" href="https://arxiv.org/abs/1706.02216" rel="noopener ugc nofollow" target="_blank"> GraphSAGE </a>。GraphSAGE在许多方面不同于GCN，但GCN可以轻松适应这些差异。</p><p id="09f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，GCN最初是为直推式学习而建立的，而GraphSAGE既可以进行直推式学习，也可以进行归纳式学习；GCN看起来像所有邻居，而<code class="fe mv mw mx my b">GraphSAGE</code>对邻居进行采样，这在社交网络等节点度可能非常高的环境中更实用。</p><p id="b6e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GraphSAGE和GCN之间最有意义的区别在于模型如何聚集来自节点及其邻居的信息。</p><p id="1cc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GCN使用一种简单的聚合方案，在该方案中，模型将所有相关节点特征(来自节点本身及其邻居)与一个共享矩阵相乘，并将结果相加。</p><p id="cb61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在GraphSAGE中，相邻要素通过聚合函数进行聚合，其结果随后与节点要素本身连接在一起。</p><p id="becb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的意义是双重的:(1)聚合函数也是可以学习的——比如一个max-pooling层或者LSTM；(2)串联形成一种到节点特征本身的跳过连接，允许模型特别注意节点自身的特征。请参见下图作为说明。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/df4f9c60bdca8f8cc2b8894cb1e0d072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i-PJwjCbTTfy45xpuW-oiw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图表说明</p></figure><p id="81cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，GraphSAGE论文还提出了一种无监督损失函数，该函数进行优化以使相同邻域中的节点的节点嵌入更接近，同时分离图中相距较远的节点的节点嵌入。</p><p id="1e10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这在某种程度上是有道理的。但是，由于我们有一个直接的训练目标，我们将优化节点分类的准确性，如上面的训练对象部分所述。</p><p id="38cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用DGL <a class="ae ky" href="https://docs.dgl.ai/en/0.6.x/api/python/nn.tensorflow.html#sageconv" rel="noopener ugc nofollow" target="_blank"> GraphSAGE </a>组件实现GraphSAGE，并将模型类输入到上面的相同训练和评估代码中。它的表现优于GCN:验证准确率为77.1%对69%。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GraphSAGE类定义</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/1383191ed5f505d3ebaa64214815056f.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*YCbsUsD7diSkQgLsEzQykQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">准确性图表。最终验证准确率:77.1%</p></figure><h1 id="a946" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">图关注网</strong></h1><p id="bab0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，基于上面GraphSAGE的思想，我们为什么要规定模型应该如何关注节点特征及其邻域呢？</p><p id="3b4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这启发了<a class="ae ky" href="https://arxiv.org/abs/1710.10903" rel="noopener ugc nofollow" target="_blank">图关注网络(GAT) </a>。GAT没有使用预定义的聚合方案，而是使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Attention_(machine_learning)#:~:text=In%20neural%20networks%2C%20attention%20is,important%20part%20of%20the%20data." rel="noopener ugc nofollow" target="_blank">注意力机制</a>来学习模型应该更重视哪些特征(来自自身或邻居)。</p><p id="1010" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请参见下图进行说明。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/a217c1d9ac74bd68f3af060c4e5e87c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZ99nYxzyJXmb1ooGLDLIw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图形注意网络图</p></figure><p id="7a33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用DGL <a class="ae ky" href="https://docs.dgl.ai/en/0.6.x/api/python/nn.tensorflow.html#gatconv" rel="noopener ugc nofollow" target="_blank"> GATConv </a>组件实现GAT，并将模型输入到相同的训练和评估代码中。它的表现优于GraphSAGE:验证准确率为77.8%对77.1%。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图形注意网络类别定义</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/69f5392b5e975ac374c7bfdd0467ef48.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*Ft_Sq_Bv985C_rExkCufgQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图形注意网络的准确性。最终验证准确率:77.8%</p></figure><h1 id="dbf9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">图同构网络</strong></h1><p id="e781" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了进一步扩展GAT的思想，为什么聚集方案应该是注意力机制呢？它可以是任何东西。<a class="ae ky" href="https://arxiv.org/abs/1810.00826" rel="noopener ugc nofollow" target="_blank">图同构网络(GIN) </a>来帮忙了。</p><p id="1423" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">提出的论文使用严格的理论分析来证明图形神经网络模型的表达能力(表示能力)在于它聚集特征的方式。</p><p id="8f0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其提出的GIN模型使用多层感知器(MLP)来聚合特征，因为根据<a class="ae ky" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank">通用逼近定理</a>，MLP可以被训练来逼近任何函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/905323db44f0cbf2d39c8d4207b5272c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6fSnwAA-ZQSNhIZkznLt0A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图形同构网络图</p></figure><p id="bb54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用DGL <a class="ae ky" href="https://docs.dgl.ai/en/0.6.x/api/python/nn.tensorflow.html#ginconv" rel="noopener ugc nofollow" target="_blank"> GINConv </a>组件实现GIN，并将模型输入到相同的训练和评估代码中。</p><p id="f950" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它的表现很好，但不如上面的图形注意力网络:验证准确率77.3%比77.8%。请注意，我们并没有真的努力调整所有模型的超参数。所以都有提升的空间。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图同构网络类定义</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/ed36588037d8a6124e81496a4516fcbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*2Uoe-ThFx6VQOTSImmxILg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图同构网络的精确性。最终验证准确率:77.3%</p></figure><p id="7651" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就结束了我们对所有主要现代图形神经网络的探索。到目前为止，我们一直在单独讨论节点分类。我们将在未来探索其他与图相关的机器学习任务。</p></div></div>    
</body>
</html>
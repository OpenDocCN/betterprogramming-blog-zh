<html>
<head>
<title>Building a Neural Network From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建神经网络</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/building-a-neural-network-from-scratch-71533fc6e8bb?source=collection_archive---------5-----------------------#2020-12-10">https://betterprogramming.pub/building-a-neural-network-from-scratch-71533fc6e8bb?source=collection_archive---------5-----------------------#2020-12-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="69ff" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第二代和优化我们的神经网络</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/597fd525706fc4676657e1f0c70898e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rHx3aMQXdP89YKinMuzRDA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Artificial_Neural_Network_with_Chip.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="dfc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的<a class="ae ky" href="https://medium.com/better-programming/build-your-first-neural-network-from-scratch-c5d5490a3f76" rel="noopener">上一篇文章</a>中，我们从头开始构建了一个简单的神经网络，它能够学习并执行一个非常简单的任务。今天我们将优化我们的网络，使其面向对象，并引入学习率和偏差等概念。让我们添加一个简单但真实的例子，这样0和1就变成了故事的一部分。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="6c61" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">先决条件</h1><p id="d9e4" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">和上次一样，我们将只需要一个外部库来执行计算，<a class="ae ky" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> NumPY </a>，当然，还有Python本身。</p><h2 id="ac8c" class="mz md it bd me na nb dn mi nc nd dp mm li ne nf mo lm ng nh mq lq ni nj ms nk bi translated">输入</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/524cec0254d732426769c02c4c80747c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*_EMc6nHcUjqZqwxitqobSg.png"/></div></figure><p id="4622" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们输入的样子。我们将训练一个神经网络来确定我是否快乐，基于我生活中的元素，如咖啡、披萨和辣椒。</p><p id="90fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要教会神经网络识别模式，我们就要走强化学习的道路。这意味着我们将在一个标记的数据集上训练神经网络。我们将有两层，输入和输出。输入是我们的训练数据，输出由对应于输入数据的标签集合组成。</p><p id="4cb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输入:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="bd39" class="mz md it nn b gy nr ns l nt nu">training_set = np.array([[1,1,1],[1,1,0],[0,0,1],[1,0,1],[1,0,0]])</span></pre><p id="9d2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">标签:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="52ef" class="mz md it nn b gy nr ns l nt nu">labels = np.array([[1,1,0,1,0]])</span></pre><p id="0a43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络存在两个阶段:<em class="nv">前馈</em>和<em class="nv">反向传播</em>。给我们的超级AI前馈一些数据吧！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="7eef" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">正向输送</h1><p id="2ebb" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在前馈阶段，神经网络将根据输入数据集的值、权重和偏差进行预测。</p><p id="8957" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们查看输入数据，我们可以看到每个样本都有三个数字，分别代表咖啡、披萨和辣椒。权重是输入样本和标签之间的联系。为了做出正确的预测，我们必须调整这些权重。</p><p id="04c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前馈过程的第一步是将每个输入样本乘以相应的权重，对其求和，并向和中添加偏差。</p><p id="bf69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是这个公式的样子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/95c9e46e4ed76743eb3e75480fd274eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*NS2LjaeOyN5VIkj9oP1rbg.png"/></div></figure><p id="1d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">b在这里代表偏差，这是我们在第一篇文章中遗漏的一个非常重要的元素。假设我们有咖啡、披萨和辣椒，这意味着我们有一个类似这样的数组:[1，1，1]。我们期望的结果是1，但是，无论我们对神经网络进行多少训练，结果都将是0。偏差将允许我们训练神经网络，即使我们在训练样本中有所有相同的值。</p><p id="39d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前馈阶段的下一步是激活函数。我们将需要它将输入和标签相乘的结果矩阵转换为0或1，因为这是数据在输出层(标签)中格式化的方式。</p><p id="7d34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几种类型的激活功能。对于我们的例子，我们将使用乙状结肠。如果输入为0，sigmoid函数将返回0.5。在大正数的情况下，它返回一个接近1的值。如果该值为负，则返回一个接近于0的值。正值或负值越大，输出越接近1或0。</p><p id="72a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是sigmoid函数的数学表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/83e16b2d26de8a6c5d0353d03706905f.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*_29c1pc8V-jEKbs02vGaRA.png"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="343b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">反向传播</h1><p id="de6b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在第一次迭代中，神经网络将做出远非正确的预测。没关系，我们都会犯错。为了实现学习过程，我们需要通过比较实际预测和标签值来调整最初的随机预测。我们微调权重和偏差，使实际输出更接近标签。</p><p id="d0f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先让我们计算一下预测的成本。成本是实际预测和标签之间的差异。差价越大，成本越高。我们将借助<a class="ae ky" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方误差</a>来计算成本。</p><p id="0746" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该公式如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/329da87a6aea5dd0c96f4dc8a1203a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*4_n_ERXawURWsTmIb70v0Q.png"/></div></figure><p id="b6c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步将是最小化预测的成本。为了做到这一点，我们需要找到成本函数将返回最小可能值的权重和偏差。这被称为<em class="nv">优化问题</em>，其中<em class="nv">T5我们必须找到函数极小值。</em></p><p id="5828" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">梯度下降可以帮助我们找到函数的极小值。这是算法的数学表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/787ddfbd5dc26d86ab97cc99eb9721b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*-Y6-K7HQXQKC4XMa7d7_mA.png"/></div></figure><p id="c806" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的<em class="nv"> J </em>代表一个常量函数。该等式的作用是找到与每个权重和偏差相对应的成本函数的偏导数，然后从现有权重中减去结果以获得更新后的权重。</p><p id="df2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导数的作用是给出给定时刻的斜率。如果成本增加，那么导数给我们一个正值，这个值将从最近的值中减去。</p><p id="5f42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个公式中的alpha符号代表<em class="nv">学习率</em>，这完全是另外一个故事。简而言之，学习率定义了神经网络学习的速度。</p><p id="aa1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要重复这个等式的执行，直到我们对成本函数将返回最接近0的值的权重和偏差进行赋值。</p><p id="41f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是时候全部用Python实现了。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="1c32" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">履行</h1><p id="9632" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们将以面向对象的方式来实现这一点，这意味着我们首先创建类。下面是我们类中的helper函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/3fd6f2eae2d1b2fab6174d42d66a2bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aKWYxDI9NCcm8E4Q3wS0aA.png"/></div></div></figure><p id="84a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初，我们声明偏差和学习率。然后，我们基于输入数据的形状和维度生成权重。我们也使用之前讨论过的sigmoid和导数函数。</p><p id="5b3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是训练功能，神经网络的核心:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/9a7e6f24acc04fac914019d8552daf21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*leAn4T6nBX7O9n96hmpHxg.png"/></div></div></figure><p id="e9b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将借助于sigmoid激活函数进行预测。然后我们计算预测的成本、导数和斜率。最后，我们调整权重和偏差。</p><p id="cab5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一个功能是在训练后进行思考:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/cfbcab9e291b8726948498568658e7eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3aqpIZB0J2PIcjlJ_Siy0A.png"/></div></div></figure><p id="376d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，这是神经网络的执行过程:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/2f4763cd9e4d4030e599a9de618c54eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*KglDtRET7lxWZ_j7FD7FZg.png"/></div></figure><p id="2682" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="c733" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="65a7" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在这个人工智能的帮助下，现在你可以确定什么让我快乐了！与<a class="ae ky" href="https://medium.com/better-programming/build-your-first-neural-network-from-scratch-c5d5490a3f76" rel="noopener">第一次尝试</a>相比，我们对神经网络进行了重大改进，增加了偏差和学习率等内容，并使其面向对象。在下一篇文章中，我将尝试添加更多的隐藏层，这样我们就可以处理更复杂的数据集，做一些更有趣的事情。</p><p id="e3b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不断学习，不断成长！</p></div></div>    
</body>
</html>
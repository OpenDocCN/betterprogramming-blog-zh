<html>
<head>
<title>This AI Can Create Video From Text Prompt</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这个人工智能可以从文本提示创建视频</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/this-ai-can-create-video-from-text-prompt-6904439d7aba?source=collection_archive---------4-----------------------#2022-08-03">https://betterprogramming.pub/this-ai-can-create-video-from-text-prompt-6904439d7aba?source=collection_archive---------4-----------------------#2022-08-03</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="5d25" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">文本到图像和图像到文本的生成器工具已经越来越流行。视频转文字怎么样？</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/b755c7ef7e8c2a5a38910bc04c3f7da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gixFq60nxJiBeLF6"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">Elena Mozhvilo 在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="20f4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">革命性的文本到图像人工智能生成器<a class="ae kz" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank"> Dall-E2 </a>和<a class="ae kz" href="https://www.midjourney.com/app/" rel="noopener ugc nofollow" target="_blank">midway</a>发布才几个月。</p><p id="70cf" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">那么视频呢？</p><p id="0d3c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">显然，有一个全新的(很可能是)第一个开源的大规模预训练文本到视频的模型，叫做<a class="ae kz" href="https://github.com/THUDM/CogVideo" rel="noopener ugc nofollow" target="_blank"> CogVideo </a>。</p><p id="275b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">简单说就是一个不需要实际拍摄就能制作视频的AI工具！</p><p id="945a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们来详细说说:</p><ul class=""><li id="029d" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">什么是CogVideo？</li><li id="1973" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">它是如何工作的？</li><li id="3fbc" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">目前的局限性是什么？</li><li id="ab7b" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">下一步是什么？</li></ul></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="c87f" class="mr ms iu bd mt mu mv mw mx my mz na nb ka nc kb nd kd ne ke nf kg ng kh nh ni bi translated">什么是CogVideo？</h1><p id="bef2" class="pw-post-body-paragraph la lb iu lc b ld nj jv lf lg nk jy li lj nl ll lm ln nm lp lq lr nn lt lu lv in bi translated">直接来自他们的<a class="ae kz" href="https://models.aminer.cn/cogvideo/" rel="noopener ugc nofollow" target="_blank">演示网站</a>，这是对CogVideo的描述:</p><blockquote class="no np nq"><p id="47bc" class="la lb nr lc b ld le jv lf lg lh jy li ns lk ll lm nt lo lp lq nu ls lt lu lv in bi translated">CogVideo是通用领域中最大的用于文本到视频生成的预训练转换器，具有94亿个参数。</p></blockquote><p id="da54" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">它采用多帧速率分层训练技术，优雅而有效地改进了预训练的文本到图像生成模型(CogView2 ),用于文本到图像的制作。</p><p id="3ed8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这听起来很拗口，但是看看这个来自他们官方<a class="ae kz" href="https://github.com/THUDM/CogVideo" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>的拼贴演示。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nv"><img src="../Images/0f4a1ff88e337ca649ff943847966c07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLKL_I6Gg8FxZ4FZHxoKUg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">截图来自<a class="ae kz" href="https://github.com/THUDM/CogVideo" rel="noopener ugc nofollow" target="_blank"> CogVideo Github </a></p></figure><p id="83f7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">很棒，对吧？这些视频看起来像是直接从电视广告中截取的。</p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="7929" class="mr ms iu bd mt mu mv mw mx my mz na nb ka nc kb nd kd ne ke nf kg ng kh nh ni bi translated">它是如何工作的</h1><p id="f0bf" class="pw-post-body-paragraph la lb iu lc b ld nj jv lf lg nk jy li lj nl ll lm ln nm lp lq lr nn lt lu lv in bi translated">下面是CogVideo中的多帧率分层生成框架。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ny"><img src="../Images/f7b633ea65817a10bd32b7437c06ca85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/0*h4vkls3dvP0sBqhV.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">CogVideo <a class="ae kz" href="https://deepai.org/publication/cogvideo-large-scale-pretraining-for-text-to-video-generation-via-transformers" rel="noopener ugc nofollow" target="_blank">方法学</a></p></figure><p id="f3f8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">输入序列包括帧速率、文本和帧标记。输入帧是一个分隔符标记，从CogView2继承而来。</p><p id="6c70" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">阶段1: </strong>在帧率和文本的条件下，依次生成帧。</p><p id="57bd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">阶段2: </strong>生成的帧作为双向注意区域被重新输入，以递归内插帧。在这两个阶段都可以调整帧速率。双向注意区域用蓝色突出显示，单向区域用绿色突出显示。</p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><p id="9cfe" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">有一个简单的网络应用程序…</p><p id="36f8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">你可以用于测试目的的<a class="ae kz" href="https://huggingface.co/spaces/THUDM/CogVideo" rel="noopener ugc nofollow" target="_blank">网络应用</a>被整合到拥抱面孔机器学习应用程序库中。</p><p id="b144" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">用户界面相当简单；它由一个“运行”按钮、“种子”滑块控件和一个“输入文本”字段组成，您可以在该字段中输入文本描述。</p><p id="3197" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">就是这样。这里有一个来自web工具的小截图，带有一只猫下棋的小样本提示。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nz"><img src="../Images/e6f1ec3abfab6df38c47d44742695786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_0ftKTjozlMy-EQgRiCLg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated"><a class="ae kz" href="https://github.com/THUDM/CogVideo" rel="noopener ugc nofollow" target="_blank"> CogVideo </a>文本到视频网络工具</p></figure><p id="c238" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">什么是“种子”？</strong></p><p id="8530" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">种子为随机数生成器提供了一个起点。例如，使用-1作为缺省值会导致它选择一个随机种子。这意味着即使所有其他值都相同，输出也会每次都不同。通过输入一个数字，您允许生成器复制以前的结果。</p><p id="a560" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">好吧，如果你只是想留下深刻印象，并尝试各种文本提示，CogVideo发布了另一个演示web应用程序，你可以在这里访问<a class="ae kz" href="https://models.aminer.cn/cogvideo/" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="kk kl km kn gu oa ob oc od aw oe bi"><span id="5fe5" class="of ms iu ob b gz og oh l oi oj">Prompt: A smiling woman wearing a red dress.</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ok"><img src="../Images/412cff1dc6e15d0bf1022044681cc8fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZNGb1rYaIohE4LrwnjK94Q.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated"><a class="ae kz" href="https://github.com/THUDM/CogVideo" rel="noopener ugc nofollow" target="_blank"> CogVideo </a>演示网络应用</p></figure><p id="26f7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这是实际效果。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/f9746db3a5f5132399d5d7c0faee66bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*K21itxJQaGVe7u8zifURBg.gif"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">一个穿着红色裙子的微笑的女人</p></figure><p id="b844" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这不是令人印象深刻吗？这是一个超现实的视频，一个穿着红色裙子的微笑的女人。</p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="89a5" class="mr ms iu bd mt mu mv mw mx my mz na nb ka nc kb nd kd ne ke nf kg ng kh nh ni bi translated">当前的限制</h1><p id="7faa" class="pw-post-body-paragraph la lb iu lc b ld nj jv lf lg nk jy li lj nl ll lm ln nm lp lq lr nn lt lu lv in bi translated">尽管CogVideo的最新进展已经非常令人印象深刻，但仍有许多障碍需要克服:</p><ul class=""><li id="d00c" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">AI模型只能生成480x480的分辨率，4秒的时长，8 fps的帧率。</li><li id="be3f" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">由于该模型是使用90亿个数据集训练的，从零开始在计算方面会非常昂贵。</li><li id="a956" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">还挺年轻的。由于文本-视频数据集的缺乏和较差的相关性，该模型不能理解复杂的运动语义。到目前为止，只有41，250个视频组成了最大的带注释的文本视频数据集。</li><li id="038c" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">该模型只接受中文作为输入。当输入到提示符中时，英文输入必须翻译成简体中文。</li></ul><p id="2fae" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果你想自己尝试，你可能要等很长时间(大约一个小时)才能生成视频，因为容器是63GB，运行在NVidia A100 GPU上。</p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="4aa1" class="mr ms iu bd mt mu mv mw mx my mz na nb ka nc kb nd kd ne ke nf kg ng kh nh ni bi translated">下一步是什么？</h1><p id="0517" class="pw-post-body-paragraph la lb iu lc b ld nj jv lf lg nk jy li lj nl ll lm ln nm lp lq lr nn lt lu lv in bi translated">虽然CogVideo仍处于起步阶段，它可以生成的视频有点短，但这项技术的潜力是巨大的。</p><p id="c5ae" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">首先，它可以为电影和视频游戏创造更真实、更逼真的角色动画。</p><p id="d851" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">此外，它可以用于创建教育视频或从文本文章中自动生成视频内容。</p><p id="95f7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">几年后，这将允许人们从文本中创建视频，而不需要拍摄或编辑。其影响是巨大的——这可能会永远改变我们创作和消费视频内容的方式。</p></div><div class="ab cl mk ml hy mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="in io ip iq ir"><h1 id="a596" class="mr ms iu bd mt mu mv mw mx my mz na nb ka nc kb nd kd ne ke nf kg ng kh nh ni bi translated">最后的想法</h1><p id="399d" class="pw-post-body-paragraph la lb iu lc b ld nj jv lf lg nk jy li lj nl ll lm ln nm lp lq lr nn lt lu lv in bi translated">总的来说，CogVideo有潜力成为一个强大的工具，帮助企业在不产生高制作成本的情况下制作视频。随着技术的发展，看看它的表现如何以及它可能用于哪些其他应用将是一件有趣的事情。</p><p id="f8d1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">但有一点是肯定的:人工智能视频生成器已经出现，并且即将改变视频的格局，我迫不及待地想看看接下来会发生什么。</p></div></div>    
</body>
</html>
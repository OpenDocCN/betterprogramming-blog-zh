<html>
<head>
<title>Solving the Mystery of Modeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解开建模之谜</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/solving-the-mystery-of-modeling-a3279f50f7e?source=collection_archive---------8-----------------------#2019-06-05">https://betterprogramming.pub/solving-the-mystery-of-modeling-a3279f50f7e?source=collection_archive---------8-----------------------#2019-06-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cebb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用scikit-learn选择分类模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fffc37e9920c0609df3b5d54752012a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gspdouantuOmxyhBjnveVA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我是你的蜜蜂叶！</p></figure><h1 id="50a7" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">介绍</h1><p id="f974" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">什么是选型，为什么要关心选型？假设你的老板要求你根据鲜花的特点将它们分为两类。你将这些数据放入一个基本的逻辑回归中，然后得出一个模型，这个模型对花卉的分类准确率为70%。很好，对吧？至少比猜好？不对。想象一下，如果你把信用卡交易归类为欺诈或非欺诈，而不是花。或者一项测试是否能诊断出癌症。您可以看到，在这种情况下，70%的准确率肯定不够好，因为信用卡欺诈或癌症诊断可能未被发现。</p><p id="9250" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这就是模型选择的作用。你不仅可以选择不同的分类方法(逻辑回归、随机森林、支持向量机、K近邻等。)，这些方法中的每一种都有超参数，可以调整这些超参数来提高整体准确性并降低模型的误差。这篇文章解释了如何使用网格搜索、随机搜索和来自scikit-learn in Python的管道来轻松地比较和找到最适合您的数据的模型。系好安全带，准备好！</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="750e" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">目标</strong></h1><p id="eb1a" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">重申一下，这是我将在这篇文章中涉及的内容:</p><ul class=""><li id="a5fd" class="nd ne it ls b lt mm lw mn lz nf md ng mh nh ml ni nj nk nl bi translated">预处理数据</li><li id="6fa1" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated">分类模型:逻辑回归，随机森林，kNN，SVM</li><li id="40d0" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated">超参数</li><li id="b568" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated">网格搜索、随机搜索和管道</li><li id="be1d" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated">例子</li><li id="7ad3" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated">关键术语</li></ul><p id="057c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">所有这些都将通过Python中的<a class="ae nr" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a> (sklearn)包来解释，它是您在任何类型的建模中最好的朋友。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="00a2" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">预处理数据</strong></h1><p id="c180" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">模型的好坏取决于传递给它的数据。如果有大量的缺失值，或者有大量的特性，那么很难轻松地构建一个模型。任何缺少的值都应该用<a class="ae nr" href="https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779" rel="noopener" target="_blank"> <strong class="ls iu">估算</strong> </a>，或者删除包含它们的行，这取决于您的目标。此外，执行<strong class="ls iu">特征选择</strong>也很重要，因为正确的特征选择对模型性能的影响比超参数调整要大得多。你可以在这里阅读我关于特性选择<a class="ae nr" href="https://medium.com/@madelinemccombe/intro-to-feature-selection-methods-for-data-science-4cae2178a00a" rel="noopener">的文章。</a></p><p id="fc94" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">除了这两个概念之外，为了使用某些类型的模型，还必须进行一定的预处理。如果分类是基于特征之间的空间，那么必须对这些特征中的每一个进行缩放，以允许在特征之间进行相等的比较。特别地，支持向量机(SVM)和k-最近邻(kNN)都是基于每个实例(行/示例)相对于其他实例的距离来分组或分类的。一个简单的方法是使用一个名为<a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu">标准缩放器</strong> </a>的函数，它会自动为你完成这项工作。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="dea5" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">车型</strong></h1><p id="46ac" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">一旦数据准备就绪，下一步就是看你想尝试使用什么样的模型进行分类。我将在这篇文章中探讨的是<strong class="ls iu">逻辑回归、随机森林、k-最近邻和支持向量机</strong>。其他可能有用的类型有决策树、朴素贝叶斯和神经网络。在我今天将要介绍的四个模型中，每个模型都有一组独特的超参数，您必须定义这些参数，以便调整您的模型，使其最适合数据集。在下一节中，我将探讨每个模型都有哪些类型的超参数，它们是什么，以及对每个模型检查哪些类型的值是好的。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="8589" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">超参数</strong></h1><p id="b443" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><strong class="ls iu">超参数</strong>是为模型指定的调整措施。例如，在进行逻辑回归时，您可以在运行模型之前指定惩罚(L1或L2)以及该惩罚的相关值<em class="ns">。模型<strong class="ls iu">参数</strong>是<em class="ns">模型</em> <em class="ns">根据给定的超参数使</em>符合数据的值。比如，这是线性回归中的贝塔系数。本质上，超参数是您定义的东西，而参数是模型定义的东西。每种类型的模型都有自己独特的超参数集，并且通常基础函数都有这些超参数的默认值，因此检查文档(链接)非常重要。我们将在下一节讨论如何调优这些超参数。</em></p><p id="bfca" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">对于每个超参数，列出了您可能想要迭代的潜在值，以及什么是超参数的简要概述。在下一节中，我只列出了我的示例中使用的超参数，但是链接到每个模型类型的文档都有完整的列表。</p><p id="1798" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu">逻辑回归</strong> </a> <strong class="ls iu"> : </strong></p><ul class=""><li id="3142" class="nd ne it ls b lt mm lw mn lz nf md ng mh nh ml ni nj nk nl bi translated"><em class="ns">判罚</em> : ['L1 '，' L2']，L1判罚指拉索，L2判罚指山脊(默认' L2 ')</li><li id="4ba7" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns"> C </em> : [0.001，0.1，…，10，100]，正则项的逆(默认为1)</li><li id="a0e2" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns">解算器</em> : ['newton-cg '，' saga '，' sag '，' liblinear']，用于完成回归的不同类型的解算器，列出的四个<em class="ns">不使用</em>L1惩罚，所以只有在不包括L1惩罚的情况下才使用它们(默认为' liblinear ')</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/c41501c858f378bf456a2e7d53ec2899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0CRxsF8QxypJ2ztQYmL7w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于C值的蘑菇数据对训练和交叉验证分数的影响</p></figure><p id="d19a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu">随机森林</strong> </a> <strong class="ls iu"> : </strong></p><ul class=""><li id="c2b9" class="nd ne it ls b lt mm lw mn lz nf md ng mh nh ml ni nj nk nl bi translated"><em class="ns"> n_estimators </em> : [100，120，300，500，800，1200]，要在林中使用的决策树数量(默认为100)</li><li id="a8f8" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns"> max_depth </em> : [5，8，15，25，30，无]，设置树的最大深度，以防止过度拟合(默认为无)</li><li id="4b1e" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns"> min_samples_leaf </em> : [1，2，5，10，15，100]，在内部节点中进行拆分之前所需的最小样本数(默认为2)</li><li id="4013" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns"> max_leaf_nodes </em> : [1，2，5，10]，创建叶节点所需的最小样本数(默认为1)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/192db4b96efdfe1b0beda13c6a47571d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IhQ-tYxcRazFIUuHn3d9cw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于树数的蘑菇数据对训练和交叉验证分数的影响</p></figure><p id="f52c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu">【支持向量机(SVM) </strong> </a> <strong class="ls iu"> : </strong></p><ul class=""><li id="6c78" class="nd ne it ls b lt mm lw mn lz nf md ng mh nh ml ni nj nk nl bi translated"><em class="ns"> C </em> : [0.001，0.01，10，100，1000…]，惩罚参数，较高的值降低误分类但增加过拟合(默认为1)</li><li id="20c4" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns">内核</em> : ['线性'，'多边形'，' rbf '，' sigmoid']，指定算法中使用的内核类型(默认为' rbf ')</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/aeafc55383c7ef729ae0e15e4c17b95e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t0VpzU-nUiitXs1Qv_RhYQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于C值的蘑菇数据对训练和交叉验证分数的影响</p></figure><p id="279b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu">【kNN】</strong></a><strong class="ls iu">:</strong></p><ul class=""><li id="aa33" class="nd ne it ls b lt mm lw mn lz nf md ng mh nh ml ni nj nk nl bi translated"><em class="ns"> n_neighbors </em> : [2，4，8，16]，创建算法时使用的邻居数量(默认为5)</li><li id="21ab" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns"> p </em> : [1，2]，计算闵可夫斯基度规时的幂度规；1是曼哈顿距离，2是欧几里德距离(默认)</li><li id="9dce" class="nd ne it ls b lt nm lw nn lz no md np mh nq ml ni nj nk nl bi translated"><em class="ns">算法</em> : ['auto '，' ball_tree '，' kd_tree '，' brute']，定义用于确定邻居的算法(默认为' auto ')</li></ul></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="227b" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">型号选择</strong></h1><p id="8e4c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在您已经了解了所有不同的模型及其对应的超参数，您可能想知道如何检查每种组合，以了解哪种组合最适合您的数据。别担心，使用scikit中的三个函数有一个超级简单的方法来做到这一点——学习:<code class="fe nw nx ny nz b"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu">GridSearchCV</strong></a></code> <strong class="ls iu">、</strong> <code class="fe nw nx ny nz b"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu">RandomizedSearchCV</strong></a></code>和<code class="fe nw nx ny nz b"><a class="ae nr" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu">Pipeline</strong></a></code> <strong class="ls iu">。</strong>搜索函数中的CV代表<strong class="ls iu">交叉验证</strong>，在此详细解释<a class="ae nr" href="https://towardsdatascience.com/cross-validation-a-beginners-guide-5b8ca04962cd" rel="noopener" target="_blank">。在我的例子中，我将使用5重交叉验证来最小化计算时间，但是如果必要的话，可以调整到10重左右。</a></p><p id="97c5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">网格搜索</strong>将搜索模型内指定的超参数的所有可能组合，以找到最佳组合，而随机搜索将随机选择组合，并选择超参数的最佳随机组合。<strong class="ls iu">随机搜索</strong>将为您节省大量计算时间，因为它不会遍历每个组合，并且被证明仍然可以找到最佳模型。<strong class="ls iu">管道</strong>是一个将不同模型及其各自超参数的列表提供给网格或随机搜索的功能。通常，当您比较两种或多种不同的建模技术(例如逻辑、SVM和随机森林)以及每个模型的不同超参数组合。可以指定这些函数的<a class="ae nr" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter" rel="noopener ugc nofollow" target="_blank">评分标准</a>,以便根据特定的标准选择超参数的组合，但不必定义来运行该函数。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="24c2" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">例题</strong></h1><p id="def8" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下面是一些代码示例，使用了到目前为止涵盖的所有主题。我使用了一个蘑菇数据集，将不同的蘑菇分为有毒:1或可食用:0，可以在Kaggle上找到<a class="ae nr" href="https://www.kaggle.com/uciml/mushroom-classification/downloads/mushroom-classification.zip/1" rel="noopener ugc nofollow" target="_blank">这里</a>。我做了初步的数据清理，你可以在这里找到<a class="ae nr" href="https://github.com/madelinemccombe/LaunchDS/blob/master/Model_Selection_Medium.ipynb" rel="noopener ugc nofollow" target="_blank"/>，但主要要注意的是，我在模型中使用的最终特征包含在<code class="fe nw nx ny nz b">features</code>变量中，每一行的分类在<code class="fe nw nx ny nz b">target</code>变量中。</p><h2 id="772f" class="oa kz it bd la ob oc dn le od oe dp li lz of og lk md oh oi lm mh oj ok lo ol bi translated">基本网格搜索</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="24fb" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">上面定义的函数展示了如何执行超参数网格搜索的基本格式(在本例中为<strong class="ls iu">罚值</strong>和<strong class="ls iu"> C </strong>)。一般来说，您确定要应用于数据的模型，创建一个参数字典，然后将这两个东西插入到<code class="fe nw nx ny nz b">GridSearchCV</code>中。这为模型创建了超参数的所有组合的网格(在这种情况下，20个超参数的组合有5个折叠，等于要运行的总共100个模型)。当您调用<code class="fe nw nx ny nz b">gridsearch.fit(features, target)</code>时，组合网格将应用于数据，并选择具有最佳结果的模型。为了找到被确定为最佳的参数，您可以运行下面的代码:</p><pre class="kj kk kl km gt oo nz op oq aw or bi"><span id="b965" class="oa kz it nz b gy os ot l ou ov"># hyperparameter values for the best model<br/>print(best_model.best_estimator_.get_params()) </span></pre><p id="a6bb" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这个输出:<em class="ns">{</em><strong class="ls iu"><em class="ns">' C ':1.0</em></strong><em class="ns">，' class_weight': None，' dual': False，' fit_intercept': True，' intercept_scaling': 1，' l1_ratio': None，' max_iter': 100，' multi_class': 'warn '，' n_jobs': None，</em><strong class="ls iu"><em class="ns">【penalty ':' L1 '</em></strong><em class="ns">，' random_state': None，' solver': 'warn '，' tol ':' tol '请注意，打印输出中的超参数比函数中定义的要多得多。这是因为scikit-learn中的所有默认值都是特定于逻辑回归的。要获得<strong class="ls iu"> C </strong>或<strong class="ls iu">罚值</strong>的值，可以在打印语句的末尾添加一个<code class="fe nw nx ny nz b">['C']</code>或<code class="fe nw nx ny nz b">['penalty']</code>。</em></p><pre class="kj kk kl km gt oo nz op oq aw or bi"><span id="13d1" class="oa kz it nz b gy os ot l ou ov"># mean accuracy of model<br/>print(best_model.score(features, target))</span></pre><p id="5851" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">您还可以使用上面的代码打印出最佳模型的精确度。在这种情况下，精确度为0.9988921713441654。</p><h2 id="aea8" class="oa kz it bd la ob oc dn le od oe dp li lz of og lk md oh oi lm mh oj ok lo ol bi translated">基本随机搜索</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="7c3d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">上面的代码和前面的例子做了同样的事情，除了有一个<code class="fe nw nx ny nz b">RandomizedSearchCV</code>。同样的代码可以用来打印出最好的模型参数和精度，我将在下面展示。在这种情况下，最佳模型有<em class="ns">‘C’= 0.9183088549193021</em>和<em class="ns">‘penalty’=‘L1’。</em>精度同上，为0.9988921713441654。即使C稍作调整，精度仍然保持不变，这表明偶尔调整模型的超参数不会改变太多。</p><pre class="kj kk kl km gt oo nz op oq aw or bi"><span id="984e" class="oa kz it nz b gy os ot l ou ov"># print hyperparameter values<br/>print(best_model.best_estimator_.get_params()['C'])<br/>print(best_model.best_estimator_.get_params()['penalty'])<br/># accuracy<br/>print(best_model.score(features, target))</span></pre><h2 id="fdf3" class="oa kz it bd la ob oc dn le od oe dp li lz of og lk md oh oi lm mh oj ok lo ol bi translated">管道网格搜索</h2><p id="eaef" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下面是一个使用<code class="fe nw nx ny nz b">GridSearchCV</code>中的管道比较多个模型的例子。因为我使用SVM作为我要考虑的模型之一，所以有一些额外的预处理步骤可以构建到管道中。这个过程有很多步骤，所以我将把代码分成几个部分。</p><p id="4f5c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">首先，我定义函数并从它们各自的包中加载我需要的所有函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="2bc0" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后我做预处理步骤(缩放和PCA)并创建一个管道:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="5c1a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后我创建了一个<code class="fe nw nx ny nz b">search_space</code>,这是一个包含所有模型及其超参数的字典列表:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="7cd3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">最后，我在<code class="fe nw nx ny nz b">pipe</code>和<code class="fe nw nx ny nz b">search_space</code>上调用<code class="fe nw nx ny nz b">GridSearchCV</code>，返回最佳模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="ba5c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这可能看起来很多，但一旦你理解了这一点，所有需要做的就是将这种方法应用到你想要比较的任何其他模型子集。获取最佳模型信息的方式与基本网格搜索和基本随机搜索完全相同(代码如下)。对于这个特定的集合，SVM模型的表现最好，它具有<em class="ns">‘C’= 10</em>和<em class="ns">‘kernel’=</em>’<em class="ns">线性</em>。这给出了1.0的精度，这是非常高的，并且可能过拟合。</p><pre class="kj kk kl km gt oo nz op oq aw or bi"><span id="98c4" class="oa kz it nz b gy os ot l ou ov">print(big.best_estimator_['classifier'])<br/>print(big.score(features_final, target))</span></pre><p id="8cc0" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这种方法的一个缺点是需要大量的计算时间，但好处是它比单独运行每个模型需要更少的计算时间。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="c221" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">现在怎么办？</strong></h1><p id="a085" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下次你的老板说，‘这里有一些数据，给我找一个好的分类模型’，你知道从哪里开始！创建一个由两个模型技术和超参数组成的管道，把它插入到一个搜索函数中，让算法告诉你下一步去哪里找。不要忘记从预处理和特征选择开始。祝你好运！</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="840e" class="ky kz it bd la lb my ld le lf mz lh li jz na ka lk kc nb kd lm kf nc kg lo lp bi translated"><strong class="ak">关键术语</strong></h1><p id="6e4f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><strong class="ls iu">模型选择</strong> —根据模型对训练数据的表现来选择模型</p><p id="4d41" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">模型评估</strong> —根据模型对未来数据的表现(预测能力)选择模型</p><p id="4fd0" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">输入</strong> —填充数据中缺失的值</p><p id="2187" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">特征选择</strong> —选择特征子集以减少维度，并允许模型仅关注重要特征</p><p id="da4a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">缩放</strong> —对于kNN和SVM是强制性的；将要素缩放至0到1之间的值</p><p id="c9a0" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">超参数</strong> —数据科学家定义为模型的一部分(惩罚、正则化、估计量等)。)</p><p id="e2df" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">参数</strong> —算法产生的代表模型的值(截距、系数、分割等)。)</p><p id="039f" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">网格搜索</strong> —搜索超参数和模型的每个组合，以找到最佳集合</p><p id="34d2" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">随机搜索</strong> —搜索超参数和模型的一些组合，以找到最佳集合</p><p id="5d90" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">交叉验证</strong> —将数据分成不同的测试和训练集n次，以在模型之间进行比较并模拟真实世界的数据。</p><p id="3b97" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> Pipeline </strong> —不同模型和各自超参数的顺序列表，用于与搜索算法进行比较</p><p id="8e97" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我用于可视化和示例的代码可以在GitHub 的<a class="ae nr" href="https://github.com/madelinemccombe/LaunchDS/blob/master/Model_Selection_Medium.ipynb" rel="noopener ugc nofollow" target="_blank">中找到；你可以随意使用和修改它！</a></p></div></div>    
</body>
</html>
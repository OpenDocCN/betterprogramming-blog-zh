<html>
<head>
<title>How to Build Recommendation Models With MyAnimeList and Sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用MyAnimeList和Sklearn建立推荐模型</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-build-recommendation-models-with-myanimelist-and-sklearn-part-2-4802efba95cd?source=collection_archive---------12-----------------------#2020-04-03">https://betterprogramming.pub/how-to-build-recommendation-models-with-myanimelist-and-sklearn-part-2-4802efba95cd?source=collection_archive---------12-----------------------#2020-04-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b7b8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于用户评分相关性和特征变量推荐动漫内容的简单技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/676ebbeb039c0a54bde0d7b296e5397b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qx4wD7bEIMlWVdplVevrUg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马特·波波维奇在<a class="ae ky" href="https://unsplash.com/s/photos/anime?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="6aa3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://towardsdatascience.com/building-predictive-models-with-myanimelist-and-sklearn-54edc6c9fff3" rel="noopener" target="_blank">本系列的第一部分</a>使用<code class="fe lv lw lx ly b">MyAnimeList</code>着重于使用他们庞大的(公开可用的)数据库预测用户对动漫内容的评分。</p><p id="663a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将介绍一些用于推荐动漫内容的简单技术，基于用户评分相关性和特征变量，并使用与第一部分相同的数据框架。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lz"><img src="../Images/2e1c76c48809c2e523a7164d12d9a9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C993JY12EK1Wl7N-2N_6uQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MyAnimeList.com</p></figure><p id="e1a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的大数据时代，推荐系统对于商业成功至关重要——利用我们的观看和收听模式来预测我们未来可能想要消费的东西。对大型科技公司利用我们的数字产品组合让我们使用他们的服务的方式进行诽谤很容易，但我们有时会忘记，当我们去享受我们的电影和音乐时，我们受益于个性化的体验(尽管我在以前的帖子中谈到过这种做法的缺陷)。</p><p id="10d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">抛开观点不谈，Sklearn中有一些有用且易于实现的推荐系统，你可以在Jupyter或你选择的ide中使用。这篇文章将分为上述两种形式的建议。我还会分享我写的代码，这样你就可以复制这种形式的分析。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="e84a" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">数据准备</h1><p id="fad4" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">在执行任何分析之前，请安装必要的软件包:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="382b" class="ni mi it ly b gy nj nk l nl nm">import numpy as np<br/>import pandas as pd<br/>import sklearn<br/>import matplotlib.pyplot as plt<br/>from sklearn.decomposition import TruncatedSVD<br/>import seaborn as sb<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.ensemble import RandomForestClassifier, <br/>from sklearn.linear_model import LogisticRegression<br/>from matplotlib import rcParams<br/>from sklearn.neighbors import NearestNeighbors</span></pre></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="29a1" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">用户评级相关性</h1><p id="91bd" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">我们将使用的第一个建议将利用我们在第1部分中连接的动漫数据框架中的用户评级，使用协同过滤模型(CFM) <strong class="lb iu"> </strong>和技术，使用特定内容项目上用户评级之间的相关性。CFM是基于这样一个假设，即用户会对与他们喜欢过的其他内容相似的项目打分，并且这些项目会受到具有相似品味的其他用户的喜欢(图1)。使用CFM，您可以根据数据中的用户评分计算推荐模型，并根据该计算结果提出建议。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/4bf0a60695113195d0872e69aef79e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W3RqXMNsxFJv141h2dYKsA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。基于与另一用户(用户x)相似/相关的观看偏好向用户y推荐内容的CFM的例子</p></figure><p id="f4f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用来自<code class="fe lv lw lx ly b">MyAnimeList</code>的数据，我们将使用一种叫做效用矩阵的东西，通常被称为用户项目矩阵。这些矩阵包含<code class="fe lv lw lx ly b">MyAnimeList</code>上每个用户的值、每个内容项目以及用户对该项目的评分。我们可以通过使用熊猫中的<code class="fe lv lw lx ly b">pivot_table</code>功能来创建这种变化的矩阵:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="177d" class="ni mi it ly b gy nj nk l nl nm">rating_crosstab = anime_df.pivot_table(values=’rating_x’, index=’user_id’, columns=’title_english’, fill_value=0)<br/>rating_crosstab.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/ef1c47409f2c347024d966b31ff91193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2oXtprJOA7VazWLnQJiGZw.png"/></div></div></figure><p id="09a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的矩阵可以看出，大部分都是零值。这是因为不是每个用户都会对每条内容进行评价——最有可能的情况是<code class="fe lv lw lx ly b">user_x</code>只会查看几条内容。</p><p id="0adb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们使用奇异值分解(SVD)技术将效用矩阵改造成一种可以转换成相关矩阵的格式。SVD是一种线性代数方法，可用于将用户项矩阵分解成三个单独的压缩矩阵。SVD对于构建cfm来提出未来的建议是非常有用的，而不必参考我们的整个动漫数据库。点击此处阅读更多关于<a class="ae ky" href="https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254" rel="noopener ugc nofollow" target="_blank"> SVD的信息。</a></p><p id="e098" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将获取用户项目矩阵并对其进行转置，然后使用SVD将其分解为用户评级的综合表示。Sklearn的<code class="fe lv lw lx ly b">TruncatedSVD</code>模块返回我们上面创建的用户条目矩阵的一个压缩矩阵。</p><p id="9554" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">压缩发生在我们的数据框的列上——因为我们想要推荐动漫项目，我们需要确保我们保留了内容项目/标题。我们希望在我们的数据框架中使用用户之间的相似性，因此我们使用Sklearn将所有用户评级压缩到12个潜在参数中。为了保留内容项目/标题，我们需要调整我们的矩阵，以便标题是行而不是列:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="840f" class="ni mi it ly b gy nj nk l nl nm">rating_crosstab.shape</span><span id="822a" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (73348, 4639)</span><span id="8e9d" class="ni mi it ly b gy np nk l nl nm">X = rating_crosstab.T<br/>X.shape</span><span id="b70a" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (4639, 73348)</span></pre><p id="efd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们将使用<code class="fe lv lw lx ly b">TruncatedSVD</code>把这个矩阵压缩成4639 x 12的矩阵。所有单独的内容项目/标题将沿着行被保留。但是用户将被压缩成12个合成成分，它们代表了用户偏好的整体视图:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="e67e" class="ni mi it ly b gy nj nk l nl nm">SVD = TruncatedSVD(n_components=12, random_state=17)<br/>resultant_matrix = SVD.fit_transform(X)<br/>resultant_matrix.shape</span><span id="b065" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (4639, 12)</span></pre><p id="a19d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在将通过为我们的结果矩阵中的每个内容项对生成皮尔逊R系数来生成相关矩阵，其中相关性基于用户评级之间的相似性:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="2593" class="ni mi it ly b gy nj nk l nl nm">corr_mat = np.corrcoef(resultant_matrix)<br/>corr_mat.shape</span><span id="1494" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (4639, 4639)</span></pre><p id="faec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以在数据框架中分离出一些项目，根据有类似偏好的用户来确定它们与哪些其他动漫作品高度相关。我们将用三部电影作为例子:“千与千寻”、“龟壳里的幽灵”<em class="nq">、</em>和“阿基拉”。</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="1948" class="ni mi it ly b gy nj nk l nl nm">spirited_away = movies_list.index('Spirited Away')<br/>spirited_away</span><span id="9701" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; 3561</span><span id="f50f" class="ni mi it ly b gy np nk l nl nm">ghost_in_the_shell = movies_list.index('Ghost in the Shell')<br/>ghost_in_the_shell</span><span id="c9e9" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; 1342</span><span id="c78d" class="ni mi it ly b gy np nk l nl nm">AKIRA = movies_list.index('AKIRA')<br/>AKIRA</span><span id="2c4e" class="ni mi it ly b gy np nk l nl nm">78</span></pre><p id="4719" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用Pearson R值0.95作为高度相关内容的阈值。我们可以用Seaborn可视化系数的分布，看看有多少项存在这种普遍的关系:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="69da" class="ni mi it ly b gy nj nk l nl nm">plt.grid(True)<br/>sb.distplot(corr_spirited_away, color="black", axlabel='Pearson R Coeff').set(title = 'Spirited Away Correlation Coefficents')<br/>plt.axvline(0.95, 0,3.5)<br/>plt.show()</span><span id="83b5" class="ni mi it ly b gy np nk l nl nm">sb.distplot(corr_ghost_in_the_shell, color="black", axlabel='Pearson R Coeff').set(title = 'Spirited Away Correlation Coefficents')<br/>plt.axvline(0.95, 0,3.5)<br/>plt.show()</span><span id="74d3" class="ni mi it ly b gy np nk l nl nm">sb.distplot(corr_AKIRA, color="black", axlabel='Pearson R Coeff').set(title = 'Spirited Away Correlation Coefficents')<br/>plt.axvline(0.95, 0,3.5)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/4cd4fd0faeec6edbecf7229156946bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VG6XoZjX_S08XjNlPdzm5Q.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/fa90def83b08822a1394a0138b413c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*goLfA4WsmCVzZjao2ZnNoA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/c8b09351cbf99d76c78161e128cdbff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h012DQprigE8-g7loIUZPQ.png"/></div></div></figure><p id="41c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的分布图中，线右边的一切代表皮尔逊R值大于0.95的电影。这是我们向<code class="fe lv lw lx ly b">user_x</code>推荐的内容亮点。</p><p id="b54b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以查看我们推荐给用户的单个标题，如果他们在这些项目中得分很高:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="ec2c" class="ni mi it ly b gy nj nk l nl nm">list(movie_names[(corr_spirited_away&lt;1.0) &amp; (corr_spirited_away &gt; 0.95)])</span><span id="6a9c" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; ['Howl's Moving Castle',<br/> 'My Neighbor Totoro',<br/> 'Ponyo',<br/> 'Princess Mononoke']</span><span id="ffe7" class="ni mi it ly b gy np nk l nl nm">list(movie_names[(corr_ghost_in_the_shell&lt;1.0) &amp; (corr_ghost_in_the_shell &gt; 0.95)])</span><span id="d0de" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; ['AKIRA',<br/> 'Cowboy Bebop: The Movie',<br/> 'Cyber City',<br/> 'Dead Leaves',<br/> 'Ghost in the Shell',<br/> 'Ghost in the Shell 2.0',<br/> 'Ghost in the Shell 2: Innocence',<br/> 'Ghost in the Shell: Stand Alone Complex',<br/> 'Ghost in the Shell: Stand Alone Complex - Solid State Society',<br/> 'Ghost in the Shell: Stand Alone Complex 2nd GIG',<br/> 'Jin-Roh: The Wolf Brigade',<br/> 'Paranoia Agent',<br/> 'The Animatrix']</span><span id="8624" class="ni mi it ly b gy np nk l nl nm">list(movie_names[(corr_AKIRA &lt;1.0) &amp; (corr_ghost_in_the_shell &gt; 0.95)])</span><span id="2b67" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; ['Cowboy Bebop: The Movie',<br/> 'Cyber City',<br/> 'Dead Leaves',<br/> 'Ghost in the Shell',<br/> 'Ghost in the Shell: Stand Alone Complex - Solid State Society',<br/> 'Ghost in the Shell: Stand Alone Complex 2nd GIG',<br/> 'Jin-Roh: The Wolf Brigade',<br/> 'Paranoia Agent',<br/> 'The Animatrix']</span></pre><p id="999a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">毫不奇怪，当使用“千与千寻”时，高度相关的电影来自同一个制作工作室(吉卜力工作室)——用户会喜欢这些电影是很直观的。同样的，在使用《人鬼情未了》的时候，会把续集推荐给用户。值得一提的是，《蛋壳里的幽灵》和《阿基拉<em class="nq"/>之间有相当多的交叉，这也很直观，因为两者都是反乌托邦科幻小说。</p><p id="021b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用上面的代码来推荐类似于整个制片厂的电影。我们将以吉卜力工作室为例:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="1fa2" class="ni mi it ly b gy nj nk l nl nm">rating_crosstab_studio = anime_df.pivot_table(values=’rating_x’, index=’user_id’, columns=’studio’, fill_value=0)</span><span id="c2c9" class="ni mi it ly b gy np nk l nl nm">rating_crosstab_studio.shape</span><span id="1e24" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (73487, 636)</span><span id="8db4" class="ni mi it ly b gy np nk l nl nm">X_studio = rating_crosstab_studio.T<br/>X_studio.shape</span><span id="58d9" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (636, 73487)</span><span id="7087" class="ni mi it ly b gy np nk l nl nm">SVD = TruncatedSVD(n_components=12, random_state=17)resultant_matrix_studio = SVD.fit_transform(X_studio)<br/>resultant_matrix_studio.shape</span><span id="7fd8" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (636, 12)</span><span id="2180" class="ni mi it ly b gy np nk l nl nm">corr_mat_studio = np.corrcoef(resultant_matrix_studio)<br/>corr_mat_studio.shape</span><span id="5898" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (636, 636)</span><span id="b38e" class="ni mi it ly b gy np nk l nl nm">sb.distplot(corr_studio_ghibli, color="lightblue",axlabel='Pearson R Coeff').set(title = 'Studio Ghibli Correlation Coefficents')<br/>plt.axvline(0.9, 0,3.5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/a175f9e9d2596b294d4d0b7ef850e8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXxm6Cxc8QgBKLjayQP0lg.png"/></div></div></figure><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="892d" class="ni mi it ly b gy nj nk l nl nm">list(movie_names[(corr_studio_ghibli&lt;1.0) &amp; (corr_studio_ghibli &gt; 0.95)])</span><span id="1537" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; ['Busou Shinki: Armored War Goddess',<br/> 'Lagrange: The Flower of Rin-ne',<br/> 'Lagrange: The Flower of Rin-ne Season 2',<br/> 'Lagrange: The Flower of Rin-ne – Kamogawa Days',<br/> 'Sengoku Collection',<br/> 'Symphogear']</span></pre></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="0a3f" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">特征映射-最近邻法</h1><p id="9d36" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">既然我们已经研究了使用CFM和相关分析的推荐，我们可以使用一种<code class="fe lv lw lx ly b">NearestNeighbour</code> (NN)方法来推荐使用任意数量的特征变量的单个内容项目。神经网络算法是一种无监督的分类器。它通常被称为基于记忆的系统，因为它会记忆实例，然后根据与新实例的定量相似性来推荐内容。</p><p id="c5d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这个分析，我们将使用四个特征变量来匹配内容:内容何时首映、其类型、其来源或媒体以及其类型(电视、电影、音乐等。).由于这些变量是分类数据，我们需要对它们进行一次性编码，以确保我们可以在数量相似性上匹配传入的实例:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="d49c" class="ni mi it ly b gy nj nk l nl nm">enconder = LabelEncoder()<br/>premiered_labels = enconder.fit_transform(anime_features['premiered'])<br/>premiered_mappings = {index: label for index, label in <br/>                  enumerate(enconder.classes_)}</span><span id="64e7" class="ni mi it ly b gy np nk l nl nm">enconder = LabelEncoder()<br/>genre_labels = enconder.fit_transform(anime_features['genre'])<br/>genre_mappings = {index: label for index, label in <br/>                  enumerate(enconder.classes_)}</span><span id="4e13" class="ni mi it ly b gy np nk l nl nm">enconder = LabelEncoder()<br/>source_labels = enconder.fit_transform(anime_features['source'])<br/>source_mappings = {index: label for index, label in <br/>                  enumerate(enconder.classes_)}<br/>source_mappings</span><span id="dda1" class="ni mi it ly b gy np nk l nl nm">enconder = LabelEncoder()<br/>type_labels = enconder.fit_transform(anime_features['type'])<br/>type_mappings = {index: label for index, label in <br/>                  enumerate(enconder.classes_)}</span></pre><p id="ebfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以将编码数据合并回我们的数据框，并显示它们存在于哪些列中:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="5d44" class="ni mi it ly b gy nj nk l nl nm">anime_features[‘premiered_mappings’] = premiered_labels<br/>anime_features[‘genre_mappings’] = genre_labels<br/>anime_features[‘source_mappings’] = source_labels<br/>anime_features[‘type_mappings’] = type_labels</span><span id="efe3" class="ni mi it ly b gy np nk l nl nm">X = anime_features.iloc[:,[31,32,33,34]]<br/>X[0:10]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/51431e6493dd67cf1fadbb31e7f5824a.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*6wpKMomPgBLmZBV2ZoPxHA.png"/></div></figure><p id="f27d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以分离出一段我们想要匹配的内容。让我们用吉卜力工作室的《波妞》:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="dc91" class="ni mi it ly b gy nj nk l nl nm">ponyo = anime_features.loc[anime_features[‘title_english’] == “Ponyo”] <br/>ponyo</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b450d70a1e1a5aa011665f539ae3ca68.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*TBgX5s9R4VPx4RuhVcwE-g.png"/></div></figure><p id="0d07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将这些数字存储在一个变量中，并通过我们的<code class="fe lv lw lx ly b">NearestNeighbours</code>函数传递它们:</p><pre class="kj kk kl km gt ne ly nf ng aw nh bi"><span id="b4b9" class="ni mi it ly b gy nj nk l nl nm">t = [221,1868,9,0]</span><span id="1c1d" class="ni mi it ly b gy np nk l nl nm">nbrs = NearestNeighbors(n_neighbors=1).fit(X)</span><span id="31d4" class="ni mi it ly b gy np nk l nl nm">print(nbrs.kneighbors([t]))</span><span id="03fc" class="ni mi it ly b gy np nk l nl nm">&gt;&gt;&gt; (array([[0.]]), array([[6036]]))</span></pre><p id="3fea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，从我们的编码数据点计算出的与<code class="fe lv lw lx ly b">Ponyo</code><em class="nq"/>在数量上最相似的项目存在于索引<code class="fe lv lw lx ly b">6036</code>处。我们现在可以调用这个索引来查看<code class="fe lv lw lx ly b">NearestNeighbour</code>函数推荐了哪些内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/4e961e69660d034400e8f9e854c20be3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*XtXyP2s7DqjtQcwE_Bzo-Q.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/c7b9bc56d04417ecbc864825c851ac7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/0*6VnCyLvXru8woH0X.png"/></div></figure><p id="9559" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到它已经推荐了<strong class="lb iu"/>Yonna in the lonely Fortress，一部由竹内健吾执导的动漫奇幻/冒险短片。这个建议是有道理的，因为它也是一部儿童电影，聚焦于女性主角。看到大约有2000个独一无二的编码风格，我们有一个丰富的编码数据池来匹配这个参数。类似地，首映功能有大约200个编码条目，因为日期也按季节划分，这意味着我们可以更接近地匹配项目。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="8958" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">摘要</h1><p id="6ab5" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">本文深入探讨了向用户提供内容推荐的两种方式。</p><p id="f8a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，CFM是一种简单而有效的方法，它使用根据用户评级计算出的相似内容项之间的相关性来推荐内容。</p><p id="6cd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二，NN方法推荐来自一次性编码特征变量的内容，该特征变量将输入变量匹配到数量上相似的内容。</p><p id="707c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两种方法可以以迭代的方式使用。通过使用CFM方法，我们可以将我们的相关变量存储在一个新对象中，并对我们最相关的内容项执行NN，以便提出最佳内容。当然，这可能会产生递减的回报，因为我们想要提供大量的相关内容，而不仅仅是一个高度相关的内容。</p></div></div>    
</body>
</html>
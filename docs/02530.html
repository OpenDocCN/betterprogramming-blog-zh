<html>
<head>
<title>Computer Vision in iOS: Determine the Best Facial Expression in Live Photos</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">iOS中的计算机视觉:确定现场照片中的最佳面部表情</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/computer-vision-in-ios-determine-the-best-facial-expression-in-live-photos-452a2eaf6512?source=collection_archive---------9-----------------------#2019-12-06">https://betterprogramming.pub/computer-vision-in-ios-determine-the-best-facial-expression-in-live-photos-452a2eaf6512?source=collection_archive---------9-----------------------#2019-12-06</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="8212" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">视觉框架新的人脸捕捉质量要求的iOS实现</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/cfc2595c227496d52846e7398ee2e4c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uVA9MWl781wzyvVQ"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">罗伯特·舒涅夫在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="415b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在WWDC 2019期间，苹果公司为其愿景框架带来了许多令人兴奋的新发展。他们不仅改进了人脸跟踪和图像分类，还引入了有趣的新功能，如<a class="ae kz" href="https://medium.com/better-programming/cropping-areas-of-interest-using-vision-in-ios-e83b5e53440b" rel="noopener">显著性</a>、<a class="ae kz" href="https://medium.com/swlh/ios-vision-cat-vs-dog-image-classifier-in-5-minutes-f9fd6f264762" rel="noopener">内置动物分类模型</a>，以及用于处理核心ML分类模型的增强API。在较新的版本中，在一组图像中比较面部捕捉质量的能力是今年最有前途的功能之一。</p><p id="6a68" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">人脸捕捉质量的引入极大地推动了Vision的人脸技术。它展示了苹果公司在计算机视觉领域的投资，以使照片捕捉和处理比以往任何时候都更加智能和简单。</p><p id="10ca" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">面部捕捉质量指标使用一个在各种图像(不同的曝光、光照、面部表情等)上训练过的模型。视觉请求分析一个镜头中的图像，并为其分配一个度量分数。分数取决于面部表情(消极的表情得分较低)、光线、焦点和图像的模糊程度。</p><p id="98f5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">使用这些度量分数，我们可以比较不同的图像，以找到面部看起来最好的图像。这是许多基于自拍的定制应用程序即将实现的功能。</p><p id="792f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">面部捕捉质量不仅有助于构建更智能的基于摄像头的应用，如<a class="ae kz" href="https://developer.apple.com/documentation/vision/selecting_a_selfie_based_on_capture_quality" rel="noopener ugc nofollow" target="_blank">文档</a>中所示，而且还有助于将机器学习智能引入视频处理。本文的目标是通过在我们的iOS应用程序中利用面部捕捉质量，使实时照片(稍后将详细介绍)更加智能。</p><p id="dc83" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">实时照片是iPhone 6s在iOS中引入的，是相机最受欢迎的模式之一。它通过提供实时运动效果，重新定义了我们看待静态图像的方式。</p><h1 id="7540" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">范围</h1><p id="758d" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">这个想法是从有人脸的现场照片中找到最好的帧。我们将使用新的<code class="fe mt mu mv mw b">VNDetectFaceCaptureQualityRequest</code>类来运行我们的视觉请求，处理大量故意在糟糕/模糊状态下捕捉的实时照片，以便从中提取最佳帧。</p><p id="b81f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">但是，您也可以将相同的代码和概念扩展到视频。现场照片本质上包含视频，我们接下来会看到。</p><h1 id="599f" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">现场照片:引擎盖下</h1><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj mx"><img src="../Images/359820311c4b996fbd0c939e1eaf9fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*04qgrRAwpOJ3rzXFLVDXng.png"/></div></figure><p id="a4d1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">实时照片由一幅图像和一个视频带组成，视频带包含在捕获图像期间执行的操作。这给人一种观看时身临其境的感觉。</p><p id="d050" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在引擎盖下，现场照片由与视频资源资产文件配对的关键照片组成。我们可以通过在照片应用程序的预览编辑模式中选择任何视频帧来更改关键照片。</p><p id="05ab" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了访问代码中的关键照片或视频，您需要使用保存资产资源的类<code class="fe mt mu mv mw b">PHAssetResourceManager</code>。在接下来的几节中，我们将在我们的实现中使用它。</p><h1 id="e660" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">行动（或活动、袭击）计划</h1><p id="9fe1" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">在我们深入研究实现之前，让我们规划一下蓝图。我们将在应用程序的不同阶段使用以下类和组件:</p><ul class=""><li id="e22e" class="my mz iu lc b ld le lg lh lj na ln nb lr nc lv nd ne nf ng bi translated">一个<code class="fe mt mu mv mw b">ImagePickerController</code>，用于从相机或照片库中选择实时照片。</li><li id="c1a3" class="my mz iu lc b ld nh lg ni lj nj ln nk lr nl lv nd ne nf ng bi translated"><code class="fe mt mu mv mw b">PHAssetResource</code>检索视频资源并存储在临时的<code class="fe mt mu mv mw b">FileManager</code>目录中。</li><li id="b748" class="my mz iu lc b ld nh lg ni lj nj ln nk lr nl lv nd ne nf ng bi translated">使用<code class="fe mt mu mv mw b">CollectionView</code>显示视频帧以及来自视觉请求的面部质量度量值。</li><li id="c448" class="my mz iu lc b ld nh lg ni lj nj ln nk lr nl lv nd ne nf ng bi translated">最后，我们将在<code class="fe mt mu mv mw b">UIImageView</code>中显示具有最高面部捕捉质量的帧。</li></ul><p id="a151" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">下图从较高层面概述了实施的关联方式，从实时照片捕捉到视频提取，再到视觉人脸捕捉质量要求:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nm"><img src="../Images/e7b0a07bec6daffd307705a7838755a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5VyZPuMGmBBCSGd5y_YNrA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">将这些点连接起来</p></figure><p id="37f8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在我们已经制定了行动计划，让我们通过设置用户界面来启动实施。</p></div><div class="ab cl nn no hy np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="in io ip iq ir"><h1 id="6e8a" class="lw lx iu bd ly lz nu mb mc md nv mf mg ka nw kb mi kd nx ke mk kg ny kh mm mn bi translated">设置用户界面</h1><p id="17e6" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">以下代码在我们的<code class="fe mt mu mv mw b">ViewController.swift</code>文件中建立了按钮和图像视图:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="fd5c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果上面的代码看起来很大，那是因为我没有使用故事板，而是以编程方式构建了UI。</p><h1 id="52db" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">设置我们的图像拾取器</h1><p id="d735" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">前面提到的一个按钮负责启动图像拾取器，而另一个按钮完成视觉请求，我们将在后面看到。</p><pre class="kk kl km kn gu ob mw oc od aw oe bi"><span id="a562" class="of lx iu mw b gz og oh l oi oj">@objc func onButtonClick(sender: UIButton){</span><span id="5070" class="of lx iu mw b gz ok oh l oi oj">let imagePicker = UIImagePickerController()</span><span id="9048" class="of lx iu mw b gz ok oh l oi oj">imagePicker.sourceType = .photoLibrary</span><span id="4cf1" class="of lx iu mw b gz ok oh l oi oj">imagePicker.mediaTypes = [kUTTypeImage, kUTTypeLivePhoto] as [String]</span><span id="12ab" class="of lx iu mw b gz ok oh l oi oj">imagePicker.delegate = self</span><span id="f443" class="of lx iu mw b gz ok oh l oi oj">present(imagePicker, animated: true, completion: nil)</span><span id="1797" class="of lx iu mw b gz ok oh l oi oj">}</span></pre><p id="dcf6" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在上面的代码中，我们设置了<code class="fe mt mu mv mw b">ImagePickerController</code>来访问照片库中的实时照片。为了使<code class="fe mt mu mv mw b">ImagePicker</code>正常工作，请确保您已经在info.plist文件中添加了“照片使用”的隐私使用描述。</p><h1 id="4e52" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">现场照片的视频提取和处理</h1><p id="c78a" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">现场照片属于<code class="fe mt mu mv mw b">PHLivePhoto</code>类型。以下代码用于处理从图像拾取器中选择的实时照片:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="52d0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在上面的代码中，我们通过检查返回的结果是否包含<code class="fe mt mu mv mw b">info </code>字典中的<code class="fe mt mu mv mw b">PHLivePhoto</code>实例来过滤图像拾取器结果，以便返回实时照片图像。</p><p id="621b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在<code class="fe mt mu mv mw b">processLivePhoto</code>函数中，我们将从现场照片中提取视频资源，保存在<code class="fe mt mu mv mw b">FileManager</code>中的临时URL中，并从视频中提取图像帧。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="ecb0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe mt mu mv mw b">PHAssetResourceManager.default().writeData</code>负责将视频缓冲区写入URL。一旦资源被写入<code class="fe mt mu mv mw b">videoUrl</code>，由于属性观察器的作用，<code class="fe mt mu mv mw b">imagesFromVideos</code>函数就会被触发:</p><pre class="kk kl km kn gu ob mw oc od aw oe bi"><span id="3005" class="of lx iu mw b gz og oh l oi oj">var videoUrl : URL? {<br/>        didSet{<br/>            DispatchQueue.global(qos: .background).async {<br/>                guard let videoURL = self.videoUrl else{ return }<br/>                self.imagesFromVideo(url: videoURL)<br/>            }<br/>        }<br/>}</span></pre><h1 id="4582" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">从视频中提取帧</h1><p id="4189" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">以下代码提取一定数量的帧(基于视频持续时间)并将它们放入一个数组中:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="4c7b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe mt mu mv mw b">generateCGImagesAsynchronously</code>负责在指定的<code class="fe mt mu mv mw b">NSValue</code>(时间)内从视频中异步提取多个帧。</p><p id="684c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">通过使用<code class="fe mt mu mv mw b">asset.duration</code>和<code class="fe mt mu mv mw b">numberOfFrames</code>，我们确定提取的每帧之间的时间间隔。目前，<code class="fe mt mu mv mw b">numberOfFrames</code>被设置为12来限制我们将要执行的视觉请求的数量。对于不超过3秒的现场照片来说，这似乎很好，尽管如果你正在进行视频处理，你可以使用这个数字。</p><p id="f0aa" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在上述代码片段的开头，我们定义了一些属性。<code class="fe mt mu mv mw b">setCustomData</code>用来填充我们的<code class="fe mt mu mv mw b">CollectionView</code>。为此，我们需要首先设置我们的<code class="fe mt mu mv mw b">CollectionView</code>。</p><p id="d75e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我们开始构建我们的<code class="fe mt mu mv mw b">CollectionView</code>之前，让我们先来看一下处于中间阶段的应用程序:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/d1cd240b13c77a15c2a077280dfd16ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/1*dlLYrE_PYwxAcLFZ4m-R9Q.gif"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">忽略昏昏欲睡的我。跳转到CollectionView。</p></figure><p id="2699" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当然，在上面的屏幕记录中看到的水平集合视图还有待实现。</p><h1 id="0e3b" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">设置集合视图</h1><p id="f644" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">在开始设置其他UI组件时，我们跳过了<code class="fe mt mu mv mw b">setupCollectionView</code>函数。是时候实施了。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="852d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在上面的代码中，我们设置了一个水平集合视图，并在其上注册了一个<code class="fe mt mu mv mw b">CustomCell</code>类，它保存了<code class="fe mt mu mv mw b">UICollectionViewCell</code>的布局</p></div><div class="ab cl nn no hy np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="in io ip iq ir"><h2 id="d939" class="of lx iu bd ly om on dn mc oo op dp mg lj oq or mi ln os ot mk lr ou ov mm ow bi translated">集合视图单元格、数据源和委托方法</h2><p id="d46a" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">下面的代码通过添加一个<code class="fe mt mu mv mw b">UIImageView</code>和一个<code class="fe mt mu mv mw b">Label</code>来设置集合视图单元格。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="52c6" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe mt mu mv mw b">CustomData</code>类保存每个单元格的数据。这是我们<code class="fe mt mu mv mw b">CollectionView</code>的数据来源。下面的代码定义了它:</p><pre class="kk kl km kn gu ob mw oc od aw oe bi"><span id="ca15" class="of lx iu mw b gz og oh l oi oj">public struct CustomData {</span><span id="16d7" class="of lx iu mw b gz ok oh l oi oj">var faceQualityValue: String = ""</span><span id="123b" class="of lx iu mw b gz ok oh l oi oj">var frameImage: UIImage</span><span id="4956" class="of lx iu mw b gz ok oh l oi oj">}</span></pre><p id="4e34" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">接下来，我们需要定义我们的<code class="fe mt mu mv mw b">CollectionView</code>的委托方法:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="dcf0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，是处理视觉请求的时候了。</p><h1 id="80e5" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">设置愿景请求</h1><p id="6ddc" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">我们的视觉处理器将从<code class="fe mt mu mv mw b">CollectionView</code>中获取每一幅图像，并对它们运行<code class="fe mt mu mv mw b">VNDetectFaceCaptureQualityRequest</code>以获得<code class="fe mt mu mv mw b">faceCaptureQuality</code>分数度量。我们将简单地在<code class="fe mt mu mv mw b">UIImageView</code>中显示具有最高面部捕捉质量的图像。</p><p id="60e8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当按下按钮(带有眼睛图标的按钮)触发选择器方法时，以下代码运行视觉请求:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nz oa l"/></div></figure><p id="a42a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我在几张现场自拍照片(故意模糊，姿势和表情怪异)上运行了上述视觉要求，以确定最佳帧。结果如下:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ox"><img src="../Images/0c10b84b9203933db4ae7fccad0f9cf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DqWxHX6XbVkcZaArznMRg.png"/></div></div></figure><p id="8f5f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">上述结果说明了视觉如何帮助自动确定从给定的一组图像(即视频帧)中捕获的最佳人脸。对于持续时间较短的视频，面部捕捉质量视觉要求非常快速和准确，就像我们对实时照片的要求一样。</p><h1 id="4814" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">结论</h1><p id="b0b0" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">因此，我们讨论了iOS 13和macOS 15中Vision人脸技术的新变化(特别是人脸捕捉质量)，并从头创建了一个完整的iOS应用程序，在实时照片上使用这一新功能。完整的源代码可以在这个<a class="ae kz" href="https://github.com/anupamchugh/iowncode/tree/master/iOSVisionFaceQualityLivePhoto" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>中找到。</p><p id="f3ca" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">面部捕捉质量是一项令人兴奋的功能，有多种使用案例，从照片编辑到异常检测(找出视频/直播照片是否有人脸)。</p><p id="7233" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">只有时间才能证明苹果是否决定在其内置的实时照片功能中引入这一功能，以进行智能编辑。在此之前，您可以尝试在上述应用程序的基础上即兴创作，也许可以将最佳帧存储为现场照片的关键帧(显示在照片库中)。</p><p id="1a50" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这就结束了。我希望你喜欢阅读。</p></div></div>    
</body>
</html>
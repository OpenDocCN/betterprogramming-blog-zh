<html>
<head>
<title>Create Your Own Virtual Green Screen</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建自己的虚拟绿屏</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/create-your-own-virtual-green-screen-ced00b66373f?source=collection_archive---------22-----------------------#2020-04-06">https://betterprogramming.pub/create-your-own-virtual-green-screen-ced00b66373f?source=collection_archive---------22-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0a5f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">检测屏幕上的人和他们周围的区域，给他们自己的自定义背景</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a4f71ca98f2590c7aaaaaa84c1755444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克里斯·蒙哥马利在<a class="ae ky" href="https://unsplash.com/s/photos/zoom-meeting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><p id="3a54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您是否注意到在每次Zoom会议中，您的同事似乎都在不同的位置？很有可能，他们用的是虚拟背景。越来越多的人现在在家工作，在家学习，并使用视频聊天功能与朋友联系，而不是亲自见面。向视频流应用程序添加绿屏功能可以为用户提供更多隐私或有趣的选项，同时仍然可以在在线会议、聚会或游戏之夜直观地呈现。</p><p id="3ec1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用计算机视觉构建自己的虚拟绿屏应用程序！</p><p id="6977" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将使用语义分割从背景中分离出一个人，然后模糊背景或用不同的图像替换它。如果你不熟悉语义分割，你可以看看这篇描述这个概念以及其他类型的计算机视觉模型的<a class="ae ky" href="https://towardsdatascience.com/introduction-to-computer-vision-model-training-c8d22a9af22b" rel="noopener" target="_blank">概述</a>文章。</p><p id="f00e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程使用了两篇其他文章中的代码:第一篇演示了如何使用配置文件<a class="ae ky" href="https://medium.com/@jalakoo_83320/using-a-computer-vision-classifier-to-sort-images-333d5090c0b4" rel="noopener">分离代码的配置信息</a>，第二篇演示了如何使用语义分段<a class="ae ky" href="https://learn.alwaysai.co/how-to-detect-pedestrians-and-bicyclists-in-a-cityscape-video?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=green-screen" rel="noopener ugc nofollow" target="_blank">从图像中删除不需要的项目</a>。</p><p id="bf87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程的所有代码以及设置说明都可以在<a class="ae ky" href="https://github.com/alwaysai/virtual-green-screen.git" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。按照教程，你可以先创建一个<a class="ae ky" href="https://alwaysai.co/auth?register=true?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=green-screen" rel="noopener ugc nofollow" target="_blank"> alwaysAI账户</a>(这是免费的！)并在您的机器上设置alwaysAI <a class="ae ky" href="https://alwaysai.co/docs/getting_started/development_computer_setup.html?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=green-screen" rel="noopener ugc nofollow" target="_blank">(也是免费的)。此应用程序是通过修改一个初学者应用程序创建的。您可以通过在命令行上运行“aai get-starter-apps”来获得入门应用程序，方法是在您想要存储示例应用程序的文件夹中。然后cd到‘semantic _ segmentation _ VOC’文件夹修改app创建虚拟绿屏(或将内容复制到所需区域)。然而，创建虚拟背景的代码可以应用于任何Python计算机视觉应用程序！</a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="fb8d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">我们开始吧！</strong></h1><p id="863e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">本教程将包含两个部分:</p><ol class=""><li id="886f" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">设置配置文件。</li><li id="ee7a" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">使用语义分割处理视频流<strong class="lb iu"> </strong>。</li></ol></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="53e1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">设置配置文件</strong></h1><p id="8fdc" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">将您的设置放在一个单独的文件中使您能够轻松地更改它们，而不用担心无意中更改了您现有的代码。教程的这一部分摘自最初的<a class="ae ky" href="https://medium.com/@jalakoo_83320/using-a-computer-vision-classifier-to-sort-images-333d5090c0b4" rel="noopener">博文</a>。</p><ul class=""><li id="a71f" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">使用文件浏览器或通过终端创建配置文件。如果您使用的是Mac，请输入:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="645a" class="nt md it np b gy nu nv l nw nx">touch config.json</span></pre><p id="52d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于Windows，请输入:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="c422" class="nt md it np b gy nu nv l nw nx">type nul &gt; config.json</span></pre><ul class=""><li id="58c5" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">然后，将以下内容复制粘贴到您的<code class="fe ny nz oa np b">config.json</code>文件中:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="4c66" class="nt md it np b gy nu nv l nw nx">{<br/>    “model_id” : “alwaysai/fcn_alexnet_pascal_voc”,<br/>    “target_labels” : [“person”],<br/>    “background_images” : “images/”,<br/>    “image” : “beach_pic.jpg”,<br/>    “blur” : true,<br/>    “blur_level” : 35,<br/>    “use_background_image” : false<br/>}</span></pre><p id="ed09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们指定要使用的分割模型的类型(<code class="fe ny nz oa np b">alwaysai/fcn_alexnet_pascal_voc</code>)、我们对分割出的标签感兴趣(该应用程序将只是人)、存储备选背景图像的文件夹、要使用的图像，或者我们是否希望只是模糊背景以及背景模糊的程度。</p><p id="2885" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ob">注意:</em> <code class="fe ny nz oa np b"><em class="ob">blur_level</em></code> <em class="ob">越高，人物周围出现的分割边缘就越清晰。你可以尝试不同的层次，决定是掩饰背景更重要还是避免画面中的硬边更重要。</em></p><ul class=""><li id="b71b" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">将下面的<code class="fe ny nz oa np b">import</code>语句添加到您的<code class="fe ny nz oa np b">app.py</code>文件的顶部:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="efc4" class="nt md it np b gy nu nv l nw nx">import os<br/>import json<br/>import numpy as np<br/>import cv2 as cv</span></pre><ul class=""><li id="39f1" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">在<code class="fe ny nz oa np b">import</code>语句下添加以下静态变量:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><ul class=""><li id="192c" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">创建一个方法来打开配置文件并将JSON数据返回给main。将以下内容复制到静态变量声明下:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="e84e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这段代码检查是否有配置文件，如果有，就将JSON数据转换成Python数据，并将其返回给调用方法。</p><ul class=""><li id="24b9" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">现在，使用我们之前声明的静态变量作为输入，从main调用<code class="fe ny nz oa np b">load_json</code>方法，并将结果数据存储在一个局部变量中:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="cf60" class="nt md it np b gy nu nv l nw nx">config = load_json(CONFIG_FILE)</span></pre><ul class=""><li id="738f" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">最后，在main中设置局部变量，从配置文件中提取其余的设置:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="feed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在配置都设置好了！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d340" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">使用语义分割处理视频流</strong></h1><p id="55c2" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在，我们将编辑starter应用程序，从视频流中分割出一个人，并返回修改后的图像。</p><ul class=""><li id="98bc" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">用以下代码替换<code class="fe ny nz oa np b">semantic_segmentation = edgeiq.SemanticSegmentation(“alwaysai/fcn_alexnet_pascal_voc”)</code>:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="3188" class="nt md it np b gy nu nv l nw nx">semantic_segmentation = edgeiq.SemanticSegmentation(model_id)</span></pre><p id="ff25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将使用模型的配置变量，而不是硬编码它。即使我们在<code class="fe ny nz oa np b">config.json</code>文件中设置的模型是相同的，这也使得我们的代码在交换不同的模型时更加灵活！</p><ul class=""><li id="ea69" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">删除<code class="fe ny nz oa np b">image_paths</code>及其下面相应的<code class="fe ny nz oa np b">print</code>语句。我们不会传输图像，而是使用视频流，我们将在下一步进行配置。</li><li id="7849" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu nn nf ng nh bi translated">在<code class="fe ny nz oa np b">image_paths</code>声明的地方，添加以下代码:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="8eae" class="nt md it np b gy nu nv l nw nx">fps = edgeiq.FPS()</span></pre><p id="036e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它跟踪视频输入流每秒的帧数。</p><ul class=""><li id="cdf9" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">现在将带有<code class="fe ny nz oa np b">edgeiq.Streamer(…. As streamer: line</code>的更改为:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="e371" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将使用视频流而不是单独的静态图像。</p><ul class=""><li id="13ef" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">因为我们现在正在读取视频帧，并且已经删除了<code class="fe ny nz oa np b">image</code>变量，所以将<code class="fe ny nz oa np b">results = semantic_segmentation.segment_image(image)</code>改为:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="cd38" class="nt md it np b gy nu nv l nw nx">results = semantic_segmentation.segment_image(frame)</span></pre><ul class=""><li id="0b04" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">从原始的starter应用程序中删除以下行:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="94e4" class="nt md it np b gy nu nv l nw nx">text.append(“Legend:”)<br/>text.append(semantic_segmentation.build_legend())<br/>mask = semantic_segmentation.build_image_mask(results.class_map)<br/>blended = edgeiq.blend_images(image, mask, alpha=0.5)</span></pre><p id="2140" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图例在我们的输出屏幕上会很大，因为我们只跟踪人，所以这些标签对我们来说描述性不是很强。对<code class="fe ny nz oa np b">build_image_mask</code>和<code class="fe ny nz oa np b">blend_images</code>的调用也是不需要的，因为我们不是屏蔽图像，而是从原始帧中剪切出这个人。</p><p id="d97c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将构建一个受限的类别映射，该映射仅映射到我们想要识别的对象—即人。如何做到这一点的完整教程可以在这个<a class="ae ky" href="https://learn.alwaysai.co/how-to-detect-pedestrians-and-bicyclists-in-a-cityscape-video?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=green-screen" rel="noopener ugc nofollow" target="_blank">博客</a>中看到。我们将稍微改变这种方法，只跟踪类别图中与人匹配的部分，然后剪切输入视频帧的相应部分以保持原样，模糊其余部分或用另一幅图像替换它。</p><p id="0b68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将构建<code class="fe ny nz oa np b">filtered</code>类别地图。将以下代码行添加到程序中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="374d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果这个变量在配置文件中设置为<code class="fe ny nz oa np b">true</code>,我们将模糊图像，或者用新图像替换背景。</p><ul class=""><li id="1840" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">通过添加以下代码行，用新的背景图像替换背景:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><ul class=""><li id="cfa2" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">要模糊图像，请添加以下代码行:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="0c40" class="nt md it np b gy nu nv l nw nx">if blur:<br/>    # blur the background:<br/>    background = cv.blur(background, (blur_level, blur_level))</span></pre><ul class=""><li id="130e" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">用原始图像替换新帧中与原始帧中检测到的人相对应的部分:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="adc9" class="nt md it np b gy nu nv l nw nx">background[detection_map] = frame[detection_map].copy()</span></pre><ul class=""><li id="5302" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">最后，删除这几行代码:</li></ul><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="21a6" class="nt md it np b gy nu nv l nw nx">streamer.send_data(blended, text)<br/>streamer.wait()<br/>print(“Program Ending”)</span></pre><ul class=""><li id="4c7f" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nn nf ng nh bi translated">并用以下代码行替换它们:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="8f8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这会将新的帧发送到流处理器，更新视频输出流，并检查用户是否关闭了程序。每当用户关闭程序或者在我们的<code class="fe ny nz oa np b">try</code>块中出现问题时，就会执行<code class="fe ny nz oa np b">finally</code>语句。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="3006" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">就是这样！</strong></h1><p id="5e51" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">要查看您的应用程序的运行情况，只需<a class="ae ky" href="https://alwaysai.co/blog/building-and-deploying-apps-on-alwaysai?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=green-screen" rel="noopener ugc nofollow" target="_blank">构建并启动</a>它，然后打开任何浏览器到localhost:5000来查看您的虚拟绿屏的运行情况。</p><p id="a9b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面，我展示了当<code class="fe ny nz oa np b">blur</code>设置为<code class="fe ny nz oa np b">true</code>和<code class="fe ny nz oa np b">use_background_image</code>设置为<code class="fe ny nz oa np b">false</code>时的输出示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/e511aa74155f667ca29250fcc011e068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TEP6kdGPE8v_h2UonZc-ag.png"/></div></div></figure><p id="462f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，如果您选择使用背景图像，就像这张在海滩上的图像，您可以期待如下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/dde561f8aa4da862759783d87728be0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UotS-4fMQCtZC_ntzWwO0g.png"/></div></div></figure><p id="1eb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你很可能注意到的，这个模型生成的边相当大，而且是块状的，这是由于在这个应用程序中使用的模型。然而，在随后的教程中，我将讲述如何平滑这些边缘，使其看起来不那么块状！</p><p id="4fc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p></div></div>    
</body>
</html>
<html>
<head>
<title>When IO-bound Hides Inside CPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当IO绑定隐藏在CPU内部时</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/when-io-bound-hides-inside-cpu-e6e7f9df3187?source=collection_archive---------4-----------------------#2022-02-15">https://betterprogramming.pub/when-io-bound-hides-inside-cpu-e6e7f9df3187?source=collection_archive---------4-----------------------#2022-02-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1d46" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Go揭示纯CPU限制的应用程序中的IO瓶颈</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e2dd3c0c44766177e54bcd0b62bc9d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tw707d_Q1B7H3D0RmspVMg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克里斯蒂安·威迪格在<a class="ae kv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="25f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们中的许多人倾向于非常直观地考虑IO受限与CPU受限的应用程序，判断是CPU工作负载还是网络/文件IO操作占主导地位。在这个故事中，我将演示发生在CPU内部的IO工作负载——一种值得了解的特殊IO。</p><p id="5304" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了简单起见，我将使用Go编程语言，因为Go对并发操作有一流的支持。如果您不熟悉它也没关系——代码非常简单！我们走吧！</p><h1 id="3204" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">旅程开始了</h1><p id="208d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">考虑一个简单的函数，它将一个整数变量递增若干次:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="3e0e" class="mu lt iq mq b gy mv mw l mx my">func incrementManyTimes(val *int64, times int) {<br/>    for i := 0; i &lt; times; i++ {<br/>        *val++<br/>    }<br/>}</span></pre><p id="dbc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些参数是:</p><ul class=""><li id="dce5" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">指向我们想要增加的整数值</li><li id="67b3" class="mz na iq ky b kz nl lc nm lf nn lj no ln np lr ne nf ng nh bi translated"><code class="fe ni nj nk mq b">times</code>表示我们想要增加的次数</li></ul><p id="ca33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个任务很受CPU的限制，对吗？不涉及IO。</p><h1 id="8819" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">并行做事</h1><p id="ba2f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">假设我们有两个需要递增的整数变量。由于任务是受CPU限制的，通常在多核机器中，我们只是并行化这样的任务——每个CPU内核一个变量。</p><p id="84b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Go中，这很容易编码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="17ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们只是在两个并行的后台任务中运行最初的<code class="fe ni nj nk mq b">incrementManyTimes</code>功能。因为Go试图利用尽可能多的CPU内核，所以它会将每个对<code class="fe ni nj nk mq b">incrementManyTimes</code>的调用卸载到一个专用的CPU内核。</p><p id="b07c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看它是如何工作的。</p><p id="cf47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们定义实际的变量(它们将保存增加的值)。我们选择将它们定义为一个结构的一部分，这样它们就不会感到孤独:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="5d1f" class="mu lt iq mq b gy mv mw l mx my">// define structure type to hold the values<br/>type IntVars struct {<br/>   i1 int64<br/>   i2 int64<br/>}</span><span id="6a8b" class="mu lt iq mq b gy ns mw l mx my">// create the actual values<br/>vars := IntVars{i1: 0, i2: 0}</span></pre><p id="f574" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将单个值递增一千次的代码如下所示:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="6b1b" class="mu lt iq mq b gy mv mw l mx my">incrementManyTimes(&amp;vars.i1, 1000)</span></pre><p id="9fa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了并行增加2个值，我们将使用上面实现的<code class="fe ni nj nk mq b">incrementParallel</code>:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="7936" class="mu lt iq mq b gy mv mw l mx my">incrementParallel<!-- -->(&amp;vars.i1, &amp;vars.i2, 1000)</span></pre><p id="ea05" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们的建议是正确的——在多核机器中，增加一个变量所需的时间必须与增加两个这样的变量所需的时间相同，因为我们是在不同的CPU内核上并行处理事情。</p><p id="f70b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们进行基准测试，看看结果:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="f9ca" class="mu lt iq mq b gy mv mw l mx my">cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</span><span id="4aac" class="mu lt iq mq b gy ns mw l mx my">BenchmarkIncrement1Value              1.408 ns/op<br/>BenchmarkIncrement2ValuesInParallel   2.172 ns/op</span></pre><p id="f0d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">什么？并行增加2个值的时间比只增加一个值的时间多54%!要么我们关于多核处理的建议是错误的【剧透:不是】，要么<strong class="ky ir">这里有猫腻</strong>。</p><p id="0979" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了理解为什么我们没有得到预期的结果，我们需要更深入地研究CPU缓存的工作原理。</p><h1 id="d0d1" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">CPU缓存</h1><p id="d741" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现代的CPU是一头野兽。它实际上是如此之快，以至于RAM跟不上它，成为一个瓶颈。为了克服这一点，CPU尽可能使用嵌入式缓存来避免RAM访问。</p><p id="89ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">高速缓存是一种更小、更快的内存，位于处理器内核附近。当试图从主存储器中的一个位置读取或向其写入时，处理器检查来自该位置的数据是否已经在高速缓存中。如果是这样，处理器将从高速缓存中读取或写入，而不是从慢得多的主存储器中读取或写入。</p><p id="f2bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数CPU都有多个缓存级别(L1、L2，通常是L3，甚至很少是L4)，即由较大、较慢的缓存备份的小型快速缓存。多级高速缓存通常通过首先检查最快的(L1)高速缓存来操作；如果命中，处理器高速处理。如果较小的高速缓存未命中，则在访问外部存储器之前，检查下一个最快的高速缓存(L2 ),依此类推。每个CPU内核通常都有其本地缓存(在Core-i7中— L1和L2 [2]):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/71a8947b24189e78d69b4c1dd9f5223f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*umv2v9PWrZpqL1ihvEgLqw.png"/></div></figure><p id="14f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你认为拉姆很快，我有消息告诉你。以下是英特尔酷睿i7处理器的CPU高速缓存与RAM的访问时间比较[1，4]:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="a785" class="mu lt iq mq b gy mv mw l mx my">Core i7 Xeon 5500 Series Data Source Latency (approximate)               <br/><br/>L1 CACHE hit               1-2   ns<br/>L2 CACHE hit               3-5   ns<br/>L3 CACHE hit               12-40 ns<br/><br/>local  DRAM                ~60   ns<br/>remote DRAM                ~100  ns</span></pre><p id="336d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">CPU缓存可能比RAM快几个数量级！</p><p id="260b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，回到基准测试结果:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="d7e7" class="mu lt iq mq b gy mv mw l mx my">cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</span><span id="8d28" class="mu lt iq mq b gy ns mw l mx my">BenchmarkIncrement1Value              1.408 ns/op<br/>BenchmarkIncrement2ValuesInParallel   2.172 ns/op</span></pre><p id="62e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些数字显示了执行一个值的<strong class="ky ir">单次增量</strong>所需的平均时间。1–2纳秒令人印象深刻！RAM就是不能给我们提供这样的速度。请确保—这些计算是在CPU缓存中完成的。</p><p id="4740" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但问题仍然存在:为什么并行增加2个值(使用不同的CPU内核)比增加一个值要慢？</p><p id="e445" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">答案是“假分享”。</p><h1 id="59f5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">虚假分享</h1><p id="cb2e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">CPU缓存由固定大小的内存区域——“缓存行”组成。CPU只能缓存来自主存的完整大小的行。例如，如果我们访问RAM中的8字节整数值，CPU将缓存整个行区域，这很可能超过8个字节(在Core-i7缓存行中是64个字节)。</p><p id="b2ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当不同的内核访问主内存的同一个区域时，每个内核在本地CPU缓存中都有自己的数据副本。当一个CPU内核改变该内存时，其他内核的缓存会失效，使它们重新加载缓存行，从而导致性能下降。这种情况称为假共享。</p><p id="71a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，事情是这样的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/fab0d9c558fac24afc6dde7f3162bd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*gnHDK59CtU96v9lRVusIIA.png"/></div></figure><p id="20be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管每个CPU内核都在处理不同的值，但它们都共享同一个缓存行，导致每次任何一个变量发生变化时，彼此的缓存都会失效。这正是虚假分享。</p><h2 id="6592" class="mu lt iq bd lu nv nw dn ly nx ny dp mc lf nz oa me lj ob oc mg ln od oe mi of bi translated">减轻</h2><p id="1b76" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了避免错误的共享，我们需要确保我们的变量不落入同一缓存行。实现这一点的一种方法是在它们之间插入填充:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="eda8" class="mu lt iq mq b gy mv mw l mx my">type IntVars struct {<br/>   i1 int64<br/>   _  [56]byte // padding<br/>   i2 int64<br/>}</span></pre><p id="ba9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请记住，在核心i-7缓存线是64字节长。为了保证变量<code class="fe ni nj nk mq b">i1</code>和<code class="fe ni nj nk mq b">i2</code>落入不同的缓存行，我们需要确保在内存布局中它们之间至少有64字节的距离。为了实现这一点，我们可以在它们之间插入56字节的填充(我们不需要插入64字节，因为类型<code class="fe ni nj nk mq b">int64</code>的<code class="fe ni nj nk mq b">i1</code>已经占用了8字节)。</p><p id="bf55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们重新运行我们的基准测试:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="b61f" class="mu lt iq mq b gy mv mw l mx my">cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</span><span id="180f" class="mu lt iq mq b gy ns mw l mx my">BenchmarkIncrement1Value               1.367 ns/op<br/>BenchmarkIncrement2ValuesInParallel    1.374 ns/op</span></pre><p id="5069" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然我们已经消除了错误共享，并行增加2个值与增加一个值一样快。</p><p id="7f61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种优化非常具体，编译器无法为我们做到这一点，因为我们牺牲了一些内存(56字节)来填充。所以做这样的优化是程序员的责任。</p><h2 id="2d0d" class="mu lt iq bd lu nv nw dn ly nx ny dp mc lf nz oa me lj ob oc mg ln od oe mi of bi translated">跨架构支持</h2><p id="4cb5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在上面的示例中，我们专门针对酷睿i7 CPU架构优化了并行代码执行，知道了高速缓存行的大小。但是如果我们希望这种填充也能在其他CPU上工作呢？</p><p id="0e42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Go标准库的扩展为此提供了一个特殊的类型:<a class="ae kv" href="https://pkg.go.dev/golang.org/x/sys/cpu#CacheLinePad" rel="noopener ugc nofollow" target="_blank">https://pkg.go.dev/golang.org/x/sys/cpu#CacheLinePad</a></p><p id="385e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了使我们的代码独立于CPU架构，我们可以将填充重写如下:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="c926" class="mu lt iq mq b gy mv mw l mx my">import "golang.org/x/sys/cpu"</span><span id="d6c2" class="mu lt iq mq b gy ns mw l mx my">type IntVars struct {<br/>   i1 int64<br/>   _  cpu.CacheLinePad // padding<br/>   i2 int64<br/>}</span></pre><h2 id="b0ac" class="mu lt iq bd lu nv nw dn ly nx ny dp mc lf nz oa me lj ob oc mg ln od oe mi of bi translated">测量CPU缓存性能</h2><p id="6d4a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">实际上有一种测量CPU缓存性能的方法来证明我们的发现。许多CPU都支持硬件性能计数器——一组专用的<a class="ae kv" href="https://en.wikipedia.org/wiki/Processor_register" rel="noopener ugc nofollow" target="_blank">寄存器</a>来存储硬件相关活动的计数。每个计数器都可以编程为要监控的事件类型，如L1缓存未命中或分支预测失误。然后可以使用特殊的汇编指令读取这些计数器。</p><p id="a80d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Linux上，我们可以使用<code class="fe ni nj nk mq b">perf</code>工具为程序执行读取这样的计数器。让我们尝试并行递增的填充和非填充实现，并查看L1缓存未命中的结果(在错误共享期间会发生)。这个程序非常简单，我们只是并行增加2个值，1亿次:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="d9a0" class="mu lt iq mq b gy mv mw l mx my">func main() {<br/>   a := IntVars{}<br/>   incrementParallel(&amp;a.i1, &amp;a.i2, 100000000)<br/>}</span></pre><p id="2819" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们测量两种实现的L1缓存未命中。</p><p id="0d7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非填充，带有错误共享:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="1bc5" class="mu lt iq mq b gy mv mw l mx my">▶ perf stat -B -e L1-dcache-load-misses ./test</span><span id="2966" class="mu lt iq mq b gy ns mw l mx my"><strong class="mq ir">8,650,268</strong>      L1-dcache-load-misses</span></pre><p id="98cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">填充，没有虚假共享:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="b8f0" class="mu lt iq mq b gy mv mw l mx my">▶ perf stat -B -e L1-dcache-load-misses ./test-padded</span><span id="d936" class="mu lt iq mq b gy ns mw l mx my"><strong class="mq ir">205,526 </strong>     L1-dcache-load-misses</span></pre><p id="925f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，由于错误共享，最初的实现会产生40倍的L1缓存未命中。</p><h1 id="7a9a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">其他技术</h1><p id="da45" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在我们的示例中，通过在内存布局中的值之间添加填充，就可以消除错误共享。取决于算法，可以应用其他技术。例如:</p><ul class=""><li id="b2fd" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">大型源数据阵列可以以防止缓存行重叠的方式跨CPU内核拆分</li><li id="98b6" class="mz na iq ky b kz nl lc nm lf nn lj no ln np lr ne nf ng nh bi translated">多维数组的遍历可以以内存线性的方式完成，这是缓存友好的</li><li id="36b1" class="mz na iq ky b kz nl lc nm lf nn lj no ln np lr ne nf ng nh bi translated">如果内存值被并行例程改变，它们可以将该值复制到它们的本地堆栈中，完成工作，然后将结果合并回原来的内存位置</li></ul><p id="24b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是一些CPU缓存优化的真实例子[3]:</p><blockquote class="og oh oi"><p id="cb7c" class="kw kx oj ky b kz la jr lb lc ld ju le ok lg lh li ol lk ll lm om lo lp lq lr ij bi translated">Linux以大约30Mbps(有线)的速度路由数据包，无线以大约30Mbps的速度。Windows CE的有线网速仅为12Mbps，无线网速仅为6Mbps。我们发现Windows CE比Linux有更多的指令缓存未命中。在我们改变了路由算法，使之更加缓存本地化之后，我们开始做35 Mbps[有线]和25MBps无线——比Linux好20%。</p><p id="7b96" class="kw kx oj ky b kz la jr lb lc ld ju le ok lg lh li ol lk ll lm om lo lp lq lr ij bi translated">谢尔盖·索利亚尼克(来自微软)。</p></blockquote></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><blockquote class="og oh oi"><p id="afa8" class="kw kx oj ky b kz la jr lb lc ld ju le ok lg lh li ol lk ll lm om lo lp lq lr ij bi translated">缓存线是关键！毋庸置疑！如果你在数据布局上犯了哪怕一个错误，你将会得到慢100倍的解决方案！不开玩笑！</p><p id="3598" class="kw kx oj ky b kz la jr lb lc ld ju le ok lg lh li ol lk ll lm om lo lp lq lr ij bi translated">Dmitriy Vyukov(继电器竞争检测器的开发者)。</p></blockquote><h1 id="d970" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="0cf3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这个故事中，我们探讨了什么是错误共享，以及如何利用CPU内存架构知识来实现算法实现中的显著性能提升。</p><p id="87f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以使用随附的Github repo:<a class="ae kv" href="https://github.com/glebarez/false-sharing-demo" rel="noopener ugc nofollow" target="_blank">https://github.com/glebarez/false-sharing-demo</a>轻松复制结果</p><blockquote class="og oh oi"><p id="95fc" class="kw kx oj ky b kz la jr lb lc ld ju le ok lg lh li ol lk ll lm om lo lp lq lr ij bi translated">如果您热衷于代码的速度，那么在设计和实现您的算法和数据结构时，您必须考虑缓存/内存层次结构。</p><p id="35ec" class="kw kx oj ky b kz la jr lb lc ld ju le ok lg lh li ol lk ll lm om lo lp lq lr ij bi translated">Jan Gray(微软CLR性能团队)。</p></blockquote><h1 id="e372" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><ol class=""><li id="a72d" class="mz na iq ky b kz mk lc ml lf ou lj ov ln ow lr ox nf ng nh bi translated"><a class="ae kv" href="https://web.archive.org/web/20160315021718/https://software.intel.com/sites/products/collateral/hpc/vtune/performance_analysis_guide.pdf" rel="noopener ugc nofollow" target="_blank">https://web . archive . org/web/20160315021718/https://software . Intel . com/sites/products/parallels/HPC/vtune/performance _ analysis _ guide . pdf</a></li><li id="2178" class="mz na iq ky b kz nl lc nm lf nn lj no ln np lr ox nf ng nh bi translated">【https://www.aristeia.com/TalkNotes/ACCU2011_CPUCaches.pdf T4】</li><li id="0693" class="mz na iq ky b kz nl lc nm lf nn lj no ln np lr ox nf ng nh bi translated"><a class="ae kv" href="https://www.researchgate.net/figure/Intel-Core-i7-cache-architecture_fig1_324029106" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/figure/Intel-Core-i7-cache-architecture _ fig 1 _ 324029106</a></li><li id="aef6" class="mz na iq ky b kz nl lc nm lf nn lj no ln np lr ox nf ng nh bi translated"><a class="ae kv" href="https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/4087280/approximate-cost-to-access-variable-caches-and-main-memory</a></li></ol></div></div>    
</body>
</html>
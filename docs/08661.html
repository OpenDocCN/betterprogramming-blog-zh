<html>
<head>
<title>Face Tracking With JavaScript on the Browser (Mobile or Desktop)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在浏览器(移动或桌面)上使用JavaScript进行人脸跟踪</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/face-tracking-with-javascript-on-any-device-with-a-browser-mobile-or-desktop-48aa561fd9d5?source=collection_archive---------1-----------------------#2021-05-27">https://betterprogramming.pub/face-tracking-with-javascript-on-any-device-with-a-browser-mobile-or-desktop-48aa561fd9d5?source=collection_archive---------1-----------------------#2021-05-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bb50" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">想建一个使用人脸追踪的网站？嗯，你来对地方了！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6495b2493b366f885854ddef6cce37b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*f3pNK8ScdwpSTT3S"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉格斯技术人员在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="05cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天我将向大家展示如何在任何浏览器、手机或桌面上建立一个可以进行实时人脸跟踪的网页。我用HTML和JavaScript做一切事情，以允许跨设备的可移植性。我还将展示一些易于扩展的工作演示，用于面部跟踪、基本的Snapchat过滤器和科学应用。</p><p id="4dae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【facemeshmedium.netlify.app/】<a class="ae ky" href="https://facemeshmedium.netlify.app/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">所有试玩都可以在这里找到</strong></a></p><h1 id="7a2f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">关于模型</h1><p id="5e5d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">随着Google对Tensorflow的快速发展。JS，网络上的机器学习从未如此简单。我们将使用Google MediaPipe的<strong class="lb iu">面部网格</strong>模型来满足我们所有的面部追踪需求。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/03441200f0c9ea46181483854cb38811.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/0*HIq8UDR3JLBFzwdw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html" rel="noopener ugc nofollow" target="_blank">https://blog . tensor flow . org/2020/03/face-and-hand-tracking-in-browser-with-media pipe-and-tensor flow js . html</a></p></figure><p id="82e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Google Research有一个名为MediaPipe的细分市场，专注于让机器学习模型跨设备运行。这让他们可以预测任何东西，从大而笨重的台式机到没有GPU的移动智能手机(这里是主站点<a class="ae ky" href="https://mediapipe.dev/" rel="noopener ugc nofollow" target="_blank"/>)。<a class="ae ky" href="https://google.github.io/mediapipe/solutions/face_mesh" rel="noopener ugc nofollow" target="_blank">人脸网格</a>是他们的人脸跟踪模型，它接收一个相机帧，并输出468个检测到的人脸上的标记标志。它还通过面部区域(“上唇”、“左眼”等)对标志进行聚类。)并在输出中给出面部的边界框。</p><p id="af3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哦，我有没有提到它给你的地标是3D坐标——有脸部的深度？！这有多蠢？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4eb84243a4a818b1f685598456935833.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*24m9a3JyK7wH9lBL3D1oGg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">面部网格也输出你面部各个区域的相对深度(<a class="ae ky" href="https://google.github.io/mediapipe/solutions/face_mesh.html" rel="noopener ugc nofollow" target="_blank">链接</a>)</p></figure><p id="c276" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你向下滚动Face Mesh的页面，你可能会奇怪我为什么要写这个指南；MediaPipe已经提供了使用面网格的HTML示例。这有两个原因:</p><ol class=""><li id="12e5" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">由于移动和桌面JavaScript处理视频流的方式不同，他们的例子不能在移动浏览器上运行。</li><li id="55a7" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">绘图和编辑库是这种<script>导入格式，它掩盖了面网格输出的实际情况。这很烦人，因为他们的例子让业余程序员很难修改和扩展他们的代码，这是提供例子的全部意义！&lt;/root&gt;</script></li></ol><p id="a7ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经找到了一个修复方法，允许移动浏览器也使用面网格，我将展示几个使用面网格输出的易于扩展的示例，以使编写自己的程序更容易。让我们开始吧！</p><h1 id="50be" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">设置摄像机</h1><p id="4b90" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在我们在摄像机上运行面部跟踪之前，我们必须首先访问摄像机流。我将重用来自<a class="ae ky" href="https://kongmunist.medium.com/ml-in-browser-accessing-smartphone-cameras-with-javascript-86c9a9c6a20e" rel="noopener">早期帖子</a> ( <a class="ae ky" href="https://gist.github.com/kongmunist/cea925f04feecf8983cb40321f8ae59b#file-cameraandcanvasonly-html" rel="noopener ugc nofollow" target="_blank">代码</a>)的代码来访问前置摄像头并输出到网站。此外，由于网站不能在大多数现代浏览器上获得摄像头访问，除非它们托管在HTTP认证的域上，我们将托管来自这个<a class="ae ky" href="https://facemeshmedium.netlify.app/" rel="noopener ugc nofollow" target="_blank">网络生活网站</a>的所有演示。</p><p id="3c54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">JavaScript代码假设您有一个HTML页面，旁边有一个<code class="fe ni nj nk nl b">&lt;video&gt;</code>和<code class="fe ni nj nk nl b">&lt;canvas&gt;</code>元素。我们通过画布把东西画到我们的网站上。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">相机流的基本HTML</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摄像机流的基本JavaScript</p></figure><p id="103d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">JavaScript通过<code class="fe ni nj nk nl b">mediaDevices</code> API设置摄像头，然后分配画布和上下文(ctx ),我们需要在上面绘制。最后，视频流循环绘制到画布上。</p><h1 id="2c51" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">导入面网格和张量流。射流研究…</h1><p id="1402" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在我们需要在视频流上调用Face Mesh。我们通过将这些标签添加到HTML页面的头部，将模型包含到JavaScript的导入中。</p><pre class="kj kk kl km gt no nl np nq aw nr bi"><span id="0af9" class="ns lw it nl b gy nt nu l nv nw"><strong class="nl iu">&lt;script src</strong>="<a class="ae ky" href="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs" rel="noopener ugc nofollow" target="_blank">https://cdn.jsdelivr.net/npm/@tensorflow/tfjs</a>"&gt;<strong class="nl iu">&lt;/script&gt;</strong><br/><strong class="nl iu">&lt;script</strong> <strong class="nl iu">src</strong>=”https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"&gt;<strong class="nl iu">&lt;/script&gt;</strong></span></pre><p id="5a68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还将添加一行代码来初始化我们的<code class="fe ni nj nk nl b">main</code>函数中的<code class="fe ni nj nk nl b">facemesh</code>。加载带有允许您定制模型的选项。我们只关心一次可以检测到的最大人脸数量。</p><pre class="kj kk kl km gt no nl np nq aw nr bi"><span id="53d3" class="ns lw it nl b gy nt nu l nv nw">// In main()<br/>fmesh = <strong class="nl iu">await</strong> facemesh.<strong class="nl iu">load</strong>({detectionConfidence:0.9, maxFaces:3});</span></pre><p id="69fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的JavaScript中，我们将添加一个循环，在我们的视频提要上运行人脸网格并输出预测的人脸。你也可以在<code class="fe ni nj nk nl b">facemesh.estimateFaces</code>中输入一个HTML画布，但是因为我们将在画布上进行绘制，所以我更喜欢在未编辑的<code class="fe ni nj nk nl b">video</code>流中进行面网格预测。这里有一些代码可以帮助你:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="20ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了！现在，无论何时我们出现在网络摄像头中，Face Mesh都会检测我们在画面中的位置，并为我们的脸匹配一系列地标作为<code class="fe ni nj nk nl b">curFaces</code>。将这些预测导出到一个全局变量，让我们的绘图循环(或任何其他函数)处理我们的面部位置。别忘了在你的main的某个地方调用<code class="fe ni nj nk nl b">renderPrediction()</code>；它永远循环，但你必须先启动它。</p><p id="79a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在面部网格输出的面部标志上画点，但要做到这一点，我们需要理解<code class="fe ni nj nk nl b">curFaces</code>到底包含什么。</p><h2 id="79d6" class="ns lw it bd lx nx ny dn mb nz oa dp mf li ob oc mh lm od oe mj lq of og ml oh bi translated">面网格输出格式</h2><p id="0c58" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">面部网格的输出是面部预测的<code class="fe ni nj nk nl b">Array</code>，其中每个预测具有以下格式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/5d9a7e1c9e1a5c9702d49247c880a8c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*KZEBnSXCI0VhPPj6xkSiBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">视频流上调用人脸网格的单个输出</p></figure><p id="266f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将详细讨论每一个问题。</p><ul class=""><li id="b5d2" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu oj na nb nc bi translated"><code class="fe ni nj nk nl b">faceInViewConfidence</code>范围从0.0到1.0，当一张脸在帧中时，通常位于0.99。我们用这个来剔除假阳性人脸检测。</li><li id="96bb" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu oj na nb nc bi translated"><code class="fe ni nj nk nl b">boundingBox</code>包含两个<code class="fe ni nj nk nl b">Coord2Ds</code>，它们是可以使用<code class="fe ni nj nk nl b">topLeft.x</code>和<code class="fe ni nj nk nl b">topLeft.y</code>访问的对象。这些在输入坐标中给出了脸部的角，所以你可以使用它们直接索引到图像中。</li><li id="5cbd" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu oj na nb nc bi translated"><code class="fe ni nj nk nl b">mesh</code>使用非相机坐标系给出面部标志。这使得它有点难以使用，所以我们将考虑它的兄弟，</li><li id="802a" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu oj na nb nc bi translated"><code class="fe ni nj nk nl b">scaledMesh</code>包含格式为(X，Y，Z)的468个3D面部标志，其中X和Y是我们输入视频流上的坐标，Z是深度。每个地标一致地表示脸上的一个点，在他们的<a class="ae ky" href="https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg" rel="noopener ugc nofollow" target="_blank"> Github </a>上有一个网格地图，你可以用它来选择你想要的点。我们稍后将在Snapchat过滤器中使用它。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/027b6fa58a6bee75facf16e71d7967c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QURn3rGIgpWugxgt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">映射到你脸上的网格的可怕远景。点击<a class="ae ky" href="https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg" rel="noopener ugc nofollow" target="_blank">此处</a>查看放大版本。</p></figure><ul class=""><li id="9908" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu oj na nb nc bi translated"><code class="fe ni nj nk nl b">annotations</code>是最后一个，非常有用。面部网格开发人员继续为面部的每个区域创建命名的点集。例如，<code class="fe ni nj nk nl b">annotations.lipsLowerOuter</code>包含下唇外侧的所有点。我们稍后将使用这些来创建脸的特定部分的裁剪。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/94bdf7656a1334432f7d8e5921dff587.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wXMLh_iaUxyI-fa92rY5dw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">所有你能要求的注释，就在你的指尖！</p></figure><p id="4acf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过键入<code class="fe ni nj nk nl b">annotations.</code>在Inspect Element控制台中访问注释的完整列表，然后按tab键自动完成。</p><h1 id="6e17" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">为了乐趣和利益在我脸上画地标</h1><p id="fabe" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在我们知道网格的点只是三维坐标，我们可以索引它们来显示我们的脸在相机上的位置。作为一个基本的例子，我们将在<code class="fe ni nj nk nl b">scaledMesh</code>上循环，并在用户的脸上画一些小点，以显示地标从上面那个可怕的网格映射到哪里。</p><p id="ed51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们将修改我们的<code class="fe ni nj nk nl b">drawVideo</code>函数来绘制<code class="fe ni nj nk nl b">curFaces</code>中的每一张脸。<code class="fe ni nj nk nl b">for (face of curFaces){</code>技巧是用Python编写的JavaScript版本的<code class="fe ni nj nk nl b">for … in …</code>，它在for循环中从<code class="fe ni nj nk nl b">curFaces</code>给我们一个预测。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="1088" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还需要写<code class="fe ni nj nk nl b">drawFace()</code>，它包含在底部。在HTML画布上绘图是通过其<a class="ae ky" href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D" rel="noopener ugc nofollow" target="_blank">画布呈现上下文</a>进行的，在我们的代码中是<code class="fe ni nj nk nl b">ctx</code>。我们首先指定点应该是什么颜色，然后循环遍历这些点。由于每个点都是一个[X，Y，Z]的三维向量，我们可以直接索引到它们，以知道在哪里画我们的圆。<code class="fe ni nj nk nl b">beginPath()</code>开始一个形状，<code class="fe ni nj nk nl b">fill()</code>结束它。</p><p id="5286" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们得到的！布满圆点的脸。自己试试<a class="ae ky" href="https://facemeshmedium.netlify.app/dotsonly/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/676f4d92f6d15a21f54286d62e207475.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*09ZjApPNRhD0hzrleJqddg.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标有圆点的地标。在桌面上，尝试一下<a class="ae ky" href="https://facemeshmedium.netlify.app/dotsonly/" rel="noopener ugc nofollow" target="_blank">这里</a></p></figure><p id="6ae4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要做更高级的事情，你需要知道每个标志点的索引。我们可以添加一条<code class="fe ni nj nk nl b">fillText</code>线来绘制每个圆圈旁边的索引号，但在全尺寸的<a class="ae ky" href="https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg" rel="noopener ugc nofollow" target="_blank">网格地图</a>上可能更容易看到索引。试试看！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/1d87b8ee7fdc687bb2a777a240f0f638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*BpJhcvGwx6ucBjbosW11WA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">旁边标有索引的地标。在手机上。演示<a class="ae ky" href="https://facemeshmedium.netlify.app/labeleddots/" rel="noopener ugc nofollow" target="_blank">这里</a></p></figure><p id="1cff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们知道了界标的位置以及它们的格式，我们可以开始玩了。在下一个例子中，我将向您展示如何使用这些地标来实现一个基本的Snapchat过滤器。</p><h1 id="1ff9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">大眼睛翻嘴(Snapchat滤镜)</h1><p id="98ba" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将使用面网格重新创建大眼睛和嘴巴过滤器，但我们也将翻转嘴巴上下颠倒。从概念上讲，您可能认为过滤器非常简单。两倍的眼睛尺寸，两倍的嘴巴尺寸，把它们叠放在原来的照片上，对吗？你说得对，这很简单！嗯，执行起来会有点棘手，但这是一般程序。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/bf3dea46e00f0452cf6ed81b0a6e30bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*vr6f8Ho9XVUj09W7plJhsg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://support.lensstudio.snapchat.com/hc/en-us/community/posts/360016745206-Big-Eyes-and-Mouth-Filter" rel="noopener ugc nofollow" target="_blank">大眼大嘴滤镜</a></p></figure><p id="a1ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个人都有自己喜欢的图像编辑和计算机视觉编程语言，但我敢打赌没有人会选择JavaScript作为他们的最爱！我也不会，但是我可以向您展示足够多的内容，让您开始作为JavaScript计算机视觉开发人员的漫长而富有成效的职业生涯。这是我们最终制作的过滤器的图片:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/37319f04b9d81d74c8623fa43f4028c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*XlxQ2V_r-7e_jmzFV3-4_A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我演绎的大眼大嘴Snapchat滤镜</p></figure><h2 id="23b2" class="ns lw it bd lx nx ny dn mb nz oa dp mf li ob oc mh lm od oe mj lq of og ml oh bi translated">使用HTML画布</h2><p id="e446" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">从相机设置页面开始，我们的HTML文档中就有了一个<code class="fe ni nj nk nl b">&lt;canvas&gt;</code>。在face landmarks页面中，我们找到了它，因此我们可以设置大小并创建一个名为<code class="fe ni nj nk nl b">ctx</code>的“上下文”。这个<code class="fe ni nj nk nl b">ctx</code>允许我们画圆圈和文字。</p><p id="a5a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但即使在那之前，我们已经在使用<code class="fe ni nj nk nl b">ctx</code>。还记得我们一开始调用的将<code class="fe ni nj nk nl b">video</code>流复制到画布上的函数吗？</p><pre class="kj kk kl km gt no nl np nq aw nr bi"><span id="c288" class="ns lw it nl b gy nt nu l nv nw">ctx.drawImage(<strong class="nl iu">video</strong>, 0, 0, canvas.width, canvas.height);</span></pre><p id="ee3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实证明，这只是从一个图像源绘制到另一个图像源的几个重载JavaScript函数之一。我们上面调用的<code class="fe ni nj nk nl b">drawImage</code>只指定了目的地的左上角坐标以及绘制<code class="fe ni nj nk nl b">video</code>的宽度或高度。我们可以使用另一个<code class="fe ni nj nk nl b">drawImage</code>，它也指定了在将帧绘制到画布上之前，如何从<code class="fe ni nj nk nl b">video</code> <em class="oq">中裁剪帧。</em></p><pre class="kj kk kl km gt no nl np nq aw nr bi"><span id="e350" class="ns lw it nl b gy nt nu l nv nw">ctx.drawImage(video, <br/>source_x, source_y, source_Width, source_Height, // Source location<br/>dest_x, dest_y, dest_Width, dest_Height);  // Destination location</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/6dd93fd9b2de7b55861dd18f15b1115a.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*6lkq4UZmxjBg-Jir.jpg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage" rel="noopener ugc nofollow" target="_blank"> Mozilla </a>，里面有一些很棒的HTML文档。</p></figure><p id="d477" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于Face Mesh以像素为单位输出用户的眼睛位置，因此我们可以通过索引特定的界标来获得眼睛的边界。我们只需要找到眼睛的边界，然后我们可以从视频帧中裁剪出眼睛，并在画布上绘制时将它们的大小加倍。然后我们的滤镜就做好了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/d22a228a77ecac3f6a190ad6deb6abfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*t-o-Gru2-tiaG_YW3_ME3A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们选择标志来定义眼睛的边界框，然后索引它们来找到它们在相机帧中的X和Y值</p></figure><p id="797e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经进入了<a class="ae ky" href="https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg" rel="noopener ugc nofollow" target="_blank">网格图</a>，找到了眼睛周围的这些关键点。在这8个位置索引到<code class="fe ni nj nk nl b">face.scaledMesh</code>，我们可以得到双眼的上、左、右、下四边。我们需要这些坐标来把眼睛画到画布上。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">画大眼睛的完整代码</p></figure><p id="15d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ni nj nk nl b">drawImage</code>调用(第24行)偏移了眼睛的位置，因此2倍大的眼睛仍然位于原来眼睛的中心。</p><p id="2fd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这给了我们这样的东西:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/2a31bd55c914d0aad83cf883c368a611.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*JlskJ-5_NzMwrsV2ylNdNg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">眼珠子瞪得老大的安迪</p></figure><p id="b586" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完美！</p><p id="0fc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在说说嘴。就像我们之前用眼睛看到的那样，尺寸翻倍非常简单，但是翻转就比较难了。实际上不可能颠倒使用<code class="fe ni nj nk nl b">drawImage</code>。相反，我们需要从画布中提取出<code class="fe ni nj nk nl b">ImageData</code>，将其转换成张量流。JS张量，翻转<em class="oq">那个</em>，然后在我们的画布上画出来。咻！</p><p id="8134" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要像做眼睛一样开始。这一次，我们将使用<code class="fe ni nj nk nl b">face.annotations</code>来查找上下嘴唇点，而不是索引。通过迭代这些点，我们将能够找到边界框，并使用<code class="fe ni nj nk nl b">ctx.getImageData</code>从画布中获得嘴巴。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">把嘴唇画大的前半段代码。我们完成了边界的查找，并将它们索引到图像中。</p></figure><p id="5c24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在有了<code class="fe ni nj nk nl b">ImageData</code>。JavaScript ImageData对象不是很友好，但是可以转换成Tensorflow。JS张量。然后我们可以在上面使用所有的Tensorflow函数，也就是<code class="fe ni nj nk nl b">.reverse(0)</code>，逐行翻转图像(从上到下)。</p><pre class="kj kk kl km gt no nl np nq aw nr bi"><span id="f85d" class="ns lw it nl b gy nt nu l nv nw"><strong class="nl iu">lipsUpsideDown</strong> = <strong class="nl iu">tf.browser.fromPixels</strong>(lips,4).reverse(0);</span></pre><p id="b2c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将其转换回ImageData对象，以将其绘制到画布上。以下是完整的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/3c13f163ddfa584094e3baa7a0dde6ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*ppDPzwngq_8scTZtz21oRw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">翻转唇</p></figure><p id="8caf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的另一种方法是使用第二块画布来保存翻转的嘴图像，但我尝试了一下，发现它在精神上不直观而且很慢。</p><p id="f1da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是最终产品。你可以自己试试<a class="ae ky" href="https://facemeshmedium.netlify.app/eyeswap/" rel="noopener ugc nofollow" target="_blank">这里</a>！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/46df83fa03439372f49598cc98305a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/1*3KKM9_ZnWKgrm6_nZkks1w.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">大眼睛翻转嘴使用面网格</p></figure><p id="0665" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然使用Tensorflow仅仅翻转一张图片似乎有些矫枉过正。JS是完全不同的野兽。自从Tensorflow。JS用的是WebGL，很好用，加载也很快(整个库才1.1 MB)。我见过企业logos占了10 MB，所以TF。相比之下JS真的相当便宜。</p><h2 id="2baa" class="ns lw it bd lx nx ny dn mb nz oa dp mf li ob oc mh lm od oe mj lq of og ml oh bi translated">科学使用面网格！</h2><p id="abe7" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在浏览器中使用Tensorflow打开了一个充满可能性的世界。大量的新受众现在可以访问机器学习，而根本不需要下载任何东西。</p><p id="e500" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于民用医疗保健、科学和计算机视觉来说，这些应用非常广泛，尤其是在智能手机如此普及的情况下。我将向您展示一个特别有趣的用例:<strong class="lb iu">仅使用摄像头从远处检测用户的心率。</strong></p><h1 id="d1cb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用照相机检测用户的脉搏(光电容积描记法)</h1><p id="71a3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">你见过那些能从手电筒和摄像头判断你脉搏的智能手机app吗？这种效应被称为<strong class="lb iu">光电容积描记法(PPG) </strong>，因为它用光(<em class="oq">照片</em>)来确定你的脉搏(<em class="oq">容积描记法</em>)。它利用了你的血液在跳动时会改变体积和颜色这一事实。</p><p id="81a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相当酷！然而，我发现这样做更酷，不需要用户触摸任何东西。</p><p id="2c52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着智能手机在21世纪初的普及，高分辨率相机变得越来越容易获得。一些聪明的研究人员正在研究广泛应用的高分辨率相机，并意识到他们可以通过拍摄视频来检测某人的心率。这被称为<strong class="lb iu"> <em class="oq">远程</em> </strong>体积描记法，因为它可以从远处进行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b3b5c5413abdc8453fcbed3071623db4.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/0*U7AOBbf9CCPa7EPK.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.microsoft.com/en-us/research/project/cardiolens/" rel="noopener ugc nofollow" target="_blank">微软研究院的CardioLens </a>在AR中使用了这种确切的效果！</p></figure><p id="2dac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想知道这怎么可能，这和你触摸的智能手机闪光灯的机制是一样的。你的心脏大约每秒跳动一次，每次跳动时，你的血液都会通过血管向前涌动。我们的脸会脸红，会动很多小肌肉做出面部表情，所以我们的面部皮肤有很多表层血管。把这个和你的心跳结合起来，你的脸在每次心跳时闪得更红，亮到可以瞥见用相机。</p><p id="8b46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，没有一台普通的相机能看到你的脸随着每一拍而发红，因为它们太吵了。但是通过对一大片皮肤进行平均，我们可以从普通相机拍摄的视频中看到用户的心跳。我们将使用面网格来完成。</p><h2 id="7338" class="ns lw it bd lx nx ny dn mb nz oa dp mf li ob oc mh lm od oe mj lq of og ml oh bi translated">使用面网格构建网络PPG</h2><p id="9d24" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们可以利用之前学到的知识来构建这个心率监测器，并在浏览器中运行。我们需要做的就是找到脸部的边界，然后对该区域像素的亮度值求和。我们跟踪阵列中的强度，然后对阵列进行FFT以获得频率分量。瞧啊。取这个FFT的峰值应该可以得到心率。</p><p id="c546" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要修改代码，从面部获取一块皮肤。我在网格贴图上选择了一些点(就像我们为眼睛做的一样)，所以我们使用了从眼睛到嘴唇顶部的补丁。</p><p id="285d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们取平均像素值，这样盒子大小的变化不会影响我们的测量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/491a129a4f322c696a83b093cc2585ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*BwCosdwbRoY33vb0OXbz9g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我脸上感兴趣的区域(鼻子和脸颊)。我们将对这个盒子中的像素进行平均。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="6ffd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以使用getImageData提取补丁并对其进行平均。这个平均值被添加到运行历史中。我们还跟踪这个循环的FPS，因为我们需要它将FFT从“指数”转换成频率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="5ea5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我正在使用<a class="ae ky" href="https://dygraphs.com/" rel="noopener ugc nofollow" target="_blank"> Dygraphs </a>库来绘图。下面是强度图的截图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/3f5e1c1101bb6209bc4bacc56e9e1324.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*8ZMr0N_vtxKWf77vew2bkQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一段时间内盒子的平均像素密度。在5秒内可以清楚地看到4个节拍，255个级别中只有1.5个像素的变化！</p></figure><p id="2b01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你试图在JavaScript中找一个FFT库(不是node，而是browser)，你会遇到很多麻烦。幸运的是，在过去的一个项目中，我使用Browserify和Emscripten将一个用C++编写的名为KISS的FFT库转换为JavaScript(详情<a class="ae ky" href="https://andykong.org/projects/heartratemonitor/" rel="noopener ugc nofollow" target="_blank">见</a>)。我用它来计算强度阵列的FFT。一个问题是，将FFT“箱”转换为频率并不需要采样速率参数，但我们自己可以做到这一点！</p><h2 id="0132" class="ns lw it bd lx nx ny dn mb nz oa dp mf li ob oc mh lm od oe mj lq of og ml oh bi translated">FFT仓至频率</h2><p id="3814" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">FFT将时域信号转换为频域信号，并以频率“仓”中的幅度形式输出必须使用以下公式将其转换为频率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/993d5767e2cce70caf2e39e6e1d23960.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*IMddrpzWojoD6OkXC43vog.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">出于我们的目的，DFT和FFT是一回事。从<a class="ae ky" href="https://dsp.stackexchange.com/questions/26927/what-is-a-frequency-bin" rel="noopener ugc nofollow" target="_blank">堆栈溢出</a></p></figure><p id="8bf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该公式给出了每个仓中心的频率。每个面元宽<code class="fe ni nj nk nl b">sampleFreq/numDFTPoints</code> Hz，横跨两侧。你会注意到，我们历史的长度决定了我们频率测量的精度，因为仓宽除以<code class="fe ni nj nk nl b">numDFTPoints</code>。那么，我们的频率精度是多少？</p><p id="ae78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的数组有64个元素长，采样率是可变的(在我的笔记本电脑上大约是8-10赫兹)。这样我们得到的最小bin宽度为8/64 = 0.125Hz，由于人的心率通常以每分钟心跳数给出，所以0.125Hz*60秒就变成了<strong class="lb iu"> 7.5 bpm </strong>。对于心率来说，这种精度不是很高，但您会看到，对多个FFT求平均值可以得到准确的心率。</p><p id="8d84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">库使得计算FFT变得容易，但是知道如何进行bin转换是很重要的，因为它允许灵活地使用哪些库。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">FFT代码</p></figure><p id="3e4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为FFT添加另一个Dygraph，我们就完成了！这里可以自己试试:<a class="ae ky" href="https://facemeshmedium.netlify.app/ppg/" rel="noopener ugc nofollow" target="_blank">facemeshmedium.netlify.app/ppg/</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/39e1b7586211d49755e8497c185ac2da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zd_-TgIEM6mnTU53hldvcQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">左侧是像素强度的FFT图。FFT噪声很大，但如果进行充分的平均，峰值就会出现。<a class="ae ky" href="https://facemeshmedium.netlify.app/ppg/" rel="noopener ugc nofollow" target="_blank">演示在这里</a></p></figure><p id="4340" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">坐着不动，我可以让我的心率在FFT上显示出来，与我手机上的非远程PPG应用程序相比，准确度相当高:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/9836cab3248ccf17bfca4a941ca8399c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*-21Bij_4M_crbnMmEQugCQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">实际心率读数是在那之后获得的(使用智能手机闪光灯，哈！)</p></figure><p id="5b5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多酷啊。你可以坐在你的笔记本电脑前找到你的心率，甚至可以在房间的另一边用一个更好的摄像机。被动生物识别，你甚至不需要穿任何东西！</p><h1 id="a877" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结束语</h1><p id="67b1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">你可以在这里找到所有的演示:</strong><a class="ae ky" href="https://facemeshmedium.netlify.app/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">face mesh medium . net lify . app</strong></a></p><p id="6031" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">以及Github上的所有代码:</strong><a class="ae ky" href="https://github.com/kongmunist/FaceMeshDemos" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">github.com/kongmunist/FaceMeshDemos</strong></a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/df9b92d69b55d6da623c532254297331.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*hdZSlCW4FpjM23XOZczJ5A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">窃听器回来了</p></figure><p id="ec61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我能如此轻松地制作这些演示，这已经是网络进步的一个巨大标志。通过将Tensorflow推送到浏览器中，谷歌使得演示机器学习和计算机视觉项目和产品变得容易得多。人们将不再抱怨“它在我的设置上无法工作”，因为现在它只能在谷歌Chrome、Safari或任何其他支持现代JavaScript的浏览器上工作(但不是Internet Explorer)。</p><p id="8405" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想做一个能告诉你别人穿什么鞋的应用吗？还是智能手机生命监护仪？不用花几个月的时间来编写一个Android和iPhone应用程序，你可以使用一个预先制作的网站，并添加几行JavaScript，立即让任何拥有智能手机的人都能立即访问你的想法。</p></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><p id="6f8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望您在阅读本文时已经了解了一两件关于JavaScript的事情，尤其是当您精通基于web的编程时所展现的可能性。用Tensorflow。JS按照现在的速度发展，我预计基于网络的图像处理和机器学习将在未来几年成为科技领域的重要参与者。技术是为大众服务的，这也是将机器学习带给大众的一个很好的步骤。</p><p id="5489" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你能用你学到的东西做出一些很酷的东西，如果你做了，我很乐意看到它！</p><p id="301b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给我发电子邮件或者在推特上给我发短信。</p><p id="c064" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Cya soon！</p></div></div>    
</body>
</html>
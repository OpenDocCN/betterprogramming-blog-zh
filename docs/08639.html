<html>
<head>
<title>3 Techniques for Importing Large CSV Files Into a Django App</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将大型CSV文件导入Django应用程序的3个技巧</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/3-techniques-for-importing-large-csv-files-into-a-django-app-2b6e5e47dba0?source=collection_archive---------1-----------------------#2021-05-25">https://betterprogramming.pub/3-techniques-for-importing-large-csv-files-into-a-django-app-2b6e5e47dba0?source=collection_archive---------1-----------------------#2021-05-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6f71" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将大量数据加载到数据库变得更加容易</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/23f23e84a346c83323a767e7061a1623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRFrK75ZDk1EwZDG9XFy-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供。</p></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="5398" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak">问题概述和App配置</strong></h1><p id="76a3" class="pw-post-body-paragraph lx ly it lz b ma mb ju mc md me jx mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">通常情况下，您希望将数据从CSV文件加载到数据库中。通常，这根本不是问题，但是在某些情况下可能会出现性能问题，尤其是当您想要加载大量数据时。在这种情况下，“海量”意味着CSV文件具有500MB到1GB的数据和数百万行。</p><p id="75f0" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">在本文中，我将重点关注无法使用数据库实用程序加载CSV文件的情况(如PostgreSQL <code class="fe my mz na nb b">COPY</code>)，因为您需要在这个过程中进行转换。</p><p id="673a" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">此外，值得注意的是，这种规模的数据负载应该总是受到质疑，您应该尝试找到更合适的方法来完成它。经常检查是否可以使用数据库引擎实用程序(如<code class="fe my mz na nb b">COPY</code>)将数据直接复制到数据库中。这些类型的操作几乎总是比使用ORM和您的应用程序代码更高效。</p><p id="9466" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">假设我们有两种型号:<code class="fe my mz na nb b">Product</code>和<code class="fe my mz na nb b">ProductCategory</code>。我们从不同的组织部门获取数据，并且必须将数据加载到系统中。我们的Django模型将如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="60be" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">数据结构非常简单，但足以显示大量数据负载的问题。这里值得注意的一点是<code class="fe my mz na nb b">Product</code>和<code class="fe my mz na nb b">ProductCategory</code>的关系。在这种情况下，我们可以预计产品类别的数量将比产品数量低几个数量级。我们以后会用到这些知识。</p><p id="d502" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">我们还需要一个CSV文件的生成器。CSV文件包含以下各列:</p><ul class=""><li id="f508" class="ne nf it lz b ma mt md mu mg ng mk nh mo ni ms nj nk nl nm bi translated"><code class="fe my mz na nb b">product_name</code></li><li id="fe85" class="ne nf it lz b ma nn md no mg np mk nq mo nr ms nj nk nl nm bi translated"><code class="fe my mz na nb b">product_code</code></li><li id="a655" class="ne nf it lz b ma nn md no mg np mk nq mo nr ms nj nk nl nm bi translated"><code class="fe my mz na nb b">price</code></li><li id="547d" class="ne nf it lz b ma nn md no mg np mk nq mo nr ms nj nk nl nm bi translated"><code class="fe my mz na nb b">product_category_name</code></li><li id="7fc6" class="ne nf it lz b ma nn md no mg np mk nq mo nr ms nj nk nl nm bi translated"><code class="fe my mz na nb b">product_category_code</code></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="7061" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">使用上面的脚本，您可以用我们进行负载测试所需的数据创建一个CSV文件。调用参数时可以传递一个数字，这将是生成的文件中的行数:</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="39a2" class="nw lg it nb b gy nx ny l nz oa">python3 csv_mock_data_create.py 10000</span></pre><p id="7342" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">上面的命令将创建一个包含10，000个产品的文件。注意，脚本现在跳过了CSV文件头。我稍后将回到这一点。</p><p id="5b4b" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">这里要小心，因为1000万行将创建一个大约600MB的文件。</p><p id="6a0b" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">现在我们只需要一个简单的Django管理命令来加载文件。我们不会通过视图来完成，因为正如我们已经知道的，文件非常大。这意味着我们将需要使用一个请求处理程序来上传大约500MB的文件，并因此将文件加载到内存中。这是低效的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="d50e" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">该命令现在有了数据加载的简单实现，还显示了处理CSV文件所需的时间:</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="3782" class="nw lg it nb b gy nx ny l nz oa">python3 manage.py load_csv /path/to/your/file.csv </span></pre><p id="6c8c" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">对于200个产品，上面的代码在0.220191秒内被执行。对于100，000件产品，耗时103.066553秒。一百万件产品可能需要十倍的时间。我们能让它更快吗？</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="b4aa" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak"> 1。不要将整个文件加载到内存中</strong></h1><p id="2894" class="pw-post-body-paragraph lx ly it lz b ma mb ju mc md me jx mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">首先要注意的是，上面的代码将整个CSV加载到内存中。更有趣的是，它做了两次。这两句台词真的很烂:</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="d57a" class="nw lg it nb b gy nx ny l nz oa">data = list(csv.reader(csv_file, delimiter=","))<br/>for row in data[1:]:<br/>    ...</span></pre><p id="8c75" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">试图跳过这样的头处理是一个常见的错误。代码从列表中的第二个元素开始迭代，但是<code class="fe my mz na nb b">csv.reader</code>是一个迭代器，这意味着它是内存高效的。如果程序员强制进行<code class="fe my mz na nb b">list</code>转换，那么CSV文件将被加载到一个列表中，从而加载到进程的内存中。在没有足够RAM内存的情况下，这可能是一个问题。当在<code class="fe my mz na nb b">for</code>循环中使用<code class="fe my mz na nb b">data[1:]</code>时，完成数据的第二次复制。那么我们该如何处理呢？</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="28ec" class="nw lg it nb b gy nx ny l nz oa">data = csv.reader(csv_file, delimiter=",")<br/>next(data)<br/>for row in data:<br/>    ...</span></pre><p id="4064" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">调用<code class="fe my mz na nb b">next</code>会将迭代器移动到下一项，我们将能够跳过一个CSV文件头(在大多数情况下，处理时不需要它)。此外，该进程的内存占用将会低得多。这个变化对执行时间没有大的影响(可以忽略不计)，但是对进程使用的内存有很大的影响。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="d6c0" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak"> 2。迭代</strong>时不要进行不必要的查询</h1><p id="9242" class="pw-post-body-paragraph lx ly it lz b ma mb ju mc md me jx mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">我特别指的是这条线:</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="4d77" class="nw lg it nb b gy nx ny l nz oa">product_category = ProductCategory.objects.get_or_create(name=row[3], code=row[4])</span></pre><p id="d587" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">我们在这里获取的是使用类别名称和代码的每个循环上的<code class="fe my mz na nb b">ProductCategory</code>实例。我们如何解决这个问题？</p><p id="6eed" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">我们可以在<code class="fe my mz na nb b">for</code>循环之前加载类别，只有当它们不在数据库中时才添加它们:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="1aef" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">仅这一项变化就将100，000件产品的生产时间缩短了34秒(约30%)。该命令在更改后的69秒<strong class="lz iu"> </strong>执行。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="523e" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak"> 3。不要一次保存一个元素</strong></h1><p id="5a0e" class="pw-post-body-paragraph lx ly it lz b ma mb ju mc md me jx mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">当我们创建<code class="fe my mz na nb b">Product</code>的实例时，我们要求数据库提交每个循环中的更改:</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="7112" class="nw lg it nb b gy nx ny l nz oa">Product.objects.create(<br/>    name=row[0],<br/>    code=row[1],<br/>    price=row[2],<br/>    product_category=product_category<br/>)</span></pre><p id="834a" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">这是每个循环的I/O操作。它一定很贵。由于它非常快，这里的问题是可能有数百万次这样的操作，我们可以显著减少这样的操作的数量。怎么会？通过使用Django的<code class="fe my mz na nb b">bulk_create</code>方法:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="7ebb" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">这种变化产生了巨大的影响。对于100，000个产品，该命令只需3.5秒即可执行。<strong class="lz iu"> </strong>你需要记住最后一个循环在<code class="fe my mz na nb b">products</code>列表中仍然可以有条目(在我们的例子中少于5000个)。这需要在循环之后处理:</p><pre class="kj kk kl km gt ns nb nt nu aw nv bi"><span id="52d9" class="nw lg it nb b gy nx ny l nz oa">if products:<br/>    Product.objects.bulk_create(products)</span></pre><p id="03da" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">我们共同做出的这三项更改让我们将命令的性能提高了96%以上。代码很重要。好的代码更重要。最后的命令如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="6a2e" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">用上面的代码，30秒就加载了100万个产品！</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="ccd5" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak">专业提示:使用多进程</strong></h1><p id="2075" class="pw-post-body-paragraph lx ly it lz b ma mb ju mc md me jx mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">另一个提高大型CSV加载速度的方法是使用多重处理，我在这里只介绍这个方法。在上面的命令中，您可以将一个大的CSV文件分割成多个较小的文件(最好的方法是尝试使用行索引),并将每批工作放在一个单独的进程下。如果您可以在一台机器上使用多个CPU，那么扩展将是线性的(2个CPU—快2倍，4个CPU—快4倍)。</p><p id="e83a" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">假设您有一百万行要处理。然后，第一个进程可以获取编号为<code class="fe my mz na nb b">0</code>–<code class="fe my mz na nb b">99999</code>的行，第二个进程获取编号为<code class="fe my mz na nb b">100000</code>–<code class="fe my mz na nb b">199999</code>的行，以此类推，直到最后一个进程获取编号为<code class="fe my mz na nb b">900000</code>–<code class="fe my mz na nb b">999999</code>的行。</p><p id="e5f1" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">这里唯一的缺点是你需要有十个空闲的CPU。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="b576" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak">总结</strong></h1><ul class=""><li id="753c" class="ne nf it lz b ma mb md me mg ob mk oc mo od ms nj nk nl nm bi translated">您应该避免将文件加载到内存中。请改用迭代器。</li><li id="6801" class="ne nf it lz b ma nn md no mg np mk nq mo nr ms nj nk nl nm bi translated">如果您正在逐行处理文件，请避免在<code class="fe my mz na nb b">for</code>循环体中查询数据库。</li><li id="c271" class="ne nf it lz b ma nn md no mg np mk nq mo nr ms nj nk nl nm bi translated">不要在每个循环中保存一个元素。使用<code class="fe my mz na nb b">bulk_create</code>方法。</li></ul><p id="9b75" class="pw-post-body-paragraph lx ly it lz b ma mt ju mc md mu jx mf mg mv mi mj mk mw mm mn mo mx mq mr ms im bi translated">感谢阅读！</p></div></div>    
</body>
</html>
# Kubernetes Pod 冗余策略

> 原文：<https://betterprogramming.pub/kubernetes-pod-redundancy-strategies-a6d9b560749a>

## 分布式系统中的故障防范策略

![](img/c478b21d99386e2a31a397e577b12652.png)

米歇尔·格里斯特在 Unsplash[上拍摄的照片。](https://unsplash.com?utm_source=medium&utm_medium=referral)

在分布式系统中，不可避免地会出现一些故障，我们应该像正常情况一样进行规划。这个问题的一个解决方案是运行一个服务的多个实例。这样，如果一个失败，其他人可以接管。

在本文中，我们将探索在 [Kubernetes](https://kubernetes.io/) (K8s)上实现这一点的一些不同方法。

# 没有人

冗余是有成本的，在决定我们需要多大的弹性时，我们应该考虑这一点。如果您的客户可以忍受少量的中断，并且不会对他们的体验产生太大影响，那么您可能不需要任何中断。

当谈到一项服务的正常运行时间时，通常用 9 来表示(例如 99.9%的正常运行时间)。这意味着每 1000 个请求中，只有一个会失败。根据经验，每增加 9 项服务，就要花费 10 倍的成本。

只要您的应用程序不经常崩溃，您就可以运行一个 pod，并在出现问题时依靠 K8s 重新调度它。这确实假设一个 pod 可以处理服务正在接收的负载。

# 普通

当您的服务开始需要更多的 pod 来处理负载时，您可以向外扩展。如果流量情况随时间变化(例如午餐高峰)，您应该有足够的 pod 来处理高峰时间的负载。这种策略只会在 pod 接收的流量明显减少时为您提供更多弹性。

如果一个 pod 在高峰时间出现故障，请求将分散到剩余的 pod 上，并有可能淹没它们。在交通流量较低的时候，剩余的吊舱可能有足够的容量来处理负载。

当谈到缩放时，您可能会听到术语 *in* 、 *out* 、 *up* 和 *down* 。通常，向上和向下扩展意味着保持相同数量的实例，但是增加服务器的 CPU 和/或内存。进出是引入或移除服务实例但保持资源不变的过程。这允许您进一步扩展，因为您可能会受到可以使用的最大 CPU 或内存的限制。

# N + 1

和前面的`n`一样，我们需要了解需要多少个 pod 来处理高峰流量。这一次，我们增加了一个额外的吊舱。这为我们提供了保护，防止一个 pod 在高峰时间出现故障。这种恢复能力的成本是一个 pod 的成本，因为这是额外的，只在故障情况下需要。如果一个单元可以处理所有的流量，您应该还有一个额外的单元。

# 缩放比例

我们可以让 K8s 为我们做这件事，而不是手动计算高峰期我们需要的吊舱数量。给定一个扩展指标，K8s 可以根据当前需求扩展和缩小我们的服务。这通过在需求较低时缩减规模，在我们需要时增加规模来降低成本。扩展本身并不能让我们从 pod 故障中恢复过来，但确实可以应对不断增长的需求。让 pods 在内存和 CPU 方面保持较小，可以让我们更精确地扩展，并进一步削减成本。

有关如何确定何时扩展服务的信息，请查看我关于 K8s 自动扩展的[性能测试的文章。](https://itnext.io/performance-testing-for-kubernetes-autoscaling-ed6418cf6f70)

当扩展服务时，您应该包括一些扩展空间，这意味着您不应该将您的 pod 推到极限。您的 pod 需要一些时间来启动，自动缩放指标会定期计算。您的应用程序需要能够处理请求纵向扩展和实际纵向扩展之间的请求。如果你有很多吊舱，净空会缩小，因为它分散在所有吊舱。

水平 Pod 自动缩放器(HPA)用于自动缩放我们在 K8s 中的服务。关于如何设置的更多信息，请查看[文档](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)。有关哪些指标不适合用于自动缩放的更多信息，请查看本文。

# 75%缩放

一旦我们实现了自动扩展，并且知道何时应该扩展我们的服务，我们就可以控制我们需要多少弹性。通过以 75%的服务容量进行扩展，我们可以失去 25%的 pod，并且只能达到容量。我们拥有的豆荚越多，我们失去的豆荚就越多——但我们为未充分利用的豆荚付出的代价也就越多。当运行大量的 pod 时，您可以考虑降低弹性百分比，因为您仍然有大量的 pod 可能会出现故障。

如果一个服务的流量曲线特别尖锐，这种技术就特别有用。对于自动缩放来说，尖峰可能是一个特别麻烦的问题，因为它们可能非常短暂，以至于自动缩放器没有时间做出反应。如果您大致知道峰值有多大，您可以将它计划到服务扩展的地方。

# 缩放+ N

如果我们想更精确地控制我们的冗余，我们可以扩展容量，然后引入额外的单元。这将允许`n`吊舱失败，但仍然给我们留下足够的容量。这使我们能够准确控制我们支付多少冗余吊舱。

K8s 服务使用标签来决定 pods 的请求被路由到哪个 pods。这允许我们部署具有不同配置的相同服务的两个副本集。一个副本集将使用水平 pod 自动缩放器进行缩放，而我们将配置另一个副本集，使其具有`n`pod。两个副本集将使用相同的标签标记 pod，并且服务将路由到该标签。该服务将在所有单元之间平均分配流量，允许服务扩展，同时保持`n`冗余单元。

# 多个集群

更进一步，我们可以将我们的应用程序部署到两个 K8s 集群上。这将允许整个集群出现故障，但仍能维持服务。负载平衡器将位于集群的前端，并在集群之间路由流量。如果您在云提供商(如 AWS)上托管集群，该集群会自动跨多个可用性区域进行部署。这可以防止物理故障，如断电、自然灾害或更糟的情况，因此需要有一个好的理由来拥有多个集群。

当运行多个集群时，自动扩展变得更具挑战性，因为扩展指标通常不会在集群间共享。如果某个集群确实发生故障，仍在工作的集群将会收到来自故障集群的所有流量，而不会引起任何注意。有多种方法来处理这种负载的突然增加。您的自动伸缩可能能够足够快地做出反应来处理流量，或者您可能会在规模扩大时受到影响并降低性能。

根据需要多少冗余，集群可以以主动-被动模式运行，这意味着一个集群接收所有请求。在这种设置中，服务必须从零开始纵向扩展，除非跨集群共享扩展指标。

# 数量与冗余

你拥有的吊舱越多，一个吊舱的故障对其他吊舱的影响就越小。假设我们有 10 个可以服务 100 个 rps 的 pod。如果我们以 90rps 的速度扩展，并且一个 pod 出现故障，剩余的 pod 将收到 100rps，使它们达到最大值。如果我们有 20 个吊舱，其中一个出现故障，剩下的吊舱将只需要处理 95 个 rps。这两种场景都假设服务接收的请求数量正好是服务应该扩展的数量。实际上，如果服务试图扩大规模，服务通常会收到稍少或稍多的流量。

# 结论

自动缩放是一件复杂的事情，有很多选项需要考虑。我希望您能更好地了解您可用的选项，并利用这些选项来降低您的云账单成本，同时保持服务正常运行。

感谢阅读！
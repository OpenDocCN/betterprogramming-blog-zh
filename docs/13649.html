<html>
<head>
<title>How to Export a Full History of Ethereum Blockchain to S3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将以太坊区块链的完整历史输出到S3</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/how-to-dump-full-ethereum-history-to-s3-296fb3ad175?source=collection_archive---------3-----------------------#2022-09-14">https://betterprogramming.pub/how-to-dump-full-ethereum-history-to-s3-296fb3ad175?source=collection_archive---------3-----------------------#2022-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="16f9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用公共以太坊节点或公共BigQuery数据集</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c6e8061d280d2049a0d96960fc80fcbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QQBY7-XnazoPyCnE"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的GuerrillaBuzz Crypto PR拍摄</p></figure><p id="f92d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你来这里只是为了一个简单的指南，这里有一些主要的要点:</p><ul class=""><li id="dbf7" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">理想情况下，运行自己的节点</strong>。以太坊节点的实现有很好的同步设施，所以让节点先和一个区块链同步，然后通过一个IPC接口使用JSON RPC API直接从节点卸载数据。</li><li id="4803" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">或者，使用<a class="ae kv" href="https://ethereumnodes.com/" rel="noopener ugc nofollow" target="_blank">一个公共节点提供者</a>。它们中的大多数不需要任何身份验证，因此请求将像<code class="fe mg mh mi mj b">curl -XPOST <a class="ae kv" href="https://cloudflare-eth.com/" rel="noopener ugc nofollow" target="_blank">https://cloudflare-eth.com/</a> -d '{"method":"eth_blockNumber", "params": [], "id": 1, "jsonrpc": "2.0"}'</code>一样简单</li><li id="0d51" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">遵循KISS(“保持简单，愚蠢”)原则:<strong class="ky ir">简单地从0到<code class="fe mg mh mi mj b">eth.block_number</code>(当前最新块)循环通过块</strong>。首先，取出<code class="fe mg mh mi mj b">hydrated</code>参数设置为<code class="fe mg mh mi mj b">true</code>的块。这将包括块响应中的交易数据。如果你需要日志(比如提取ERC-20 <code class="fe mg mh mi mj b">Transfer</code>事件)，也要获取收据(每笔交易一张)。收据包括日志。<br/>基本管道相当简单:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/13acdaf48c8d08756b9a81a641010e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*Qqdwju7e3AbFkSUhFyJiQA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从以太坊节点到面向客户的DynamoDB表的批处理和实时获取</p></figure><ul class=""><li id="36f4" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">使用批处理请求</strong>:将一组请求作为有效负载发送给JSON RPC API。例子:<code class="fe mg mh mi mj b">[{"method":"eth_getBlockByNumber","params":["0x1",true],…},{"method":…},…]</code>。在批量响应中，您将获得一系列单独的响应。重要提示:规格不能保证响应<strong class="ky ir">顺序</strong>。</li><li id="fa8f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">并行化批处理请求:<strong class="ky ir">运行异步或多线程</strong>。</li><li id="eeec" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">作为最佳数据工程实践:转储原始数据而不进行转换(以JSON这样的原始格式)。例如，您可以将其存储在S3(块+交易+收据+日志现在总计约为4.5TB)。这将允许您基于整个历史重新运行任何计算，而无需再次接触JSON RPC API。</li><li id="53f0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用这些方法的组合没有花费我们任何额外的成本(除了EC2实例的几个小时),并且花费了<strong class="ky ir"> 10天来导出</strong>完整的历史。在S3托管一个未压缩的JSON数据集每月花费110美元。</li><li id="d8d2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">为了快速初始化您的数据湖，您可以使用<a class="ae kv" href="https://console.cloud.google.com/bigquery(cameo:product/ethereum/crypto-ethereum-blockchain)" rel="noopener ugc nofollow" target="_blank">公共BigQuery数据集和以太坊数据</a>。这种方法花费了我们大约100美元，并且花费了大约<strong class="ky ir"> 24小时来导出</strong>数据块、交易和令牌传输数据集。</li></ul><p id="c137" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的其余部分将详细介绍上述内容。</p><p id="11e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">🎞更喜欢看视频？在YouTube上观看我的演讲，获得这篇文章的快速摘要。或者看<a class="ae kv" href="https://medium.com/@bryzgaloff/ethereum-data-analysis-and-integration-youtube-talk-transcription-3a9b45c7ed2f" rel="noopener">我的转录</a>看带幻灯片的视频。或者甚至是一个超级简短的摘要(2分钟阅读)<a class="ae kv" href="https://blockchain.works-hub.com/learn/how-to-export-a-full-ethereum-history-into-s3-efficiently-f37df" rel="noopener ugc nofollow" target="_blank">在这里可以得到</a>。</p><h1 id="5310" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">里面是什么？</h1><p id="bbf1" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">下面是这篇文章的简要计划:</p><ul class=""><li id="2dc6" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">目标和需求:为什么我们决定导出这些数据？</li><li id="c513" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">从BigQuery公共数据集中导出数据:这是个好主意吗？如何高效的做到？这要花多少钱？</li><li id="9a87" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">天真的方法——从一个节点获取以太坊数据:完全同步需要多长时间？托管结果数据集的成本是多少？</li><li id="a926" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">低延迟服务令牌平衡:如何实现？如何在Athena中处理uint256？</li><li id="b517" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">正在进行的以太坊更新:实时获取最近的块。</li><li id="361e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们的方法的架构的当前状态，带有图表可视化。</li></ul><h1 id="6d27" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">为什么我们需要区块链以太坊的全部历史？</h1><p id="93aa" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">在CoinStats.app中，我们构建了一个高级加密组合管理器。除了余额跟踪和交易列表等标准功能，我们还帮助用户搜索新的代币进行投资。</p><p id="8500" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，代币余额跟踪仍然是我们的核心功能。最初，我们一直依赖各种第三方服务。但是他们有几个缺点:</p><ul class=""><li id="a54f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">往往不准确/不完整，</li><li id="4b3d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">从最近的街区落后很多，</li><li id="3c4b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">和/或不允许在单个请求中检索钱包的所有代币余额。</li></ul><p id="3d63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总的来说，这导致了以下一组要求:</p><ul class=""><li id="bc2d" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">该解决方案必须尽可能少地滞后于区块链</li><li id="2a35" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">提供100%精确的天平</li><li id="acac" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">并返回一个完整的钱包组合在一个单一的回应</li><li id="b384" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">此外，为了进一步扩展我们基于分析的产品功能，该解决方案必须在区块链数据的基础上提供SQL接口</li><li id="6a72" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们不能运行自己的以太坊节点。</li></ul><p id="af41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">是的，我知道，最后一个要求是有争议的。但是，我加入的团队已经有过维护一个节点的不愉快经历。他们坚持使用节点提供商。所以，现在让我们把它当作一个不可协商的要求。</p><p id="3af3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总的来说，我们的目标是(1)将区块链交易和收据的完整历史导出到低成本存储(AWS S3)，(2)附加一个SQL引擎(AWS Athena)，以及(3)在<em class="ni">实时</em>应用中使用它，如余额跟踪。</p><h1 id="00dd" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">现有解决方案</h1><p id="51a0" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">我们希望加快新数据平台MVP版本的发布，因此我们决定寻找现有的解决方案。现在最耀眼的是<a class="ae kv" href="https://github.com/blockchain-etl/ethereum-etl" rel="noopener ugc nofollow" target="_blank">以太坊ETL </a>。它是一个开源(托管在GitHub上)工具集，用于导出区块链数据(主要是以太坊)。</p><p id="0718" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，<code class="fe mg mh mi mj b">ethereum-etl</code> repository是一个更大的<a class="ae kv" href="https://github.com/blockchain-etl/" rel="noopener ugc nofollow" target="_blank">区块链ETL </a>的核心部分——一系列将区块链数据导出到各种数据目的地的解决方案，从<a class="ae kv" href="http://ethereum-etl-postgres" rel="noopener ugc nofollow" target="_blank"> Postgres </a>到<a class="ae kv" href="https://github.com/blockchain-etl/bigquery-to-pubsub" rel="noopener ugc nofollow" target="_blank"> BigQuery和PubSub+Dataflow </a>。甚至有一个特殊的库<a class="ae kv" href="https://github.com/blockchain-etl/ethereum-etl-airflow" rel="noopener ugc nofollow" target="_blank">使所有的脚本适应气流Dag。</a></p><p id="346d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个令人惊讶的事实是，Google <a class="ae kv" href="https://github.com/blockchain-etl/public-datasets" rel="noopener ugc nofollow" target="_blank">托管着具有完整以太坊历史的公共BigQuery数据集</a>，这些数据集是使用以太坊ETL项目收集的。在BigQuery控制台上亲自查看它们<a class="ae kv" href="https://console.cloud.google.com/bigquery(cameo:product/ethereum/crypto-ethereum-blockchain)" rel="noopener ugc nofollow" target="_blank">。重要提示:即使数据集是公开的，你(作为谷歌云用户)也要为查询它们付费。所以，如果你不想破产，就不要做<code class="fe mg mh mi mj b">SELECT *</code>😅</a></p><p id="7137" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，以太坊ETL有一些缺点:</p><ul class=""><li id="533b" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">它是高度面向谷歌云的。存储库对AWS有一些支持，但是它们看起来维护得很差。我贡献的动力支持已经过期几个月了。而对于数据相关的项目，我更喜欢AWS。</li><li id="5974" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">解决方案在创作的时候用文章(<a class="ae kv" href="https://evgemedvedev.medium.com/exporting-and-analyzing-ethereum-blockchain-f5353414a94e" rel="noopener">一个</a>、<a class="ae kv" href="https://cloud.google.com/blog/products/data-analytics/ethereum-bigquery-how-we-built-dataset" rel="noopener ugc nofollow" target="_blank">两个</a>、<a class="ae kv" href="https://medium.com/coinmonks/how-to-export-the-entire-ethereum-blockchain-to-csv-in-2-hours-for-10-69fef511e9a2" rel="noopener">三个</a>、…)覆盖的很好，现在看起来很过时。Airflow版本非常旧，数据模式(尤其是AWS Athena)与实际的导出格式不同步。</li><li id="989d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">以太坊ETL不保留数据的原始格式。它在摄取时进行了太多的转换。因此，它是一个ETL(提取-转换-加载)解决方案，而现代的方法是ELT(提取-加载-转换)。CoinStats.app用于最佳实践</li></ul><h1 id="1e9e" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">我们是如何开始的:将BigQuery卸载到S3</h1><p id="d6d7" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">反正以太坊ETL已经为我们自己主动打下了很好的基础。通过请求public node的JSON RPC API天真地获取原始数据需要一个多星期才能完成。因此，我们决定使用BigQuery来初始化我们的S3存储桶。</p><p id="8460" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简而言之，我们将执行以下步骤:将BigQuery表导出到Google云存储(gzipped Parquet格式)，使用<code class="fe mg mh mi mj b">gsutil rsync</code>将其复制到S3，然后在Athena中查询这些数据。</p><p id="f3d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面你会找到如何做到这一点的详细说明。</p><h2 id="bf45" class="nj mm iq bd mn nk nl dn mr nm nn dp mv lf no np mx lj nq nr mz ln ns nt nb nu bi translated">1.在BigQuery上发现公共以太坊数据集</h2><p id="a62d" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">在谷歌云平台打开<a class="ae kv" href="https://console.cloud.google.com/bigquery" rel="noopener ugc nofollow" target="_blank"> BigQuery控制台。在数据集搜索字段(左侧)中输入<code class="fe mg mh mi mj b">crypto_ethereum</code>或<code class="fe mg mh mi mj b">bigquery-public-data</code>，然后点击“扩大搜索范围”。</a></p><p id="838f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ❕你必须有一个付费的GCP账户</strong>(配置了账单明细)才能发现公共数据集:否则搜索结果将是空的。您<em class="ni">尚未支付任何费用</em>，但是如果没有配置好的账单，您将一无所获。</p><p id="c298" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了进一步方便导航，我建议您找到后锁定<code class="fe mg mh mi mj b">bigquery-public-data</code>项目。</p><h2 id="8071" class="nj mm iq bd mn nk nl dn mr nm nn dp mv lf no np mx lj nq nr mz ln ns nt nb nu bi translated">2.将表格导出到Google云存储</h2><p id="b727" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">选择任意表格，例如<code class="fe mg mh mi mj b">blocks</code>。要导出完整的表格，请单击右上角的“导出”并选择“导出到GCS”。</p><p id="84a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以导出特定查询的结果，而不是导出整个表:每个查询都会生成一个新的临时表(显示在底部“个人历史”中的作业详细信息中)。执行后，单击作业详细信息中的临时表名，并将其导出为普通表。这对于过滤掉大型表格中的一些不必要的数据非常有用(例如<code class="fe mg mh mi mj b">logs</code>或<code class="fe mg mh mi mj b">traces</code>)。不要忘记在查询设置中选中“允许大结果”。否则，您将只能看到数据样本(≈128MB)。</p><p id="3846" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注意</strong>:如果你<em class="ni">在一个公共数据集上运行一个查询</em>，那么<em class="ni">你</em>作为一个GCP用户为其付费(参见<a class="ae kv" href="https://cloud.google.com/bigquery/pricing#on_demand_pricing" rel="noopener ugc nofollow" target="_blank"> BQ分析定价</a>)。导出一个完整的表格是免费的(详见下文)。</p><p id="a0eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于导出，选择任何GCS位置。随意使用默认设置创建一个新的bucket(标准存储对于我们的用例来说是最便宜的)。您可以在数据复制到S3后立即删除该时段(这是下一步)。</p><p id="ec57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">唯一重要的GCS配置选项是region:“选择与您的目标S3存储桶相同的区域”。在这种情况下，你的转移成本和速度将是最佳的。</p><p id="cf93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe mg mh mi mj b">Export format = Parquet. Compression = GZIP</code> <strong class="ky ir">。</strong>这种组合提供了最佳的压缩率，因此它将加速从GCS到S3的数据传输。</p><p id="29b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">⏱通常，这项工作在<strong class="ky ir"> ≈30秒</strong>内完成(参见底部“个人历史”中的工作进度)。</p><p id="57d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导出作业每天免费高达50TB(参见<a class="ae kv" href="https://cloud.google.com/bigquery/pricing" rel="noopener ugc nofollow" target="_blank"> BQ定价</a>)，而总<code class="fe mg mh mi mj b">crypto_ethereum</code>大小为&lt; 10TB。</p><p id="0541" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您只需为廉价的GCS存储每月支付0.02美元。数据是压缩的(<code class="fe mg mh mi mj b">blocks</code>截至2022年8月约为65 GB)，存储时间不会超过几天，因此<strong class="ky ir">这将花费你&lt; $5 </strong>。</p><h2 id="8870" class="nj mm iq bd mn nk nl dn mr nm nn dp mv lf no np mx lj nq nr mz ln ns nt nb nu bi translated">3.将数据从GCS复制到S3</h2><p id="56fb" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">一旦BQ导出作业完成，您可以将数据导出到S3。这可以使用方便的CLI实用程序<code class="fe mg mh mi mj b"><a class="ae kv" href="https://cloud.google.com/storage/docs/gsutil" rel="noopener ugc nofollow" target="_blank">gsutil</a></code>来完成。要设置它:</p><ol class=""><li id="f063" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nv ly lz ma bi translated">创建一个EC2实例。选择实例大小时，考虑<a class="ae kv" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-network-bandwidth.html" rel="noopener ugc nofollow" target="_blank"> EC2网络吞吐量限制</a>。理想情况下，<strong class="ky ir">选择与GCS和S3存储桶相同的区域</strong>。</li><li id="d345" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated"><a class="ae kv" href="https://cloud.google.com/storage/docs/gsutil_install" rel="noopener ugc nofollow" target="_blank">遵循<code class="fe mg mh mi mj b">gsutil</code>的安装说明</a>。</li><li id="f644" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">运行<code class="fe mg mh mi mj b">gsutil init</code>来配置GCS凭证。</li><li id="9fba" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">用AWS凭证填充<code class="fe mg mh mi mj b">~/.boto</code>配置文件:只需将<code class="fe mg mh mi mj b">aws_access_key_id </code>和<code class="fe mg mh mi mj b">aws_secret_access_key</code>设置为适当的值。对于AWS，拥有S3多部分上传和列表桶权限的用户就足够了。当然，为了简单起见，您可以使用您的个人AWS密钥，但我不应该告诉您…相关文档:<a class="ae kv" href="https://cloud.google.com/storage/docs/boto-gsutil#config-file-structure" rel="noopener ugc nofollow" target="_blank"> Boto配置参考</a>，<a class="ae kv" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html" rel="noopener ugc nofollow" target="_blank">管理IAM访问密钥</a>。</li><li id="84dc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">如果还没有，创建一个S3存储桶。为了加速传输，你必须<strong class="ky ir">在与GCS桶</strong>相同的区域创建S3桶。</li><li id="5bba" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">要复制文件，请使用<code class="fe mg mh mi mj b">gsutil rsync -m</code>。<code class="fe mg mh mi mj b">-m</code>选项通过在多线程模式下运行传输作业来实现传输作业的并行化。</li></ol><p id="f672" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用单个<code class="fe mg mh mi mj b">m5a.xlarge</code> EC2实例来传输数据。这不是最佳方式:EC2有<a class="ae kv" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-network-bandwidth.html" rel="noopener ugc nofollow" target="_blank">带宽限制</a>和难以预测的“突发”网络吞吐量。我们已经考虑过使用AWS数据同步服务的<a class="ae kv" href="https://aws.amazon.com/ru/blogs/storage/migrating-google-cloud-storage-to-amazon-s3-using-aws-datasync/" rel="noopener ugc nofollow" target="_blank">:然而，它也依赖EC2虚拟机(你必须自己部署一个代理)，所以我不期望与<code class="fe mg mh mi mj b">gsutil rsync</code>相比有很大的好处，除非你选择一个更大的实例。</a></p><p id="bb5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对我们来说，<strong class="ky ir">从Google云存储中以gzipped Parquet格式导出块、事务和日志数据集花了大约24个小时。</strong></p><p id="ca77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个阶段<strong class="ky ir">你将支付</strong>:</p><ul class=""><li id="ed73" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" href="https://cloud.google.com/storage/pricing#network-egress" rel="noopener ugc nofollow" target="_blank"> GCS网络出口</a>(到GCS外部)。我们总共花了大约100美元买了几个压缩数据集。</li><li id="9e72" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://aws.amazon.com/s3/pricing/" rel="noopener ugc nofollow" target="_blank"> S3存储</a>:压缩数据集每月占用&lt; 1TB的数据总量≈20美元。</li><li id="6651" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://aws.amazon.com/s3/pricing/" rel="noopener ugc nofollow" target="_blank"> S3把作战</a>。导出的事务数据集包含8k个对象，因此结果总计为0.05美元。</li><li id="2c0b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://cloud.google.com/storage/pricing#process-pricing" rel="noopener ugc nofollow" target="_blank"> GCS数据检索操作</a>≈0.01美元。</li><li id="5ca5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">显然，<a class="ae kv" href="https://aws.amazon.com/ec2/pricing/on-demand/" rel="noopener ugc nofollow" target="_blank">小时的EC2实例</a>是用来传输数据的。</li><li id="e706" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">你还需要支付将数据临时存储在GCS 中的费用<a class="ae kv" href="https://cloud.google.com/storage/pricing#price-tables" rel="noopener ugc nofollow" target="_blank">，但是与上面的费用相比，这是非常便宜的:&lt;1美元。</a></li></ul><h2 id="9da3" class="nj mm iq bd mn nk nl dn mr nm nn dp mv lf no np mx lj nq nr mz ln ns nt nb nu bi translated">4.使用Athena使数据可进行SQL查询</h2><p id="bb35" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">一旦数据到达S3，您可以使用<a class="ae kv" href="https://aws.amazon.com/athena/" rel="noopener ugc nofollow" target="_blank"> AWS Athena </a>在其上附加一个SQL引擎。你可以在这里找到我最近更新的模式。</p><p id="0af2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最初，导出的数据没有在S3上进行分区，因此您必须创建一个指向导出数据的非分区表。然后，我建议您按月对数据集进行分区:Athena不能一次写入100个以上的分区，因此每日分区将需要额外的工作。每月分区查询将会非常简单:</p><pre class="kg kh ki kj gt nw mj nx ny aw nz bi"><span id="9a39" class="nj mm iq mj b gy oa ob l oc od">INSERT INTO partitioned SELECT *, date_trunc('month', block_timestamp) FROM nonpartitioned</span></pre><p id="80a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Athena中，您需要为扫描的数据量付费。所以，现在<strong class="ky ir">你不会有任何损失</strong>。</p><p id="626f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您可以在导出的数据上运行SQL查询。例如，我们用它来计算每个钱包的代币余额…</p><p id="609f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">…但是基于BQ数据集的<strong class="ky ir">计算似乎不完整！</strong>🤯原因是<code class="fe mg mh mi mj b">bigquery-public-data.crypto_ethereum.token_transfer</code>表仅包含ERC-20/ERC-721 <code class="fe mg mh mi mj b">Transfer</code>事件，但是也需要一些其他事件(例如<code class="fe mg mh mi mj b">Deposit</code>)的完整视图。</p><p id="fe79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们已经切换到另一种导出方法——从一个公共以太坊节点获取完整的原始历史。</p><h1 id="85cb" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">我们从以太坊节点获取数据</h1><p id="0803" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">与使用Ethereum ETL公共数据集相比，这种方法有一个显著的优势:数据从一个节点按原样导出。我们可以以原始格式存储它，并无限制地进一步重用它，甚至模仿以太坊节点“离线”响应。</p><p id="86d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">⏱然而，以这种方式获取数据需要<em class="ni">更长的时间</em>。在带有<a class="ae kv" href="https://github.com/blockchain-etl/ethereum-etl/blob/develop/ethereumetl/providers/rpc.py" rel="noopener ugc nofollow" target="_blank">批处理请求</a>的多线程模式(16个内核上的20个线程)下，导出全部历史并将其存储到S3总共需要大约10天时间。</p><p id="153f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一些开销来自每天管理该导出的气流。对于块范围计算，使用了<a class="ae kv" href="https://github.com/blockchain-etl/ethereum-etl/blob/be1892dffa54a83c130a950bf7aa6986e25a28be/ethereumetl/cli/get_block_range_for_date.py#L46" rel="noopener ugc nofollow" target="_blank">以太坊ETL函数</a> <code class="fe mg mh mi mj b">get_block_range_for_date</code>。</p><p id="369b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用了带有回退机制的<a class="ae kv" href="https://ethereumnodes.com/" rel="noopener ugc nofollow" target="_blank">公共节点</a>，在失败的情况下一个接一个地请求提供者。</p><p id="6424" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">💰生成的原始数据集(包含交易的块+包含日志的收据，作为未压缩的JSON，具有<a class="ae kv" href="https://docs.python.org/3/library/json.html#json.JSONEncoder" rel="noopener ugc nofollow" target="_blank">非压缩</a> <code class="fe mg mh mi mj b"><a class="ae kv" href="https://docs.python.org/3/library/json.html#json.JSONEncoder" rel="noopener ugc nofollow" target="_blank">separators</a>=(', ', ': ')</code>)的总大小约为4.5 TB，这<strong class="ky ir">每月花费我们110美元</strong>。</p><p id="a984" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了降低成本，您可以使用GZIP压缩将数据集重新格式化为拼花格式:这是最佳选择。这将节省存储和Athena查询成本。</p><p id="e607" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速提示:大多数节点提供程序在批处理模式下允许多达1000个请求，但事实上，当请求超过200个带有水合事务的块(<code class="fe mg mh mi mj b">eth_getBlockByNumber</code>)时，它们就会超时。因此，将批量大小限制为块200，收据1000(后者几乎不会超时)。</p><h1 id="b0c2" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">导入到DynamoDB</h1><p id="25be" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">作为一个web应用程序，CoinStats.app需要一个低延迟且经济高效的存储来检索个人钱包的余额。雅典娜和S3不是这项工作的合适工具，这就是为什么需要一个OLTP数据库。我们使用DynamoDB，它允许我们快速构建原型。</p><p id="4e46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">⚡️幸运的是，AWS最近引入了一个很棒的特性:<a class="ae kv" href="https://aws.amazon.com/ru/blogs/database/amazon-dynamodb-can-now-import-amazon-s3-data-into-a-new-table/" rel="noopener ugc nofollow" target="_blank"> DynamoDB表现在可以从S3导入</a>！这允许您创建一个新表，并最初用来自S3的数据填充它。</p><p id="b4dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">💰使用这个，你只需为从S3插入的<em class="ni">未压缩的</em>数据量付费。我们的余额数据集为28.5 GB，导出<strong class="ky ir">的成本为&lt;5美元</strong>。文件没有提到任何与S3相关的额外费用。</p><p id="8570" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">⏱该操作的执行速度非常快:30GB的数据集在3小时内导入<strong class="ky ir">。</strong></p><p id="c9cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相比之下:一个简单的方法，通过批量<code class="fe mg mh mi mj b">PutItem</code>呼叫和3K wcu的配置容量，我们花了21个小时才完成。由于EC2实例吞吐量限制，更高的写入容量未得到充分利用。并行化是一种选择，但需要不必要的额外努力。</p><p id="71f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">表导入功能的另一个显著优点是它不会消耗DynamoDB表的写容量！因此，您可以创建一个按需表，最初用来自S3的大量数据填充。</p><h2 id="efe8" class="nj mm iq bd mn nk nl dn mr nm nn dp mv lf no np mx lj nq nr mz ln ns nt nb nu bi translated">天平计算:挑战</h2><p id="65a0" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">你可能想知道:如果令牌转移值类型是<code class="fe mg mh mi mj b">uint256</code>，Athena本身不支持，我们如何计算令牌余额？</p><p id="7251" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Athena数字类型受十进制数的限制，十进制数最多可表示128字节的数字。为了克服这个限制，我在Athena中实现了长运算。细节值得另文讨论，但简单来说，方法就像这样简单:</p><ol class=""><li id="1953" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nv ly lz ma bi translated">将一个传输的十六进制值拆分成几部分:<code class="fe mg mh mi mj b">regexp_extract_all(reverse(value), ‘.{1,8}’)</code>。<code class="fe mg mh mi mj b">uint256</code>值表示为64个十六进制字符，因此该提取产生8个部分，每个部分表示一个<code class="fe mg mh mi mj b">uint32</code>数字。这些数字将是我们的长算术“数字”。</li><li id="ae82" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">解析各部分:<code class="fe mg mh mi mj b">from_base(reverse(digit), 16)</code>。</li><li id="a407" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">每个数字单独求和:<code class="fe mg mh mi mj b">SELECT ARRAY[SUM(digits[0]), SUM(digits[1]), …]</code>。</li><li id="12ac" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nv ly lz ma bi translated">将数字归一化为余数:<code class="fe mg mh mi mj b">SELECT ARRAY[sums[0] % uint32, sums[1] % uint32 + sums[0] // uint32, …]</code>。对每个数字重复此操作。</li></ol><p id="913b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行<code class="fe mg mh mi mj b">SUM(digits[*])</code>整体来看，历史可能会溢出雅典娜的类型。为了避免这种情况，我建议你每月累计计算余额<em class="ni"/>。</p><p id="2c0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">⏱从最开始(2015年7月)到现在(2022年8月)<strong class="ky ir">用这种方法计算余额需要2分钟</strong>。</p><p id="ac1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">💰我们使用压缩的Parquet数据集进行历史余额计算，因此查询执行(=使用Athena读取完整历史)花费了我们<strong class="ky ir">大约0.65美元</strong>。</p><p id="d0e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你熟悉Java，你会更喜欢用<a class="ae kv" href="https://docs.aws.amazon.com/athena/latest/ug/querying-udf.html#udf-creating-and-deploying" rel="noopener ugc nofollow" target="_blank">的雅典娜UDF功能</a>进行这种操作，因为Java <a class="ae kv" href="https://docs.oracle.com/javase/7/docs/api/java/math/BigInteger.html" rel="noopener ugc nofollow" target="_blank">有一个内置的</a> <code class="fe mg mh mi mj b"><a class="ae kv" href="https://docs.oracle.com/javase/7/docs/api/java/math/BigInteger.html" rel="noopener ugc nofollow" target="_blank">BigInteger</a></code> <a class="ae kv" href="https://docs.oracle.com/javase/7/docs/api/java/math/BigInteger.html" rel="noopener ugc nofollow" target="_blank">类</a>。Athena UDFs不支持其他语言。</p><h2 id="69ca" class="nj mm iq bd mn nk nl dn mr nm nn dp mv lf no np mx lj nq nr mz ln ns nt nb nu bi translated">转换为导入格式</h2><p id="b3c2" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">将数据上传到DynamoDB之前的最后一步是转换成一种<a class="ae kv" href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/S3DataImport.Format.html" rel="noopener ugc nofollow" target="_blank">支持的导入格式</a>。我们也决定使用Athena进行这种转换，并尝试了所有三种格式，但都有缺点:</p><ul class=""><li id="63d0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">CSV是最简单的选项，但是不支持数字类型:所有非键属性都作为字符串导入。</li><li id="2420" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">DynamoDB JSON格式需要显式的属性类型:例如，一个数值字段被表示为<code class="fe mg mh mi mj b">{"field_name": {"N": "1234"}}</code>。</li><li id="c5ad" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">Ion和DynamoDB都区分大小写，而Athena将所有字段名小写。</li></ul><p id="7eea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有趣的事情，但我已经完成了一个<code class="fe mg mh mi mj b">ROW FORMAT DELIMITED</code>(又名CSV)雅典娜表，但模仿DynamoDB JSON格式使用字符串连接:</p><pre class="kg kh ki kj gt nw mj nx ny aw nz bi"><span id="39a9" class="nj mm iq mj b gy oa ob l oc od">'{"Item": {"wallet": "' || wallet || '", …}}' as csv_field</span></pre><p id="4ddf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这工作得很好！</p><h1 id="7d94" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">流式传输部分:实时获取块</h1><p id="ba4a" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">DynamoDB表导入功能的唯一限制(<a class="ae kv" href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/S3DataImport.Validation.html" rel="noopener ugc nofollow" target="_blank">除了标准配额</a>)是它只能填充一个新创建的<em class="ni">表。不能以这种方式覆盖现有的表。</em></p><p id="6f65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，这非常适合我们的用例:我们使用Athena基于<em class="ni">完整历史</em>计算余额，将它们上传到一个新的DynamoDB表，然后继续获取<em class="ni">最近的</em>块以就地更新DynamoDB余额表。</p><p id="9bc8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最新的部分非常简单:我们轮询以太坊节点以获取最新的块号，当新的块出现时，我们使用<code class="fe mg mh mi mj b">eth_getBlockByNumber</code>获取它们。与我们获取历史数据时的方式相同，但是是连续的，并且是随着新数据块的出现。</p><p id="98a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更好的方法是使用<code class="fe mg mh mi mj b"><a class="ae kv" href="https://geth.ethereum.org/docs/rpc/pubsub" rel="noopener ugc nofollow" target="_blank">eth_subscribe</a></code> <a class="ae kv" href="https://geth.ethereum.org/docs/rpc/pubsub" rel="noopener ugc nofollow" target="_blank">方法</a>，但是轮询只是一种更简单的方法。</p><h1 id="4246" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">结论</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/6dfc3574fde502a958a3ec76008895bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P5hHsWpM37TAqu9baJ4Zlg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">整体架构:从以太坊节点到DynamoDB平衡表</p></figure><p id="1465" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有:</p><ul class=""><li id="668a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">一个气流管理的数据管道，每天导出新的以太坊块(包含交易)和收据(包含日志)。</li><li id="e209" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用Athena解析原始JSON数据。</li><li id="5821" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">然后，数据被重新格式化为拼花格式，以便进行更便宜的扫描。</li><li id="f9b3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">这使我们可以在大约2分钟内轻松地重新计算代币的余额和交易历史，并且只需0.65美元。</li><li id="6654" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在管道的最后，我们还可以手动触发一个数据导入作业到DynamoDB中。为此，首先，我们使用Athena将输出数据重新格式化为DynamoDB JSON，然后我们调用AWS API从tokens balances数据集创建一个新的DynamoDB表。</li><li id="a50c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一旦一个新表被部署到DynamoDB，我们就给它“附加”一个脚本，该脚本将新块更新直接传输到该表。</li></ul><p id="7946" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法允许我们将完整的以太坊块和日志数据集保持在每月100美元，以0.65美元的价格从头开始重新计算令牌余额，在3小时内部署一个具有新余额计算的DynamoDB表，并将新块处理延迟减少到主要概念的&lt;1 second.</p><p id="4075" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Thank you for reading!</p><pre class="kg kh ki kj gt nw mj nx ny aw nz bi"><span id="adac" class="nj mm iq mj b gy oa ob l oc od"><strong class="mj ir">Want to discuss further or even hire me?</strong></span><span id="4dbd" class="nj mm iq mj b gy of ob l oc od">Drop me a direct message through <a class="ae kv" href="https://www.linkedin.com/in/bryzgaloff/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> or <a class="ae kv" href="https://t.me/bryzgaloff" rel="noopener ugc nofollow" target="_blank">Telegram</a>, and I will be happy to reply!</span></pre><p id="2602" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">To better grasp the knowledge and browse this article in other formats:</p><ul class=""><li id="a525" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">A <a class="ae kv" href="https://blockchain.works-hub.com/learn/how-to-export-a-full-ethereum-history-into-s3-efficiently-f37df" rel="noopener ugc nofollow" target="_blank">简短摘要</a>(2分钟阅读)。对你以后回忆很有用。</li><li id="2d84" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=MtBakcKJUCQ" rel="noopener ugc nofollow" target="_blank">我在YouTube上的演讲</a>是基于这篇文章:幻灯片和演讲，为了更好地澄清，增加了一些额外的细节。</li><li id="f3ec" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我为YouTube演讲准备的带幻灯片的<a class="ae kv" href="https://medium.com/@bryzgaloff/ethereum-data-analysis-and-integration-youtube-talk-transcription-3a9b45c7ed2f" rel="noopener">文稿。</a></li></ul></div></div>    
</body>
</html>
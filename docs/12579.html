<html>
<head>
<title>Create a Truly Immersive Metaverse Experience Through Spatial Sound Effects</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过空间音效创造真正身临其境的元宇宙体验</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/create-a-truly-immersive-metaverse-experience-through-web3-sound-effects-c6c3645e27fa?source=collection_archive---------18-----------------------#2022-06-14">https://betterprogramming.pub/create-a-truly-immersive-metaverse-experience-through-web3-sound-effects-c6c3645e27fa?source=collection_archive---------18-----------------------#2022-06-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dbb2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用<code class="fe kf kg kh ki b">AudioListener</code>和<code class="fe kf kg kh ki b">PannerNode</code>接口实现空间音频效果(声音在听者头部周围移动)。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ko"><img src="../Images/98542d6a5ec2c73f6a59ea5b27a1f62d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*8ZqM82qy042mY3Hk72IDMA.jpeg"/></div></figure><p id="04f2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">随着元宇宙和3D游戏(如《皇家战役》)的兴起，对虚拟环境中沉浸式音频体验的需求正在快速增长。空间音频是一种允许用户在虚拟场景中感知周围声源的位置和距离的技术，它正迅速成为创建沉浸式虚拟体验的重要组成部分。</p><p id="dd9d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了应对这种快速增长的沉浸式音频体验需求，我们在ZEGOCLOUD Express Web SDK(从v2.10.0开始)中添加了一个<strong class="kt ir">接近语音</strong>模块，该模块提供以下功能:</p><ul class=""><li id="32fe" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm ls lt lu lv bi translated"><strong class="kt ir">邻近语音聊天</strong>:虚拟空间聊天中的一种语音聊天形式，用户只能听到一定邻近范围内其他用户的声音，声音的音量根据听者与声源的距离而变化。</li><li id="2fd4" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><strong class="kt ir">空间音频</strong>:虚拟空间中的用户可以像在现实世界中听到声音一样，感知到声源的位置和距离。</li><li id="b5ac" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><strong class="kt ir">团队语音聊天</strong>:用户可以加入一个团队，随心所欲地在<strong class="kt ir">团队专用</strong>模式(用户的语音只能被同一团队的其他用户听到)和<strong class="kt ir">所有人</strong>模式(用户的语音可以被房间里的所有人听到)之间切换。</li></ul><p id="e94b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本文中，我们将重点讨论如何使用web浏览器提供的Web音频API来实现空间音频效果。这是一个简单的<a class="ae mb" href="https://keen_wang.gitee.io/demo/music3d_en" rel="noopener ugc nofollow" target="_blank">空间音频演示页面</a>我们使用网络音频API制作的。</p><ul class=""><li id="49bb" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm ls lt lu lv bi translated">点击<strong class="kt ir">播放</strong>按钮开始播放音乐。</li><li id="29bd" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated">点击<strong class="kt ir">打开/关闭空间音频</strong>按钮，打开或关闭空间音频效果。</li><li id="71c4" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated">当打开空间音效时，你可以听到音乐在你的头部周围移动。</li></ul><p id="ce1a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">(要体验空间音效，您需要使用立体声耳机或扬声器。)</p><p id="eacf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好吧。让我们深入了解更多细节。</p><h2 id="793d" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">网络音频API简介</h2><p id="bc81" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">Web音频API可用于许多不同的音频操作。例如，它经常被用来代替<code class="fe kf kg kh ki b">&lt;audio&gt;</code>标签在网络上播放音频。此外，它还提供其他音频处理功能，如音量调节、音频混合和音频空间化。</p><p id="c365" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Web Audio API允许您在<strong class="kt ir">音频环境</strong>中执行音频操作，并且被设计为允许<strong class="kt ir">模块化路由</strong>。用<strong class="kt ir">音频节点</strong>进行基本的音频操作，这些节点链接在一起形成一个<strong class="kt ir">音频路由图</strong>。一个非常基本的音频路由图如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ko"><img src="../Images/55158cb7c1ac5e61704fb3b8ea59b9e8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*groc8eIMbWanTh_H2v11pA.jpeg"/></div></figure><p id="9ccb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在图中，输入、效果和目的模块是三个<code class="fe kf kg kh ki b">AudioNode</code>,分别代表音频源、中间处理模块和音频目的。</p><p id="9092" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面描述了简单音频处理工作流程的基本步骤:</p><h2 id="e367" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">1.创建音频上下文</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="f894" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一个<code class="fe kf kg kh ki b">AudioContext</code>代表一个由音频模块链接在一起构建的音频处理图，每个音频模块由一个<code class="fe kf kg kh ki b">AudioNode</code>代表。它是一个中央处理单元，控制它包含的节点的创建和每个节点的音频处理的执行。</p><h2 id="b3f6" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">2.在创建的音频上下文中创建一个源节点和一个效果节点。</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><h2 id="e673" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">3.将源节点连接到效果节点</h2><p id="182d" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">调用源节点的<code class="fe kf kg kh ki b">connect</code>方法，将其连接到指定的效果节点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><h2 id="0f16" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">4.将效果节点连接到音频上下文的目标</h2><p id="e29f" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">调用效果节点的<code class="fe kf kg kh ki b">connect</code>方法，将处理后的音频发送到音频上下文的目的地。在这个例子中，目的节点<code class="fe kf kg kh ki b">audioCtx.destination</code>代表当前正在使用的扬声器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><h2 id="0a6e" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">5.通过更改效果节点的属性来更改音频输出。</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><h2 id="b820" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">使用Web音频API实现空间音频效果</h2><p id="b5e0" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">现在，让我们看看如何使用Web Audio API实现空间音效。</p><p id="c5be" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">基本上，要将空间音频效果添加到音频源，您需要结合使用以下两个界面:</p><p id="5d96" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe kf kg kh ki b">AudioListener</code>:表示虚拟3D空间中唯一的听者。您可以从<code class="fe kf kg kh ki b">AudioContext.listener</code>属性中获取音频上下文的监听器实例。</p><p id="ca42" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe kf kg kh ki b">PannerNode</code>:表示虚拟3D空间中的音频源。您可以调用<code class="fe kf kg kh ki b">new</code>方法或<code class="fe kf kg kh ki b">AudioContext.createPanner()</code>方法来创建一个<code class="fe kf kg kh ki b">PannerNode</code>。</p><p id="6169" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面介绍如何设置<code class="fe kf kg kh ki b">AudioListener</code>和<code class="fe kf kg kh ki b">PannerNode</code>以实现您想要的音频空间化效果。</p><h2 id="59c2" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">1.设置<code class="fe kf kg kh ki b">AudioListener</code></h2><p id="5c31" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">一个<code class="fe kf kg kh ki b">AudioListener</code>描述了一个独特的人听音频空间化中使用的音频场景的位置和方向。一个<code class="fe kf kg kh ki b">PannerNode</code>可以用来描述音源相对于听众的位置。</p><p id="c2a0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe kf kg kh ki b">AudioListener</code>的以下三个属性定义了它在右手笛卡尔坐标系中的位置:</p><ul class=""><li id="568e" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">positionX</code>:表示听者的水平位置。默认值为<code class="fe kf kg kh ki b">0</code>。</li><li id="3eeb" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">positionY</code>:表示听者的垂直位置。默认值为<code class="fe kf kg kh ki b">0</code>。</li><li id="571c" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">positionZ</code>:表示听者的纵向(前后)位置。默认值为<code class="fe kf kg kh ki b">0</code>。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ko"><img src="../Images/9605cf92935a1056ae86bb9b649e73cd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*w1uJrPrB_cn5iaT_sL7fRw.png"/></div></figure><p id="e601" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下三个属性在与位置值(<code class="fe kf kg kh ki b">positionX</code>、<code class="fe kf kg kh ki b">positionY</code>和<code class="fe kf kg kh ki b">positionZ</code>)相同的右手笛卡尔坐标系中定义收听者的前进方向的位置:</p><ul class=""><li id="9559" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">forwardX</code>:表示收听者前进方向的水平位置。默认值为<code class="fe kf kg kh ki b">0</code>。</li><li id="0e31" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">forwardY</code>:表示听者前进方向的垂直位置。默认值为<code class="fe kf kg kh ki b">0</code>。</li><li id="db41" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">forwardZ</code>:表示听者前进方向的纵向(前后)位置。默认值为<code class="fe kf kg kh ki b">-1</code>。</li></ul><p id="cc36" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下三个属性将听者头顶在同一右手笛卡尔坐标系中的位置定义为位置值(<code class="fe kf kg kh ki b">positionX</code>、<code class="fe kf kg kh ki b">positionY</code>和<code class="fe kf kg kh ki b">positionZ</code>):</p><p id="5d20" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe kf kg kh ki b">upX</code>:代表听者头顶的水平位置。默认值为<code class="fe kf kg kh ki b">1</code>。</p><p id="96cf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe kf kg kh ki b">upY</code>:代表听者头顶的垂直位置。默认值为<code class="fe kf kg kh ki b">0</code>。</p><p id="4081" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe kf kg kh ki b">upZ</code>:表示听者头顶的纵向(前后)位置。默认值为<code class="fe kf kg kh ki b">0</code>。</p><p id="9e0e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通过设置这两个方向向量，可以确定收听者耳朵的位置来创建空间音频效果。</p><h2 id="0f96" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">2.设置<code class="fe kf kg kh ki b">PannerNode</code></h2><p id="adbd" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated"><code class="fe kf kg kh ki b">PannerNode</code>是音频处理模块，用右手笛卡尔坐标描述音频源信号在3D音频空间中的位置和移动。它使用音频源信号在<code class="fe kf kg kh ki b">AudioContext</code>内相对于当前<code class="fe kf kg kh ki b">AudioListener</code>的位置和方向来对其进行空间化。</p><p id="e4ec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是<code class="fe kf kg kh ki b">PannerNode</code>的一些常用属性:</p><ul class=""><li id="6ab9" class="ln lo iq kt b ku kv kx ky la lp le lq li lr lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">panningModel</code>:一个枚举值，确定使用哪种空间化算法在3D空间中定位音频。默认值为<code class="fe kf kg kh ki b">equalpower</code>，代表等幂平移算法。我们建议将该属性设置为<code class="fe kf kg kh ki b">HRTF</code>，这意味着呈现比<code class="fe kf kg kh ki b">equalpower</code>更高质量的立体声输出。</li><li id="722a" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">positionX</code> / <code class="fe kf kg kh ki b">positionY</code> / <code class="fe kf kg kh ki b">positionZ</code>:音频在右手笛卡尔坐标系中的水平/垂直/纵向(前后)位置。</li><li id="2e31" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">orientationX</code> / <code class="fe kf kg kh ki b">orientationY</code> / <code class="fe kf kg kh ki b">orientationZ</code>:音频源矢量在右手笛卡尔坐标系中的水平/垂直/纵向(前后)位置。</li><li id="691d" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">coneInnerAngle</code>:一个double值，描述一个圆锥体的角度，以度为单位，其内部不会有体积减少。默认值为<code class="fe kf kg kh ki b">360</code>。</li><li id="103f" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">rolloffFactor</code>:一个double值，描述当声源远离听者时音量降低的速度。默认值为<code class="fe kf kg kh ki b">1</code>。</li><li id="2f87" class="ln lo iq kt b ku lw kx lx la ly le lz li ma lm ls lt lu lv bi translated"><code class="fe kf kg kh ki b">distanceModel</code>:一个枚举值，确定当音频源远离听众时，使用哪种算法来降低音频源的音量。默认值为<code class="fe kf kg kh ki b">inverse</code>。</li></ul><h2 id="2467" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">3.实现音频平移效果</h2><p id="17ef" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">下面的代码片段显示了如何实现音频平移效果，使听众感觉音频在他们的头上移动。只需在音乐播放时改变<code class="fe kf kg kh ki b">PannerNode</code>的位置值即可。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="ffa6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该功能仅对SDK采集的声音有效。开发人员可以在通话或直播过程中动态调整声音变化、混响、混响回声和虚拟立体声。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><h2 id="4b7d" class="mc md iq bd me mf mg dn mh mi mj dp mk la ml mm mn le mo mp mq li mr ms mt mu bi translated">结论</h2><p id="5b0e" class="pw-post-body-paragraph kr ks iq kt b ku mv jr kw kx mw ju kz la mx lc ld le my lg lh li mz lk ll lm ij bi translated">本文给出了Web Audio API的基本介绍，并描述了如何使用<code class="fe kf kg kh ki b">AudioListener</code>和<code class="fe kf kg kh ki b">PannerNode</code>接口实现空间音频效果(声音在听者的头部周围移动)。</p><p id="693a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">除了音频空间化，Web音频API还有许多其他强大的音频处理功能。更多细节，你可以查看MDN 上的<a class="ae mb" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API" rel="noopener ugc nofollow" target="_blank">网络音频API文档。</a></p><p id="c150" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">关于ZEGOCLOUD Express SDK的邻近语音模块的更多细节，请参见ZEGOCLOUD网站上的<a class="ae mb" href="https://docs.zegocloud.com/article/12341?_source=medium&amp;article=1" rel="noopener ugc nofollow" target="_blank">相关开发者文档。</a></p><pre class="kj kk kl km gt nc ki nd ne aw nf bi"><span id="d30b" class="mc md iq ki b gy ng nh l ni nj"><strong class="ki ir">Want to Connect?</strong></span><span id="3b51" class="mc md iq ki b gy nk nh l ni nj">Visit <a class="ae mb" href="https://zegocloud.com?_source=medium&amp;article=1" rel="noopener ugc nofollow" target="_blank">ZEGOCLOUD website</a> to learn more about what you can build with real-time audio and video!</span></pre></div></div>    
</body>
</html>
# 人性化算法的危险

> 原文：<https://betterprogramming.pub/the-danger-of-humanizing-algorithms-a9a0e1a5c8e6>

## 误导性的术语可能是危险的。机器实际上并没有在学习

![](img/3b447cf0f9bbcd65ba0ea3c6d6c72aae.png)

迈克尔·泽兹奇在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片。

对许多人来说，2016 年标志着人工智能(AI)的成熟。AlphaGo 战胜了世界上最好的人类*围棋选手*，展示了人工智能几乎无穷无尽的潜力。像 AlphaGo 或 [AlphaZero](https://www.wired.com/story/alphabets-latest-ai-show-pony-has-more-than-one-trick/) 这样具有超人技能的棋盘游戏程序已经创造了围绕人工智能的无与伦比的宣传，而这只是由大数据的可用性推动的。

在这种背景下，公众、企业和科学界对机器学习的兴趣没有受到抑制就不足为奇了。这些程序可以比击败人类玩家更进一步，甚至发明新的和巧妙的游戏。他们从数据中学习，识别模式，并根据这些模式做出决策。根据应用的不同，决策可以在没有或只有最少人工干预的情况下进行。由于数据生产是一个连续的过程，机器学习解决方案可以自主适应，从新信息和以前的操作中学习。2016 年，AlphaGo [共使用 30 万场](https://arxiv.org/pdf/1902.04885.pdf)作为训练数据，取得了优异的成绩。

每一本关于如何实现机器学习应用的指南都会告诉你，你需要对它所要解决的问题有一个清晰的认识。

在许多情况下，机器学习应用程序更快、更准确、更省时，因此，除了其他好处之外，还缩短了上市时间。然而，它只能解决给定数据的这个具体问题。

但是这种学习方式符合人类的学习方式吗？不，不是的。一点也不。

# 未解之谜:什么是智力？

作为人类，我们对自己认为的聪明或智慧有一个概念。然而，从科学上来说，事实证明几乎不可能掌握和理解它。

这有几个原因，其中之一是文化。例如，在西方，聪明与敏捷联系在一起。回答问题最快的人被认为是最聪明的。但在其他文化中，聪明是指在回答之前对一个想法进行彻底的考虑。一个深思熟虑、深思熟虑的答案是最好的答案。另一个原因是我们不能测量智力的所有方面。

发展心理学家哈沃德·加德纳认为，智力有九个领域，而不是一个。其中只有三种可以通过智商测试来衡量:

*   逻辑-数学
*   语言的
*   空间的

然而，智商测试完全忽略了以下六点:

*   音乐的
*   身体动觉的
*   自然的
*   人与人之间的
*   内心的
*   有关存在的

因此，高智商并不意味着生活成功，也不表明一个人有常识或优秀的人际交往能力。其他关于智力的理论包括斯腾伯格的智力三元理论。

所有心理学理论的共同点是，智力被视为一个广义的术语，用来描述人类的智力能力，表现为复杂的认知成就和高水平的动机和自我意识。

> “智力是一种非常普遍的心理能力，其中包括推理、计划、解决问题、抽象思考、理解复杂想法、快速学习和从经验中学习的能力。这不仅仅是书本知识、狭隘的学术技能或应试技巧。相反，它反映了理解我们周围环境的更广泛和更深入的能力——“理解”、“理解”事物，或者“弄清楚”该做什么。”— [关于智力的主流科学](https://en.wikipedia.org/wiki/Mainstream_Science_on_Intelligence)

然而，在机器学习的背景下，学习是统计的，并且应该回答下面的基本问题(根据[统计学习的本质](https://link.springer.com/content/pdf/bfm%3A978-1-4757-2440-0%2F1.pdf)):“为了在观察的基础上估计未知的函数依赖，我们必须事先知道什么？”

虽然莱昂·博图[认为](https://link.springer.com/article/10.1007/s10994-013-5335-x#ref-CR52)这种统计学性质已经被很好地理解，统计机器学习方法现在也很常见，但是[推理的质量证明更加难以捉摸](https://link.springer.com/article/10.1007/s10994-013-5335-x)。

# 人工智能中的拟人

拟人化是[将人类特征赋予非人类物体](https://www.sciencedirect.com/science/article/abs/pii/S0191886914004863)(如[斑比](https://en.wikipedia.org/wiki/Bambi))的倾向，在整个领域都很明显。只要问问自己，“人工智能本身暗示了什么？”

如果我们更仔细地研究试图实现推理的统计概念，有缺陷的术语在深度学习应用中尤其突出。在人工智能的这个子集里，[人工神经网络](https://www.unlikelytechie.com/post/what-exactly-is-artificial-intelligence-what-are-the-three-types-of-artificial-intelligence)是为算法从大量数据中学习而建立的。他们的中心是建立一个学习机器来完成一项有价值的任务。它的创建是为了将复杂的信息总结成有形的结果，受人脑的启发。这些网络的优势是输入数据和抽象神经元值之间的关系的深度抽象，输出数据通过网络的几个层完成(传统的神经网络只包含 2-3 个隐藏层，深度网络[可以有多达 150 个](https://data-science-blog.com/blog/2018/05/14/machine-learning-vs-deep-learning-wo-liegt-der-unterschied/))。但是，与真正的人脑相比，深度神经网络仍然是[脆弱、低效和短视的。](https://blogs.wsj.com/cio/2020/02/07/conceptualizing-ai-in-human-terms-is-misleading/)

## 易碎

深度神经网络很容易被训练输入的轻微扰动所欺骗。这里的一个小故障和深度学习算法开始错误地标记对象和其他荒谬的组合。生物和人工神经网络之间的这种关键区别，在与临床医学和自动驾驶相当的领域，对深度神经网络提出了深远的挑战。

## 无能的

渴求数据的深度神经网络效率低下，需要大量的训练样本。此外，这些模型如何频繁地处理它们仍然是一个谜。我们可以马上分辨出狗和斑马。然而，类脑网络需要训练数据来实现这一点。这表明，人类水平的洞察力需要超越信息和深度学习计算的能力。人们可以构建他们所看到的世界模型，包括普通常识信息和日常常识知识，并随后利用这些模型来解释他们的行动和决策。

## 近视的

让我们面对现实吧。深度学习模型奇怪地不宽容，缺乏相同水平的认知。换句话说，尽管人类[可以本能地分辨出可能具有狗](https://blogs.wsj.com/cio/2020/02/07/conceptualizing-ai-in-human-terms-is-misleading/)的形状和特征的云不是真正的狗，但深度学习算法将很难区分看起来像的*和像*的*。*

但是，我们称之为神经网络。如果这不是高明的营销，那我就不知道这是什么了。与迄今为止构建的任何深度学习应用程序相比，一个三个月大的婴儿对如何利用周围环境有着更好的理解。

# 这种说辞往好里说是误导，往坏里说是完全危险的

人类一直想创造能够思考、学习和推理的机器。当前对人工智能的研究促使我们关注声称与人类思维方式以及推理方式相当的特定算法。因为这种说辞，每个人都期待智能机器人随时会出现。坦率地说，论文显示，不仅仅是普通大众在科幻小说、虚构和可以实现的事物之间左右为难。

我们如何判断这些描述是字面意义上的还是隐喻意义上的？

这就是棘手的地方。一方面，使用拟人化倾向来描述人工智能现象可以有利于该领域的未来研究。然而，在社交敏感的应用中，这也是非常阻碍的，甚至是危险的。为什么？因为 AI 中的拟人化倾向并不是伦理中立的。

当我们在社交敏感的应用中让算法决定会发生什么？首先，在依赖输入系统的数据时，我们可能会面临种族主义、性别歧视和歧视的结果。第二，我们如何保持我们的能力，让有影响力的个人和团体对他们通过技术手段进行的行为负责？

最重要的是要明白，机器学习技术在完全理解数据的能力(即发现模式并利用它们)方面与人类相似的概念是不正确的。虽然这些应用程序功能强大(例如[验光师算法](https://www.unlikelytechie.com/post/how-to-name-an-algorithm))，但它们只是模仿人类智能。

这就是这里的本质:这样的系统是行善或作恶的强大工具。或者，正如大卫·沃森在最近的一篇文章中所说的，“选择权一如既往地在我们手中。”
<html>
<head>
<title>Cropping Areas Of Interest Using Vision in iOS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在iOS中使用Vision裁剪感兴趣的区域</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/cropping-areas-of-interest-using-vision-in-ios-e83b5e53440b?source=collection_archive---------5-----------------------#2019-11-20">https://betterprogramming.pub/cropping-areas-of-interest-using-vision-in-ios-e83b5e53440b?source=collection_archive---------5-----------------------#2019-11-20</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="5922" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">使用升级后的视觉框架提取显著特征</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/9f783882b9e69e933892c3b117bc456c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EKboKCRYOwceqb4FgB7yyw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://pixabay.com/users/kropekk_pl-114936/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=285825" rel="noopener ugc nofollow" target="_blank"> kropekk_pl </a>来自<a class="ae kz" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=285825" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="93cd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">苹果在WWDC 2019期间在愿景框架中引入了大量新功能。除了提供内置的图像分类模型来识别宠物并改进面部特征跟踪，突出的特征之一是显著性。</p><p id="a716" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">显著性在计算机视觉和图像处理中有许多应用。从突出显示感兴趣的区域，到模糊检测、异常检测、自动图像裁剪和图像后处理，这样的例子不胜枚举。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="f5ed" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">什么是显著性？</h1><p id="9d79" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">简单来说，显著性意味着最显著或最重要的特征。显著性主要分为两种类型:</p><p id="6eb5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">基于注意力的显著性</strong> —这种算法提供了一眼就能抓住人眼的图像特征。该算法的模型是基于当人们看到一批图像时他们在图像中的位置来训练的。</p><p id="8619" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">基于对象的显著性</strong> —这是在对象分割上训练的，以便突出图像中存在的突出对象。</p><p id="c5b5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">基于注意力的显著性是一个更棘手的问题，因为它依赖于许多因素，如图像中的人脸、对比度和光照，来确定引人注目的部分。</p><p id="c735" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这些显著性类型中的每一种都返回一个热图，它实际上是68X68像素的缓冲区，用于保存图像每个区域的显著性值。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj na"><img src="../Images/a04f40d37135db3d3a3432f79b2d88e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Z534Rn3CmQqpgo8PxC8lw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated"><a class="ae kz" href="https://developer.apple.com/videos/play/wwdc19/222/" rel="noopener ugc nofollow" target="_blank">来自苹果文档</a></p></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="8443" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">我们的目标</h1><p id="5cc5" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">我们将开发一个iOS应用程序，自动裁剪图像，只显示突出区域。我们将使用两种显著性类型，并将比较结果。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="1d38" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">履行</h1><p id="de1e" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">为了简单起见，UI由一个图像和一个按钮组成，两者都是在我们的ViewController中以编程方式创建的。按钮选择器负责使用ImagePickerController选择图像，如下所示:</p><pre class="kk kl km kn gu nb nc nd ne aw nf bi"><span id="c9cb" class="ng me iu nc b gz nh ni l nj nk">@objc func onButtonClick(sender: UIButton){</span><span id="1859" class="ng me iu nc b gz nl ni l nj nk">let imagePicker = UIImagePickerController()</span><span id="b7e9" class="ng me iu nc b gz nl ni l nj nk">imagePicker.sourceType = .photoLibrary</span><span id="a8c3" class="ng me iu nc b gz nl ni l nj nk">imagePicker.delegate = self</span><span id="b1b4" class="ng me iu nc b gz nl ni l nj nk">present(imagePicker, animated: true, completion: nil)</span><span id="897a" class="ng me iu nc b gz nl ni l nj nk">}</span></pre><p id="6a77" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了按预期工作，请确保您已经实现了<code class="fe nm nn no nc b">UIImagePickerControllerDelegate</code>、<code class="fe nm nn no nc b">UINavigationControllerDelegate</code>协议，并且在您的<code class="fe nm nn no nc b">info.plist</code>文件中添加了照片库的隐私使用权限。</p><pre class="kk kl km kn gu nb nc nd ne aw nf bi"><span id="bf8a" class="ng me iu nc b gz nh ni l nj nk">func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {<br/>        dismiss(animated: true) {<br/>            if let image = info[UIImagePickerController.InfoKey.originalImage] as? UIImage {<br/>                self.imageView?.image = image<br/>                self.processImage(image)<br/>                <br/>            }<br/>        }<br/>}</span></pre><p id="f79f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在<code class="fe nm nn no nc b">processImage</code>函数中，我们的视觉API处理显著性请求。我们将在下一节中讨论这一点。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="a949" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">设置我们的愿景请求</h1><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj np"><img src="../Images/6d86180e16fa08ca4e9355c5c817b9db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKr08LltXfhvuGF7Leqe5w.png"/></div></div></figure><p id="ff1a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们将使用标准的<code class="fe nm nn no nc b">VNImageRequestHandler</code>来处理我们的图像，并在视觉请求处理器中传递算法类型，如下所示:</p><pre class="kk kl km kn gu nb nc nd ne aw nf bi"><span id="d779" class="ng me iu nc b gz nh ni l nj nk">let requestHandler = VNImageRequestHandler(cgImage: originalImage, options: [:])</span><span id="41f5" class="ng me iu nc b gz nl ni l nj nk">let saliencyRequest = VNGenerateAttentionBasedSaliencyImageRequest(completionHandler: nil)</span><span id="a483" class="ng me iu nc b gz nl ni l nj nk">try requestHandler.perform([self.saliencyRequest])<br/>guard let results = self.saliencyRequest.results?.first else{return}</span><span id="002d" class="ng me iu nc b gz nl ni l nj nk">let observations = results as? VNSaliencyImageObservation</span><span id="011b" class="ng me iu nc b gz nl ni l nj nk">let salientObjects = observation.salientObjects</span></pre><p id="98ce" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在上面的代码中有一些非常新的术语。让我们看看它们是什么:</p><ul class=""><li id="5e0f" class="nq nr iu lc b ld le lg lh lj ns ln nt lr nu lv nv nw nx ny bi translated"><code class="fe nm nn no nc b">salientObjects</code>属性是算法检测到的所有显著特征的<code class="fe nm nn no nc b">VNRectangleObservation</code>数组。它保存每个特征的<code class="fe nm nn no nc b">boundingBox</code>和置信度阈值。为了裁剪图像以仅显示突出的特征，我们将合并所有突出的边界框区域。</li><li id="5bb4" class="nq nr iu lc b ld nz lg oa lj ob ln oc lr od lv nv nw nx ny bi translated">由视觉框架返回的边界框使用归一化的坐标系，使得左下角点是原点。因此，我们将把边界框联合传递给一个<code class="fe nm nn no nc b">VNImageRectForNormalizedRect</code>来将显著区域投影到UIKit坐标系中。</li><li id="7ff7" class="nq nr iu lc b ld nz lg oa lj ob ln oc lr od lv nv nw nx ny bi translated">在图像没有高亮显示的情况下，返回的<code class="fe nm nn no nc b">salientObjects</code>为空。</li></ul><p id="8444" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">以下代码包含基于显著特征裁剪图像的视觉请求的完整实现:</p><pre class="kk kl km kn gu nb nc nd ne aw nf bi"><span id="f70b" class="ng me iu nc b gz nh ni l nj nk">private let workQueue = DispatchQueue(label: "VisionRequest", qos: .userInitiated, attributes: [], autoreleaseFrequency: .workItem)<br/><br/>private func processImage(_ image: UIImage) {<br/>        <br/>        guard let originalImage = image.cgImage else { return }<br/>        <br/>        workQueue.async {<br/>            let requestHandler = VNImageRequestHandler(cgImage: originalImage, options: [:])<br/>            do {<br/>                try requestHandler.perform([self.saliencyRequest])<br/>                guard let results = self.saliencyRequest.results?.first<br/>                    else{return}<br/>                <br/>                if let observation = results as? VNSaliencyImageObservation<br/>                {<br/>                    var unionOfSalientRegions = CGRect(x: 0, y: 0, width: 0, height: 0)<br/>                    let salientObjects = observation.salientObjects<br/>                    <br/>                    let showAlert = (salientObjects?.isEmpty ?? false)<br/>                    <br/>                    for salientObject in salientObjects ?? [] {<br/>                        unionOfSalientRegions = unionOfSalientRegions.union(salientObject.boundingBox)<br/>                    }<br/>                    <br/>                    if let ciimage = CIImage(image: image)<br/>                    {<br/>                        let salientRect = VNImageRectForNormalizedRect(unionOfSalientRegions,<br/>                                                                       Int(ciimage.extent.size.width),<br/>                                                                       Int(ciimage.extent.size.height))<br/>                        let croppedImage = ciimage.cropped(to: salientRect)<br/>                        let thumbnail =  UIImage(ciImage:croppedImage)<br/>                        DispatchQueue.main.async {<br/>                            <br/>                            if showAlert{<br/>                                let alertController = UIAlertController(title: "Oops!", message: "No highlights were found", preferredStyle: .alert)<br/>                                <br/>                                alertController.addAction(UIAlertAction(title: "Dismiss", style: .default, handler: { _ in<br/>                                }))<br/>                                self.present(alertController, animated: false, completion: nil)<br/>                            }<br/>                            <br/>                            self.imageView?.image = thumbnail<br/>                        }<br/>                    }<br/>                }<br/>                <br/>            } catch {<br/>                print(error)<br/>            }<br/>        }<br/>    }</span></pre><p id="5fcd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">基于注意力的显著性类型只返回一个包围盒，而基于对象的算法可以返回多达三个包围盒。</p><p id="c99b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">下面给出了实际应用程序的输出:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oe"><img src="../Images/f95d6abc08c6dc73ad8bfeb6619f5dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLN0fIB1dCkrsN4ow-FUWg.png"/></div></div></figure><p id="7264" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，让我们比较一下风景图片上基于客体和注意力的类型，如下所示:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj of"><img src="../Images/97f2c3e4a9a6a63c66b928831bc1c5c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CXN7G73qaFoW5RXvxBh4pw.png"/></div></div></figure><p id="775c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">基于注意力的算法对风景图像没有太大的影响。根据用例，您可以使用任何一种显著性请求类型。为了在缩略图中显示感兴趣的部分，通常使用基于注意力的显著性。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="96cb" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">结论</h1><p id="5c1f" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">我们已经很好地研究了视觉的显著性特征，并比较了基于注意力和基于客体的类型。Vision framework今年将有更多改进，如图像相似性、人脸捕捉质量等——很快会有更多改进！上述示例的完整源代码可以在<a class="ae kz" href="https://github.com/anupamchugh/iowncode/tree/master/iOSVisionCroppingSalientFeatures" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>中找到。</p><p id="73ec" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这一次到此为止。我希望你喜欢阅读。</p></div></div>    
</body>
</html>
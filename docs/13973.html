<html>
<head>
<title>Using Large Language Models for Data Labeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用大型语言模型进行数据标注</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/using-large-language-models-for-data-labeling-1357f2880a38?source=collection_archive---------3-----------------------#2022-10-21">https://betterprogramming.pub/using-large-language-models-for-data-labeling-1357f2880a38?source=collection_archive---------3-----------------------#2022-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8aa8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让人工智能为你标注数据</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/cf52cabb873b65cd3cc879febcb61cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UXa2Sr83y7UzOWZ0"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马特·布里内在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4fff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TL；DR——我们可以利用GPT3等大型语言模型的文本生成能力来生成用于监督学习的标记数据。我们可以使用提示来做到这一点，在提示中，我们给LM一个任务描述、一些例子和一个生成标签的新例子。由此产生的数据，一般来说，将是嘈杂的，质量低于人类的标签。然而，数据收集的速度和在循环中使用人的能力使这成为为难以标记的任务收集大量标记数据的有效方法。</p><h1 id="78c0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">自然语言处理中的数据标注</h1><p id="d794" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这一点上，很好理解的是，标记数据的质量和数量是机器学习项目成功的唯一最佳预测器。在工业界，有没有这些数据往往决定了一个项目是被批准还是被搁置。</p><p id="04c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，在许多情况下收集可能非常昂贵和耗时。医疗保健或招聘等专业领域的标注可能需要专家来协助标注。这可能会增加注释的成本，并减少潜在注释者的数量。</p><p id="04ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，有些任务不太适合人工注释。例如，生成摘要是众所周知的困难，因为它不仅吞吐量低(因为每个示例都需要阅读、理解和编写一个可能很长的文档)，而且注释者的意见也很不一致(其中重要的摘要可能因人而异)。</p><h2 id="b7e4" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">语言模型增强数据标注</h2><p id="4298" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">ML文献中的一个增长趋势是使用大型语言模型作为传统注释管道的替代或补充。这允许模型为注释管道中最劳动密集型的部分做繁重的工作。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/4d802941423709b2cd23f0a8581803cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DgFYsoM5_yOQkR23_co52w.png"/></div></div></figure><p id="f919" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">LM增强数据注记的工作方式如下:</p><ol class=""><li id="4be1" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">使用提示从语言模型生成嘈杂标签数据集</li><li id="009b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">人类注释者要么接受要么拒绝样本</li><li id="2ff8" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">学习一个critic模型，根据注释者的决定过滤生成的例子</li><li id="50df" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">critic模型应用于生成的数据集，以过滤有噪声的示例</li></ol><h2 id="0648" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">快速噪音标签&gt;慢速清洁标签</h2><p id="ac70" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在行业中担任ML工程师时，快速完成有效的POC往往比找到最佳方法更重要。工程时间通常是公司最重要的资源之一，允许我们自己被封锁是不可接受的，即使是像数据这样重要的东西。在这里，我们将看到，虽然生成的数据并不总是更好，但它的生成速度明显更快，成本也更低，这有助于回答每个项目经理在ML项目之前都会遇到的关键问题:这是否可行？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/4916e5c321586247f4661ab20f137ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*MA_fM8MEHkYnvELj8elhNQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">上市速度&gt;准确性</p></figure><p id="51b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这次审查中，我将:</p><ul class=""><li id="d307" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nr ni nj nk bi translated">简要介绍如何使用语言模型生成数据</li><li id="6069" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nr ni nj nk bi translated">看一个使用端到端标签管道的案例研究</li><li id="c7ce" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nr ni nj nk bi translated">展示了一个引导书名分类数据集的工作示例</li></ul><h1 id="02a2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">从语言模型生成数据</h1><h2 id="cf04" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">大型语言模型</h2><p id="8ebf" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在过去的几年中，语言模型在规模和性能上呈指数级增长。就模型的大小、训练数据量和用于创建它们的训练时间量而言，诸如GPT-3的当代语言模型要大几个数量级。这些模型已经变得非常强大，并显示出在没有数据的情况下为新任务生成文本的非凡能力。</p><h2 id="175d" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">基于提示的生成</h2><p id="b577" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们可以通过构造称为提示的文本模板来为未标记的数据生成标签，当我们允许语言模型继续运行时，这将很可能生成标签。提示通常包含三个部分:</p><ul class=""><li id="1433" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nr ni nj nk bi translated">对我们要执行的任务的描述</li><li id="0d5b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nr ni nj nk bi translated">正在执行的任务的示例(也称为情境演示)</li><li id="a4cc" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nr ni nj nk bi translated">一个我们想要标记的新例子</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/f31422171e8ce6d4bf3a5a80e56353f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*535wzmn0nBpE1shOPDN2RA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">红色—任务的描述。黄色—正在执行的任务的示例(也称为情境演示)。蓝色—我们希望模型为其生成的新示例</p></figure><p id="05ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的例子是来自<a class="ae kv" href="https://beta.openai.com/playground" rel="noopener ugc nofollow" target="_blank"> openai playground </a>的工作示例，展示了我们如何使用语言模型将食物标记为素食或不素食。</p><h1 id="5bf8" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">符号知识蒸馏——人在回路与数据质量的案例研究</h1><p id="7094" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><a class="ae kv" href="https://arxiv.org/pdf/2110.07178.pdf" rel="noopener ugc nofollow" target="_blank">象征性的知识蒸馏:从一般语言模型到常识模型</a>。EditSign paper将这一思想应用于为常识推理任务生成数据。<a class="ae kv" href="https://www.youtube.com/watch?v=kP-dXK9JEhY&amp;t=2377s&amp;ab_channel=YannicKilcher" rel="noopener ugc nofollow" target="_blank"> Yannic Kilcher </a>对这篇论文的技术细节进行了非常详细的描述，我强烈建议观看这篇论文，但我将在这里对重要的发现进行简要概述。</p><h2 id="9188" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">常识推理任务</h2><p id="cca2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">任务是生成常识推理三元组。它们采用主语、谓语和结果的形式，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/88b7bd1e03385991068924da6bf14b8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*LHCiEBxX-MqqihMtkb7evg.png"/></div></figure><h2 id="10f7" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">生成的数据集</h2><p id="94d9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">作者使用GPT3使用上一节描述的方法生成数据集。它们可以生成一个大得多的数据集，比人工标注大10倍，而成本只有人工标注的15%。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/ad25e4a238128dc21148c5907b2f9c8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*iVImGl_WWGk4UAbSv-tocw.png"/></div></figure><h2 id="253f" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">数据生成质量</h2><p id="3f22" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果都是垃圾，我们有多少数据并不重要。作者进行了一项荟萃分析，评估由人工注释和GPT3产生的数据的质量。自然，数据的质量要低得多，如接受率一栏所示。然而，当我们应用critic过滤模型时，我们看到数据集的质量提高并超过了人类数据集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/44443766a9d92deb686a203bb253fb85.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*AYFv4CNN3o_sNpJkaYWyDg.png"/></div></figure><h2 id="299e" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">对下游性能的影响</h2><p id="2ce1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个过程产生了比人工注释质量更高、成本更低的更多数据，但是对下游模型有什么影响呢？作者表明，简单地通过增加数据集，相同的模型可以实现性能的显著跃升。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/5b748602130b70d86c5a1a14132a0a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*-wyS3gRmU14K5NZnFgs82w.png"/></div></figure><h1 id="6234" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">示例—图书流派预测</h1><p id="5262" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">让我们看看如何使用这种方法来预测给定书名的书的类型。我们将使用来自<a class="ae kv" href="https://www.kaggle.com/datasets/athu1105/book-genre-prediction?resource=download" rel="noopener ugc nofollow" target="_blank">书籍类型预测</a> Kaggle数据集的数据，该数据集包含4657本带有标题、摘要和类型的书籍。Openai的API按令牌收费，所以我将把探索限制在书名上，但同样的方法也适用于更长的上下文。</p><h2 id="cbcd" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated"><strong class="ak">装载数据</strong></h2><p id="7dbe" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">首先，我们加载从kaggle下载的数据，并设置从https://beta.openai.com/<a class="ae kv" href="https://beta.openai.com/" rel="noopener ugc nofollow" target="_blank">复制的openai API密钥</a></p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="f330" class="mp lt iq ny b gy oc od l oe of">import pandas as pd<br/>import os<br/>import openai<br/>from tqdm.auto import tqdm</span><span id="266f" class="mp lt iq ny b gy og od l oe of">openai.api_key = os.getenv("OPENAI_API_KEY")</span><span id="9156" class="mp lt iq ny b gy og od l oe of">books = pd.read_csv("./data.csv")</span></pre><h2 id="d299" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated"><strong class="ak">情境演示</strong></h2><p id="17d9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们从每种类型中抽取一个样本(总共11个)作为模型的演示。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="d579" class="mp lt iq ny b gy oc od l oe of"># Sample 1 labeled example of each class to serve as the seed for our generator model<br/>few_shot_example_idx = []<br/>for genre in books["genre"].value_counts().index:<br/>    few_shot_example_idx.append(books[books["genre"] == genre].sample(1).index[0])<br/>books.loc[few_shot_example_idx]</span></pre><h2 id="1a94" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">即时设计</h2><p id="7254" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我写了一个提示，给出每种类型的随机上下文演示和问题的简要描述。我还在下面添加了我们想要生成的书名:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="97ee" class="mp lt iq ny b gy oc od l oe of"># Create a template for the prompt with the examples<br/>prompt_template = f"Classify the given book title as thriller, fantasy, science, history, horror, crime, romance, psychology, sports or travel:\n"<br/>for idx in few_shot_example_idx:<br/>    prompt_template += f'{books["title"].loc[idx]}=&gt; {books["genre"].loc[idx]}\n'</span><span id="b51d" class="mp lt iq ny b gy og od l oe of">Classify the given book title as thriller, fantasy, science, history, horror, crime, romance, psychology, sports or travel:<br/>Deception Point=&gt; thriller<br/>Hounded=&gt; fantasy<br/>The Star Fraction=&gt; science<br/>Laura Blundy=&gt; history<br/>The Vampire Lestat=&gt; horror<br/>At Bertram's Hotel=&gt; crime<br/>City of Lost Souls=&gt; romance<br/>The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life=&gt; psychology<br/>Long Shot=&gt; sports<br/>The Old Ways: A Journey on Foot=&gt; travel<br/>Drowned Wednesday=&gt;</span></pre><h2 id="4675" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated"><strong class="ak">生成数据</strong></h2><p id="1fa1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们调用openai为每个例子生成标签。注意:我建议在处理整个数据集之前，先进行小规模的测试来验证提示。从这11个示例的种子中生成其余的注释大约需要10分钟。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="f02f" class="mp lt iq ny b gy oc od l oe of">for i in tqdm(range(books.shape[0])):<br/>    <br/>    prompt = prompt_template + books.iloc[i]["title"] + "=&gt;"</span><span id="1835" class="mp lt iq ny b gy og od l oe of">response = openai.Completion.create(<br/>      model="text-ada-001",<br/>      prompt=prompt,<br/>      temperature=0,<br/>      max_tokens=60,<br/>      top_p=1.0,<br/>      frequency_penalty=0.5,<br/>      presence_penalty=0.0<br/>    )<br/>    <br/>    books["gpt3_annotations"].iloc[i] = response.to_dict()["choices"][0]["text"].strip()</span></pre><h2 id="9f35" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">特征表示</h2><p id="aada" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我使用流行的<a class="ae kv" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">句子转换器</a>库来表示标题，该库为每个标题构建嵌入，以便在下游逻辑回归模型中使用(为了简单起见)。</p><pre class="kg kh ki kj gt nx ny oh bn oi oj bi"><span id="d029" class="ok lt iq ny b be ol om l on of">from sklearn.model_selection import train_test_split<br/>from sklearn import preprocessing<br/>from sentence_transformers import SentenceTransformer<br/><br/>le = preprocessing.LabelEncoder()<br/>true_labels = le.fit_transform(books["genre"])<br/>noisy_labels = le.transform(books["gpt3_annotations"])<br/><br/>model = SentenceTransformer('all-MiniLM-L6-v2')<br/>embeddings = model.encode(books["title"])<br/>embeddings_train, embeddings_test, y_true_train, y_true_test, y_noisy_train, y_noisy_test = train_test_split(embeddings, true_labels, noisy_labels, test_size=0.2, random_state=42)</span></pre><h2 id="1726" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">批评家模型</h2><p id="e59b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">批评家模型学习接受或拒绝基于人类注释生成的例子。这里我们用100个例子来说明。请注意，这可以通过以下方式非常有效地学习:</p><ol class=""><li id="45d7" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">通过将标注任务变成二进制标记任务，它使得标注任务对人类来说更容易</li><li id="0297" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">它允许更高效的样本学习，因为我们不需要覆盖整个标签空间。</li></ol><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="25a0" class="mp lt iq ny b gy oc od l oe of">import numpy as np<br/>from sklearn.linear_model import LogisticRegression</span><span id="1ed0" class="mp lt iq ny b gy og od l oe of"># Simulate a human critic accepting or rejecting the label </span><span id="e16b" class="mp lt iq ny b gy og od l oe of">critic_examples = np.random.randint(embeddings_train.shape[0], size=100)</span><span id="f9ca" class="mp lt iq ny b gy og od l oe of"># Train model to learn from these critic examples</span><span id="c4e4" class="mp lt iq ny b gy og od l oe of">critic_features = embeddings_train[critic_examples]<br/>critic_labels = (y_noisy_train == y_true_train)[critic_examples]</span><span id="a276" class="mp lt iq ny b gy og od l oe of">critic_model = LogisticRegression()</span><span id="05b0" class="mp lt iq ny b gy og od l oe of">critic_model.fit(critic_features , critic_labels)</span><span id="0bdd" class="mp lt iq ny b gy og od l oe of"># Score examples in the dataset and remove those that score in the lowest 30% for acceptance</span><span id="cca3" class="mp lt iq ny b gy og od l oe of">critic_scores = critic_model.predict_proba(embeddings_train)[:,1]</span><span id="cd6d" class="mp lt iq ny b gy og od l oe of">filtered_training_input = embeddings_train[critic_scores &gt; np.percentile(critic_scores, 30)]<br/>filtered_training_label = y_noisy_train[critic_scores &gt; np.percentile(critic_scores, 30)]</span></pre><h2 id="87ce" class="mp lt iq bd lu mq mr dn ly ms mt dp mc lf mu mv me lj mw mx mg ln my mz mi na bi translated">模型比较</h2><p id="3a8b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我针对每个数据集(手动标记的小型种子数据集、没有critic的嘈杂标签、critic过滤的数据和完全标记的数据集)训练简单的逻辑回归模型，并比较结果的准确性。我还报告了每个数据集所需的几个人工注释。</p><p id="9eb3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然我们的表现肯定比完全监督差，但考虑到它只能访问11个人类标记的示例，该模型的性能还是相当不错的。我认为这种差距可以进一步缩小，只要花更多的精力调整提示符和使用更昂贵的引擎。</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="6f19" class="mp lt iq ny b gy oc od l oe of">+----------------------------+----------+<br/>|           Data             | Accuracy |<br/>+----------------------------+----------+<br/>| Only Labeled Examples (11) |    0.117 |<br/>| Noisy Examples (11)      |    0.177 |<br/>| Critic Filtered (111)     |    0.185 |</span><span id="4ccc" class="mp lt iq ny b gy og od l oe of">| True Labels (3725)     |    0.251 |<br/>+----------------------------+----------+</span></pre><h1 id="b3fd" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="0a4c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">从金钱和工程时间的角度来看，传统的人工注释可能是昂贵的。一种新的人在回路语言模型增强数据注释范例旨在使用GPT3s巨大的生成能力来减轻人类的负担。这项技术在以下任务中非常有用:</p><ul class=""><li id="0f60" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nr ni nj nk bi translated">需要专业注释者(医疗保健)</li><li id="fd1b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nr ni nj nk bi translated">注释是劳动密集型的(抽象概括)</li><li id="0651" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nr ni nj nk bi translated">上市时间很重要(对MVP来说，更快&gt;更准确)</li></ul><p id="68ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过将人作为评审者而不是实际的注释者包含在注释过程中，我们仍然可以控制生成的数据的质量，并在内部注释者意见不一致的领域中获得更高质量的数据。</p></div></div>    
</body>
</html>
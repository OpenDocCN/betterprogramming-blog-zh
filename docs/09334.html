<html>
<head>
<title>Generate Conversational Podcasts With GPT-2 and Google WaveNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GPT-2和谷歌WaveNet制作对话播客</h1>
<blockquote>原文：<a href="https://betterprogramming.pub/generate-conversational-podcasts-with-gpt-2-and-google-wavenet-1dc9c2edc3ef?source=collection_archive---------14-----------------------#2021-08-11">https://betterprogramming.pub/generate-conversational-podcasts-with-gpt-2-and-google-wavenet-1dc9c2edc3ef?source=collection_archive---------14-----------------------#2021-08-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a884" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">永远听你最喜欢的播客</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f3245d464fd286ef7e8baebdf6fbc5a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hO3R-xE7_Yl8qIEVWHjpmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">作者图片</em></p></figure><p id="a244" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GPT-2已经进行了许多生殖实验，从栩栩如生的聊天机器人到复制Twitter个人资料。</p><p id="b459" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来自OpenAI <a class="ae lv" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank">博客</a>，GPT-2是一个大型的基于transformer的语言模型，拥有15亿个参数，在800万个网页的数据集上进行训练。</p><p id="ce2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着播客的风靡，如果我们可以用GPT 2和文本到语音生成逼真的对话会怎么样？</p><p id="0ea4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我根据埃隆·马斯克关于乔·罗根的经验对GPT-2进行微调后得出的一个例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="701c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个教程的所有文件都可以在<a class="ae lv" href="https://github.com/thesanjeetc/PodcastGenerator" rel="noopener ugc nofollow" target="_blank">这里</a>找到，减去微调的模型。</p><h1 id="51c7" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">准备笔录</h1><p id="1b5c" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">截至发稿时，埃隆·马斯克已经完成了三集《乔·罗根的经历》——也就是八个多小时的对话！</p><p id="2fba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">微调的一个重要部分是通过遵循特定格式和清除随机伪像来标准化输入文本。对于播客抄本来说，这意味着要清楚地区分主持人和嘉宾的对话，并删除时间戳。</p><p id="15c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于文字记录来自不同的网站，因此有许多不一致之处。这是一个文件中的<a class="ae lv" href="https://raw.githubusercontent.com/thesanjeetc/PodcastGenerator/main/transcriptsOriginal.txt" rel="noopener ugc nofollow" target="_blank">原始抄本</a>。</p><p id="9457" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过一点点<a class="ae lv" href="https://regexr.com/" rel="noopener ugc nofollow" target="_blank">正则表达式</a>的魔力，我们可以很容易地清理它，得到<a class="ae lv" href="https://raw.githubusercontent.com/thesanjeetc/PodcastGenerator/main/transcriptsFormatted.txt" rel="noopener ugc nofollow" target="_blank">想要的输出</a>。代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><h1 id="ca6a" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">与GPT-2展开对话</h1><p id="7328" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">现在是时候开始全新的从未说过的对话了。</p><p id="a81f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用<code class="fe mw mx my mz b"><a class="ae lv" href="https://github.com/minimaxir/gpt-2-simple" rel="noopener ugc nofollow" target="_blank">gpt-2-simple</a></code>库与GPT 2号一起工作。我为这个教程创建了一个简化的Colab <a class="ae lv" href="https://colab.research.google.com/drive/1jaJB6Zbo2Ulb22CQzShpcJJWjF4VXDTk#scrollTo=I0knKJEmS4dg" rel="noopener ugc nofollow" target="_blank">笔记本</a>——关于更深入的讨论，请参见Max Woolf的精彩博文<a class="ae lv" href="https://minimaxir.com/2019/09/howto-gpt2/" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="234d" class="na lz it bd ma nb nc dn me nd ne dp mi li nf ng mk lm nh ni mm lq nj nk mo nl bi translated">设置</h2><p id="14a8" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">安装所需的库并运行导入。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><h2 id="6f33" class="na lz it bd ma nb nc dn me nd ne dp mi li nf ng mk lm nh ni mm lq nj nk mo nl bi translated">火车</h2><ol class=""><li id="12bd" class="nm nn it lb b lc mq lf mr li no lm np lq nq lu nr ns nt nu bi translated">为了保存和加载模型，最好安装您的驱动器。将格式化的抄本文件拖到您的主驱动器文件夹中。</li><li id="d8e8" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">确保您在<code class="fe mw mx my mz b">Runtime &gt; Change runtime type</code>之前拥有GPU运行时。</li><li id="0dbb" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">似乎“中型”1.5GB模型最适合我们生成对话对话的用例。由于内存限制，较大的模型不能在Colab空闲层上进行微调。代码如下:</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><p id="c402" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是时候微调GPT-2了——这需要一些时间，所以赶紧喝杯咖啡☕️.吧完成后，模型将保存到您的驱动器中以备将来使用。以下是该任务的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><h2 id="2d46" class="na lz it bd ma nb nc dn me nd ne dp mi li nf ng mk lm nh ni mm lq nj nk mo nl bi translated">产生</h2><ol class=""><li id="51a2" class="nm nn it lb b lc mq lf mr li no lm np lq nq lu nr ns nt nu bi translated">出于演示目的，重新启动运行时，重新运行导入并从Drive加载回您的模型。</li><li id="9fb8" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">现在是时候开始对话了。请随意试验参数。请注意——它有时会变得相当疯狂！</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><p id="6df0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现，在挑选对话进行监管时，用批量生成的文本保存文件要容易得多。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><h1 id="d3fc" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">使用Google WaveNet添加语音</h1><p id="6137" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">在撰写本文时，谷歌WaveNet似乎仍然以API的形式提供了最逼真的声音。你可以尝试不同的声音参数<a class="ae lv" href="https://cloud.google.com/text-to-speech/#section-2" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><ol class=""><li id="039a" class="nm nn it lb b lc ld lf lg li oa lm ob lq oc lu nr ns nt nu bi translated"><code class="fe mw mx my mz b">pip install --upgrade google-cloud-texttospeech</code></li><li id="bd32" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">按照这些步骤设置凭证<a class="ae lv" href="https://cloud.google.com/text-to-speech/docs/libraries#setting_up_authentication" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="be36" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">用所需参数更新<code class="fe mw mx my mz b">config.json</code>并运行<code class="fe mw mx my mz b">speak.py</code>。</li></ol><p id="9ddb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仅此而已。现在你有能力听埃隆·马斯克无休止地谈论他的想法了！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv lx l"/></div></figure><h1 id="ba27" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">结束语</h1><p id="c47e" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">这是一个非常有趣的兼职项目。我创造了许多有趣的对话，甚至发表了一些播客:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od lx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae lv" href="https://rickandmorty.fandom.com/wiki/Elon_Tusk" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">埃隆·图斯克</strong></a>——图斯克拉公司首席执行官</p></figure><p id="ceb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种设置有很大的实验空间，从不同的客人微调到不同的声音，甚至多个角色在一个小组中交谈。</p><p id="e600" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，OpenAI发布了包含1750亿个参数的<a class="ae lv" href="https://openai.com/blog/openai-api/" rel="noopener ugc nofollow" target="_blank">GPT-3</a>——比GPT-2大17倍！然而，在撰写本文时，它只能通过私有的beta API访问，生成长格式文本可能会变得非常昂贵。所以目前来看，GPT-2似乎最适合这个用例。</p><p id="6ea1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">倾听GPT 2号和它自己之间的对话会令人毛骨悚然地把你吸引进去。栩栩如生的声音让幻觉栩栩如生——内容生成的未来是什么？</p><p id="82d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读。</p></div></div>    
</body>
</html>